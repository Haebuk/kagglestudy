{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "statewide-plaza",
   "metadata": {},
   "source": [
    "# Kaggle Study Day 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-spider",
   "metadata": {},
   "source": [
    "# Fruits-360 - Transfer Learning using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-mumbai",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/amadeus1996/fruits-360-transfer-learning-using-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-spyware",
   "metadata": {},
   "source": [
    "-- 내 정리 - 시온 -- <br>\n",
    "Transfer Learning : 전이학습\n",
    "- 이미지 분류에 사용\n",
    "- 비교적 짧은 시간에 높은 정확도 달성\n",
    "- 주로 사전학습된 모델(pre-trained) 이용 : 사전학습모델이란, 풀고자 하는 문제와 비슷하며 대용량 데이터로 이미 학습되어있는 모델. 이것을 import 해서 사용 (예: VGG, MobileNet, Inception)\n",
    "- 데이터가 부족한(데이터셋이 작은) 분야에 적용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-eclipse",
   "metadata": {},
   "source": [
    "- Fruits-360 데이터셋에 전이학습을 간단히 적용한 커널이다.\n",
    "- 데이터셋은 64개 과일 이미지 42345개로 구성된다.\n",
    "- 전이학습 접근방식을 일반 접근방식과 비교한다.\n",
    "- 98.44%의 정확도는 2 epochs 내에서 얻어진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-municipality",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T13:35:27.006504Z",
     "start_time": "2021-02-15T13:35:26.988554Z"
    }
   },
   "source": [
    "1. 전이학습에 대한 간략한 설명\n",
    "2. Kaggle Kernel을 사용한 전이학습\n",
    "3. 데이터 읽 및 시각화\n",
    "4. 모델 구축 및 컴파일\n",
    "5. 사전학습(pre-trained) 모델 학습 및 검증\n",
    "6. Vanilla 모델 학습 및 검증\n",
    "7. 사전학습모델과 Vanilla 모델 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "structured-politics",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T13:42:18.911484Z",
     "start_time": "2021-02-15T13:41:38.476525Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir, makedirs\n",
    "from os.path import join, exists, expanduser\n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as k\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-motorcycle",
   "metadata": {},
   "source": [
    "# 1. 전이학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-communications",
   "metadata": {},
   "source": [
    "전이학습에서 먼저 기본 데이터셋으로 기본 네트워크를 학습시키고 나서, target 데이터셋과 작업에 대해 학습되도록 학습된 변수를 변경하거나, 두번째 target 네트워크에 학습된 변수를 전달(전이)한다. 이 과정은 기본 작업에 특정되는 대신, 기본 작업과 target 작업 모두에 적합하게 일반적일 경우 작동하는 경향이 있다.\n",
    "\n",
    "Lisa Torrey와 Jude Shavlik은 전이학습을 사용할 경우의 세가지 이점을 설명한다.\n",
    "- Higher start : 원래 모델에서 초기 기술(모델을 다듬기 전)이 그렇지 않은 경우보다 높다.\n",
    "- Higher slope : 원래 모델의 학습 도중 스킬 향상 속도는 그렇지 않은 경우보다 더 가파르다.\n",
    "- Higher asymptote : 학습된 모델의 융합된 기술은 그렇지 않은 경우보다 더 우수하다.\n",
    "\n",
    "기본적으로, 사전학습된 모델(다른 누군가에 의해 대규모 데이터셋을 학습한 네트워크의 가중치와 파라미터)을 취하고 자체 데이터셋으로 모델을 \"fine-tune\"한다. 이는 사전학습된 모델이 초기 가중치를 제공해 더 빠른 수렴을 유도하거나, 관심 작업의 고정 변수 추출기로 작용할 것이라는 아이디어다.\n",
    "\n",
    "이러한 두 가지 주요 전이학습 시나리오는 다음과 같다.\n",
    "- Finetunning the convnet : 랜덤초기화 대신, imagenet 1000처럼 대규모 데이터셋을 학습한 것과 같이, 사전학습된 네트워크로 네트워크를 초기화한다. 나머지 train 데이터는 평소와 같다. 이 시나리오에서 전체 네트워크는 관심 데이터셋에 대해 재학습해야한다.\n",
    "- ConvNet as fixed feature extractor : 여기서, 최종적으로 완전연결된 레이어(Dense)의 가중치를 제외한 네트워크의 모든 가중치를 고정시킨다. 마지막으로 완전연결된 레이어는 랜덤 가중치를 가진 새로운 레이어와 대체되고 이 레이어만 학습된다.\n",
    "\n",
    "이 커널에선 첫 시나리오를 실행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-measurement",
   "metadata": {},
   "source": [
    "# 2. Transfer Learning using Kaggle Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-torture",
   "metadata": {},
   "source": [
    "#### Using the Keras Pretrained Models dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-rocket",
   "metadata": {},
   "source": [
    "캐글 커널은 사전학습된 keras 모델을 다운로드하기 위해 네트워크 연결을 사용할 수 없다. 이 데이터셋은 캐글 커널 환경에서 우리가 선호하는 사전학습된 모델을 사용할 수 있도록 도와준다.\n",
    "\n",
    "해야할 일은 kears가 찾고있는 캐시 디렉토리(~/.keras/models)에 사전학습된 모델을 복사하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "executive-share",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T14:18:58.581631Z",
     "start_time": "2021-02-15T14:18:58.565674Z"
    }
   },
   "outputs": [],
   "source": [
    "cache_dir = expanduser(join('~', 'keras'))\n",
    "if not exists(cache_dir):\n",
    "    makedirs(cache_dir)\n",
    "models_dir = join(cache_dir, 'models')\n",
    "if not exists(models_dir):\n",
    "    makedirs(models_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-teens",
   "metadata": {},
   "source": [
    "# 3. Reading and Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-fruit",
   "metadata": {},
   "source": [
    "## Reading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-senate",
   "metadata": {},
   "source": [
    "남은 Keras처럼, 이미지 증강 API는 간단하고 강력하다. ImageDataGenrator를 사용해 데이터를 가져오고 네트워크에 제공할 것이다.\n",
    "\n",
    "Keras는 이미지 데이터 준비와 증강을 위한 구성을 정의하는 ImageDataGenerator 클래스를 제공한다. 메모리에서 전체 이미지 데이터셋에 대한 작업을 수행하는 것보다, 딥러닝 모델 fit 과정을 통해 반복되도록 API를 설계하여 제때에 증강 이미지 데이터를 생성한다. 이렇게 하면 메모리 오버헤드가 줄어들지만, 모델 학습 시간이 약간 늘어난다.\n",
    "\n",
    "데이터 생성기 자체는 사실 반복자(iterator)라서 요청시 디렉토리에서 이미지 샘플의 batch를 반환한다. flow_from_directory() 함수를 호출해 batch size를 구성하고 데이터 생성기를 준비하고 이미지의 batch를 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "differential-clinton",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T14:29:17.073327Z",
     "start_time": "2021-02-15T14:29:17.063354Z"
    }
   },
   "outputs": [],
   "source": [
    "# 이미지의 차원\n",
    "img_width, img_height = 224, 224  \n",
    "# 사용할 사전학습된 모델에 따라 img_width, img_height 설정\n",
    "# ResNet-50의 input size는 224 * 224 * 3이다.\n",
    "\n",
    "train_data_dir = '../input/fruits/fruits-360_dataset_2018_06_03/fruits-360/Training'\n",
    "validation_data_dir = '../input/fruits/fruits-360_dataset_2018_06_03/fruits-360/Validation/'\n",
    "nb_train_samples = 31688\n",
    "nb_validation_samples = 10657\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-appendix",
   "metadata": {},
   "source": [
    "## Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "resistant-intersection",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T14:35:13.282572Z",
     "start_time": "2021-02-15T14:35:10.366362Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.DataFrame(train_generator.classes, columns=['classes'])\n",
    "testing_data = pd.DataFrame(validation_generator.classes, columns=['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "blank-debate",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T14:37:44.459639Z",
     "start_time": "2021-02-15T14:37:44.441688Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_stack_bar_data(col, df):\n",
    "    aggregated = df[col].value_counst().sort_index()\n",
    "    x_values = aggregated.index.tolist()\n",
    "    y_values = aggregated.values.tolist()\n",
    "    return x_values, y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = create_stack_bar_data('classes', training_data)\n",
    "x1 = list(train_generator.class_indices.keys())\n",
    "\n",
    "trace1 = go.Bar(x=x1, y=y1, opacity=0.75, name='Class Count')\n",
    "layout = dict(height=400, width=1200, title='Class Distribution in Training Data',\n",
    "             legend=dict(orientation='h'), yaxis=dict(title='Class Count'))\n",
    "fig = go.Figure(data=[trace1], layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = create_stack_bar_data('classes', testing_data)\n",
    "x1 = list(validation_generator.class_indices.keys())\n",
    "\n",
    "trace1 = go.Bar(x=x1, y=y1, opacity=0.75, name='Class Count')\n",
    "layout = dict(height=400, width=1100, title='Class Distribution in Validation Data',\n",
    "             legend=dict(orientation='h'), yaxis=dict(title='Class Count'))\n",
    "fig = go.Figure(data=[trace1], layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-layout",
   "metadata": {},
   "source": [
    "볼 수 있듯이 모든 클래스는 validation 뿐만 아니라 training에서도 균형이 잘 잡혀있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-vegetation",
   "metadata": {},
   "source": [
    "## Building the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-clinic",
   "metadata": {},
   "source": [
    "여기서는 ImageNet의 가중치로 ResNet-50을 로딩한다. 클래스의 수에 따라 자체 레이어를 추가할 수 있도록 탑을 제거한다. 그런 다음 모델 아키텍쳐를 완성하기 위해 자체 레이어를 추가한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-graduation",
   "metadata": {},
   "source": [
    "### Building Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전학습된 가중치로 inception을 import. 완전연결된 레이어는 포함하지 않는다.\n",
    "inception_base = applications.ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "# global spatial average pooling 레이어 추가\n",
    "x = inception_base.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# 완전연결된 레이어 추가\n",
    "x = Dense(512, activation='relu')(x)\n",
    "# 완전연결된 output과 분류 레이어 \n",
    "predictions = Dense(65, activation='softmax')(x)\n",
    "# 전체 네트워크를 생성해 학습시킬 수 있다\n",
    "inception_transfer = Model(inputs=inception_base.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-brush",
   "metadata": {},
   "source": [
    "### Building the Vanilla Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-lucas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전학습된 가중치로 inception을 import. 완전연결된 레이어는 포함하지 않는다.\n",
    "inception_base_vanilla = applications.ResNet50(weights=None, include_top=False)\n",
    "\n",
    "# global spatial average pooling 레이어 추가\n",
    "x = inception_base_vanilla.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# 완전연결된 레이어 추가\n",
    "x = Dense(512, activation='relu')(x)\n",
    "# 완전연결된 output과 분류 레이어 \n",
    "predictions = Dense(54, activation='softmax')(x)\n",
    "# 전체 네트워크를 생성해 학습시킬 수 있다.\n",
    "inception_transfer_vanilla = Model(inputs=inception_base_vanilla.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-empty",
   "metadata": {},
   "source": [
    "## Compiling the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-coordination",
   "metadata": {},
   "source": [
    "손실함수(loss)와 사용할 최적화 알고리즘, 각 epoch 마지막에 계산될 metrics를 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_transfer.compile(loss='categorical_crossentropy', \n",
    "                          optimizer=opimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "                           metrics=['accuracy'])\n",
    "inception_transfer_vanilla.compile(loss='categorical_crossentropy',\n",
    "                                  optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "                                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aging-lodging",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T15:04:41.723051Z",
     "start_time": "2021-02-15T15:04:41.636282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15071504910450225592\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-leadership",
   "metadata": {},
   "source": [
    "# 5. Training and Validating the Pretrained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-karaoke",
   "metadata": {},
   "source": [
    "데이터를 불러오기 위해 ImageDataGenerator의 객체를 사용할 것이기 때문에 fit_generator() 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "with tf.device('/device:GPU:0'):\n",
    "    history_pretrained = inception_transfer.fit_generator(\n",
    "        train_generator, epochs=5, shuffle=True, verbose=1, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    history_vanilla = inception_transfer_vanilla.fit_generator(\n",
    "        train_generator, epochs=5, shuffle=True, verbose=1, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-cross",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# accuracy history 요약\n",
    "plt.plot(histroy_pretrained.history['val_acc'])\n",
    "plt.plot(history_vanilla.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Pretrained', 'Vanilla'], loc='upper left')\n",
    "plt.show()\n",
    "# loss history 요약\n",
    "plt.plot(history_pretrained.history['val_loss'])\n",
    "plt.plot(history_vanilla.history['val_acc'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Pretrained', 'Vanilla'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "564px",
    "left": "53px",
    "top": "122.8px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
