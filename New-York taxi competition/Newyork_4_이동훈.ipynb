{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kaggle study 30일차(New-York taxi)\n",
    "코드출처 : https://www.kaggle.com/danijelk/beat-the-benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T00:43:42.616990Z",
     "start_time": "2021-02-26T00:43:35.174295Z"
    }
   },
   "outputs": [],
   "source": [
    "## 라이브러리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T00:45:18.891229Z",
     "start_time": "2021-02-26T00:45:10.401452Z"
    }
   },
   "outputs": [],
   "source": [
    "## 데이터 읽기\n",
    "train = pd.read_csv('C:/Users/이동훈/Desktop/github/kaggle/kagglestudy/Data/Newyork/train.csv')\n",
    "test = pd.read_csv('C:/Users/이동훈/Desktop/github/kaggle/kagglestudy/Data/Newyork/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T00:46:28.496570Z",
     "start_time": "2021-02-26T00:46:25.770688Z"
    }
   },
   "outputs": [],
   "source": [
    "## 날짜형으로 변경\n",
    "train['pickup_datetime'] = pd.to_datetime(train['pickup_datetime'])\n",
    "test['pickup_datetime'] = pd.to_datetime(test['pickup_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T00:49:33.233530Z",
     "start_time": "2021-02-26T00:49:32.447783Z"
    }
   },
   "outputs": [],
   "source": [
    "## 문자열을 숫자로 변경\n",
    "le = LabelEncoder()\n",
    "le.fit(train['store_and_fwd_flag'])\n",
    "train['store_and_fwd_flag'] = le.transform(train['store_and_fwd_flag'])\n",
    "test['store_and_fwd_flag'] = le.transform(test['store_and_fwd_flag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T00:57:49.217409Z",
     "start_time": "2021-02-26T00:57:46.922024Z"
    }
   },
   "outputs": [],
   "source": [
    "train['month'] = train['pickup_datetime'].dt.month\n",
    "train['day'] = train['pickup_datetime'].dt.day\n",
    "train['weekday'] = train['pickup_datetime'].dt.weekday\n",
    "train['hour'] = train['pickup_datetime'].dt.hour\n",
    "train['minute'] = train['pickup_datetime'].dt.minute\n",
    "\n",
    "test['month'] = test['pickup_datetime'].dt.month\n",
    "test['day'] = test['pickup_datetime'].dt.day\n",
    "test['weekday'] = test['pickup_datetime'].dt.weekday\n",
    "test['hour'] = test['pickup_datetime'].dt.hour\n",
    "test['minute'] = test['pickup_datetime'].dt.minute\n",
    "\n",
    "train['dist_long'] = train['pickup_longitude'] - train['dropoff_longitude']\n",
    "test['dist_long'] = test['pickup_longitude'] - test['dropoff_longitude']\n",
    "\n",
    "train['dist_lat'] = train['pickup_latitude'] - train['dropoff_latitude']\n",
    "test['dist_lat'] = test['pickup_latitude'] - test['dropoff_latitude']\n",
    "\n",
    "train['dist'] = np.sqrt(np.square(train['dist_long']) + np.square(train['dist_lat']))\n",
    "test['dist'] = np.sqrt(np.square(test['dist_long']) + np.square(test['dist_lat']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### spatial features: count and speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T00:59:50.595888Z",
     "start_time": "2021-02-26T00:59:49.709966Z"
    }
   },
   "outputs": [],
   "source": [
    "train['pickup_longitude_bin'] = np.round(train['pickup_longitude'], 2)\n",
    "train['pickup_latitude_bin'] = np.round(train['pickup_latitude'], 2)\n",
    "train['dropoff_longitude_bin'] = np.round(train['dropoff_longitude'], 2)\n",
    "train['dropoff_latitude_bin'] = np.round(train['dropoff_latitude'], 2)\n",
    "\n",
    "test['pickup_longitude_bin'] = np.round(test['pickup_longitude'], 2)\n",
    "test['pickup_latitude_bin'] = np.round(test['pickup_latitude'], 2)\n",
    "test['dropoff_longitude_bin'] = np.round(test['dropoff_longitude'], 2)\n",
    "test['dropoff_latitude_bin'] = np.round(test['dropoff_latitude'], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### count features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T01:08:56.712591Z",
     "start_time": "2021-02-26T01:08:30.567365Z"
    }
   },
   "outputs": [],
   "source": [
    "a = pd.concat([train,test]).groupby(['pickup_longitude_bin', 'pickup_latitude_bin']).size().reset_index()\n",
    "b = pd.concat([train,test]).groupby(['dropoff_longitude_bin', 'dropoff_latitude_bin']).size().reset_index()\n",
    "\n",
    "train = pd.merge(train, a, on = ['pickup_longitude_bin', 'pickup_latitude_bin'], how = 'left')\n",
    "test = pd.merge(test, a, on = ['pickup_longitude_bin', 'pickup_latitude_bin'], how = 'left')\n",
    "\n",
    "train = pd.merge(train, b, on = ['dropoff_longitude_bin', 'dropoff_latitude_bin'], how = 'left')\n",
    "test = pd.merge(test, b, on = ['dropoff_longitude_bin', 'dropoff_latitude_bin'], how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### speed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T01:13:12.792301Z",
     "start_time": "2021-02-26T01:12:59.971571Z"
    }
   },
   "outputs": [],
   "source": [
    "train['speed'] = 100000*train['dist'] / train['trip_duration']\n",
    "\n",
    "a = train[['speed', 'pickup_longitude_bin', 'pickup_latitude_bin']].groupby(['pickup_longitude_bin', 'pickup_latitude_bin']).mean().reset_index()\n",
    "a = a.rename(columns = {'speed': 'ave_speed'})\n",
    "b = train[['speed', 'dropoff_longitude_bin', 'dropoff_latitude_bin']].groupby(['dropoff_longitude_bin', 'dropoff_latitude_bin']).mean().reset_index()\n",
    "b = b.rename(columns = {'speed': 'ave_speed'})\n",
    "\n",
    "train = pd.merge(train, a, on = ['pickup_longitude_bin', 'pickup_latitude_bin'], how = 'left')\n",
    "test = pd.merge(test, a, on = ['pickup_longitude_bin', 'pickup_latitude_bin'], how = 'left')\n",
    "\n",
    "train = pd.merge(train, b, on = ['dropoff_longitude_bin', 'dropoff_latitude_bin'], how = 'left')\n",
    "test = pd.merge(test, b, on = ['dropoff_longitude_bin', 'dropoff_latitude_bin'], how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### drop bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T01:14:56.661329Z",
     "start_time": "2021-02-26T01:14:55.039469Z"
    }
   },
   "outputs": [],
   "source": [
    "train = train.drop(['speed', 'pickup_longitude_bin', 'pickup_latitude_bin', 'dropoff_longitude_bin', 'dropoff_latitude_bin'], axis = 1)\n",
    "test = test.drop(['pickup_longitude_bin', 'pickup_latitude_bin', 'dropoff_longitude_bin', 'dropoff_latitude_bin'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T01:17:53.800685Z",
     "start_time": "2021-02-26T01:17:50.588050Z"
    }
   },
   "outputs": [],
   "source": [
    "weather = pd.read_csv('C:/Users/이동훈/Desktop/github/kaggle/kagglestudy/Data/Newyork/KNYC_Metars.csv')\n",
    "weather['Time'] = pd.to_datetime(weather['Time'])\n",
    "weather['year'] = weather['Time'].dt.year\n",
    "weather['month'] = weather['Time'].dt.month\n",
    "weather['day'] = weather['Time'].dt.day\n",
    "weather['hour'] = weather['Time'].dt.hour\n",
    "weather = weather[weather['year'] == 2016]\n",
    "\n",
    "train = pd.merge(train, weather[['Temp.', 'month', 'day', 'hour']], on = ['month', 'day', 'hour'], how = 'left')\n",
    "test = pd.merge(test, weather[['Temp.', 'month', 'day', 'hour']], on = ['month', 'day', 'hour'], how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T01:25:39.920464Z",
     "start_time": "2021-02-26T01:19:12.331667Z"
    }
   },
   "outputs": [],
   "source": [
    "xtrain = train.drop(['id', 'pickup_datetime', 'dropoff_datetime', 'trip_duration'], axis = 1).values\n",
    "xtest = test.drop(['id', 'pickup_datetime', ], axis = 1).values\n",
    "ytrain = train['trip_duration'].values\n",
    "id_train = train['id'].values\n",
    "id_test = test['id'].values\n",
    "del(train, test)\n",
    "\n",
    "## xgb parameters\n",
    "params = {\n",
    "    'booster':            'gbtree',\n",
    "    'objective':          'reg:linear',\n",
    "    'learning_rate':      0.1,\n",
    "    'max_depth':          14,\n",
    "    'subsample':          0.8,\n",
    "    'colsample_bytree':   0.7,\n",
    "    'colsample_bylevel':  0.7,\n",
    "    'silent':             1\n",
    "}\n",
    "\n",
    "## number of rounds\n",
    "nrounds = 200\n",
    "\n",
    "dtrain = xgb.DMatrix(xtrain, np.log(ytrain+1))\n",
    "gbm = xgb.train(params,\n",
    "                dtrain,\n",
    "                num_boost_round = nrounds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T01:25:48.828995Z",
     "start_time": "2021-02-26T01:25:39.951372Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_test = np.exp(gbm.predict(xgb.DMatrix(xtest))) - 1\n",
    "\n",
    "df = pd.DataFrame({'id': id_test, 'trip_duration': pred_test}) \n",
    "df = df.set_index('id')\n",
    "df.to_csv('sub_bench.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
