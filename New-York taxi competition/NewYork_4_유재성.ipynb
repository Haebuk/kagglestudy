{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beat the benchmark\n",
    "https://www.kaggle.com/danijelk/beat-the-benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T01:17:46.837656Z",
     "start_time": "2021-02-26T00:56:37.296808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read Data...\n",
      "Create features...\n",
      "Train model...\n",
      "[09:57:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[09:57:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print('Read Data...')\n",
    "## read data\n",
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/test.csv')\n",
    "\n",
    "# dates\n",
    "train['pickup_datetime'] = pd.to_datetime(train['pickup_datetime'])\n",
    "test['pickup_datetime'] = pd.to_datetime(test['pickup_datetime'])\n",
    "\n",
    "# transform character to numeric\n",
    "le = LabelEncoder()\n",
    "le.fit(train['store_and_fwd_flag'])\n",
    "train['store_and_fwd_flag'] = le.transform(train['store_and_fwd_flag'])\n",
    "test['store_and_fwd_flag'] = le.transform(test['store_and_fwd_flag'])\n",
    "\n",
    "#### New Features ####\n",
    "print('Create features...')\n",
    "# date features\n",
    "train['month'] = train['pickup_datetime'].dt.month\n",
    "train['day'] = train['pickup_datetime'].dt.day\n",
    "train['weekday'] = train['pickup_datetime'].dt.weekday\n",
    "train['hour'] = train['pickup_datetime'].dt.hour\n",
    "train['minute'] = train['pickup_datetime'].dt.minute\n",
    "\n",
    "test['month'] = test['pickup_datetime'].dt.month\n",
    "test['day'] = test['pickup_datetime'].dt.day\n",
    "test['weekday'] = test['pickup_datetime'].dt.weekday\n",
    "test['hour'] = test['pickup_datetime'].dt.hour\n",
    "test['minute'] = test['pickup_datetime'].dt.minute\n",
    "\n",
    "# distance features\n",
    "train['dist_long'] = train['pickup_longitude'] - train['dropoff_longitude']\n",
    "test['dist_long'] = test['pickup_longitude'] - test['dropoff_longitude']\n",
    "\n",
    "train['dist_lat'] = train['pickup_latitude'] - train['dropoff_latitude']\n",
    "test['dist_lat'] = test['pickup_latitude'] - test['dropoff_latitude']\n",
    "\n",
    "train['dist'] = np.sqrt(np.square(train['dist_long']) + np.square(train['dist_lat']))\n",
    "test['dist'] = np.sqrt(np.square(test['dist_long']) + np.square(test['dist_lat']))\n",
    "\n",
    "# spatial features: count and speed\n",
    "train['pickup_longitude_bin'] = np.round(train['pickup_longitude'], 2)\n",
    "train['pickup_latitude_bin'] = np.round(train['pickup_latitude'], 2)\n",
    "train['dropoff_longitude_bin'] = np.round(train['dropoff_longitude'], 2)\n",
    "train['dropoff_latitude_bin'] = np.round(train['dropoff_latitude'], 2)\n",
    "\n",
    "test['pickup_longitude_bin'] = np.round(test['pickup_longitude'], 2)\n",
    "test['pickup_latitude_bin'] = np.round(test['pickup_latitude'], 2)\n",
    "test['dropoff_longitude_bin'] = np.round(test['dropoff_longitude'], 2)\n",
    "test['dropoff_latitude_bin'] = np.round(test['dropoff_latitude'], 2)\n",
    "\n",
    "# count features\n",
    "a = pd.concat([train, test]).groupby(['pickup_longitude_bin', 'pickup_latitude_bin']).size().reset_index()\n",
    "b = pd.concat([train, test]).groupby(['dropoff_longitude_bin', 'dropoff_latitude_bin']).size().reset_index()\n",
    "\n",
    "train = pd.merge(train, a, on=['pickup_longitude_bin', 'pickup_latitude_bin'], how='left')\n",
    "test = pd.merge(test, a, on=['pickup_longitude_bin', 'pickup_latitude_bin'], how='left')\n",
    "\n",
    "train = pd.merge(train, b, on=['dropoff_longitude_bin', 'dropoff_latitude_bin'], how='left')\n",
    "test = pd.merge(test, b, on=['dropoff_longitude_bin', 'dropoff_latitude_bin'], how='left')\n",
    "\n",
    "# speed features\n",
    "train['speed'] = 100000 * train['dist'] / train['trip_duration']\n",
    "\n",
    "a = train[['speed', 'pickup_longitude_bin', 'pickup_latitude_bin']].groupby(['pickup_longitude_bin', 'pickup_latitude_bin']).mean().reset_index()\n",
    "a = a.rename(columns = {'speed': 'ave_speed'})\n",
    "b = train[['speed', 'dropoff_longitude_bin', 'dropoff_latitude_bin']].groupby(['dropoff_longitude_bin', 'dropoff_latitude_bin']).mean().reset_index()\n",
    "b = b.rename(columns = {'speed': 'ave_speed'})\n",
    "\n",
    "train = pd.merge(train, a, on=['pickup_longitude_bin', 'pickup_latitude_bin'], how='left')\n",
    "test = pd.merge(test, a, on=['pickup_longitude_bin', 'pickup_latitude_bin'], how='left')\n",
    "\n",
    "train = pd.merge(train, b, on=['dropoff_longitude_bin', 'dropoff_latitude_bin'], how='left')\n",
    "test = pd.merge(test, b, on=['dropoff_longitude_bin', 'dropoff_latitude_bin'], how='left')\n",
    "\n",
    "# drop bins\n",
    "train = train.drop(['speed', 'pickup_longitude_bin', 'pickup_latitude_bin', 'dropoff_longitude_bin', 'dropoff_latitude_bin'], axis=1)\n",
    "test = test.drop(['pickup_longitude_bin', 'pickup_latitude_bin', 'dropoff_longitude_bin', 'dropoff_latitude_bin'], axis=1)\n",
    "\n",
    "# weather data\n",
    "weather = pd.read_csv('input/KNYC_Metars.csv')\n",
    "weather['Time'] = pd.to_datetime(weather['Time'])\n",
    "weather['year'] = weather['Time'].dt.year\n",
    "weather['month'] = weather['Time'].dt.month\n",
    "weather['day'] = weather['Time'].dt.day\n",
    "weather['hour'] = weather['Time'].dt.hour\n",
    "weather = weather[weather['year']==2016]\n",
    "\n",
    "train = pd.merge(train, weather[['Temp.', 'month', 'day', 'hour']], on = ['month', 'day', 'hour'], how='left')\n",
    "test = pd.merge(test, weather[['Temp.', 'month', 'day', 'hour']], on = ['month', 'day', 'hour'], how='left')\n",
    "\n",
    "# train/test features. y, id\n",
    "xtrain = train.drop(['id' ,'pickup_datetime', 'dropoff_datetime', 'trip_duration'], axis=1).values\n",
    "xtest = test.drop(['id', 'pickup_datetime'], axis=1).values\n",
    "ytrain = train['trip_duration'].values\n",
    "id_train = train['id'].values\n",
    "id_test = test['id'].values\n",
    "del (train, test)\n",
    "\n",
    "# xgb parameters\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'reg:linear',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 14,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'colsample_bylevel': 0.7,\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "# number of rounds\n",
    "nrounds = 200\n",
    "\n",
    "# train model\n",
    "print('Train model...')\n",
    "dtrain = xgb.DMatrix(xtrain, np.log(ytrain+1))\n",
    "gbm = xgb.train(params, dtrain, num_boost_round = nrounds)\n",
    "\n",
    "# test predictions\n",
    "pred_test = np.exp(gbm.predict(xgb.DMatrix(xtest))) - 1\n",
    "\n",
    "# create submission\n",
    "df = pd.DataFrame({'id': id_test, 'trip_duration': pred_test})\n",
    "df = df.set_index('id')\n",
    "df.to_csv('sub_bench.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
