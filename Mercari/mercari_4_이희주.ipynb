{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- competition/dataset : [https://www.kaggle.com/c/mercari-price-suggestion-challenge](https://www.kaggle.com/c/mercari-price-suggestion-challenge)\n",
    "- date : 2021/03/22\n",
    "- original : [https://www.kaggle.com/rumbok/ridge-lb-0-41944](https://www.kaggle.com/rumbok/ridge-lb-0-41944)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGB and FM [18th Place - 0.40604]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-19T23:23:23.804833Z",
     "iopub.status.busy": "2021-01-19T23:23:23.803834Z",
     "iopub.status.idle": "2021-01-19T23:23:23.811814Z",
     "shell.execute_reply": "2021-01-19T23:23:23.810817Z",
     "shell.execute_reply.started": "2021-01-19T23:23:23.804833Z"
    }
   },
   "source": [
    "**✏ 필사 1회** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-22T02:54:57.605724Z",
     "iopub.status.busy": "2021-03-22T02:54:57.604727Z",
     "iopub.status.idle": "2021-03-22T02:55:06.820378Z",
     "shell.execute_reply": "2021-03-22T02:55:06.819409Z",
     "shell.execute_reply.started": "2021-03-22T02:54:57.605724Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "SUBMIT_MODE = True\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import string\n",
    "import string\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import wordbatch\n",
    "from wordbatch.pipelines import WordBatch\n",
    "from wordbatch.extractors import WordBag\n",
    "from wordbatch.models import FM_FTRL\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-22T02:55:06.821376Z",
     "iopub.status.busy": "2021-03-22T02:55:06.821376Z",
     "iopub.status.idle": "2021-03-22T02:55:06.834340Z",
     "shell.execute_reply": "2021-03-22T02:55:06.834340Z",
     "shell.execute_reply.started": "2021-03-22T02:55:06.821376Z"
    }
   },
   "outputs": [],
   "source": [
    "def rmse(predictied, actual):\n",
    "    return np.sqrt(((predictied - actual)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-22T02:55:06.837334Z",
     "iopub.status.busy": "2021-03-22T02:55:06.836336Z",
     "iopub.status.idle": "2021-03-22T02:55:06.850307Z",
     "shell.execute_reply": "2021-03-22T02:55:06.849300Z",
     "shell.execute_reply.started": "2021-03-22T02:55:06.837334Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_cat(text):\n",
    "    try:\n",
    "        return text.split('/')\n",
    "    except:\n",
    "        return ('No Label', 'No Label', 'No Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-22T02:55:06.852292Z",
     "iopub.status.busy": "2021-03-22T02:55:06.851295Z",
     "iopub.status.idle": "2021-03-22T02:55:06.865258Z",
     "shell.execute_reply": "2021-03-22T02:55:06.864265Z",
     "shell.execute_reply.started": "2021-03-22T02:55:06.852292Z"
    }
   },
   "outputs": [],
   "source": [
    "class TargetEncoder:\n",
    "    def __repr__(self):\n",
    "        return 'TargetEncoder'\n",
    "    \n",
    "    def __init__(self, cols, smoothing=1, min_samples_leaf=1, noise_level=0, keep_original=False):\n",
    "        self.cols = cols\n",
    "        self.smoothing = smoothing\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.noise_level = noise_level\n",
    "        self.keep_original = keep_original\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_noise(series, noise_level):\n",
    "        return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "    \n",
    "    def encode(self, train, test, target):\n",
    "        for col in self.cols:\n",
    "            if self.keep_original:\n",
    "                train[col + '_te'], test[col + '_te'] = self.encode_column(train[col], test[col], target)\n",
    "            else:\n",
    "                train[col], test[col] = self.encode_column(train[col], test[col], target)\n",
    "        return train, test\n",
    "    \n",
    "    def encode_column(self, trn_series, tst_series, target):\n",
    "        temp = pd.concat([trn_series, target], axis=1)\n",
    "        # target의 평균\n",
    "        averages = temp.groupby(trn_series['name'])[target['name']].agg(['mean', 'count'])\n",
    "        # 평활화\n",
    "        smooting = 1 / (1 + np.exp(-(averages['count'] - self.min_samples_leaf)/self.smoothing))\n",
    "        # 모든 target 데이터에 평균 적용\n",
    "        prior = target.mean()\n",
    "        # count가 클수록 낮은 full_avg 고려\n",
    "        averages[target['name']] = prior * (1 - smoothing) + averages['mean'] * smoothing\n",
    "        averages.drop(['mean', 'count'], axis=1, inplace=True)\n",
    "        # trn, tst 시리즈에 평균 적용\n",
    "        ft_trn_series = pd.merge(\n",
    "            trn_series.to_frame(trn_series['name']),\n",
    "            averages.reset_index().rename(columns={'index':target['name'],\n",
    "                                                   target['name']: 'average'}),\n",
    "            on=trn_series['name'],\n",
    "            how='left')['average'].rename(trn_series['name'] + '_mean').fillna(prior)\n",
    "        # pd.merge는 인덱스가 유지되지 않으므로 인덱스 저장\n",
    "        ft_trn_series.index = trn_series.index\n",
    "        ft_tst_series = pd.merge(\n",
    "            tst_series.to_frame(tst_series['name']),\n",
    "            averages.reset_index().rename(columns={'index':target['name'],\n",
    "                                                   target['name']:'average'}),\n",
    "            on=tst_series['name'],\n",
    "            how='left')['average'].rename(trn_series['name'] + '_mean').fillna(prior)\n",
    "        ft_tst_series.index = tst_series.index\n",
    "        return self.add_noise(ft_trn_series, self.noise_level), self.add_noise(ft_tst_series, self.noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-22T02:55:06.866256Z",
     "iopub.status.busy": "2021-03-22T02:55:06.866256Z",
     "iopub.status.idle": "2021-03-22T02:55:06.881217Z",
     "shell.execute_reply": "2021-03-22T02:55:06.880218Z",
     "shell.execute_reply.started": "2021-03-22T02:55:06.866256Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_number(x):\n",
    "    try:\n",
    "        if not x.isdigit():\n",
    "            return 0\n",
    "        x = int(x)\n",
    "        if x > 100:\n",
    "            return 100\n",
    "        else:\n",
    "            return x\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-22T02:55:06.883211Z",
     "iopub.status.busy": "2021-03-22T02:55:06.882214Z",
     "iopub.status.idle": "2021-03-22T02:55:06.895178Z",
     "shell.execute_reply": "2021-03-22T02:55:06.895178Z",
     "shell.execute_reply.started": "2021-03-22T02:55:06.883211Z"
    }
   },
   "outputs": [],
   "source": [
    "def sum_numbers(desc):\n",
    "    if not isinstance(desc, str):\n",
    "        return 0\n",
    "    try:\n",
    "        return sum([to_number(s) for s in desc.split()])\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-22T02:55:06.897173Z",
     "iopub.status.busy": "2021-03-22T02:55:06.897173Z",
     "iopub.status.idle": "2021-03-22T02:55:06.911136Z",
     "shell.execute_reply": "2021-03-22T02:55:06.910139Z",
     "shell.execute_reply.started": "2021-03-22T02:55:06.897173Z"
    }
   },
   "outputs": [],
   "source": [
    "stopwords = {x: 1 for x in stopwords.words('english')}\n",
    "non_alphanums = re.compile(u'[^A-z0-9]+')\n",
    "non_alphanumpunct = re.compile(u'[^A-z0-9\\.?!,; \\(\\)\\[\\]\\'\\\"\\$]+')\n",
    "RE_PUNCTUATION = '|'.join([re.escape(x) for x in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-22T02:55:06.912133Z",
     "iopub.status.busy": "2021-03-22T02:55:06.912133Z",
     "iopub.status.idle": "2021-03-22T02:55:06.927093Z",
     "shell.execute_reply": "2021-03-22T02:55:06.926095Z",
     "shell.execute_reply.started": "2021-03-22T02:55:06.912133Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    return u' '.join(\n",
    "        [x for x in [y for y in non_alphanums.sub(' ', text).lower().strip().split(' ')]\\\n",
    "         if len(x) > 1 and x not in stopwords]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-22T02:55:06.929088Z",
     "iopub.status.busy": "2021-03-22T02:55:06.929088Z",
     "iopub.status.idle": "2021-03-22T02:55:06.942054Z",
     "shell.execute_reply": "2021-03-22T02:55:06.941054Z",
     "shell.execute_reply.started": "2021-03-22T02:55:06.929088Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_name(x):\n",
    "    if len(x):\n",
    "        x = non_alphanums.sub(' ', x).split()\n",
    "        if len(x):\n",
    "            return x[0].lower()\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-22T02:55:06.944048Z",
     "iopub.status.busy": "2021-03-22T02:55:06.944048Z",
     "iopub.status.idle": "2021-03-22T02:55:06.958011Z",
     "shell.execute_reply": "2021-03-22T02:55:06.957013Z",
     "shell.execute_reply.started": "2021-03-22T02:55:06.944048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.331342220306396] Finished defining stuff\n"
     ]
    }
   ],
   "source": [
    "print('[{}] Finished defining stuff'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-22T02:55:06.959008Z",
     "iopub.status.busy": "2021-03-22T02:55:06.959008Z",
     "iopub.status.idle": "2021-03-22T02:55:20.201581Z",
     "shell.execute_reply": "2021-03-22T02:55:20.200609Z",
     "shell.execute_reply.started": "2021-03-22T02:55:06.959008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22.224878549575806] Finished load data\n",
      "[22.22883892059326] Compiled train / test\n",
      "Train shape: (1482535, 9)\n",
      "Test shape: (693359, 8)\n",
      "[22.56992244720459] Removed nonzero price\n",
      "Train shape: (1481661, 9)\n",
      "Test shape: (693359, 8)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_table('data/train.tsv', engine='c',\n",
    "                      dtype={'item_condition_id':'category',\n",
    "                             'shipping':'category'},\n",
    "                      converters={'category_name':split_cat})\n",
    "test = pd.read_table('data/test.tsv', engine='c',\n",
    "                     dtype={'item_condition_id':'category',\n",
    "                            'shipping':'category'},\n",
    "                     converters={'category_name':split_cat})\n",
    "print('[{}] Finished load data'.format(time.time() - start_time))\n",
    "\n",
    "train['is_train'] = 1\n",
    "test['is_train'] = 0\n",
    "print('[{}] Compiled train / test'.format(time.time() - start_time))\n",
    "print('Train shape:', train.shape)\n",
    "print('Test shape:', test.shape)\n",
    "\n",
    "train = train[train['price'] != 0].reset_index(drop=True)\n",
    "print('[{}] Removed nonzero price'.format(time.time() - start_time))\n",
    "print('Train shape:', train.shape)\n",
    "print('Test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-22T02:55:20.202578Z",
     "iopub.status.busy": "2021-03-22T02:55:20.202578Z",
     "iopub.status.idle": "2021-03-22T02:55:21.664445Z",
     "shell.execute_reply": "2021-03-22T02:55:21.663471Z",
     "shell.execute_reply.started": "2021-03-22T02:55:20.202578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23.04664969444275] Compiled merge\n",
      "Merge shape: (2175020, 10)\n",
      "[24.03179359436035] Garbage collection\n"
     ]
    }
   ],
   "source": [
    "y = np.log1p(train['price'])\n",
    "nrow_train = train.shape[0]\n",
    "\n",
    "merge = pd.concat([train, test])\n",
    "submission = test[['test_id']]\n",
    "print('[{}] Compiled merge'.format(time.time() - start_time))\n",
    "print('Merge shape:', merge.shape)\n",
    "\n",
    "del train, test\n",
    "merge.drop(['train_id', 'test_id', 'price'], axis=1, inplace=True)\n",
    "gc.collect()\n",
    "print('[{}] Garbage collection'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-22T02:55:21.667438Z",
     "iopub.status.busy": "2021-03-22T02:55:21.666442Z",
     "iopub.status.idle": "2021-03-22T02:57:46.866657Z",
     "shell.execute_reply": "2021-03-22T02:57:46.865678Z",
     "shell.execute_reply.started": "2021-03-22T02:55:21.667438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29.161094903945923] Split categories completed.\n",
      "[29.964921712875366] Handle missing completed.\n",
      "[36.13743710517883] FE 1/37\n",
      "[36.57227826118469] FE 2/37\n",
      "[36.61014533042908] FE 3/37\n",
      "[36.648075103759766] FE 4/37\n",
      "[36.68496632575989] FE 5/37\n",
      "[36.72284293174744] FE 6/37\n",
      "[44.61376237869263] FE 7/37\n",
      "[84.04957509040833] FE 8/37\n",
      "[87.5123450756073] FE 9/37\n",
      "[95.9696877002716] FE 10/37\n",
      "[96.737633228302] FE 11/37\n",
      "[97.60135316848755] FE 12/37\n",
      "[97.6152856349945] FE 13/37\n",
      "[102.21099829673767] FE 14/37\n",
      "[107.2894356250763] FE 15/37\n",
      "[108.82930970191956] FE 16/37\n",
      "[110.76006412506104] FE 17/37\n",
      "[110.77103543281555] FE 18/37\n",
      "[110.78200650215149] FE 19/37\n",
      "[110.79394268989563] FE 20/37\n",
      "[110.80690717697144] FE 21/37\n",
      "[110.81989288330078] FE 22/37\n",
      "[110.83084273338318] FE 23/37\n",
      "[112.61506962776184] FE 24/37\n",
      "[117.91588950157166] FE 25/37\n",
      "[117.92685985565186] FE 26/37\n",
      "[117.9388279914856] FE 27/37\n",
      "[119.87724757194519] FE 28/37\n",
      "[124.53777980804443] FE 29/37\n",
      "[124.54974842071533] FE 30/37\n",
      "[124.560622215271] FE 31/37\n",
      "[134.85904169082642] FE 32/37\n",
      "[149.9506914615631] FE 33/37\n",
      "[158.74206686019897] FE 34/37\n",
      "[161.5395839214325] FE 35/37\n",
      "[168.52589583396912] FE 36/37\n",
      "[169.24799799919128] FE 37/37\n"
     ]
    }
   ],
   "source": [
    "merge['gencat_name'] = merge['category_name'].str.get(0).replace('', 'missing').astype('category')\n",
    "merge['subcat1_name'] = merge['category_name'].str.get(1).fillna('missing').astype('category')\n",
    "merge['subcat2_name'] = merge['category_name'].str.get(2).fillna('missing').astype('category')\n",
    "merge.drop('category_name', axis=1, inplace=True)\n",
    "print('[{}] Split categories completed.'.format(time.time() - start_time))\n",
    "\n",
    "merge['item_condition_id'] = merge['item_condition_id'].cat.add_categories(['missing']).fillna('missing')\n",
    "merge['shipping'] = merge['shipping'].cat.add_categories(['missing']).fillna('missing')\n",
    "merge['item_description'].fillna('missing', inplace=True)\n",
    "merge['brand_name'] = merge['brand_name'].fillna('missing').astype('category')\n",
    "print('[{}] Handle missing completed.'.format(time.time() - start_time))\n",
    "\n",
    "merge['name_first'] = merge['name'].apply(clean_name)\n",
    "print('[{}] FE 1/37'.format(time.time() - start_time))\n",
    "merge['name_first_count'] = merge.groupby('name_first')['name_first'].transform('count')\n",
    "print('[{}] FE 2/37'.format(time.time() - start_time))\n",
    "merge['gencat_name_count'] = merge.groupby('gencat_name')['gencat_name'].transform('count')\n",
    "print('[{}] FE 3/37'.format(time.time() - start_time))\n",
    "merge['subcat1_name_count'] = merge.groupby('subcat1_name')['subcat1_name'].transform('count')\n",
    "print('[{}] FE 4/37'.format(time.time() - start_time))\n",
    "merge['subcat2_name_count'] = merge.groupby('subcat2_name')['subcat2_name'].transform('count')\n",
    "print('[{}] FE 5/37'.format(time.time() - start_time))\n",
    "merge['brand_name_count'] = merge.groupby('brand_name')['brand_name'].transform('count')\n",
    "print('[{}] FE 6/37'.format(time.time() - start_time))\n",
    "merge['NameLower'] = merge.name.str.count('[a-z]')\n",
    "print('[{}] FE 7/37'.format(time.time() - start_time))\n",
    "merge['DescriptionLower'] = merge.item_description.str.count('[a-z]')\n",
    "print('[{}] FE 8/37'.format(time.time() - start_time))\n",
    "merge['NameUpper'] = merge.name.str.count('[A-Z]')\n",
    "print('[{}] FE 9/37'.format(time.time() - start_time))\n",
    "merge['DescriptionUpper'] = merge.item_description.str.count('[A-Z]')\n",
    "print('[{}] FE 10/37'.format(time.time() - start_time))\n",
    "merge['name_len'] = merge['name'].apply(lambda x: len(x))\n",
    "print('[{}] FE 11/37'.format(time.time() - start_time))\n",
    "merge['des_len'] = merge['item_description'].apply(lambda x: len(x))\n",
    "print('[{}] FE 12/37'.format(time.time() - start_time))\n",
    "merge['name_desc_len_ratio'] = merge['name_len']/merge['des_len']\n",
    "print('[{}] FE 13/37'.format(time.time() - start_time))\n",
    "merge['desc_word_count'] = merge['item_description'].apply(lambda x: len(x.split()))\n",
    "print('[{}] FE 14/37'.format(time.time() - start_time))\n",
    "merge['mean_des'] = merge['item_description'].apply(lambda x: 0 if len(x) == 0 else float(len(x.split())) / len(x)) * 10\n",
    "print('[{}] FE 15/37'.format(time.time() - start_time))\n",
    "merge['name_word_count'] = merge['name'].apply(lambda x: len(x.split()))\n",
    "print('[{}] FE 16/37'.format(time.time() - start_time))\n",
    "merge['mean_name'] = merge['name'].apply(lambda x: 0 if len(x) == 0 else float(len(x.split())) / len(x))  * 10\n",
    "print('[{}] FE 17/37'.format(time.time() - start_time))\n",
    "merge['desc_letters_per_word'] = merge['des_len'] / merge['desc_word_count']\n",
    "print('[{}] FE 18/37'.format(time.time() - start_time))\n",
    "merge['name_letters_per_word'] = merge['name_len'] / merge['name_word_count']\n",
    "print('[{}] FE 19/37'.format(time.time() - start_time))\n",
    "merge['NameLowerRatio'] = merge['NameLower'] / merge['name_len']\n",
    "print('[{}] FE 20/37'.format(time.time() - start_time))\n",
    "merge['DescriptionLowerRatio'] = merge['DescriptionLower'] / merge['des_len']\n",
    "print('[{}] FE 21/37'.format(time.time() - start_time))\n",
    "merge['NameUpperRatio'] = merge['NameUpper'] / merge['name_len']\n",
    "print('[{}] FE 22/37'.format(time.time() - start_time))\n",
    "merge['DescriptionUpperRatio'] = merge['DescriptionUpper'] / merge['des_len']\n",
    "print('[{}] FE 23/37'.format(time.time() - start_time))\n",
    "merge['NamePunctCount'] = merge.name.str.count(RE_PUNCTUATION)\n",
    "print('[{}] FE 24/37'.format(time.time() - start_time))\n",
    "merge['DescriptionPunctCount'] = merge.item_description.str.count(RE_PUNCTUATION)\n",
    "print('[{}] FE 25/37'.format(time.time() - start_time))\n",
    "merge['NamePunctCountRatio'] = merge['NamePunctCount'] / merge['name_word_count']\n",
    "print('[{}] FE 26/37'.format(time.time() - start_time))\n",
    "merge['DescriptionPunctCountRatio'] = merge['DescriptionPunctCount'] / merge['desc_word_count']\n",
    "print('[{}] FE 27/37'.format(time.time() - start_time))\n",
    "merge['NameDigitCount'] = merge.name.str.count('[0-9]')\n",
    "print('[{}] FE 28/37'.format(time.time() - start_time))\n",
    "merge['DescriptionDigitCount'] = merge.item_description.str.count('[0-9]')\n",
    "print('[{}] FE 29/37'.format(time.time() - start_time))\n",
    "merge['NameDigitCountRatio'] = merge['NameDigitCount'] / merge['name_word_count']\n",
    "print('[{}] FE 30/37'.format(time.time() - start_time))\n",
    "merge['DescriptionDigitCountRatio'] = merge['DescriptionDigitCount']/merge['desc_word_count']\n",
    "print('[{}] FE 31/37'.format(time.time() - start_time))\n",
    "merge['stopword_ratio_desc'] = merge['item_description'].apply(lambda x: len([w for w in x.split() if w in stopwords])) / merge['desc_word_count']\n",
    "print('[{}] FE 32/37'.format(time.time() - start_time))\n",
    "merge['num_sum'] = merge['item_description'].apply(sum_numbers) \n",
    "print('[{}] FE 33/37'.format(time.time() - start_time))\n",
    "merge['weird_characters_desc'] = merge['item_description'].str.count(non_alphanumpunct)\n",
    "print('[{}] FE 34/37'.format(time.time() - start_time))\n",
    "merge['weird_characters_name'] = merge['name'].str.count(non_alphanumpunct)\n",
    "print('[{}] FE 35/37'.format(time.time() - start_time))\n",
    "merge['prices_count'] = merge['item_description'].str.count('[rm]')\n",
    "print('[{}] FE 36/37'.format(time.time() - start_time))\n",
    "merge['price_in_name'] = merge['item_description'].str.contains('[rm]', regex=False).astype('int')\n",
    "print('[{}] FE 37/37'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-22T02:57:46.868649Z",
     "iopub.status.busy": "2021-03-22T02:57:46.868649Z",
     "iopub.status.idle": "2021-03-22T02:57:50.084411Z",
     "shell.execute_reply": "2021-03-22T02:57:50.083444Z",
     "shell.execute_reply.started": "2021-03-22T02:57:46.868649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[171.31779193878174] FE Normalized\n",
      "[172.344074010849] FE Merged\n",
      "[172.46372509002686] Garbage collection\n"
     ]
    }
   ],
   "source": [
    "cols = set(merge.columns.values)\n",
    "basic_cols = {\n",
    "    'name', 'item_condition_id', 'brand_name', 'shipping', 'item_description',\n",
    "    'gencat_name', 'subcat1_name', 'subcat2_name', 'name_first', 'is_train'\n",
    "}\n",
    "\n",
    "cols_to_normalize = cols - basic_cols - {'price_in_name'}\n",
    "other_cols = basic_cols | {'price_in_name'}\n",
    "\n",
    "merge_to_normalize = merge[list(cols_to_normalize)]\n",
    "merge_to_normalize = (merge_to_normalize - merge_to_normalize.mean())/(merge_to_normalize.max() - merge_to_normalize.min())\n",
    "print('[{}] FE Normalized'.format(time.time() - start_time))\n",
    "\n",
    "merge = merge[list(other_cols)]\n",
    "merge = pd.concat([merge, merge_to_normalize], axis=1)\n",
    "print('[{}] FE Merged'.format(time.time() - start_time))\n",
    "\n",
    "del(merge_to_normalize)\n",
    "gc.collect()\n",
    "print('[{}] Garbage collection'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-22T02:57:50.085407Z",
     "iopub.status.busy": "2021-03-22T02:57:50.085407Z",
     "iopub.status.idle": "2021-03-22T02:57:51.452757Z",
     "shell.execute_reply": "2021-03-22T02:57:51.451751Z",
     "shell.execute_reply.started": "2021-03-22T02:57:50.085407Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = merge.loc[merge['is_train'] == 0]\n",
    "df_train = merge.loc[merge['is_train'] == 1]\n",
    "\n",
    "del merge\n",
    "gc.collect()\n",
    "\n",
    "df_test.drop(['is_train'], axis=1, inplace=True)\n",
    "df_train.drop(['is_train'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-22T02:57:51.453748Z",
     "iopub.status.busy": "2021-03-22T02:57:51.453748Z",
     "iopub.status.idle": "2021-03-22T02:57:51.514585Z",
     "shell.execute_reply": "2021-03-22T02:57:51.513587Z",
     "shell.execute_reply.started": "2021-03-22T02:57:51.453748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[173.88492369651794] Splitting completed\n"
     ]
    }
   ],
   "source": [
    "if SUBMIT_MODE:\n",
    "    y_train = y\n",
    "    del y\n",
    "    gc.collect()\n",
    "else:\n",
    "    df_train, df_test, y_train, y_test = train_test_split(df_train, y, test_size=0.2, random_state=27)\n",
    "print('[{}] Splitting completed'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-22T02:57:51.516580Z",
     "iopub.status.busy": "2021-03-22T02:57:51.515582Z"
    }
   },
   "outputs": [],
   "source": [
    "wb = WordBatch(normalize_text,\n",
    "               extractor=(WordBag, {'hash_ngrams':2,\n",
    "                                    'hash_ngrams_weights':[1.5, 1.0],\n",
    "                                    'hash_size':2**29,\n",
    "                                    'norm':None,\n",
    "                                    'tf':'binary',\n",
    "                                    'idf':None}))\n",
    "wb.dictionary_freeze = True\n",
    "x_name_train = wb.fit_transform(df_train['name'])\n",
    "x_name_test = wb.transform(df_test['name'])\n",
    "del(wb)\n",
    "\n",
    "mask = np.where(x_name_train.getnnz(axis=0) > 3)[0]\n",
    "x_name_train = x_name_train[:, mask]\n",
    "x_name_test = x_name_test[:, mask]\n",
    "print('[{}] Vectorize `name` completed.'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = WordBatch(normalize_text,\n",
    "               extractor=(WordBag, {'hash_ngrams':2,\n",
    "                                    'hash_ngrams_weights':[1.0, 1.0],\n",
    "                                    'hash_size':2**28,\n",
    "                                    'norm':'l2',\n",
    "                                    'tf':1.0,\n",
    "                                    'idf':None}))\n",
    "wb.dictionary_freeze = True\n",
    "x_description_train = wb.fit_transform(df_train['item_description'])\n",
    "x_description_test = wb.transform(df_test['item_description'])\n",
    "del(wb)\n",
    "\n",
    "mask = np.where(x_description_train.getnnz(axis=0) > 3)[0]\n",
    "x_description_train = x_description_train[:, mask]\n",
    "x_description_test = x_description_test[:, mask]\n",
    "print('[{}] Vectorize `item_description` completed.'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1, x_train_2, y_train_1, y_train_2 = train_test_split(\n",
    "    x_description_train, y_train, test_size=0.5, shuffle=False\n",
    ")\n",
    "print('[{}] Finished splitting.'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(solver='sag', fit_intercept=True, random_state=205, alpha=3.3)\n",
    "model.fit(X_train_1, y_train_1)\n",
    "print('[{}] Finished to train desc ridge (1)'.format(time.time() - start_time))\n",
    "desc_ridge_preds1 = model.predict(X_train_2)\n",
    "desc_ridge_preds1f = model.predict(X_description_test)\n",
    "print('[{}] Finished to predict desc ridge (1)'.format(time.time() - start_time))\n",
    "model = Ridge(solver='sag', fit_intercept=True, random_state=205, alpha=3.3)\n",
    "model.fit(X_train_2, y_train_2)\n",
    "print('[{}] Finished to train desc ridge (2)'.format(time.time() - start_time))\n",
    "desc_ridge_preds2 = model.predict(X_train_1)\n",
    "desc_ridge_preds2f = model.predict(X_description_test)\n",
    "print('[{}] Finished to predict desc ridge (2)'.format(time.time() - start_time))\n",
    "desc_ridge_preds_oof = np.concatenate((desc_ridge_preds2, desc_ridge_preds1), axis=0)\n",
    "desc_ridge_preds_test = (desc_ridge_preds1f + desc_ridge_preds2f) / 2.0\n",
    "print('RMSLE OOF: {}'.format(rmse(desc_ridge_preds_oof, y_train)))\n",
    "if not SUBMIT_MODE:\n",
    "    print('RMSLE TEST: {}'.format(rmse(desc_ridge_preds_test, y_test)))\n",
    "\n",
    "x_train_1, x_train_2, y_train_1, y_train_2 = train_test_split(\n",
    "    x_name_train, y_train, test_size=0.5, shuffle=False\n",
    ")\n",
    "print('[{}] Finished splitting.'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(solver='sag', fit_intercept=True, random_state=205, alpha=3.3)\n",
    "model.fit(X_train_1, y_train_1)\n",
    "print('[{}] Finished to train name ridge (1)'.format(time.time() - start_time))\n",
    "name_ridge_preds1 = model.predict(X_train_2)\n",
    "name_ridge_preds1f = model.predict(X_name_test)\n",
    "print('[{}] Finished to predict name ridge (1)'.format(time.time() - start_time))\n",
    "model = Ridge(solver='sag', fit_intercept=True, random_state=205, alpha=3.3)\n",
    "model.fit(X_train_2, y_train_2)\n",
    "print('[{}] Finished to train name ridge (2)'.format(time.time() - start_time))\n",
    "name_ridge_preds2 = model.predict(X_train_1)\n",
    "name_ridge_preds2f = model.predict(X_name_test)\n",
    "print('[{}] Finished to predict name ridge (2)'.format(time.time() - start_time))\n",
    "name_ridge_preds_oof = np.concatenate((name_ridge_preds2, name_ridge_preds1), axis=0)\n",
    "name_ridge_preds_test = (name_ridge_preds1f + name_ridge_preds2f) / 2.0\n",
    "print('RMSLE OOF: {}'.format(rmse(name_ridge_preds_oof, y_train)))\n",
    "if not SUBMIT_MODE:\n",
    "    print('RMSLE TEST: {}'.format(rmse(name_ridge_preds_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train_1, x_train_2, y_train_1, y_train_2\n",
    "del name_ridge_preds1, name_ridge_preds1f, name_ridge_preds2, name_ridge_preds2f\n",
    "del desc_ridge_preds1, desc_ridge_preds1f, desc_ridge_preds2, desc_ridge_preds2f\n",
    "gc.collect()\n",
    "print('[{}] Finished garbage collection.'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer(sparse_output=True)\n",
    "x_brand_train = lb.fit_transform(df_train['brand_name'])\n",
    "x_brand_test = lb.transform(df_test['brand_name'])\n",
    "print('[{}] Finished label binarize `brand_name`.'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cat_train = lb.fit_transform(df_train['gencat_name'])\n",
    "x_cat_test = lb.transform(df_test['gencat_name'])\n",
    "x_cat1_train = lb.fit_transform(df_train['subcat1_name'])\n",
    "x_cat1_test = lb.transform(df_test['subcat1_name'])\n",
    "x_cat2_train = lb.fit_transform(df_train['subcat2_name'])\n",
    "x_cat2_test = lb.transform(df_test['subcat2_name'])\n",
    "print('[{}] Finished label binarize categories.'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dummies_train = csr_matrix(\n",
    "    pd.get_dummies(df_train[list(cols - (basic_cols - {'item_condition_id', 'shipping'}))],\n",
    "                   sparse=True).values\n",
    ")\n",
    "print('[{}] Create dummies completed - train.'.format(time.time() - start_time))\n",
    "\n",
    "x_dummies_test = csr_matrix(\n",
    "    pd.get_dummies(df_test[list(cols - (basic_cols - {'item_condition_id', 'shipping'}))],\n",
    "                   sparse=True).values\n",
    ")\n",
    "print('[{}] Create dummies completed - test.'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_merge_train = hstack((x_dummies_train, x_description_train, x_brand_train, x_cat_train,\n",
    "                             x_cat1_train, x_cat2_train, x_name_train)).tocsr()\n",
    "del x_description_train, lb, x_name_train, x_dummies_train\n",
    "gc.collect()\n",
    "print('[{}] Create sparse merge train completed'.format(time.time() - start_time))\n",
    "\n",
    "sparse_merge_test = hstack((x_dummies_test, x_description_test, x_brand_test, x_cat_test,\n",
    "                             x_cat1_test, x_cat2_test, x_name_test)).tocsr()\n",
    "del x_description_test, x_name_test, x_dummies_test\n",
    "gc.collect()\n",
    "print('[{}] Create sparse merge test completed'.format(time.time() - start_time))\n",
    "\n",
    "if SUBMIT_MODE:\n",
    "    iters = 3\n",
    "else:\n",
    "    iters = 1\n",
    "    rounds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FM_FTRL(\n",
    "    alpha=0.035, beta=0.001, L1=0.00001, L2=0.15, D=sparse_merge_train.shape[1],\n",
    "    alpha_fm=0.05, L2_fm=0.0, init_fm=0.01, D_fm=100, e_noise=0, iters=iters,\n",
    "    inv_link=\"identity\", threads=4)\n",
    "\n",
    "if SUBMIT_MODE:\n",
    "    model.fit(sparse_merge_train, y_train)\n",
    "    print('[{}] Train FM completed'.format(time.time() - start_time))\n",
    "    predsFM = model.predict(sparse_merge_test)\n",
    "    print('[{}] Predict FM completed'.format(time.time() - start_time))\n",
    "else:\n",
    "    for i in range(rounds):\n",
    "        model.fit(sparse_merge_train, y_train)\n",
    "        predsFM = model.predict(sparse_merge_test)\n",
    "        print('[{}] Iteration {}/{} -- RMSLE: {}'.format(time.time() - start_time, i + 1, rounds, rmse(predsFM, y_test)))\n",
    "\n",
    "del model\n",
    "gc.collect()\n",
    "if not SUBMIT_MODE:\n",
    "    print(\"FM_FTRL dev RMSLE:\", rmse(predsFM, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fselect = SelectKBest(f_regression, k=48000)\n",
    "train_features = fselect.fit_transform(sparse_merge_train, y_train)\n",
    "test_features = fselect.transform(sparse_merge_test)\n",
    "print('[{}] Select best completed'.format(time.time() - start_time))\n",
    "\n",
    "\n",
    "del sparse_merge_train\n",
    "del sparse_merge_test\n",
    "gc.collect()\n",
    "print('[{}] Garbage collection'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer(max_features=250000, ngram_range=(1, 3), stop_words=None)\n",
    "x_name_train = tv.fit_transform(df_train['name'])\n",
    "print('[{}] Finished TFIDF vectorize `name` (1/2)'.format(time.time() - start_time))\n",
    "x_name_test = tv.transform(df_test['name'])\n",
    "print('[{}] Finished TFIDF vectorize `name` (2/2)'.format(time.time() - start_time))\n",
    "\n",
    "tv = TfidfVectorizer(max_features=500000, ngram_range=(1, 3), stop_words=None)\n",
    "x_description_train = tv.fit_transform(df_train['item_description'])\n",
    "print('[{}] Finished TFIDF vectorize `item_description` (1/2)'.format(time.time() - start_time))\n",
    "x_description_test = tv.transform(df_test['item_description'])\n",
    "print('[{}] Finished TFIDF vectorize `item_description` (2/2)'.format(time.time() - start_time))\n",
    "\n",
    "x_dummies_train = csr_matrix(\n",
    "    pd.get_dummies(df_train[['item_condition_id', 'shipping']], sparse=True).values\n",
    ")\n",
    "x_dummies_test = csr_matrix(\n",
    "    pd.get_dummies(df_test[['item_condition_id', 'shipping']], sparse=True).values\n",
    ")\n",
    "\n",
    "sparse_merge_train = hstack((x_description_train, x_brand_train, x_cat_train,\n",
    "                             x_cat1_train, x_cat2_train, x_name_train)).tocsr()\n",
    "del x_dummies_train, x_description_train, x_brand_train, x_cat_train\n",
    "del x_cat1_train, x_cat2_train, x_name_train\n",
    "gc.collect()\n",
    "print('[{}] Create sparse merge train completed'.format(time.time() - start_time))\n",
    "\n",
    "sparse_merge_test = hstack((x_description_test, x_brand_test, x_cat_test,\n",
    "                            x_cat1_test, x_cat2_test, x_name_test)).tocsr()\n",
    "del x_dummies_test, x_description_test, x_brand_test, x_cat_test\n",
    "del x_cat1_test, x_cat2_test, x_name_test\n",
    "gc.collect()\n",
    "print('[{}] Create sparse merge test completed'.format(time.time() - start_time))\n",
    "\n",
    "\n",
    "x_train_1, x_train_2, y_train_1, y_train_2 = train_test_split(\n",
    "    sparse_merge_train, y_train, test_size = 0.5, shuffle = False)\n",
    "print('[{}] Finished splitting'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(solver='sag', fit_intercept=True, random_state=205, alpha=3.3)\n",
    "model.fit(X_train_1, y_train_1)\n",
    "print('[{}] Finished to train ridge (1)'.format(time.time() - start_time))\n",
    "ridge_preds1 = model.predict(X_train_2)\n",
    "ridge_preds1f = model.predict(sparse_merge_test)\n",
    "print('[{}] Finished to predict ridge (1)'.format(time.time() - start_time))\n",
    "model = Ridge(solver='sag', fit_intercept=True, random_state=205, alpha=3.3)\n",
    "model.fit(X_train_2, y_train_2)\n",
    "print('[{}] Finished to train ridge (2)'.format(time.time() - start_time))\n",
    "ridge_preds2 = model.predict(X_train_1)\n",
    "ridge_preds2f = model.predict(sparse_merge_test)\n",
    "print('[{}] Finished to predict ridge (2)'.format(time.time() - start_time))\n",
    "ridge_preds_oof = np.concatenate((ridge_preds2, ridge_preds1), axis=0)\n",
    "ridge_preds_test = (ridge_preds1f + ridge_preds2f) / 2.0\n",
    "print('RMSLE OOF: {}'.format(rmse(ridge_preds_oof, y_train)))\n",
    "if not SUBMIT_MODE:\n",
    "    print('RMSLE TEST: {}'.format(rmse(ridge_preds_test, y_test)))\n",
    "\n",
    "model = MultinomialNB(alpha=0.01)\n",
    "model.fit(X_train_1, y_train_1 >= 4)\n",
    "print('[{}] Finished to train MNB (1)'.format(time.time() - start_time))\n",
    "mnb_preds1 = model.predict_proba(X_train_2)[:, 1]\n",
    "mnb_preds1f = model.predict_proba(sparse_merge_test)[:, 1]\n",
    "print('[{}] Finished to predict MNB (1)'.format(time.time() - start_time))\n",
    "model = MultinomialNB(alpha=0.01)\n",
    "model.fit(X_train_2, y_train_2 >= 4)\n",
    "print('[{}] Finished to train MNB (2)'.format(time.time() - start_time))\n",
    "mnb_preds2 = model.predict_proba(X_train_1)[:, 1]\n",
    "mnb_preds2f = model.predict_proba(sparse_merge_test)[:, 1]\n",
    "print('[{}] Finished to predict MNB (2)'.format(time.time() - start_time))\n",
    "mnb_preds_oof = np.concatenate((mnb_preds2, mnb_preds1), axis=0)\n",
    "mnb_preds_test = (mnb_preds1f + mnb_preds2f) / 2.0\n",
    "\n",
    "\n",
    "del ridge_preds1, ridge_preds1f, ridge_preds2, ridge_preds2f\n",
    "del mnb_preds1, mnb_preds1f, mnb_preds2, mnb_preds2f\n",
    "del x_train_1, x_train_2, y_train_1, y_train_2\n",
    "del sparse_merge_train, sparse_merge_test, model\n",
    "gc.collect()\n",
    "print('[{}] Finished garbage collection'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['ridge'] = ridge_preds_oof\n",
    "df_train['name_ridge'] = name_ridge_preds_oof\n",
    "df_train['desc_ridge'] = desc_ridge_preds_oof\n",
    "df_train['mnb'] = mnb_preds_oof\n",
    "df_test['ridge'] = ridge_preds_test\n",
    "df_test['name_ridge'] = name_ridge_preds_test\n",
    "df_test['desc_ridge'] = desc_ridge_preds_test\n",
    "df_test['mnb'] = mnb_preds_test\n",
    "print('[{}] Finished adding submodels'.format(time.time() - start_time))\n",
    "\n",
    "f_cats = ['brand_name', 'gencat_name', 'subcat1_name', 'subcat2_name', 'name_first']\n",
    "target_encode = TargetEncoder(\n",
    "    min_samples_leaf=100, smoothing=10, noise_level=0.01,\n",
    "    keep_original=True, cols=f_cats\n",
    ")\n",
    "df_train, df_test = target_encode.encode(df_train, df_test, y_train)\n",
    "print('[{}] Finished target encoding'.format(time.time() - start_time))\n",
    "\n",
    "df_train.drop(f_cats, axis=1, inplace=True)\n",
    "df_test.drop(f_cats, axis=1, inplace=True)\n",
    "del mnb_preds_oof, mnb_preds_test, ridge_preds_oof, ridge_preds_test\n",
    "gc.collect()\n",
    "print('[{}] Finished garbage collection'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['gencat_name_te', 'brand_name_te', 'subcat1_name_te', 'subcat2_name_te',\n",
    "        'name_first_te', 'mnb', 'desc_ridge', 'name_ridge', 'ridge']\n",
    "train_dummies = csr_matrix(df_train[cols].values)\n",
    "print('[{}] Finished dummyizing model 1/5'.format(time.time() - start_time))\n",
    "test_dummies = csr_matrix(df_test[cols].values)\n",
    "print('[{}] Finished dummyizing model 2/5'.format(time.time() - start_time))\n",
    "\n",
    "del df_train\n",
    "del df_test\n",
    "gc.collect()\n",
    "\n",
    "print('[{}] Finished dummyizing model 3/5'.format(time.time() - start_time))\n",
    "train_features = hstack((train_features, train_dummies)).tocsr()\n",
    "print('[{}] Finished dummyizing model 4/5'.format(time.time() - start_time))\n",
    "test_features = hstack((test_features, test_dummies)).tocsr()\n",
    "print('[{}] Finished dummyizing model 5/5'.format(time.time() - start_time))\n",
    "\n",
    "d_train = lgb.Dataset(train_features, label=y_train)\n",
    "\n",
    "del train_features\n",
    "gc.collect()\n",
    "\n",
    "if SUBMIT_MODE:\n",
    "    watchlist = [d_train]\n",
    "else:\n",
    "    d_valid = lgb.Dataset(test_features, label=y_test)\n",
    "    watchlist = [d_train, d_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': 0.15,\n",
    "    'application': 'regression',\n",
    "    'max_depth': 13,\n",
    "    'num_leaves': 400,\n",
    "    'verbosity': -1,\n",
    "    'metric': 'RMSE',\n",
    "    'data_random_seed': 1,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'feature_fraction': 0.6,\n",
    "    'nthread': 4,\n",
    "    'lambda_l1': 10,\n",
    "    'lambda_l2': 10\n",
    "}\n",
    "print('[{}] Finished compiling LGB'.format(time.time() - start_time))\n",
    "\n",
    "modelL = lgb.train(params,\n",
    "                  train_set=d_train,\n",
    "                  num_boost_round=1350,\n",
    "                  valid_sets=watchlist,\n",
    "                  verbose_eval=50)\n",
    "\n",
    "predsL = modelL.predict(test_features)\n",
    "predsL[predsL < 0] = 0\n",
    "\n",
    "if not SUBMIT_MODE:\n",
    "    print(\"LGB RMSLE:\", rmse(predsL, y_test))\n",
    "\n",
    "del d_train, modelL\n",
    "if not SUBMIT_MODE:\n",
    "    del d_valid\n",
    "gc.collect()\n",
    "\n",
    "preds_final = predsFM * 0.33 + predsL * 0.67\n",
    "if not SUBMIT_MODE:\n",
    "    print('Final RMSE: ', rmse(preds_final, y_test))\n",
    "\n",
    "if SUBMIT_MODE:\n",
    "    preds_final = np.expm1(preds_final)\n",
    "    submission['price'] = preds_final\n",
    "    submission.to_csv('lgb_and_fm_separate_train_test.csv', index=False)\n",
    "    print('[{}] Writing submission done'.format(time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
