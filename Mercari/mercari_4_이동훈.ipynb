{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kaggle Study 41일차(Mercari)\n",
    "코드출처 : https://www.kaggle.com/peterhurford/lgb-and-fm-18th-place-0-40604"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:41:31.326290Z",
     "start_time": "2021-03-22T08:41:31.322301Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "SUBMIT_MODE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:41:52.368975Z",
     "start_time": "2021-03-22T08:41:31.329280Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gc\n",
    "import string\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import wordbatch\n",
    "from wordbatch.extractors import WordBag\n",
    "from wordbatch.models import FM_FTRL\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:41:52.398861Z",
     "start_time": "2021-03-22T08:41:52.379909Z"
    }
   },
   "outputs": [],
   "source": [
    "def rmse(predicted, actual):\n",
    "    return np.sqrt(((predicted - actual) ** 2).mean())\n",
    "\n",
    "\n",
    "def split_cat(text):\n",
    "    try:\n",
    "        return text.split(\"/\")\n",
    "    except:\n",
    "        return (\"No Label\", \"No Label\", \"No Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:41:52.445728Z",
     "start_time": "2021-03-22T08:41:52.408832Z"
    }
   },
   "outputs": [],
   "source": [
    "class TargetEncoder:\n",
    "    # 출처: https://www.kaggle.com/ogrellier/python-target-encoding-for-categorical-features\n",
    "    def __repr__(self):\n",
    "        return 'TargetEncoder'\n",
    "\n",
    "    def __init__(self, cols, smoothing=1, min_samples_leaf=1, noise_level=0, keep_original=False):\n",
    "        self.cols = cols\n",
    "        self.smoothing = smoothing\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.noise_level = noise_level\n",
    "        self.keep_original = keep_original\n",
    "\n",
    "    @staticmethod\n",
    "    def add_noise(series, noise_level):\n",
    "        return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "    def encode(self, train, test, target):\n",
    "        for col in self.cols:\n",
    "            if self.keep_original:\n",
    "                train[col + '_te'], test[col + '_te'] = self.encode_column(train[col], test[col], target)\n",
    "            else:\n",
    "                train[col], test[col] = self.encode_column(train[col], test[col], target)\n",
    "        return train, test\n",
    "\n",
    "    def encode_column(self, trn_series, tst_series, target):\n",
    "        temp = pd.concat([trn_series, target], axis=1)\n",
    "        # target 평균 계산\n",
    "        averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "        \n",
    "        # smoothing 계산\n",
    "        smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - self.min_samples_leaf) / self.smoothing))\n",
    "        \n",
    "        # 평균함수를 타겟에 적용\n",
    "        prior = target.mean()\n",
    "        \n",
    "        # 카운트가 클수록 덜 가득 찬_avg가 고려됩니다.\n",
    "        averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "        averages.drop(['mean', 'count'], axis=1, inplace=True)\n",
    "        \n",
    "        # trn과 tst 시리즈에 적용\n",
    "        ft_trn_series = pd.merge(\n",
    "            trn_series.to_frame(trn_series.name),\n",
    "            averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "            on=trn_series.name,\n",
    "            how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "        \n",
    "        # merge는 인덱스를 그대로 들고 오지 못함. 그래서 복원 과정을 거침\n",
    "        ft_trn_series.index = trn_series.index\n",
    "        ft_tst_series = pd.merge(\n",
    "            tst_series.to_frame(tst_series.name),\n",
    "            averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "            on=tst_series.name,\n",
    "            how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "        ft_tst_series.index = tst_series.index\n",
    "        \n",
    "        return self.add_noise(ft_trn_series, self.noise_level), self.add_noise(ft_tst_series, self.noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:41:52.460687Z",
     "start_time": "2021-03-22T08:41:52.448721Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_number(x):\n",
    "    try:\n",
    "        if not x.isdigit():\n",
    "            return 0\n",
    "        x = int(x)\n",
    "        if x > 100:\n",
    "            return 100\n",
    "        else:\n",
    "            return x\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def sum_numbers(desc):\n",
    "    if not isinstance(desc, str):\n",
    "        return 0\n",
    "    try:\n",
    "        return sum([to_number(s) for s in desc.split()])\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:41:52.493600Z",
     "start_time": "2021-03-22T08:41:52.470660Z"
    }
   },
   "outputs": [],
   "source": [
    "stopwords = {x: 1 for x in stopwords.words('english')}\n",
    "non_alphanums = re.compile(u'[^A-Za-z0-9]+')\n",
    "non_alphanumpunct = re.compile(u'[^A-Za-z0-9\\.?!,; \\(\\)\\[\\]\\'\\\"\\$]+')\n",
    "RE_PUNCTUATION = '|'.join([re.escape(x) for x in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:41:52.507564Z",
     "start_time": "2021-03-22T08:41:52.495594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.176255464553833] Finished defining stuff\n"
     ]
    }
   ],
   "source": [
    "def normalize_text(text):\n",
    "    return u\" \".join(\n",
    "        [x for x in [y for y in non_alphanums.sub(' ', text).lower().strip().split(\" \")] \\\n",
    "         if len(x) > 1 and x not in stopwords])\n",
    "\n",
    "def clean_name(x):\n",
    "    if len(x):\n",
    "        x = non_alphanums.sub(' ', x).split()\n",
    "        if len(x):\n",
    "            return x[0].lower()\n",
    "    return ''\n",
    "\n",
    "    \n",
    "print('[{}] Finished defining stuff'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:42:15.610999Z",
     "start_time": "2021-03-22T08:41:52.510556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44.21486163139343] Finished load data\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_table('C:/Users/이동훈/Desktop/github/kaggle/kagglestudy/Data/Mercari/train.tsv', engine='c', \n",
    "                      dtype={'item_condition_id': 'category',\n",
    "                             'shipping': 'category',\n",
    "                            }, \n",
    "                     converters={'category_name': split_cat})\n",
    "test = pd.read_table('C:/Users/이동훈/Desktop/github/kaggle/kagglestudy/Data/Mercari/test.tsv', engine='c', \n",
    "                      dtype={'item_condition_id': 'category',\n",
    "                             'shipping': 'category',\n",
    "                            },\n",
    "                    converters={'category_name': split_cat})\n",
    "print('[{}] Finished load data'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:42:17.305966Z",
     "start_time": "2021-03-22T08:42:15.628953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44.38939666748047] Compiled train / test\n",
      "Train shape:  (1482535, 9)\n",
      "Test shape:  (693359, 8)\n",
      "[45.977837800979614] Removed nonzero price\n",
      "Train shape:  (1481661, 9)\n",
      "Test shape:  (693359, 8)\n"
     ]
    }
   ],
   "source": [
    "train['is_train'] = 1\n",
    "test['is_train'] = 0\n",
    "print('[{}] Compiled train / test'.format(time.time() - start_time))\n",
    "print('Train shape: ', train.shape)\n",
    "print('Test shape: ', test.shape)\n",
    "\n",
    "train = train[train.price != 0].reset_index(drop=True)\n",
    "print('[{}] Removed nonzero price'.format(time.time() - start_time))\n",
    "print('Train shape: ', train.shape)\n",
    "print('Test shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:42:18.298373Z",
     "start_time": "2021-03-22T08:42:17.308958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46.96740674972534] Compiled merge\n",
      "Merge shape:  (2175020, 10)\n"
     ]
    }
   ],
   "source": [
    "y = np.log1p(train['price'])\n",
    "nrow_train = train.shape[0]\n",
    "\n",
    "merge = pd.concat([train, test])\n",
    "submission = test[['test_id']]\n",
    "print('[{}] Compiled merge'.format(time.time() - start_time))\n",
    "print('Merge shape: ', merge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:42:20.346746Z",
     "start_time": "2021-03-22T08:42:18.306354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49.02042603492737] Garbage collection\n"
     ]
    }
   ],
   "source": [
    "del train\n",
    "del test\n",
    "merge.drop(['train_id', 'test_id', 'price'], axis=1, inplace=True)\n",
    "gc.collect()\n",
    "print('[{}] Garbage collection'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:42:32.342245Z",
     "start_time": "2021-03-22T08:42:20.349709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61.01393270492554] Split categories completed.\n"
     ]
    }
   ],
   "source": [
    "merge['gencat_name'] = merge['category_name'].str.get(0).replace('', 'missing').astype('category')\n",
    "merge['subcat1_name'] = merge['category_name'].str.get(1).fillna('missing').astype('category')\n",
    "merge['subcat2_name'] = merge['category_name'].str.get(2).fillna('missing').astype('category')\n",
    "merge.drop('category_name', axis=1, inplace=True)\n",
    "print('[{}] Split categories completed.'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:42:34.355540Z",
     "start_time": "2021-03-22T08:42:32.345355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63.0271999835968] Handle missing completed.\n"
     ]
    }
   ],
   "source": [
    "merge['item_condition_id'] = merge['item_condition_id'].cat.add_categories(['missing']).fillna('missing')\n",
    "merge['shipping'] = merge['shipping'].cat.add_categories(['missing']).fillna('missing')\n",
    "merge['item_description'].fillna('missing', inplace=True)\n",
    "merge['brand_name'] = merge['brand_name'].fillna('missing').astype('category')\n",
    "print('[{}] Handle missing completed.'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:48:10.196404Z",
     "start_time": "2021-03-22T08:42:34.358476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78.89764499664307] FE 1/37\n",
      "[79.89736986160278] FE 2/37\n",
      "[80.00770044326782] FE 3/37\n",
      "[80.16642713546753] FE 4/37\n",
      "[80.28806519508362] FE 5/37\n",
      "[80.43016791343689] FE 6/37\n",
      "[99.90466833114624] FE 7/37\n",
      "[194.90528893470764] FE 8/37\n",
      "[202.7518482208252] FE 9/37\n",
      "[223.17396426200867] FE 10/37\n",
      "[224.31655859947205] FE 11/37\n",
      "[226.17887616157532] FE 12/37\n",
      "[226.31310558319092] FE 13/37\n",
      "[237.59004521369934] FE 14/37\n",
      "[250.1481113433838] FE 15/37\n",
      "[253.9563069343567] FE 16/37\n",
      "[257.324893951416] FE 17/37\n",
      "[257.3498649597168] FE 18/37\n",
      "[257.37371134757996] FE 19/37\n",
      "[257.40186405181885] FE 20/37\n",
      "[257.43097734451294] FE 21/37\n",
      "[257.45374631881714] FE 22/37\n",
      "[257.4766957759857] FE 23/37\n",
      "[262.0637195110321] FE 24/37\n",
      "[273.98565554618835] FE 25/37\n",
      "[274.0084545612335] FE 26/37\n",
      "[274.0323910713196] FE 27/37\n",
      "[279.2341980934143] FE 28/37\n",
      "[290.2329251766205] FE 29/37\n",
      "[290.2648091316223] FE 30/37\n",
      "[290.29771757125854] FE 31/37\n",
      "[315.7753438949585] FE 32/37\n",
      "[355.9365510940552] FE 33/37\n",
      "[374.51886463165283] FE 34/37\n",
      "[380.5076084136963] FE 35/37\n",
      "[397.24660062789917] FE 36/37\n",
      "[398.8680922985077] FE 37/37\n"
     ]
    }
   ],
   "source": [
    "merge['name_first'] = merge['name'].apply(clean_name)\n",
    "print('[{}] FE 1/37'.format(time.time() - start_time))\n",
    "merge['name_first_count'] = merge.groupby('name_first')['name_first'].transform('count')\n",
    "print('[{}] FE 2/37'.format(time.time() - start_time))\n",
    "merge['gencat_name_count'] = merge.groupby('gencat_name')['gencat_name'].transform('count')\n",
    "print('[{}] FE 3/37'.format(time.time() - start_time))\n",
    "merge['subcat1_name_count'] = merge.groupby('subcat1_name')['subcat1_name'].transform('count')\n",
    "print('[{}] FE 4/37'.format(time.time() - start_time))\n",
    "merge['subcat2_name_count'] = merge.groupby('subcat2_name')['subcat2_name'].transform('count')\n",
    "print('[{}] FE 5/37'.format(time.time() - start_time))\n",
    "merge['brand_name_count'] = merge.groupby('brand_name')['brand_name'].transform('count')\n",
    "print('[{}] FE 6/37'.format(time.time() - start_time))\n",
    "merge['NameLower'] = merge.name.str.count('[a-z]')\n",
    "print('[{}] FE 7/37'.format(time.time() - start_time))\n",
    "merge['DescriptionLower'] = merge.item_description.str.count('[a-z]')\n",
    "print('[{}] FE 8/37'.format(time.time() - start_time))\n",
    "merge['NameUpper'] = merge.name.str.count('[A-Z]')\n",
    "print('[{}] FE 9/37'.format(time.time() - start_time))\n",
    "merge['DescriptionUpper'] = merge.item_description.str.count('[A-Z]')\n",
    "print('[{}] FE 10/37'.format(time.time() - start_time))\n",
    "merge['name_len'] = merge['name'].apply(lambda x: len(x))\n",
    "print('[{}] FE 11/37'.format(time.time() - start_time))\n",
    "merge['des_len'] = merge['item_description'].apply(lambda x: len(x))\n",
    "print('[{}] FE 12/37'.format(time.time() - start_time))\n",
    "merge['name_desc_len_ratio'] = merge['name_len']/merge['des_len']\n",
    "print('[{}] FE 13/37'.format(time.time() - start_time))\n",
    "merge['desc_word_count'] = merge['item_description'].apply(lambda x: len(x.split()))\n",
    "print('[{}] FE 14/37'.format(time.time() - start_time))\n",
    "merge['mean_des'] = merge['item_description'].apply(lambda x: 0 if len(x) == 0 else float(len(x.split())) / len(x)) * 10\n",
    "print('[{}] FE 15/37'.format(time.time() - start_time))\n",
    "merge['name_word_count'] = merge['name'].apply(lambda x: len(x.split()))\n",
    "print('[{}] FE 16/37'.format(time.time() - start_time))\n",
    "merge['mean_name'] = merge['name'].apply(lambda x: 0 if len(x) == 0 else float(len(x.split())) / len(x))  * 10\n",
    "print('[{}] FE 17/37'.format(time.time() - start_time))\n",
    "merge['desc_letters_per_word'] = merge['des_len'] / merge['desc_word_count']\n",
    "print('[{}] FE 18/37'.format(time.time() - start_time))\n",
    "merge['name_letters_per_word'] = merge['name_len'] / merge['name_word_count']\n",
    "print('[{}] FE 19/37'.format(time.time() - start_time))\n",
    "merge['NameLowerRatio'] = merge['NameLower'] / merge['name_len']\n",
    "print('[{}] FE 20/37'.format(time.time() - start_time))\n",
    "merge['DescriptionLowerRatio'] = merge['DescriptionLower'] / merge['des_len']\n",
    "print('[{}] FE 21/37'.format(time.time() - start_time))\n",
    "merge['NameUpperRatio'] = merge['NameUpper'] / merge['name_len']\n",
    "print('[{}] FE 22/37'.format(time.time() - start_time))\n",
    "merge['DescriptionUpperRatio'] = merge['DescriptionUpper'] / merge['des_len']\n",
    "print('[{}] FE 23/37'.format(time.time() - start_time))\n",
    "merge['NamePunctCount'] = merge.name.str.count(RE_PUNCTUATION)\n",
    "print('[{}] FE 24/37'.format(time.time() - start_time))\n",
    "merge['DescriptionPunctCount'] = merge.item_description.str.count(RE_PUNCTUATION)\n",
    "print('[{}] FE 25/37'.format(time.time() - start_time))\n",
    "merge['NamePunctCountRatio'] = merge['NamePunctCount'] / merge['name_word_count']\n",
    "print('[{}] FE 26/37'.format(time.time() - start_time))\n",
    "merge['DescriptionPunctCountRatio'] = merge['DescriptionPunctCount'] / merge['desc_word_count']\n",
    "print('[{}] FE 27/37'.format(time.time() - start_time))\n",
    "merge['NameDigitCount'] = merge.name.str.count('[0-9]')\n",
    "print('[{}] FE 28/37'.format(time.time() - start_time))\n",
    "merge['DescriptionDigitCount'] = merge.item_description.str.count('[0-9]')\n",
    "print('[{}] FE 29/37'.format(time.time() - start_time))\n",
    "merge['NameDigitCountRatio'] = merge['NameDigitCount'] / merge['name_word_count']\n",
    "print('[{}] FE 30/37'.format(time.time() - start_time))\n",
    "merge['DescriptionDigitCountRatio'] = merge['DescriptionDigitCount']/merge['desc_word_count']\n",
    "print('[{}] FE 31/37'.format(time.time() - start_time))\n",
    "merge['stopword_ratio_desc'] = merge['item_description'].apply(lambda x: len([w for w in x.split() if w in stopwords])) / merge['desc_word_count']\n",
    "print('[{}] FE 32/37'.format(time.time() - start_time))\n",
    "merge['num_sum'] = merge['item_description'].apply(sum_numbers) \n",
    "print('[{}] FE 33/37'.format(time.time() - start_time))\n",
    "merge['weird_characters_desc'] = merge['item_description'].str.count(non_alphanumpunct)\n",
    "print('[{}] FE 34/37'.format(time.time() - start_time))\n",
    "merge['weird_characters_name'] = merge['name'].str.count(non_alphanumpunct)\n",
    "print('[{}] FE 35/37'.format(time.time() - start_time))\n",
    "merge['prices_count'] = merge['item_description'].str.count('[rm]')\n",
    "print('[{}] FE 36/37'.format(time.time() - start_time))\n",
    "merge['price_in_name'] = merge['item_description'].str.contains('[rm]', regex=False).astype('int')\n",
    "print('[{}] FE 37/37'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:48:31.224302Z",
     "start_time": "2021-03-22T08:48:10.199397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[415.0425934791565] FE Normalized\n",
      "[419.2011065483093] FE Merged\n",
      "[419.89499139785767] Garbage collection\n"
     ]
    }
   ],
   "source": [
    "cols = set(merge.columns.values)\n",
    "basic_cols = {'name', 'item_condition_id', 'brand_name',\n",
    "  'shipping', 'item_description', 'gencat_name',\n",
    "  'subcat1_name', 'subcat2_name', 'name_first', 'is_train'}\n",
    "\n",
    "cols_to_normalize = cols - basic_cols - {'price_in_name'}\n",
    "other_cols = basic_cols | {'price_in_name'}\n",
    "\n",
    "merge_to_normalize = merge[list(cols_to_normalize)]\n",
    "merge_to_normalize = (merge_to_normalize - merge_to_normalize.mean()) / (merge_to_normalize.max() - merge_to_normalize.min())\n",
    "print('[{}] FE Normalized'.format(time.time() - start_time))\n",
    "\n",
    "merge = merge[list(other_cols)]\n",
    "merge = pd.concat([merge, merge_to_normalize],axis=1)\n",
    "print('[{}] FE Merged'.format(time.time() - start_time))\n",
    "\n",
    "del(merge_to_normalize)\n",
    "gc.collect()\n",
    "print('[{}] Garbage collection'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T08:48:34.307623Z",
     "start_time": "2021-03-22T08:48:31.230315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[422.9802756309509] Splitting completed.\n"
     ]
    }
   ],
   "source": [
    "df_test = merge.loc[merge['is_train'] == 0]\n",
    "df_train = merge.loc[merge['is_train'] == 1]\n",
    "del merge\n",
    "gc.collect()\n",
    "df_test = df_test.drop(['is_train'], axis=1)\n",
    "df_train = df_train.drop(['is_train'], axis=1)\n",
    "\n",
    "if SUBMIT_MODE:\n",
    "    y_train = y\n",
    "    del y\n",
    "    gc.collect()\n",
    "else:\n",
    "    df_train, df_test, y_train, y_test = train_test_split(df_train, y, test_size=0.2, random_state=144)\n",
    "\n",
    "print('[{}] Splitting completed.'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-22T08:41:35.686Z"
    }
   },
   "outputs": [],
   "source": [
    "from wordbatch.pipelines import WordBatch\n",
    "wb = WordBatch(normalize_text, extractor=(WordBag, {\"hash_ngrams\": 2,\n",
    "                                                    \"hash_ngrams_weights\": [1.5, 1.0],\n",
    "                                                    \"hash_size\": 2 ** 29,\n",
    "                                                    \"norm\": None,\n",
    "                                                    \"tf\": 'binary',\n",
    "                                                    \"idf\": None,\n",
    "                                                   }))\n",
    "wb.dictionary_freeze = True\n",
    "X_name_train = wb.fit_transform(df_train['name'])\n",
    "X_name_test = wb.transform(df_test['name'])\n",
    "del(wb)\n",
    "mask = np.where(X_name_train.getnnz(axis=0) > 3)[0]\n",
    "X_name_train = X_name_train[:, mask]\n",
    "X_name_test = X_name_test[:, mask]\n",
    "print('[{}] Vectorize `name` completed.'.format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = WordBatch(normalize_text, extractor=(WordBag, {\"hash_ngrams\": 2,\n",
    "                                                    \"hash_ngrams_weights\": [1.0, 1.0],\n",
    "                                                    \"hash_size\": 2 ** 28,\n",
    "                                                    \"norm\": \"l2\",\n",
    "                                                    \"tf\": 1.0,\n",
    "                                                    \"idf\": None}))\n",
    "wb.dictionary_freeze = True\n",
    "X_description_train = wb.fit_transform(df_train['item_description'])\n",
    "X_description_test = wb.transform(df_test['item_description'])\n",
    "del(wb)\n",
    "mask = np.where(X_description_train.getnnz(axis=0) > 3)[0]\n",
    "X_description_train = X_description_train[:, mask]\n",
    "X_description_test = X_description_test[:, mask]\n",
    "print('[{}] Vectorize `item_description` completed.'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, X_train_2, y_train_1, y_train_2 = train_test_split(X_description_train, y_train,\n",
    "                                                              test_size = 0.5,\n",
    "                                                              shuffle = False)\n",
    "print('[{}] Finished splitting'.format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge 함수 가져오기 (출처 : https://www.kaggle.com/object/more-effective-ridge-script?scriptVersionId=1851819)\n",
    "model = Ridge(solver=\"sag\", fit_intercept=True, random_state=205, alpha=3.3)\n",
    "model.fit(X_train_1, y_train_1)\n",
    "print('[{}] Finished to train desc ridge (1)'.format(time.time() - start_time))\n",
    "\n",
    "desc_ridge_preds1 = model.predict(X_train_2)\n",
    "desc_ridge_preds1f = model.predict(X_description_test)\n",
    "print('[{}] Finished to predict desc ridge (1)'.format(time.time() - start_time))\n",
    "\n",
    "model = Ridge(solver=\"sag\", fit_intercept=True, random_state=205, alpha=3.3)\n",
    "model.fit(X_train_2, y_train_2)\n",
    "print('[{}] Finished to train desc ridge (2)'.format(time.time() - start_time))\n",
    "\n",
    "desc_ridge_preds2 = model.predict(X_train_1)\n",
    "desc_ridge_preds2f = model.predict(X_description_test)\n",
    "print('[{}] Finished to predict desc ridge (2)'.format(time.time() - start_time))\n",
    "\n",
    "desc_ridge_preds_oof = np.concatenate((desc_ridge_preds2, desc_ridge_preds1), axis=0)\n",
    "desc_ridge_preds_test = (desc_ridge_preds1f + desc_ridge_preds2f) / 2.0\n",
    "print('RMSLE OOF: {}'.format(rmse(desc_ridge_preds_oof, y_train)))\n",
    "\n",
    "if not SUBMIT_MODE:\n",
    "    print('RMSLE TEST: {}'.format(rmse(desc_ridge_preds_test, y_test)))\n",
    "\n",
    "\n",
    "X_train_1, X_train_2, y_train_1, y_train_2 = train_test_split(X_name_train, y_train,\n",
    "                                                              test_size = 0.5,\n",
    "                                                              shuffle = False)\n",
    "print('[{}] Finished splitting'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge 함수 가져오기 (출처 : https://www.kaggle.com/object/more-effective-ridge-script?scriptVersionId=1851819)\n",
    "model = Ridge(solver=\"sag\", fit_intercept=True, random_state=205, alpha=3.3)\n",
    "model.fit(X_train_1, y_train_1)\n",
    "print('[{}] Finished to train name ridge (1)'.format(time.time() - start_time))\n",
    "\n",
    "name_ridge_preds1 = model.predict(X_train_2)\n",
    "name_ridge_preds1f = model.predict(X_name_test)\n",
    "print('[{}] Finished to predict name ridge (1)'.format(time.time() - start_time))\n",
    "\n",
    "model = Ridge(solver=\"sag\", fit_intercept=True, random_state=205, alpha=3.3)\n",
    "model.fit(X_train_2, y_train_2)\n",
    "print('[{}] Finished to train name ridge (2)'.format(time.time() - start_time))\n",
    "\n",
    "name_ridge_preds2 = model.predict(X_train_1)\n",
    "name_ridge_preds2f = model.predict(X_name_test)\n",
    "print('[{}] Finished to predict name ridge (2)'.format(time.time() - start_time))\n",
    "\n",
    "name_ridge_preds_oof = np.concatenate((name_ridge_preds2, name_ridge_preds1), axis=0)\n",
    "name_ridge_preds_test = (name_ridge_preds1f + name_ridge_preds2f) / 2.0\n",
    "print('RMSLE OOF: {}'.format(rmse(name_ridge_preds_oof, y_train)))\n",
    "if not SUBMIT_MODE:\n",
    "    print('RMSLE TEST: {}'.format(rmse(name_ridge_preds_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_1\n",
    "del X_train_2\n",
    "del y_train_1\n",
    "del y_train_2\n",
    "del name_ridge_preds1\n",
    "del name_ridge_preds1f\n",
    "del name_ridge_preds2\n",
    "del name_ridge_preds2f\n",
    "del desc_ridge_preds1\n",
    "del desc_ridge_preds1f\n",
    "del desc_ridge_preds2\n",
    "del desc_ridge_preds2f\n",
    "gc.collect()\n",
    "print('[{}] Finished garbage collection'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer(sparse_output=True)\n",
    "X_brand_train = lb.fit_transform(df_train['brand_name'])\n",
    "X_brand_test = lb.transform(df_test['brand_name'])\n",
    "print('[{}] Finished label binarize `brand_name`'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat_train = lb.fit_transform(df_train['gencat_name'])\n",
    "X_cat_test = lb.transform(df_test['gencat_name'])\n",
    "X_cat1_train = lb.fit_transform(df_train['subcat1_name'])\n",
    "X_cat1_test = lb.transform(df_test['subcat1_name'])\n",
    "X_cat2_train = lb.fit_transform(df_train['subcat2_name'])\n",
    "X_cat2_test = lb.transform(df_test['subcat2_name'])\n",
    "print('[{}] Finished label binarize categories'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummies_train = csr_matrix(\n",
    "    pd.get_dummies(df_train[list(cols - (basic_cols - {'item_condition_id', 'shipping'}))],\n",
    "                   sparse=True).values)\n",
    "print('[{}] Create dummies completed - train'.format(time.time() - start_time))\n",
    "\n",
    "X_dummies_test = csr_matrix(\n",
    "    pd.get_dummies(df_test[list(cols - (basic_cols - {'item_condition_id', 'shipping'}))],\n",
    "                   sparse=True).values)\n",
    "print('[{}] Create dummies completed - test'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_merge_train = hstack((X_dummies_train, X_description_train, X_brand_train, X_cat_train,\n",
    "                             X_cat1_train, X_cat2_train, X_name_train)).tocsr()\n",
    "del X_description_train, lb, X_name_train, X_dummies_train\n",
    "gc.collect()\n",
    "print('[{}] Create sparse merge train completed'.format(time.time() - start_time))\n",
    "\n",
    "sparse_merge_test = hstack((X_dummies_test, X_description_test, X_brand_test, X_cat_test,\n",
    "                             X_cat1_test, X_cat2_test, X_name_test)).tocsr()\n",
    "del X_description_test, X_name_test, X_dummies_test\n",
    "gc.collect()\n",
    "print('[{}] Create sparse merge test completed'.format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SUBMIT_MODE:\n",
    "    iters = 3\n",
    "else:\n",
    "    iters = 1\n",
    "    rounds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FM_FTRL(alpha=0.035, beta=0.001, L1=0.00001, L2=0.15, D=sparse_merge_train.shape[1],\n",
    "                alpha_fm=0.05, L2_fm=0.0, init_fm=0.01,\n",
    "                D_fm=100, e_noise=0, iters=iters, inv_link=\"identity\", threads=4)\n",
    "\n",
    "if SUBMIT_MODE:\n",
    "    model.fit(sparse_merge_train, y_train)\n",
    "    print('[{}] Train FM completed'.format(time.time() - start_time))\n",
    "    predsFM = model.predict(sparse_merge_test)\n",
    "    print('[{}] Predict FM completed'.format(time.time() - start_time))\n",
    "else:\n",
    "    for i in range(rounds):\n",
    "        model.fit(sparse_merge_train, y_train)\n",
    "        predsFM = model.predict(sparse_merge_test)\n",
    "        print('[{}] Iteration {}/{} -- RMSLE: {}'.format(time.time() - start_time, i + 1, rounds, rmse(predsFM, y_test)))\n",
    "\n",
    "del model\n",
    "gc.collect()\n",
    "if not SUBMIT_MODE:\n",
    "    print(\"FM_FTRL dev RMSLE:\", rmse(predsFM, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fselect = SelectKBest(f_regression, k=48000)\n",
    "train_features = fselect.fit_transform(sparse_merge_train, y_train)\n",
    "test_features = fselect.transform(sparse_merge_test)\n",
    "print('[{}] Select best completed'.format(time.time() - start_time))\n",
    "\n",
    "\n",
    "del sparse_merge_train\n",
    "del sparse_merge_test\n",
    "gc.collect()\n",
    "print('[{}] Garbage collection'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer(max_features=250000,\n",
    "                     ngram_range=(1, 3),\n",
    "                     stop_words=None)\n",
    "X_name_train = tv.fit_transform(df_train['name'])\n",
    "print('[{}] Finished TFIDF vectorize `name` (1/2)'.format(time.time() - start_time))\n",
    "X_name_test = tv.transform(df_test['name'])\n",
    "print('[{}] Finished TFIDF vectorize `name` (2/2)'.format(time.time() - start_time))\n",
    "\n",
    "tv = TfidfVectorizer(max_features=500000,\n",
    "                     ngram_range=(1, 3),\n",
    "                     stop_words=None)\n",
    "X_description_train = tv.fit_transform(df_train['item_description'])\n",
    "print('[{}] Finished TFIDF vectorize `item_description` (1/2)'.format(time.time() - start_time))\n",
    "X_description_test = tv.transform(df_test['item_description'])\n",
    "print('[{}] Finished TFIDF vectorize `item_description` (2/2)'.format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummies_train = csr_matrix(\n",
    "    pd.get_dummies(df_train[['item_condition_id', 'shipping']], sparse=True).values)\n",
    "X_dummies_test = csr_matrix(\n",
    "    pd.get_dummies(df_test[['item_condition_id', 'shipping']], sparse=True).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_merge_train = hstack((X_description_train, X_brand_train, X_cat_train,\n",
    "                             X_cat1_train, X_cat2_train, X_name_train)).tocsr()\n",
    "del X_dummies_train, X_description_train, X_brand_train, X_cat_train\n",
    "del X_cat1_train, X_cat2_train, X_name_train\n",
    "gc.collect()\n",
    "print('[{}] Create sparse merge train completed'.format(time.time() - start_time))\n",
    "\n",
    "sparse_merge_test = hstack((X_description_test, X_brand_test, X_cat_test,\n",
    "                            X_cat1_test, X_cat2_test, X_name_test)).tocsr()\n",
    "del X_dummies_test, X_description_test, X_brand_test, X_cat_test\n",
    "del X_cat1_test, X_cat2_test, X_name_test\n",
    "gc.collect()\n",
    "print('[{}] Create sparse merge test completed'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, X_train_2, y_train_1, y_train_2 = train_test_split(sparse_merge_train, y_train,\n",
    "                                                              test_size = 0.5,\n",
    "                                                              shuffle = False)\n",
    "print('[{}] Finished splitting'.format(time.time() - start_time))\n",
    "\n",
    "\n",
    "model = Ridge(solver=\"sag\", fit_intercept=True, random_state=205, alpha=3.3)\n",
    "model.fit(X_train_1, y_train_1)\n",
    "print('[{}] Finished to train ridge (1)'.format(time.time() - start_time))\n",
    "ridge_preds1 = model.predict(X_train_2)\n",
    "ridge_preds1f = model.predict(sparse_merge_test)\n",
    "print('[{}] Finished to predict ridge (1)'.format(time.time() - start_time))\n",
    "model = Ridge(solver=\"sag\", fit_intercept=True, random_state=205, alpha=3.3)\n",
    "model.fit(X_train_2, y_train_2)\n",
    "print('[{}] Finished to train ridge (2)'.format(time.time() - start_time))\n",
    "ridge_preds2 = model.predict(X_train_1)\n",
    "ridge_preds2f = model.predict(sparse_merge_test)\n",
    "print('[{}] Finished to predict ridge (2)'.format(time.time() - start_time))\n",
    "ridge_preds_oof = np.concatenate((ridge_preds2, ridge_preds1), axis=0)\n",
    "ridge_preds_test = (ridge_preds1f + ridge_preds2f) / 2.0\n",
    "print('RMSLE OOF: {}'.format(rmse(ridge_preds_oof, y_train)))\n",
    "if not SUBMIT_MODE:\n",
    "    print('RMSLE TEST: {}'.format(rmse(ridge_preds_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB(alpha=0.01)\n",
    "model.fit(X_train_1, y_train_1 >= 4)\n",
    "print('[{}] Finished to train MNB (1)'.format(time.time() - start_time))\n",
    "mnb_preds1 = model.predict_proba(X_train_2)[:, 1]\n",
    "mnb_preds1f = model.predict_proba(sparse_merge_test)[:, 1]\n",
    "print('[{}] Finished to predict MNB (1)'.format(time.time() - start_time))\n",
    "model = MultinomialNB(alpha=0.01)\n",
    "model.fit(X_train_2, y_train_2 >= 4)\n",
    "print('[{}] Finished to train MNB (2)'.format(time.time() - start_time))\n",
    "mnb_preds2 = model.predict_proba(X_train_1)[:, 1]\n",
    "mnb_preds2f = model.predict_proba(sparse_merge_test)[:, 1]\n",
    "print('[{}] Finished to predict MNB (2)'.format(time.time() - start_time))\n",
    "mnb_preds_oof = np.concatenate((mnb_preds2, mnb_preds1), axis=0)\n",
    "mnb_preds_test = (mnb_preds1f + mnb_preds2f) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ridge_preds1\n",
    "del ridge_preds1f\n",
    "del ridge_preds2\n",
    "del ridge_preds2f\n",
    "del mnb_preds1\n",
    "del mnb_preds1f\n",
    "del mnb_preds2\n",
    "del mnb_preds2f\n",
    "del X_train_1\n",
    "del X_train_2\n",
    "del y_train_1\n",
    "del y_train_2\n",
    "del sparse_merge_train\n",
    "del sparse_merge_test\n",
    "del model\n",
    "gc.collect()\n",
    "print('[{}] Finished garbage collection'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['ridge'] = ridge_preds_oof\n",
    "df_train['name_ridge'] = name_ridge_preds_oof\n",
    "df_train['desc_ridge'] = desc_ridge_preds_oof\n",
    "df_train['mnb'] = mnb_preds_oof\n",
    "df_test['ridge'] = ridge_preds_test\n",
    "df_test['name_ridge'] = name_ridge_preds_test\n",
    "df_test['desc_ridge'] = desc_ridge_preds_test\n",
    "df_test['mnb'] = mnb_preds_test\n",
    "print('[{}] Finished adding submodels'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_cats = ['brand_name', 'gencat_name', 'subcat1_name', 'subcat2_name', 'name_first']\n",
    "target_encode = TargetEncoder(min_samples_leaf=100, smoothing=10, noise_level=0.01,\n",
    "                              keep_original=True, cols=f_cats)\n",
    "df_train, df_test = target_encode.encode(df_train, df_test, y_train)\n",
    "print('[{}] Finished target encoding'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(f_cats, axis=1, inplace=True)\n",
    "df_test.drop(f_cats, axis=1, inplace=True)\n",
    "del mnb_preds_oof\n",
    "del mnb_preds_test\n",
    "del ridge_preds_oof\n",
    "del ridge_preds_test\n",
    "gc.collect()\n",
    "print('[{}] Finished garbage collection'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['gencat_name_te', 'brand_name_te', 'subcat1_name_te', 'subcat2_name_te',\n",
    "        'name_first_te', 'mnb', 'desc_ridge', 'name_ridge', 'ridge']\n",
    "train_dummies = csr_matrix(df_train[cols].values)\n",
    "print('[{}] Finished dummyizing model 1/5'.format(time.time() - start_time))\n",
    "test_dummies = csr_matrix(df_test[cols].values)\n",
    "print('[{}] Finished dummyizing model 2/5'.format(time.time() - start_time))\n",
    "del df_train\n",
    "del df_test\n",
    "gc.collect()\n",
    "print('[{}] Finished dummyizing model 3/5'.format(time.time() - start_time))\n",
    "train_features = hstack((train_features, train_dummies)).tocsr()\n",
    "print('[{}] Finished dummyizing model 4/5'.format(time.time() - start_time))\n",
    "test_features = hstack((test_features, test_dummies)).tocsr()\n",
    "print('[{}] Finished dummyizing model 5/5'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = lgb.Dataset(train_features, label=y_train)\n",
    "del train_features; gc.collect()\n",
    "if SUBMIT_MODE:\n",
    "    watchlist = [d_train]\n",
    "else:\n",
    "    d_valid = lgb.Dataset(test_features, label=y_test)\n",
    "    watchlist = [d_train, d_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': 0.15,\n",
    "    'application': 'regression',\n",
    "    'max_depth': 13,\n",
    "    'num_leaves': 400,\n",
    "    'verbosity': -1,\n",
    "    'metric': 'RMSE',\n",
    "    'data_random_seed': 1,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'feature_fraction': 0.6,\n",
    "    'nthread': 4,\n",
    "    'lambda_l1': 10,\n",
    "    'lambda_l2': 10\n",
    "}\n",
    "print('[{}] Finished compiling LGB'.format(time.time() - start_time))\n",
    "\n",
    "modelL = lgb.train(params,\n",
    "                  train_set=d_train,\n",
    "                  num_boost_round=1350,\n",
    "                  valid_sets=watchlist,\n",
    "                  verbose_eval=50)\n",
    "\n",
    "predsL = modelL.predict(test_features)\n",
    "predsL[predsL < 0] = 0\n",
    "\n",
    "if not SUBMIT_MODE:\n",
    "    print(\"LGB RMSLE:\", rmse(predsL, y_test))\n",
    "\n",
    "del d_train\n",
    "del modelL\n",
    "if not SUBMIT_MODE:\n",
    "    del d_valid\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_final = predsFM * 0.33 + predsL * 0.67\n",
    "if not SUBMIT_MODE:\n",
    "    print('Final RMSE: ', rmse(preds_final, y_test))\n",
    "\n",
    "\n",
    "if SUBMIT_MODE:\n",
    "    preds_final = np.expm1(preds_final)\n",
    "    submission['price'] = preds_final\n",
    "    submission.to_csv('lgb_and_fm_separate_train_test.csv', index=False)\n",
    "    print('[{}] Writing submission done'.format(time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
