{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "underlying-dylan",
   "metadata": {},
   "source": [
    "- Day 42 : 21/03/24\n",
    "- Toxic Comment Classification Challenge : https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-accounting",
   "metadata": {},
   "source": [
    "# Tackling Toxic Using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-multimedia",
   "metadata": {},
   "source": [
    "Keras LSTM을 사용해 분류 문제를 해결할 것이다. Keras 라이브러리를 임포트하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "third-approach",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T14:41:32.369333Z",
     "start_time": "2021-03-25T14:41:17.158286Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mental-vermont",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T14:41:38.984216Z",
     "start_time": "2021-03-25T14:41:37.027552Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "absolute-stocks",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T14:41:41.093265Z",
     "start_time": "2021-03-25T14:41:41.072320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-secret",
   "metadata": {},
   "source": [
    "일반적인 전처리 단계는 null을 확인하고 다음 단계로 진행하기 전 null값을 무언가로 채우는 것이다. null 값을 그대로 두면, 나중 모델링 단계에서 괴로울 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "legislative-collins",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T14:43:51.221750Z",
     "start_time": "2021-03-25T14:43:51.147947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(id               False\n",
       " comment_text     False\n",
       " toxic            False\n",
       " severe_toxic     False\n",
       " obscene          False\n",
       " threat           False\n",
       " insult           False\n",
       " identity_hate    False\n",
       " dtype: bool,\n",
       " id              False\n",
       " comment_text    False\n",
       " dtype: bool)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().any(), test.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-tunnel",
   "metadata": {},
   "source": [
    "null값을 처리할 필요가 없어 보인다.\n",
    "\n",
    "참고 : 데이터셋에 대해 수행할 수 있는 수많은 전처리 및 feature engineering 단계가 있지만, 오늘 초점은 전처리 작업에 대한 것이 아니므로 나머지 단계가 제대로 작동될 수 있는 최소 작업을 할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-crossing",
   "metadata": {},
   "source": [
    "종속 변수가 train 셋 자체에 있으므로 이것들을 X와 Y 셋으로 나눠야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "premium-travel",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T14:47:08.196472Z",
     "start_time": "2021-03-25T14:47:08.182511Z"
    }
   },
   "outputs": [],
   "source": [
    "list_classes = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "y = train[list_classes].values\n",
    "list_sentences_train = train['comment_text']\n",
    "list_sentences_test = test['comment_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-following",
   "metadata": {},
   "source": [
    "우리는 LSTM에 코멘트를 전달하는 접근방식을 취하지만, 단어를 그대로 전달할 수 없다. \n",
    "1. Tokenization : 문장을 하나의 단어로 나눠야한다. 예를 들어, 'I love cats and love dogs'는 ['I','love','cats','and','dogs']가 된다.\n",
    "2. Indexing : 단어들을 사전과 같은 구조로 배치하고 각각의 인덱스를 제공한다. 예: {1:'I', 2:'love', 3:'cats', 4:'and', 5:'dogs'}\n",
    "3. Index Representation : 코멘트에서 단어 순서를 인덱스 형식으로 나타낼 수 있고, 이 인덱스 체인을 LSTM에 제공할 수 있다. 예: [1,2,3,4,2,5]\n",
    "\n",
    "다행히 keras로 쉽게 할 수 있다. vanilla Tensorflow를 사용하는 경우, 자신만의 사전 구조를 구현하고 인덱스를 직접 처리해야할 수 있다. keras에서는 위의 모든 단계를 4줄의 코드로 수행할 수 있다. 문장을 토큰화할 때 사전에 고유 단어 수를 정의해야한다는 점에 유의하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "quarterly-hardwood",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T14:55:18.134971Z",
     "start_time": "2021-03-25T14:54:46.321892Z"
    }
   },
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-savage",
   "metadata": {},
   "source": [
    "이제 'list_tokenized_train'을 보면 keras가 우리 말을 인덱스 표현으로 바꾼 걸 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "frequent-arrow",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T14:55:48.230118Z",
     "start_time": "2021-03-25T14:55:48.210170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[688,\n",
       "  75,\n",
       "  1,\n",
       "  126,\n",
       "  130,\n",
       "  177,\n",
       "  29,\n",
       "  672,\n",
       "  4511,\n",
       "  12052,\n",
       "  1116,\n",
       "  86,\n",
       "  331,\n",
       "  51,\n",
       "  2278,\n",
       "  11448,\n",
       "  50,\n",
       "  6864,\n",
       "  15,\n",
       "  60,\n",
       "  2756,\n",
       "  148,\n",
       "  7,\n",
       "  2937,\n",
       "  34,\n",
       "  117,\n",
       "  1221,\n",
       "  15190,\n",
       "  2825,\n",
       "  4,\n",
       "  45,\n",
       "  59,\n",
       "  244,\n",
       "  1,\n",
       "  365,\n",
       "  31,\n",
       "  1,\n",
       "  38,\n",
       "  27,\n",
       "  143,\n",
       "  73,\n",
       "  3462,\n",
       "  89,\n",
       "  3085,\n",
       "  4583,\n",
       "  2273,\n",
       "  985]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tokenized_train[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-presence",
   "metadata": {},
   "source": [
    "하지만 아직 한 가지 문제가 있다. 어떤 댓글은 너무 길고 어떤 댓글은 한 단어일 뿐이다. 인덱스화된 문장은 다음과 같다. <br>\n",
    "Comment #1: [8,9,3,7,3,6,3,6,3,6,2,3,4,9] <br>\n",
    "Comment #2: [1,2] <br>\n",
    "또한 일관된 길이(변수의 고정 수)를 가진 데이터 스트림을 제공해야한다.<br>\n",
    "그리고 이것이 'padding'을 사용하는 이유다. 부족한 부분을 0으로 채워 다른 문장들처럼 짧은 문장을 만들 수 있다. 하지만 반면 긴 것을 짧은 것과 같은 길이(maxlen)로 잘라야한다. 이 경우 최대 길이는 200으로 설정했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mighty-ribbon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-25T15:04:46.959356Z",
     "start_time": "2021-03-25T15:04:43.692770Z"
    }
   },
   "outputs": [],
   "source": [
    "maxlen = 200\n",
    "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-saturday",
   "metadata": {},
   "source": [
    "설정하기 가장 좋은 'maxlen'가 몇인지 어떻게 알 수 있을까? 너무 짧게 설정하면 일부 정확도가 저하될 수 있는 유용한 변수를 잃을 수 있다. 너무 길게 설정하면 LSTM 셀이 가능한 값이나 상태를 저장하도록 더 커져야한다. \n",
    "\n",
    "이 문제를 해결하는 방법 중 하나는 문장의 단어 수 분포를 보는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-community",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-norway",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-strain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-nepal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-consumption",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-superior",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-bowling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-implementation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-constitution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-bruce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-riverside",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-measure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-sense",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-utility",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
