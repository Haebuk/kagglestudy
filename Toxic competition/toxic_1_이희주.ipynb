{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- competition/dataset : [https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data)\n",
    "- date : 2021/03/24\n",
    "- original : [https://www.kaggle.com/sbongo/for-beginners-tackling-toxic-using-keras](https://www.kaggle.com/sbongo/for-beginners-tackling-toxic-using-keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [For Beginners] Tackling Toxic Using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-19T23:23:23.804833Z",
     "iopub.status.busy": "2021-01-19T23:23:23.803834Z",
     "iopub.status.idle": "2021-01-19T23:23:23.811814Z",
     "shell.execute_reply": "2021-01-19T23:23:23.810817Z",
     "shell.execute_reply.started": "2021-01-19T23:23:23.804833Z"
    }
   },
   "source": [
    "**✏ 필사 1회** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 노트북은 Keras LSTM을 사용하여 이 분류 문제를 해결하고자 합니다. 많은 노트북들이 이미 이 접근 방법을 사용하여 해결하고 있으나 각 단계마다 진행되는 작업에 대한 설명이 충분하지 않다고 느낍니다. vanilla Tensorflow를 사용하고 최근에는 Keras의 멋진 세계를 받아들인 사람으로서 연구와 공부를 통해 내가 얻은 직관력을 동료 초보자들과 공유하기 원합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-24T02:48:41.812739Z",
     "iopub.status.busy": "2021-03-24T02:48:41.812739Z",
     "iopub.status.idle": "2021-03-24T02:48:41.831689Z",
     "shell.execute_reply": "2021-03-24T02:48:41.831689Z",
     "shell.execute_reply.started": "2021-03-24T02:48:41.812739Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-24T02:48:41.833684Z",
     "iopub.status.busy": "2021-03-24T02:48:41.833684Z",
     "iopub.status.idle": "2021-03-24T02:48:44.163735Z",
     "shell.execute_reply": "2021-03-24T02:48:44.162772Z",
     "shell.execute_reply.started": "2021-03-24T02:48:41.833684Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading the train and test files\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-24T02:48:44.166727Z",
     "iopub.status.busy": "2021-03-24T02:48:44.165729Z",
     "iopub.status.idle": "2021-03-24T02:48:44.179693Z",
     "shell.execute_reply": "2021-03-24T02:48:44.178704Z",
     "shell.execute_reply.started": "2021-03-24T02:48:44.166727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a sneak peek at the training and testing dataset\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적인 전처리 단계는 결측값을 확인하고 다음 단계로 넘어가기 전에 결측값을 채우는 것입니다. 만약 결측값을 그대로 두고 넘어간다면 이후에 모델링 단계에서 우리를 괴롭힐 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-24T02:48:44.183683Z",
     "iopub.status.busy": "2021-03-24T02:48:44.181688Z",
     "iopub.status.idle": "2021-03-24T02:48:44.227565Z",
     "shell.execute_reply": "2021-03-24T02:48:44.226566Z",
     "shell.execute_reply.started": "2021-03-24T02:48:44.183683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               False\n",
       "comment_text     False\n",
       "toxic            False\n",
       "severe_toxic     False\n",
       "obscene          False\n",
       "threat           False\n",
       "insult           False\n",
       "identity_hate    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-24T02:48:44.229560Z",
     "iopub.status.busy": "2021-03-24T02:48:44.228563Z",
     "iopub.status.idle": "2021-03-24T02:48:44.273442Z",
     "shell.execute_reply": "2021-03-24T02:48:44.272444Z",
     "shell.execute_reply.started": "2021-03-24T02:48:44.229560Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              False\n",
       "comment_text    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값을 다룰 필요가 없어 보입니다!  \n",
    "\n",
    "데이터 셋에 대해 수행할 수 있는 수많은 전처리와 feature engineering 단계가 있지만 오늘 우리의 목적은 전처리가 아니기 때문에 여기서 우리가 하고 있는 것은 남은 단계들을 잘 작동시킬 수 있는 최소한의 전처리입니다.  \n",
    "\n",
    "위에서 잠시 봤던 것처럼 종속 변수들은 트레이닝 셋 자체에 있기 때문에 이들을 X와 Y 셋으로 나눠야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-24T02:48:44.276435Z",
     "iopub.status.busy": "2021-03-24T02:48:44.275437Z",
     "iopub.status.idle": "2021-03-24T02:48:44.319319Z",
     "shell.execute_reply": "2021-03-24T02:48:44.318322Z",
     "shell.execute_reply.started": "2021-03-24T02:48:44.276435Z"
    }
   },
   "outputs": [],
   "source": [
    "list_classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "y = train[list_classes].values\n",
    "list_sentences_train = train['comment_text']\n",
    "list_sentences_test = test['comment_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 취하고 있는 접근 방법은 신경망 일부에 LSTM의 의견을 전달하는 것이지만 단어를 그대로 전달할 수는 없습니다.  \n",
    "\n",
    "따라서 우리가 해야할 것들은 다음과 같습니다:  \n",
    "1. Tokenization - 문장을 고유 단어들로 쪼개야 합니다. 예를 들어 'I love cats and love dogs'는 ['I', 'love', 'cats', 'and', 'dogs']가 될 것입니다.  \n",
    "2. Indexing - 단어를 딕셔너리와 같은 구조에 넣고 각각에 인덱스를 주어야 합니다. ({1:'I', 2:'love', 3:'cats', 4:'and', 5:'dogs'}\n",
    "3. Index Representation - 단어의 순서를 인덱스 형태의 코멘트로 나타낼 수 있으며, 우리의 LSTM에 인덱스 체인을 입력할 수 있습니다. ([1, 2, 3, 4, 2, 5])\n",
    "\n",
    "다행히도, Keras는 이것들을 매우 쉽게 해줍니다. vanilla Tensorflow를 사용했다면 아마도 딕셔너리 형태를 직접 구현하고 인덱싱도 직접 다루어야 할 것입니다. Keras에서는 위의 모든 단계가 단 네 줄의 코드로 완성될 수 있습니다. 문장을 토큰화할 때 고유한 단어의 수를 정의해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-24T02:48:44.320316Z",
     "iopub.status.busy": "2021-03-24T02:48:44.320316Z",
     "iopub.status.idle": "2021-03-24T02:49:11.161217Z",
     "shell.execute_reply": "2021-03-24T02:49:11.160250Z",
     "shell.execute_reply.started": "2021-03-24T02:48:44.320316Z"
    }
   },
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또한 딕셔너리에서 각 단어의 발생과 색인도 살펴볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-24T02:49:11.162201Z",
     "iopub.status.busy": "2021-03-24T02:49:11.162201Z",
     "iopub.status.idle": "2021-03-24T02:49:11.176165Z",
     "shell.execute_reply": "2021-03-24T02:49:11.175168Z",
     "shell.execute_reply.started": "2021-03-24T02:49:11.162201Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 단어\n",
    "# tokenizer.word_counts\n",
    "# 인덱스\n",
    "# tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list_tokenized_train을 살펴보면 Keras가 단어를 인덱스 형태로 바꾼 것을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-24T02:49:11.181151Z",
     "iopub.status.busy": "2021-03-24T02:49:11.179157Z",
     "iopub.status.idle": "2021-03-24T02:49:11.192121Z",
     "shell.execute_reply": "2021-03-24T02:49:11.191124Z",
     "shell.execute_reply.started": "2021-03-24T02:49:11.181151Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[688,\n",
       "  75,\n",
       "  1,\n",
       "  126,\n",
       "  130,\n",
       "  177,\n",
       "  29,\n",
       "  672,\n",
       "  4511,\n",
       "  12052,\n",
       "  1116,\n",
       "  86,\n",
       "  331,\n",
       "  51,\n",
       "  2278,\n",
       "  11448,\n",
       "  50,\n",
       "  6864,\n",
       "  15,\n",
       "  60,\n",
       "  2756,\n",
       "  148,\n",
       "  7,\n",
       "  2937,\n",
       "  34,\n",
       "  117,\n",
       "  1221,\n",
       "  15190,\n",
       "  2825,\n",
       "  4,\n",
       "  45,\n",
       "  59,\n",
       "  244,\n",
       "  1,\n",
       "  365,\n",
       "  31,\n",
       "  1,\n",
       "  38,\n",
       "  27,\n",
       "  143,\n",
       "  73,\n",
       "  3462,\n",
       "  89,\n",
       "  3085,\n",
       "  4583,\n",
       "  2273,\n",
       "  985]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tokenized_train[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러나 여전히 한 가지 문제점이 있습니다. 일부 코멘트는 끔찍하게 긴 반면 어떤 단어는 그저 한 글자라면 어떨까요? 다음과 같은 경우가 있습니다:  \n",
    "\n",
    "Comment #1: [8, 9, 3, 7, 3, 6, 3, 6, 3, 6, 2, 3, 4, 9]  \n",
    "Comment #2: [1, 2]  \n",
    "\n",
    "또한 일관된 길이(고정된 수의 feature)를 가진 데이터 스트림을 제공해야 합니다.  \n",
    "\n",
    "이것이 padding을 사용하는 이유입니다. 0으로 부족한 부분을 채워 짧은 문장을 다른 문장의 길이로 만들어 줄 수 있습니다. 그러나 반대로 긴 문장도 긴 것은 짧은 것과 같은 길이로 잘라야 합니다. 이 경우에 우리는 max length를 200으로 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-24T02:49:11.194116Z",
     "iopub.status.busy": "2021-03-24T02:49:11.193119Z",
     "iopub.status.idle": "2021-03-24T02:49:13.898642Z",
     "shell.execute_reply": "2021-03-24T02:49:13.897684Z",
     "shell.execute_reply.started": "2021-03-24T02:49:11.194116Z"
    }
   },
   "outputs": [],
   "source": [
    "maxlen = 200\n",
    "x_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "x_te = pad_sequences(list_tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적의 maxlen은 어떻게 알 수 있을까요? 너무 짧은 값을 넣게 되면, 유용한 feature를 잃어 정확도가 떨어질 수 있습니다. 반대로 너무 긴 값을 넣으면, LSTM 셀이 더 커야 가능한 값이나 상태를 저장할 수 있습니다.  \n",
    "\n",
    "그 방법을 찾는 방법 중 하나는 문장 내 단어의 수의 분포를 보는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-24T02:49:13.900636Z",
     "iopub.status.busy": "2021-03-24T02:49:13.899639Z",
     "iopub.status.idle": "2021-03-24T02:49:13.930556Z",
     "shell.execute_reply": "2021-03-24T02:49:13.929580Z",
     "shell.execute_reply.started": "2021-03-24T02:49:13.900636Z"
    }
   },
   "outputs": [],
   "source": [
    "totalNumWords = [len(one_comment) for one_comment in list_tokenized_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-24T02:49:13.933548Z",
     "iopub.status.busy": "2021-03-24T02:49:13.932551Z",
     "iopub.status.idle": "2021-03-24T02:49:14.780840Z",
     "shell.execute_reply": "2021-03-24T02:49:14.779871Z",
     "shell.execute_reply.started": "2021-03-24T02:49:13.933548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(totalNumWords, bins=np.arange(0, 410, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대부분 문장의 길이는 30 정도입니다. maxlen을 50으로 설정할 수도 있습니다. 실험해보면서 마법의 숫자가 무엇인지 찾을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally the start of building our model!\n",
    "다음은 우리가 구축하고자 하는 모델의 구조입니다. 모델의 각 레이어의 차원을 나열하여 시각적으로 생각하고 이후에 디버깅에 도움이 될 수 있도록 하는 것이 좋습니다.  \n",
    "![](data/txJomEa.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input Layer\n",
    "이전에도 언급했던 것처럼 우리 네트워크의 입력은 인코딩된 문장의 리스트입니다. 우선 차원이 200인 문장 리스트를 받는 입력 레이어를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-24T02:49:14.782836Z",
     "iopub.status.busy": "2021-03-24T02:49:14.781838Z",
     "iopub.status.idle": "2021-03-24T02:49:14.796798Z",
     "shell.execute_reply": "2021-03-24T02:49:14.795800Z",
     "shell.execute_reply.started": "2021-03-24T02:49:14.782836Z"
    }
   },
   "outputs": [],
   "source": [
    "# 콤마 이후에 공백은 keras가 자동으로 연산하게 하기 위함\n",
    "inp = Input(shape=(maxlen,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 다음 임베딩 레이어로 전달하여 문장 내 주변 단어의 거리에 따라 단어를 벡터 공간에 투영합니다. 임베딩은 모델 크기와 문장의 단어를 나타내기 위해 one-hot encoding을 사용한 경우 다뤄야 하는 거대한 차원을 줄일 수 있습니다.  \n",
    "\n",
    "임베딩 레이어의 출력은 벡터 공간의 단어의 좌표 리스트입니다. 예를 들어 cat은 (-81.012), dog는 (-80.012)입니다. 또한 이러한 좌표의 거리를 이용하여 관련성과 맥락을 알 수 있습니다. 임베딩은 꽤 깊은 주제이기 때문에 흥미가 있다면 다음 가이드를 살펴보세요: [https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/](https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/)  \n",
    "\n",
    "위에서 언급한 벡터 공간의 크기와 사용하고 있는 고유한 단어의 수(max_features)를 정의해야 합니다. 임베딩 크기는 조절이 가능한 파라미터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-24T02:49:14.798793Z",
     "iopub.status.busy": "2021-03-24T02:49:14.798793Z",
     "iopub.status.idle": "2021-03-24T02:49:14.843673Z",
     "shell.execute_reply": "2021-03-24T02:49:14.842710Z",
     "shell.execute_reply.started": "2021-03-24T02:49:14.798793Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_size = 128\n",
    "x = Embedding(max_features, embed_size)(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임베딩 레이어는 (None, 200, 128)의 3D tensor를 출력했습니다. 이것은 문장의 배열(None)이며, 각 단어들(200)에 대해 임베딩의 벡터 공간에 128개의 좌표 배열이 있습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Layer\n",
    "\n",
    "다음으로 우리는 이 Tensor를 LSTM 레이어에 입력합니다. 우리는 LSTM이 차원이 60인 출력을 만들도록 설정하며, LSTM이 롤링되지 않은 결과 시퀀스를 리턴하기를 원합니다. 알고 있듯이, LSTM이나 RNN은 이전 네트워크의 출력을 현재 네트워크의 입력으로 재귀적으로 입력하는 방식으로 작동하며, x번의 반복 이후에 최종 출력을 얻을 수 있습니다. 그러나 경우에 따라 롤링되지 않은 결과나 다음 레이어로 전달하기 위한 결과로써의 각 반복의 결과를 원할 수 있습니다.  \n",
    "\n",
    "![](data/RNN-unrolled.png)  \n",
    "\n",
    "위 그림에서 unrolled LSTM는 $h_{0}$, $h_{1}$, $h_{2}$, ..., $h_{t}$를 제공합니다.  \n",
    "\n",
    "LSTM 레이어를 정의하는 짧은 코드 라인에서 필요한 입력 차원을 놓치기 쉽습니다. LSTM은 [batch size, time steps, input 수]의 tensor를 받습니다.  \n",
    "- 배치 사이즈: 배치의 샘플 수  \n",
    "- 타임 스텝: 각 입력에 대해 실행되는 재귀 횟수이거나 위 그림에서 A의 수  \n",
    "- 입력 수: 위 그림에서 x와 같이 LSTM에 전달하는 변수의 수  \n",
    "\n",
    "LSTM 레이어로 (None, 200, 128)의 3-D tensor를 출력하는 이전 임베딩 레이어로부터 출력을 사용할 수 있습니다. 이 방법은 샘플을 통해 LSTM 모델을 200회 반복 실행하며, 매번 단어의 좌표를 전달합니다. 또한 우리는 unrolled 버전을 원하기 때문에 (None, 200, 6) 형태의 tensor를 받을 것이며, 여기서 60은 우리가 정의한 출력 차원입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-24T02:49:14.844669Z",
     "iopub.status.busy": "2021-03-24T02:49:14.844669Z",
     "iopub.status.idle": "2021-03-24T02:49:15.211016Z",
     "shell.execute_reply": "2021-03-24T02:49:15.210060Z",
     "shell.execute_reply.started": "2021-03-24T02:49:14.844669Z"
    }
   },
   "outputs": [],
   "source": [
    "x = LSTM(60, return_sequences=True, name='lstm_layer')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과물을 일반 레이어에 전달하기 전에 3D tenser을 2D tenser로 변형시켜야 합니다. 우리에게 중요한 데이터를 버리지 않기 위해 주의해서 변형시켜야 하며, 이상적으로 우리는 원래의 데이터를 잘 대표하는 결과의 데이터를 원합니다.  \n",
    "\n",
    "따라서, CNN 문제에서 이미지 데이터의 차원을 줄이는 데 전통적으로 사용되는 Global Max Pooling 레이어를 사용합니다. 간단히 말하면, 각 데이터의 패치를 검토하고, 각 패치의 최댓값을 가져옵니다. 최댓값의 집합은 우리가 사용할 수 있는 새로운 down-sized 데이터일 것입니다.  \n",
    "\n",
    "다른 Kaggle 커널에서 봤듯이, pooling 레이어의 다른 변형들(평균, 최댓값 등)은 차원 축소를 위해 사용하며, 다른 결과물를 산출할 수 있으므로 사용해 보세요.  \n",
    "\n",
    "pooling에 대한 자세한 내용이 궁금하다면 여기서 읽어보세요: [https://wiseodd.github.io/techblog/2016/07/18/convnet-maxpool-layer/](https://wiseodd.github.io/techblog/2016/07/18/convnet-maxpool-layer/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-24T02:49:15.213012Z",
     "iopub.status.busy": "2021-03-24T02:49:15.213012Z",
     "iopub.status.idle": "2021-03-24T02:49:15.226985Z",
     "shell.execute_reply": "2021-03-24T02:49:15.225977Z",
     "shell.execute_reply.started": "2021-03-24T02:49:15.213012Z"
    }
   },
   "outputs": [],
   "source": [
    "x = GlobalMaxPool1D()(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout Layer\n",
    "다음 레이어에 있는 노드가 누락된 데이터를 처리하고 전체 네트워크가 더 나은 일반화를 할 수 있도록 일부 노드들을 무차별적으로 비홞성화시키는 dropout 레이어에 2D tensor를 전달합니다.  \n",
    "\n",
    "우리는 노드의 10%(0.1)를 제거하는 dropout 레이어를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-24T02:51:39.206659Z",
     "iopub.status.busy": "2021-03-24T02:51:39.205662Z",
     "iopub.status.idle": "2021-03-24T02:51:39.235581Z",
     "shell.execute_reply": "2021-03-24T02:51:39.234583Z",
     "shell.execute_reply.started": "2021-03-24T02:51:39.206659Z"
    }
   },
   "outputs": [],
   "source": [
    "x = Dropout(0.1)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense Layer\n",
    "dropout 레이어의 출력을 조밀하게 연결된 layer와 연결하고 그 출력을 ReLU 함수에 전달합니다. 간단히 말하자면 다음과 같습니다:  \n",
    "\n",
    "<center>Activation(Input * weights + bias)<\\center>  \n",
    "    \n",
    "가중치, 편향, activation 레이어가 전부 한 줄로 해결됩니다. 출력 차원이 50이 되도록 Dense 레이어를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-24T02:56:45.118354Z",
     "iopub.status.busy": "2021-03-24T02:56:45.118354Z",
     "iopub.status.idle": "2021-03-24T02:56:45.144258Z",
     "shell.execute_reply": "2021-03-24T02:56:45.143260Z",
     "shell.execute_reply.started": "2021-03-24T02:56:45.118354Z"
    }
   },
   "outputs": [],
   "source": [
    "x = Dense(50, activation='relu')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout Layer\n",
    "출력을 다시 Dropout 레이어에 입력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-24T02:57:54.270422Z",
     "iopub.status.busy": "2021-03-24T02:57:54.269424Z",
     "iopub.status.idle": "2021-03-24T02:57:54.303333Z",
     "shell.execute_reply": "2021-03-24T02:57:54.302366Z",
     "shell.execute_reply.started": "2021-03-24T02:57:54.270422Z"
    }
   },
   "outputs": [],
   "source": [
    "x = Dropout(0.1)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid Layer\n",
    "최종적으로, 출력을 Sigmoid 레이어에 입력합니다. 시그모이드가 사용되는 이유는 우리가 6개의 레이블 각각에 대해 이진 분류 (0.1)를 하고자 하며, 시그모이드 함수가 출력을 0과 1 사이로 압축시킬 수 있기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-24T02:59:41.879883Z",
     "iopub.status.busy": "2021-03-24T02:59:41.879883Z",
     "iopub.status.idle": "2021-03-24T02:59:41.894842Z",
     "shell.execute_reply": "2021-03-24T02:59:41.893878Z",
     "shell.execute_reply.started": "2021-03-24T02:59:41.879883Z"
    }
   },
   "outputs": [],
   "source": [
    "x = Dense(6, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Model\n",
    "이제 거의 완성되었습니다! 남은 것은 입력과 출력을 정의하고 학습 프로세스를 설정하는 것입니다. 우리는 이진 분류를 다루기 때문에 Adam 옵티마이저를 사용하여 손실 함수를 최적화하고, 손실 함수를 binary_crossentropy로 정의하도록 모델을 설정합니다. learning rate의 기본값은 0.001입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-24T03:04:35.605790Z",
     "iopub.status.busy": "2021-03-24T03:04:35.604792Z",
     "iopub.status.idle": "2021-03-24T03:04:35.634712Z",
     "shell.execute_reply": "2021-03-24T03:04:35.633735Z",
     "shell.execute_reply.started": "2021-03-24T03:04:35.605790Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Model\n",
    "이제 우리의 모델을 테스트하는 시간입니다. 각 배치에 대해 32개의 패딩 및 인덱싱된 리스트를 입력하고, 데이터의 10%는 검증용 셋으로 분할합니다. 검증용 셋은 각 배치마다 모델이 과적합되었는지 평가하는데 사용됩니다. epochs는 2로 설정합니다. 이러한 파라미터는 모델을 손상시키지 않고 정확도를 더 높은 수준으로 끌어올릴 수 있는지 실험해볼 수 있는 하이퍼 파라미터 중 일부입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-24T03:09:56.503840Z",
     "iopub.status.busy": "2021-03-24T03:09:56.502843Z",
     "iopub.status.idle": "2021-03-24T03:24:14.647738Z",
     "shell.execute_reply": "2021-03-24T03:24:14.646740Z",
     "shell.execute_reply.started": "2021-03-24T03:09:56.503840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "4488/4488 [==============================] - 419s 93ms/step - loss: 0.0690 - accuracy: 0.9594 - val_loss: 0.0483 - val_accuracy: 0.9937\n",
      "Epoch 2/2\n",
      "4488/4488 [==============================] - 436s 97ms/step - loss: 0.0444 - accuracy: 0.9874 - val_loss: 0.0459 - val_accuracy: 0.9926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d2a3e182c8>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_t, y, batch_size=32, epochs=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional Tips and Tricks\n",
    "**1.**  \n",
    "만약 어떤 장애물을 만났을때, 특히 차원과 관련된 오류가 생기기 시작할 때 가장 좋은 아이디어는 `model.summary()`를 보는 것입니다. 여기에는 진단에 유용한 모든 레이어의 출력이 나열되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-24T04:01:09.603534Z",
     "iopub.status.busy": "2021-03-24T04:01:09.602537Z",
     "iopub.status.idle": "2021-03-24T04:01:09.615503Z",
     "shell.execute_reply": "2021-03-24T04:01:09.614528Z",
     "shell.execute_reply.started": "2021-03-24T04:01:09.603534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "lstm_layer (LSTM)            (None, 200, 60)           45360     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                3050      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 2,608,716\n",
      "Trainable params: 2,608,716\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.**  \n",
    "레이어를 추가하고 고급 변환을 수행하는 동안 출력이 내 예상대로 잘 수행되었는지 확인하는 것도 좋은 방법입니다. 다음과 같이 특정 레이어의 출력을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-24T04:09:10.830376Z",
     "iopub.status.busy": "2021-03-24T04:09:10.830376Z",
     "iopub.status.idle": "2021-03-24T04:09:11.000921Z",
     "shell.execute_reply": "2021-03-24T04:09:10.997928Z",
     "shell.execute_reply.started": "2021-03-24T04:09:10.830376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 200, 60)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "get_3rd_layer_output = K.function([model.layers[0].input], [model.layers[2].output])\n",
    "layer_output = get_3rd_layer_output([x_t[:1]])[0]\n",
    "layer_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**  \n",
    "1. 정확도 향상을 위해 전처리된 모델 사용  \n",
    "2. 하이퍼 파라미터 튜닝  \n",
    "3. 모델 훈련에 early stopping 적용  \n",
    "4. 다른 아키텍처 실험"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
