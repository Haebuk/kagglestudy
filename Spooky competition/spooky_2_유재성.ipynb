{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "equipped-mainland",
   "metadata": {},
   "source": [
    "# Approaching (Almost) Any NLP Problem on Kaggle\n",
    "https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-medicine",
   "metadata": {},
   "source": [
    "매우 기본적인 첫 번째 모델을 만든 다음 다른 기능을 이용하여 개선할 것입니다. 또한 신경망들이 얼마나 깊이 사용될 수 있는지 살펴볼 것입니다. 그리고 일반적인 조합에 대한 몇가지 아이디어로 게시물을 마칩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fiscal-affect",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T07:06:02.644897Z",
     "start_time": "2021-03-10T07:06:02.629883Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "turkish-variable",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T07:06:31.448079Z",
     "start_time": "2021-03-10T07:06:31.357998Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/test.csv')\n",
    "sample = pd.read_csv('./input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tropical-satin",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T07:06:34.343712Z",
     "start_time": "2021-03-10T07:06:34.325695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "turkish-insight",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T07:06:43.575103Z",
     "start_time": "2021-03-10T07:06:43.558088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
       "1  id24541  If a fire wanted fanning, it could readily be ...\n",
       "2  id00134  And when they had broken down the frail door t...\n",
       "3  id27757  While I was thinking how I should possibly man...\n",
       "4  id04081  I am not sure to what limit his knowledge may ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "convertible-salem",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T07:06:46.997214Z",
     "start_time": "2021-03-10T07:06:46.982200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       EAP       HPL       MWS\n",
       "0  id02310  0.403494  0.287808  0.308698\n",
       "1  id24541  0.403494  0.287808  0.308698\n",
       "2  id00134  0.403494  0.287808  0.308698\n",
       "3  id27757  0.403494  0.287808  0.308698\n",
       "4  id04081  0.403494  0.287808  0.308698"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-details",
   "metadata": {},
   "source": [
    "이 문제는 저자를 예측해야 합니다. 즉 EAP, HPL, MWS가 텍스트로 주어집니다. 간단히 말해서, 텍스트 분류는 3개의 클래스로 분류됩니다.\n",
    "\n",
    "이 문제의 평가 지표는 다중 클래스 로그 손실입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "stuffed-feature",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T07:15:48.422881Z",
     "start_time": "2021-03-10T07:15:48.405866Z"
    }
   },
   "outputs": [],
   "source": [
    "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
    "    # 'actual'을 이진 어레이로 변환\n",
    "    if len(actual.shape) == 1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[-1]))\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "        \n",
    "    clip = np.clip(predicted, eps, 1-eps)\n",
    "    rows = actual.shape[0]\n",
    "    vsota = np.sum(actual * np.log(clip))\n",
    "    return -1.0 / rows * vsota"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-dollar",
   "metadata": {},
   "source": [
    "사이킷런의 레이블인코더를 사용해 텍스트 레이블을 0,1,2로 바꿉니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "agreed-senate",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T07:15:49.332709Z",
     "start_time": "2021-03-10T07:15:49.325703Z"
    }
   },
   "outputs": [],
   "source": [
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(train.author.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-southeast",
   "metadata": {},
   "source": [
    "더 나아가기 전에 데이터를 교육 및 검증 세트로 나누는 것이 중요합니다. 사이킷런의 train_test_split을 사용하여 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "painful-lease",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T07:15:49.749087Z",
     "start_time": "2021-03-10T07:15:49.725066Z"
    }
   },
   "outputs": [],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train.text.values, y, stratify=y,\n",
    "                                                  random_state=42,\n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "infinite-pursuit",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T07:15:49.925247Z",
     "start_time": "2021-03-10T07:15:49.918241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17621,)\n",
      "(1958,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(xvalid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-nerve",
   "metadata": {},
   "source": [
    "## Building Basic Models\n",
    "첫 번째 모델을 만들어 보겠습니다.\n",
    "\n",
    "첫 번쨰 모델은 단순 TF-IDF(용어 빈도- 역문서 빈도)이고 그 다음은 단순 로지스틱 회귀 분석입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "instrumental-corporation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T07:15:52.613691Z",
     "start_time": "2021-03-10T07:15:51.229433Z"
    }
   },
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(min_df=3, max_features=None,\n",
    "                      strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}',\n",
    "                      ngram_range=(1,3), use_idf=1, smooth_idf=1, sublinear_tf=1,\n",
    "                      stop_words='english')\n",
    "\n",
    "# 교육, 테스트 셋에 적합\n",
    "tfv.fit(list(xtrain) +list(xvalid))\n",
    "xtrain_tfv = tfv.transform(xtrain)\n",
    "xvalid_tfv = tfv.transform(xvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "defined-density",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T07:15:53.397404Z",
     "start_time": "2021-03-10T07:15:52.614692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tens_2g\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# 로지스틱회귀 적합\n",
    "clf = LogisticRegression(C=1.0)\n",
    "clf.fit(xtrain_tfv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_tfv)\n",
    "\n",
    "print('logloss: %0.3f' % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-posting",
   "metadata": {},
   "source": [
    "0.572의 다중 클래스 로그 손실을 가진 첫 번째 모델을 얻었습니다.\n",
    "\n",
    "하지만 더 좋은 점수를 원하기 때문에, 다른 데이터로 동일한 모형을 살펴보겠습니다.\n",
    "\n",
    "TF-IDF를 사용하는 대신 단어 수를 피쳐로 사용할 수도 있습니다. 이 작업은 사이킷런의 Vectorizer를 사용하여 쉽게 수행할수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "numeric-plumbing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T07:18:36.603760Z",
     "start_time": "2021-03-10T07:18:34.536882Z"
    }
   },
   "outputs": [],
   "source": [
    "ctv = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}',\n",
    "                      ngram_range=(1, 3), stop_words='english')\n",
    "# 카운트 벡터라이저를 훈련, 테스트 셋에 적합\n",
    "ctv.fit(list(xtrain) + list(xvalid))\n",
    "xtrain_ctv = ctv.transform(xtrain)\n",
    "xvalid_ctv = ctv.transform(xvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "educated-liberal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T07:20:42.697381Z",
     "start_time": "2021-03-10T07:20:32.253888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tens_2g\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# 단순 로지스틱 회귀를 적용\n",
    "clf = LogisticRegression(C=1.0)\n",
    "clf.fit(xtrain_ctv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_ctv)\n",
    "\n",
    "print('logloss: %0.3f' % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-nerve",
   "metadata": {},
   "source": [
    "첫 번째 모델을 0.045 개선했습니다.\n",
    "\n",
    "다음으로 예전에 유명했던 매우 단순한 모델 Naive bayse 모델을 사용해보겠습니다.\n",
    "\n",
    "다음 두 데이터 셋에서 나이브 베이즈를 사용할 때 어떤 일이 일어나는지 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "intensive-spank",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T07:22:14.831132Z",
     "start_time": "2021-03-10T07:22:14.822124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.578\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(xtrain_tfv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_tfv)\n",
    "\n",
    "print('logloss: %0.3f' % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-destruction",
   "metadata": {},
   "source": [
    "카운트에 대한 로지스틱 회귀 분석이 더 좋습니다. 대신 카운트 데이터에 이 모델을 사용할 때 어떻게 되는지 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "included-clinic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T07:23:23.829356Z",
     "start_time": "2021-03-10T07:23:23.788319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.485\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(xtrain_ctv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_ctv)\n",
    "print('logloss: %0.3f' % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-mistake",
   "metadata": {},
   "source": [
    "오래된 방법이 여전히 효과가 있는 것 같습니다. 추가로 유명한 알고리즘 중 하나는 SVM입니다. \n",
    "\n",
    "SVM은 시간이 많이 걸리기 때문에 적용하기 전 Single Value Decomposition을 사용하여 TF-IDF의 피쳐수를 줄입니다.\n",
    "\n",
    "또한 SVM을 적용하기 전에 데이터를 표준화해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "varied-happening",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T10:39:23.176292Z",
     "start_time": "2021-03-10T10:39:22.212416Z"
    }
   },
   "outputs": [],
   "source": [
    "# SVD 적용, 120개의 요소를 선택, 120-200개의 요소가 SVM 모델에 적합\n",
    "svd = decomposition.TruncatedSVD(n_components=120)\n",
    "svd.fit(xtrain_tfv)\n",
    "xtrain_svd = svd.transform(xtrain_tfv)\n",
    "xvalid_svd = svd.transform(xvalid_tfv)\n",
    "\n",
    "# SVD로 얻은 데이터 스케일링. \n",
    "scl = preprocessing.StandardScaler()\n",
    "scl.fit(xtrain_svd)\n",
    "xtrain_svd_scl = scl.transform(xtrain_svd)\n",
    "xvalid_svd_scl = scl.transform(xvalid_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-physiology",
   "metadata": {},
   "source": [
    "이제 SVM을 적용해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "executed-scale",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T10:43:10.448621Z",
     "start_time": "2021-03-10T10:41:17.332119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.729\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "clf = SVC(C=1.0, probability=True) \n",
    "clf.fit(xtrain_svd_scl, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_svd_scl)\n",
    "\n",
    "print('logloss: %0.3f' % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-gateway",
   "metadata": {},
   "source": [
    "점수가 매우 좋지 않게 나왔습니다. SVM이 현재 데이터에 적합하지 않는 방법인것 같습니다.\n",
    "\n",
    "더 나아가서 xgboost를 사용해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "latin-arrow",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T10:45:42.311714Z",
     "start_time": "2021-03-10T10:45:34.286420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.782\n"
     ]
    }
   ],
   "source": [
    "# xgboost를 tf-idf에 적합\n",
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8,\n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "clf.fit(xtrain_tfv.tocsc(), ytrain)\n",
    "predictions = clf.predict_proba(xvalid_tfv.tocsc())\n",
    "\n",
    "print('logloss: %0.3f' % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-exception",
   "metadata": {},
   "source": [
    "xgboost도 정확하지 않습니다. 아직 하이퍼 파라미터 최적화를 하지 않았습니다. 이 문제는 다음 섹션에서 설명합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-registration",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "하이퍼 파라미터 최적화를 위한 기술입니다. 그리 효과적이진 않지만 사용할 그리드를 알고 있으면 좋은 결과를 얻을 수 있습니다. \n",
    "\n",
    "이 섹션에서는 로지스틱 회귀 분석을 사용한 그리드 검색에 대해 설명합니다.\n",
    "\n",
    "그리드 검색을 시작하기 전에 점수 매기기 기능을 만들어야 합니다. 이 작업은 사이킷런의 make_scorer 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "sapphire-trouble",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T10:49:00.667608Z",
     "start_time": "2021-03-10T10:49:00.662604Z"
    }
   },
   "outputs": [],
   "source": [
    "mll_scorer = metrics.make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-vegetable",
   "metadata": {},
   "source": [
    "다음으로 파이프라인이 필요합니다. 여기서 실행하기 위해 SVD, 스케일링 및 로지스틱 회귀로 구성된 파이프라인을 사용합니다. 하나의 모듈보다 더 많은 모듈을 파이프라인에 배치하여 이해하는 것이 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "noted-mercury",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T10:59:13.528469Z",
     "start_time": "2021-03-10T10:59:13.516458Z"
    }
   },
   "outputs": [],
   "source": [
    "# SVD 초기화\n",
    "svd = TruncatedSVD()\n",
    "\n",
    "# 정규화 초기화\n",
    "scl = preprocessing.StandardScaler()\n",
    "\n",
    "# 로지스틱 회귀\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# 파이프라인 구축\n",
    "clf = pipeline.Pipeline([('svd', svd),\n",
    "                         ('scl', scl),\n",
    "                         ('lr', lr_model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-subscriber",
   "metadata": {},
   "source": [
    "다음으로 파라미터 그리드를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "photographic-blond",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T10:59:14.438297Z",
     "start_time": "2021-03-10T10:59:14.428288Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {'svd__n_components': [120, 180],\n",
    "              'lr__C': [0.1, 1.0, 10],\n",
    "              'lr__penalty': ['l1', 'l2']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-future",
   "metadata": {},
   "source": [
    "SVD의 경우 120개 및 180개의 성분을 평가하고, 로지스틱 회귀 분석의 경우 l1 및 l2 패널티로 세 가지 다른 C 값에 대해 평가합니다. 이제 이러한 매개 변수에 대한 그리드 검색을 시작할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "rough-runner",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T10:59:30.457739Z",
     "start_time": "2021-03-10T10:59:15.205001Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tens_2g\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [        nan         nan -0.77353914 -0.74182171         nan         nan\n",
      " -0.78048248 -0.73947463         nan         nan -0.7692571  -0.73928645]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -0.739\n",
      "Best parameters set:\n",
      "\tlr__C: 10\n",
      "\tlr__penalty: 'l2'\n",
      "\tsvd__n_components: 180\n"
     ]
    }
   ],
   "source": [
    "# 그리드 검색 모델 초기화\n",
    "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=mll_scorer,\n",
    "                     verbose=10, n_jobs=-1, refit=True, cv=2)\n",
    "\n",
    "# 그리드 검색 모델 적합\n",
    "model.fit(xtrain_tfv, ytrain) \n",
    "print('Best Score: %0.3f' %model.best_score_)\n",
    "print('Best parameters set:')\n",
    "best_parameters = model.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print('\\t%s: %r' % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-percentage",
   "metadata": {},
   "source": [
    "점수는 SVM과 비슷합니다. 이 기술은 xgboost를 파인튜닝하거나 다항 나이브 베이즈를 미세조정하는데 사용할 수 있습니다. 여기서 tfidf 데이터를 사용합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "subsequent-transcript",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T11:02:43.421228Z",
     "start_time": "2021-03-10T11:02:43.212039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "Best Score: -0.492\n",
      "Best parameters set:\n",
      "\tnb__alpha: 0.1\n"
     ]
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "\n",
    "# 파이프라인 생성\n",
    "clf = pipeline.Pipeline([('nb', nb_model)])\n",
    "\n",
    "# 파라미터 그리드\n",
    "param_grid = {'nb__alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# 그리드 검색 모델 초기화\n",
    "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=mll_scorer,\n",
    "                     verbose=10, n_jobs=-1, refit=True, cv=2)\n",
    "\n",
    "# 그리드 검색 모델 적합\n",
    "model.fit(xtrain_tfv, ytrain)\n",
    "print('Best Score: %0.3f' %model.best_score_)\n",
    "print('Best parameters set:')\n",
    "best_parameters = model.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print('\\t%s: %r' % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-savings",
   "metadata": {},
   "source": [
    "원래 나이브 베이즈랑 비슷합니다.\n",
    "\n",
    "NLP 문제에서는 일반적으로 단어 벡터를 살펴봅니다. 단어 벡터는 데이터에 대한 많은 통찰력을 제공합니다. 그 점에 대해 자세히 알아보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-designation",
   "metadata": {},
   "source": [
    "## Word vectors\n",
    "너무 자세하게 설명하지 않고, 어떻게 하면 문장 벡터를 만들 수 있는지, 그 위에 기계 학습 모델을 만드는지 설명하겠습니다. 이 게시물에서는 Glove 벡터를 사용합니다.\n",
    "http://www-nlp.stanford.edu/data/glove.840B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "indie-contrast",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T11:25:41.061091Z",
     "start_time": "2021-03-10T11:22:38.811854Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1193it [00:00, 11919.18it/s]\u001b[A\n",
      "2408it [00:00, 11984.28it/s]\u001b[A\n",
      "3611it [00:00, 11994.68it/s]\u001b[A\n",
      "4828it [00:00, 12043.50it/s]\u001b[A\n",
      "6042it [00:00, 12068.96it/s]\u001b[A\n",
      "7259it [00:00, 12095.87it/s]\u001b[A\n",
      "8470it [00:00, 12096.79it/s]\u001b[A\n",
      "9681it [00:00, 12097.46it/s]\u001b[A\n",
      "10898it [00:00, 12115.82it/s]\u001b[A\n",
      "12100it [00:01, 12083.61it/s]\u001b[A\n",
      "13275it [00:01, 11941.67it/s]\u001b[A\n",
      "14479it [00:01, 11967.77it/s]\u001b[A\n",
      "15689it [00:01, 12003.87it/s]\u001b[A\n",
      "16880it [00:01, 11972.26it/s]\u001b[A\n",
      "18091it [00:01, 12010.00it/s]\u001b[A\n",
      "19303it [00:01, 12039.53it/s]\u001b[A\n",
      "20505it [00:01, 12030.38it/s]\u001b[A\n",
      "21706it [00:01, 12020.97it/s]\u001b[A\n",
      "22907it [00:01, 11871.76it/s]\u001b[A\n",
      "24115it [00:02, 11930.25it/s]\u001b[A\n",
      "25308it [00:02, 11926.92it/s]\u001b[A\n",
      "26513it [00:02, 11960.34it/s]\u001b[A\n",
      "27730it [00:02, 12019.24it/s]\u001b[A\n",
      "28944it [00:02, 12051.94it/s]\u001b[A\n",
      "30153it [00:02, 12060.05it/s]\u001b[A\n",
      "31359it [00:02, 12056.74it/s]\u001b[A\n",
      "32568it [00:02, 12063.41it/s]\u001b[A\n",
      "33775it [00:02, 12062.10it/s]\u001b[A\n",
      "34982it [00:02, 12061.18it/s]\u001b[A\n",
      "36189it [00:03, 12060.53it/s]\u001b[A\n",
      "37396it [00:03, 12060.09it/s]\u001b[A\n",
      "38603it [00:03, 12059.76it/s]\u001b[A\n",
      "39809it [00:03, 12056.53it/s]\u001b[A\n",
      "41015it [00:03, 12054.30it/s]\u001b[A\n",
      "42221it [00:03, 12052.71it/s]\u001b[A\n",
      "43429it [00:03, 12057.60it/s]\u001b[A\n",
      "44635it [00:03, 12018.95it/s]\u001b[A\n",
      "45837it [00:03, 11944.29it/s]\u001b[A\n",
      "47037it [00:03, 11957.69it/s]\u001b[A\n",
      "48240it [00:04, 11976.03it/s]\u001b[A\n",
      "49438it [00:04, 11902.51it/s]\u001b[A\n",
      "50648it [00:04, 11957.85it/s]\u001b[A\n",
      "51852it [00:04, 11979.12it/s]\u001b[A\n",
      "53059it [00:04, 12002.98it/s]\u001b[A\n",
      "54273it [00:04, 12040.51it/s]\u001b[A\n",
      "55480it [00:04, 12046.06it/s]\u001b[A\n",
      "56686it [00:04, 12046.95it/s]\u001b[A\n",
      "57891it [00:04, 12044.59it/s]\u001b[A\n",
      "59099it [00:04, 12051.90it/s]\u001b[A\n",
      "60310it [00:05, 12065.99it/s]\u001b[A\n",
      "61531it [00:05, 12105.56it/s]\u001b[A\n",
      "62742it [00:05, 12103.59it/s]\u001b[A\n",
      "63953it [00:05, 12102.21it/s]\u001b[A\n",
      "65164it [00:05, 12101.24it/s]\u001b[A\n",
      "66379it [00:05, 12112.54it/s]\u001b[A\n",
      "67596it [00:05, 12126.41it/s]\u001b[A\n",
      "68809it [00:05, 12051.84it/s]\u001b[A\n",
      "70016it [00:05, 12054.00it/s]\u001b[A\n",
      "71238it [00:05, 12100.04it/s]\u001b[A\n",
      "72459it [00:06, 12129.54it/s]\u001b[A\n",
      "73673it [00:06, 12129.36it/s]\u001b[A\n",
      "74897it [00:06, 12159.04it/s]\u001b[A\n",
      "76113it [00:06, 12156.01it/s]\u001b[A\n",
      "77329it [00:06, 12153.91it/s]\u001b[A\n",
      "78545it [00:06, 12116.05it/s]\u001b[A\n",
      "79757it [00:06, 12113.93it/s]\u001b[A\n",
      "80969it [00:06, 12112.44it/s]\u001b[A\n",
      "82188it [00:06, 12132.31it/s]\u001b[A\n",
      "83402it [00:06, 12131.30it/s]\u001b[A\n",
      "84616it [00:07, 12004.42it/s]\u001b[A\n",
      "85820it [00:07, 12011.80it/s]\u001b[A\n",
      "87034it [00:07, 12046.71it/s]\u001b[A\n",
      "88239it [00:07, 11972.55it/s]\u001b[A\n",
      "89453it [00:07, 12019.05it/s]\u001b[A\n",
      "90658it [00:07, 12025.03it/s]\u001b[A\n",
      "91861it [00:07, 11951.50it/s]\u001b[A\n",
      "93066it [00:07, 11977.64it/s]\u001b[A\n",
      "94285it [00:07, 12037.32it/s]\u001b[A\n",
      "95502it [00:07, 12073.55it/s]\u001b[A\n",
      "96712it [00:08, 12078.18it/s]\u001b[A\n",
      "97942it [00:08, 12140.61it/s]\u001b[A\n",
      "99157it [00:08, 12140.11it/s]\u001b[A\n",
      "100372it [00:08, 12067.35it/s]\u001b[A\n",
      "101587it [00:08, 12088.75it/s]\u001b[A\n",
      "102802it [00:08, 12103.76it/s]\u001b[A\n",
      "104016it [00:08, 12111.31it/s]\u001b[A\n",
      "105228it [00:08, 11966.99it/s]\u001b[A\n",
      "106440it [00:08, 12009.23it/s]\u001b[A\n",
      "107658it [00:08, 12056.71it/s]\u001b[A\n",
      "108878it [00:09, 12096.07it/s]\u001b[A\n",
      "110094it [00:09, 12111.88it/s]\u001b[A\n",
      "111306it [00:09, 12111.00it/s]\u001b[A\n",
      "112518it [00:09, 12074.17it/s]\u001b[A\n",
      "113726it [00:09, 12072.64it/s]\u001b[A\n",
      "114934it [00:09, 11928.37it/s]\u001b[A\n",
      "116130it [00:09, 11934.58it/s]\u001b[A\n",
      "117342it [00:09, 11986.38it/s]\u001b[A\n",
      "118553it [00:09, 12019.95it/s]\u001b[A\n",
      "119766it [00:09, 12049.48it/s]\u001b[A\n",
      "120983it [00:10, 12082.11it/s]\u001b[A\n",
      "122201it [00:10, 12108.03it/s]\u001b[A\n",
      "123412it [00:10, 12105.31it/s]\u001b[A\n",
      "124629it [00:10, 12121.36it/s]\u001b[A\n",
      "125842it [00:10, 12084.38it/s]\u001b[A\n",
      "127061it [00:10, 12112.59it/s]\u001b[A\n",
      "128273it [00:10, 12111.50it/s]\u001b[A\n",
      "129485it [00:10, 12110.75it/s]\u001b[A\n",
      "130697it [00:10, 12110.22it/s]\u001b[A\n",
      "131913it [00:10, 12121.81it/s]\u001b[A\n",
      "133132it [00:11, 12138.89it/s]\u001b[A\n",
      "134346it [00:11, 12135.90it/s]\u001b[A\n",
      "135560it [00:11, 12097.51it/s]\u001b[A\n",
      "136770it [00:11, 12094.97it/s]\u001b[A\n",
      "137980it [00:11, 12093.17it/s]\u001b[A\n",
      "139190it [00:11, 12091.92it/s]\u001b[A\n",
      "140400it [00:11, 12091.04it/s]\u001b[A\n",
      "141610it [00:11, 11911.74it/s]\u001b[A\n",
      "142822it [00:11, 11970.23it/s]\u001b[A\n",
      "144034it [00:11, 12011.53it/s]\u001b[A\n",
      "145252it [00:12, 12058.33it/s]\u001b[A\n",
      "146463it [00:12, 12070.49it/s]\u001b[A\n",
      "147671it [00:12, 12070.05it/s]\u001b[A\n",
      "148879it [00:12, 12033.65it/s]\u001b[A\n",
      "150084it [00:12, 12035.25it/s]\u001b[A\n",
      "151288it [00:12, 12015.23it/s]\u001b[A\n",
      "152492it [00:12, 12019.39it/s]\u001b[A\n",
      "153694it [00:12, 11980.33it/s]\u001b[A\n",
      "154900it [00:12, 12000.85it/s]\u001b[A\n",
      "156111it [00:12, 12030.13it/s]\u001b[A\n",
      "157326it [00:13, 12062.57it/s]\u001b[A\n",
      "158533it [00:13, 12061.50it/s]\u001b[A\n",
      "159740it [00:13, 12060.77it/s]\u001b[A\n",
      "160947it [00:13, 12060.24it/s]\u001b[A\n",
      "162160it [00:13, 12077.80it/s]\u001b[A\n",
      "163374it [00:13, 12093.10it/s]\u001b[A\n",
      "164585it [00:13, 12094.86it/s]\u001b[A\n",
      "165798it [00:13, 12102.10it/s]\u001b[A\n",
      "167009it [00:13, 12101.16it/s]\u001b[A\n",
      "168220it [00:13, 12100.51it/s]\u001b[A\n",
      "169431it [00:14, 12100.06it/s]\u001b[A\n",
      "170658it [00:14, 12147.25it/s]\u001b[A\n",
      "171883it [00:14, 12174.61it/s]\u001b[A\n",
      "173101it [00:14, 12172.90it/s]\u001b[A\n",
      "174319it [00:14, 11956.45it/s]\u001b[A\n",
      "175516it [00:14, 11850.60it/s]\u001b[A\n",
      "176717it [00:14, 11894.75it/s]\u001b[A\n",
      "177926it [00:14, 11949.45it/s]\u001b[A\n",
      "179126it [00:14, 11961.30it/s]\u001b[A\n",
      "180348it [00:14, 12034.54it/s]\u001b[A\n",
      "181563it [00:15, 12065.67it/s]\u001b[A\n",
      "182770it [00:15, 12063.67it/s]\u001b[A\n",
      "183977it [00:15, 12026.20it/s]\u001b[A\n",
      "185180it [00:15, 12024.05it/s]\u001b[A\n",
      "186383it [00:15, 11986.59it/s]\u001b[A\n",
      "187589it [00:15, 12005.27it/s]\u001b[A\n",
      "188794it [00:15, 12015.37it/s]\u001b[A\n",
      "189996it [00:15, 11941.79it/s]\u001b[A\n",
      "191191it [00:15, 11834.47it/s]\u001b[A\n",
      "192375it [00:15, 11832.90it/s]\u001b[A\n",
      "193559it [00:16, 11588.38it/s]\u001b[A\n",
      "194720it [00:16, 11254.31it/s]\u001b[A\n",
      "195876it [00:16, 11341.27it/s]\u001b[A\n",
      "197033it [00:16, 11405.86it/s]\u001b[A\n",
      "198232it [00:16, 11571.99it/s]\u001b[A\n",
      "199434it [00:16, 11699.73it/s]\u001b[A\n",
      "200606it [00:16, 11702.61it/s]\u001b[A\n",
      "201808it [00:16, 11792.90it/s]\u001b[A\n",
      "203012it [00:16, 11862.78it/s]\u001b[A\n",
      "204238it [00:16, 11958.34it/s]\u001b[A\n",
      "205458it [00:17, 12026.59it/s]\u001b[A\n",
      "206672it [00:17, 12057.10it/s]\u001b[A\n",
      "207879it [00:17, 12021.64it/s]\u001b[A\n",
      "209082it [00:17, 12020.86it/s]\u001b[A\n",
      "210285it [00:17, 11984.36it/s]\u001b[A\n",
      "211484it [00:17, 11946.93it/s]\u001b[A\n",
      "212687it [00:17, 11968.47it/s]\u001b[A\n",
      "213886it [00:17, 11971.66it/s]\u001b[A\n",
      "215084it [00:17, 11970.90it/s]\u001b[A\n",
      "216294it [00:17, 12006.09it/s]\u001b[A\n",
      "217501it [00:18, 12021.92it/s]\u001b[A\n",
      "218707it [00:18, 12030.04it/s]\u001b[A\n",
      "219911it [00:18, 12029.74it/s]\u001b[A\n",
      "221114it [00:18, 12026.54it/s]\u001b[A\n",
      "222322it [00:18, 12039.26it/s]\u001b[A\n",
      "223540it [00:18, 12077.87it/s]\u001b[A\n",
      "224771it [00:18, 12143.32it/s]\u001b[A\n",
      "225988it [00:18, 12148.00it/s]\u001b[A\n",
      "227203it [00:18, 12145.27it/s]\u001b[A\n",
      "228420it [00:18, 12149.38it/s]\u001b[A\n",
      "229635it [00:19, 12146.25it/s]\u001b[A\n",
      "230850it [00:19, 12144.05it/s]\u001b[A\n",
      "232065it [00:19, 12106.20it/s]\u001b[A\n",
      "233276it [00:19, 12104.04it/s]\u001b[A\n",
      "234487it [00:19, 12066.31it/s]\u001b[A\n",
      "235694it [00:19, 12064.12it/s]\u001b[A\n",
      "236901it [00:19, 12062.60it/s]\u001b[A\n",
      "238120it [00:19, 12097.26it/s]\u001b[A\n",
      "239338it [00:19, 12118.67it/s]\u001b[A\n",
      "240550it [00:19, 12115.77it/s]\u001b[A\n",
      "241762it [00:20, 12077.47it/s]\u001b[A\n",
      "242976it [00:20, 11985.34it/s]\u001b[A\n",
      "244194it [00:20, 12039.83it/s]\u001b[A\n",
      "245403it [00:20, 12051.56it/s]\u001b[A\n",
      "246622it [00:20, 12089.47it/s]\u001b[A\n",
      "247838it [00:20, 12107.27it/s]\u001b[A\n",
      "249060it [00:20, 12137.57it/s]\u001b[A\n",
      "250274it [00:20, 12135.01it/s]\u001b[A\n",
      "251488it [00:20, 12133.16it/s]\u001b[A\n",
      "252702it [00:21, 12131.91it/s]\u001b[A\n",
      "253921it [00:21, 12145.98it/s]\u001b[A\n",
      "255145it [00:21, 12170.73it/s]\u001b[A\n",
      "256363it [00:21, 12170.17it/s]\u001b[A\n",
      "257581it [00:21, 12169.82it/s]\u001b[A\n",
      "258798it [00:21, 12166.57it/s]\u001b[A\n",
      "260015it [00:21, 12127.86it/s]\u001b[A\n",
      "261228it [00:21, 12125.19it/s]\u001b[A\n",
      "262442it [00:21, 12126.32it/s]\u001b[A\n",
      "263665it [00:21, 12153.94it/s]\u001b[A\n",
      "264885it [00:22, 12164.41it/s]\u001b[A\n",
      "266102it [00:22, 12162.77it/s]\u001b[A\n",
      "267319it [00:22, 12161.62it/s]\u001b[A\n",
      "268536it [00:22, 12160.81it/s]\u001b[A\n",
      "269753it [00:22, 12160.25it/s]\u001b[A\n",
      "270970it [00:22, 12123.49it/s]\u001b[A\n",
      "272184it [00:22, 12125.12it/s]\u001b[A\n",
      "273397it [00:22, 12123.28it/s]\u001b[A\n",
      "274610it [00:22, 12013.84it/s]\u001b[A\n",
      "275812it [00:22, 12012.41it/s]\u001b[A\n",
      "277020it [00:23, 12029.34it/s]\u001b[A\n",
      "278224it [00:23, 12029.25it/s]\u001b[A\n",
      "279428it [00:23, 12029.19it/s]\u001b[A\n",
      "280631it [00:23, 12026.16it/s]\u001b[A\n",
      "281839it [00:23, 12038.99it/s]\u001b[A\n",
      "283055it [00:23, 12071.76it/s]\u001b[A\n",
      "284267it [00:23, 12082.89it/s]\u001b[A\n",
      "285486it [00:23, 12111.55it/s]\u001b[A\n",
      "286698it [00:23, 12110.79it/s]\u001b[A\n",
      "287910it [00:23, 12110.24it/s]\u001b[A\n",
      "289125it [00:24, 12118.84it/s]\u001b[A\n",
      "290337it [00:24, 11494.80it/s]\u001b[A\n",
      "291494it [00:24, 11514.14it/s]\u001b[A\n",
      "292698it [00:24, 11663.93it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "293914it [00:24, 11805.32it/s]\u001b[A\n",
      "295136it [00:24, 11923.56it/s]\u001b[A\n",
      "296331it [00:24, 11928.23it/s]\u001b[A\n",
      "297539it [00:24, 11970.12it/s]\u001b[A\n",
      "298748it [00:24, 12002.57it/s]\u001b[A\n",
      "299958it [00:24, 12028.37it/s]\u001b[A\n",
      "301170it [00:25, 12052.43it/s]\u001b[A\n",
      "302391it [00:25, 12096.01it/s]\u001b[A\n",
      "303602it [00:25, 12096.91it/s]\u001b[A\n",
      "304817it [00:25, 12109.48it/s]\u001b[A\n",
      "306030it [00:25, 12112.34it/s]\u001b[A\n",
      "307253it [00:25, 12144.10it/s]\u001b[A\n",
      "308468it [00:25, 12142.56it/s]\u001b[A\n",
      "309688it [00:25, 12156.43it/s]\u001b[A\n",
      "310904it [00:25, 12117.81it/s]\u001b[A\n",
      "312116it [00:25, 12115.16it/s]\u001b[A\n",
      "313328it [00:26, 12113.32it/s]\u001b[A\n",
      "314542it [00:26, 12118.00it/s]\u001b[A\n",
      "315765it [00:26, 12148.09it/s]\u001b[A\n",
      "316980it [00:26, 12145.35it/s]\u001b[A\n",
      "318195it [00:26, 12143.43it/s]\u001b[A\n",
      "319410it [00:26, 12142.09it/s]\u001b[A\n",
      "320625it [00:26, 12141.15it/s]\u001b[A\n",
      "321840it [00:26, 12104.16it/s]\u001b[A\n",
      "323051it [00:26, 12102.62it/s]\u001b[A\n",
      "324262it [00:26, 12101.54it/s]\u001b[A\n",
      "325477it [00:27, 12112.74it/s]\u001b[A\n",
      "326689it [00:27, 12075.36it/s]\u001b[A\n",
      "327899it [00:27, 12079.47it/s]\u001b[A\n",
      "329107it [00:27, 12004.26it/s]\u001b[A\n",
      "330308it [00:27, 11895.61it/s]\u001b[A\n",
      "331515it [00:27, 11926.23it/s]\u001b[A\n",
      "332726it [00:27, 11977.55it/s]\u001b[A\n",
      "333947it [00:27, 12043.11it/s]\u001b[A\n",
      "335153it [00:27, 12044.88it/s]\u001b[A\n",
      "336367it [00:27, 12069.99it/s]\u001b[A\n",
      "337581it [00:28, 12087.62it/s]\u001b[A\n",
      "338790it [00:28, 12085.04it/s]\u001b[A\n",
      "339999it [00:28, 12083.23it/s]\u001b[A\n",
      "341208it [00:28, 12081.95it/s]\u001b[A\n",
      "342417it [00:28, 12081.08it/s]\u001b[A\n",
      "343626it [00:28, 12080.44it/s]\u001b[A\n",
      "344846it [00:28, 12112.80it/s]\u001b[A\n",
      "346060it [00:28, 12117.64it/s]\u001b[A\n",
      "347282it [00:28, 12144.87it/s]\u001b[A\n",
      "348497it [00:28, 12143.09it/s]\u001b[A\n",
      "349712it [00:29, 11892.06it/s]\u001b[A\n",
      "350936it [00:29, 11991.13it/s]\u001b[A\n",
      "352151it [00:29, 12035.11it/s]\u001b[A\n",
      "353364it [00:29, 12060.14it/s]\u001b[A\n",
      "354571it [00:29, 12023.72it/s]\u001b[A\n",
      "355774it [00:29, 11986.36it/s]\u001b[A\n",
      "356983it [00:29, 12014.03it/s]\u001b[A\n",
      "358191it [00:29, 12030.46it/s]\u001b[A\n",
      "359395it [00:29, 12030.04it/s]\u001b[A\n",
      "360605it [00:29, 12047.67it/s]\u001b[A\n",
      "361810it [00:30, 11866.99it/s]\u001b[A\n",
      "363021it [00:30, 11935.64it/s]\u001b[A\n",
      "364230it [00:30, 11978.29it/s]\u001b[A\n",
      "365429it [00:30, 11978.54it/s]\u001b[A\n",
      "366631it [00:30, 11987.68it/s]\u001b[A\n",
      "367830it [00:30, 11985.10it/s]\u001b[A\n",
      "369029it [00:30, 11911.81it/s]\u001b[A\n",
      "370232it [00:30, 11943.78it/s]\u001b[A\n",
      "371440it [00:30, 11981.09it/s]\u001b[A\n",
      "372648it [00:30, 12007.32it/s]\u001b[A\n",
      "373853it [00:31, 12016.83it/s]\u001b[A\n",
      "375071it [00:31, 12062.06it/s]\u001b[A\n",
      "376279it [00:31, 12064.15it/s]\u001b[A\n",
      "377496it [00:31, 12092.43it/s]\u001b[A\n",
      "378719it [00:31, 12130.08it/s]\u001b[A\n",
      "379933it [00:31, 12093.46it/s]\u001b[A\n",
      "381143it [00:31, 12092.14it/s]\u001b[A\n",
      "382353it [00:31, 12091.19it/s]\u001b[A\n",
      "383563it [00:31, 12090.54it/s]\u001b[A\n",
      "384773it [00:31, 12053.91it/s]\u001b[A\n",
      "385979it [00:32, 12052.45it/s]\u001b[A\n",
      "387192it [00:32, 12072.33it/s]\u001b[A\n",
      "388400it [00:32, 12071.34it/s]\u001b[A\n",
      "389620it [00:32, 12106.37it/s]\u001b[A\n",
      "390831it [00:32, 11996.15it/s]\u001b[A\n",
      "392031it [00:32, 11886.99it/s]\u001b[A\n",
      "393237it [00:32, 11935.15it/s]\u001b[A\n",
      "394442it [00:32, 11966.13it/s]\u001b[A\n",
      "395656it [00:32, 12014.52it/s]\u001b[A\n",
      "396871it [00:32, 12051.58it/s]\u001b[A\n",
      "398078it [00:33, 12053.82it/s]\u001b[A\n",
      "399300it [00:33, 12081.83it/s]\u001b[A\n",
      "400513it [00:33, 12092.96it/s]\u001b[A\n",
      "401725it [00:33, 12097.75it/s]\u001b[A\n",
      "402944it [00:33, 12122.00it/s]\u001b[A\n",
      "404160it [00:33, 12130.07it/s]\u001b[A\n",
      "405374it [00:33, 12129.73it/s]\u001b[A\n",
      "406587it [00:33, 12126.50it/s]\u001b[A\n",
      "407800it [00:33, 12051.91it/s]\u001b[A\n",
      "409006it [00:33, 11979.15it/s]\u001b[A\n",
      "410223it [00:34, 12032.54it/s]\u001b[A\n",
      "411442it [00:34, 12076.06it/s]\u001b[A\n",
      "412653it [00:34, 12082.94it/s]\u001b[A\n",
      "413862it [00:34, 12081.76it/s]\u001b[A\n",
      "415071it [00:34, 12044.79it/s]\u001b[A\n",
      "416276it [00:34, 12043.07it/s]\u001b[A\n",
      "417481it [00:34, 11970.03it/s]\u001b[A\n",
      "418679it [00:34, 11969.75it/s]\u001b[A\n",
      "419889it [00:34, 12005.28it/s]\u001b[A\n",
      "421099it [00:34, 12030.27it/s]\u001b[A\n",
      "422303it [00:35, 12029.89it/s]\u001b[A\n",
      "423507it [00:35, 11957.91it/s]\u001b[A\n",
      "424720it [00:35, 12005.78it/s]\u001b[A\n",
      "425929it [00:35, 12027.65it/s]\u001b[A\n",
      "427140it [00:35, 12048.96it/s]\u001b[A\n",
      "428353it [00:35, 12069.89it/s]\u001b[A\n",
      "429570it [00:35, 12096.47it/s]\u001b[A\n",
      "430780it [00:35, 12094.22it/s]\u001b[A\n",
      "431990it [00:35, 12092.66it/s]\u001b[A\n",
      "433204it [00:35, 12103.52it/s]\u001b[A\n",
      "434417it [00:36, 12108.16it/s]\u001b[A\n",
      "435637it [00:36, 12132.26it/s]\u001b[A\n",
      "436857it [00:36, 12149.21it/s]\u001b[A\n",
      "438074it [00:36, 12152.13it/s]\u001b[A\n",
      "439290it [00:36, 12151.17it/s]\u001b[A\n",
      "440506it [00:36, 12150.51it/s]\u001b[A\n",
      "441722it [00:36, 12041.65it/s]\u001b[A\n",
      "442927it [00:36, 12040.88it/s]\u001b[A\n",
      "444136it [00:36, 12052.28it/s]\u001b[A\n",
      "445342it [00:36, 12051.28it/s]\u001b[A\n",
      "446548it [00:37, 12050.64it/s]\u001b[A\n",
      "447774it [00:37, 12109.42it/s]\u001b[A\n",
      "448986it [00:37, 12109.30it/s]\u001b[A\n",
      "450201it [00:37, 12099.93it/s]\u001b[A\n",
      "451421it [00:37, 12126.49it/s]\u001b[A\n",
      "452634it [00:37, 12124.24it/s]\u001b[A\n",
      "453847it [00:37, 12086.39it/s]\u001b[A\n",
      "455059it [00:37, 12093.16it/s]\u001b[A\n",
      "456274it [00:37, 12106.85it/s]\u001b[A\n",
      "457485it [00:37, 12104.49it/s]\u001b[A\n",
      "458705it [00:38, 12129.70it/s]\u001b[A\n",
      "459918it [00:38, 12126.48it/s]\u001b[A\n",
      "461131it [00:38, 12124.23it/s]\u001b[A\n",
      "462344it [00:38, 12086.38it/s]\u001b[A\n",
      "463553it [00:38, 12084.17it/s]\u001b[A\n",
      "464762it [00:38, 12082.62it/s]\u001b[A\n",
      "465978it [00:38, 12102.44it/s]\u001b[A\n",
      "467189it [00:38, 12101.41it/s]\u001b[A\n",
      "468403it [00:38, 12109.66it/s]\u001b[A\n",
      "469614it [00:38, 12106.46it/s]\u001b[A\n",
      "470825it [00:39, 12104.22it/s]\u001b[A\n",
      "472036it [00:39, 12102.65it/s]\u001b[A\n",
      "473252it [00:39, 12116.50it/s]\u001b[A\n",
      "474469it [00:39, 12129.20it/s]\u001b[A\n",
      "475682it [00:39, 12126.12it/s]\u001b[A\n",
      "476895it [00:39, 12123.99it/s]\u001b[A\n",
      "478108it [00:39, 12122.48it/s]\u001b[A\n",
      "479321it [00:39, 12121.43it/s]\u001b[A\n",
      "480534it [00:39, 12120.68it/s]\u001b[A\n",
      "481747it [00:39, 12083.92it/s]\u001b[A\n",
      "482956it [00:40, 11903.84it/s]\u001b[A\n",
      "484149it [00:40, 11908.42it/s]\u001b[A\n",
      "485361it [00:40, 11967.89it/s]\u001b[A\n",
      "486573it [00:40, 12009.88it/s]\u001b[A\n",
      "487775it [00:40, 11902.52it/s]\u001b[A\n",
      "488988it [00:40, 11966.63it/s]\u001b[A\n",
      "490203it [00:40, 12017.81it/s]\u001b[A\n",
      "491409it [00:40, 12027.16it/s]\u001b[A\n",
      "492623it [00:40, 12057.52it/s]\u001b[A\n",
      "493842it [00:41, 12093.69it/s]\u001b[A\n",
      "495063it [00:41, 12125.06it/s]\u001b[A\n",
      "496276it [00:41, 12050.90it/s]\u001b[A\n",
      "497482it [00:41, 12050.33it/s]\u001b[A\n",
      "498688it [00:41, 12013.90it/s]\u001b[A\n",
      "499890it [00:41, 12012.46it/s]\u001b[A\n",
      "501097it [00:41, 12026.39it/s]\u001b[A\n",
      "502308it [00:41, 12048.05it/s]\u001b[A\n",
      "503513it [00:41, 11937.89it/s]\u001b[A\n",
      "504720it [00:41, 11973.96it/s]\u001b[A\n",
      "505938it [00:42, 12031.80it/s]\u001b[A\n",
      "507151it [00:42, 12057.82it/s]\u001b[A\n",
      "508357it [00:42, 12055.18it/s]\u001b[A\n",
      "509566it [00:42, 12062.33it/s]\u001b[A\n",
      "510773it [00:42, 11953.74it/s]\u001b[A\n",
      "511970it [00:42, 11955.35it/s]\u001b[A\n",
      "513183it [00:42, 12003.97it/s]\u001b[A\n",
      "514399it [00:42, 12047.09it/s]\u001b[A\n",
      "515610it [00:42, 12062.61it/s]\u001b[A\n",
      "516829it [00:42, 12097.27it/s]\u001b[A\n",
      "518048it [00:43, 12121.66it/s]\u001b[A\n",
      "519261it [00:43, 12120.85it/s]\u001b[A\n",
      "520474it [00:43, 12120.27it/s]\u001b[A\n",
      "521687it [00:43, 12119.89it/s]\u001b[A\n",
      "522900it [00:43, 12083.37it/s]\u001b[A\n",
      "524109it [00:43, 12045.91it/s]\u001b[A\n",
      "525314it [00:43, 12043.85it/s]\u001b[A\n",
      "526519it [00:43, 12042.41it/s]\u001b[A\n",
      "527724it [00:43, 11933.97it/s]\u001b[A\n",
      "528918it [00:43, 11896.82it/s]\u001b[A\n",
      "530127it [00:44, 11950.89it/s]\u001b[A\n",
      "531346it [00:44, 12018.41it/s]\u001b[A\n",
      "532551it [00:44, 12024.59it/s]\u001b[A\n",
      "533763it [00:44, 12049.78it/s]\u001b[A\n",
      "534988it [00:44, 12105.89it/s]\u001b[A\n",
      "536204it [00:44, 12118.77it/s]\u001b[A\n",
      "537416it [00:44, 12115.84it/s]\u001b[A\n",
      "538628it [00:44, 12005.69it/s]\u001b[A\n",
      "539829it [00:44, 12003.71it/s]\u001b[A\n",
      "541031it [00:44, 12005.32it/s]\u001b[A\n",
      "542246it [00:45, 12045.11it/s]\u001b[A\n",
      "543463it [00:45, 12079.02it/s]\u001b[A\n",
      "544673it [00:45, 12082.02it/s]\u001b[A\n",
      "545888it [00:45, 12099.04it/s]\u001b[A\n",
      "547101it [00:45, 12105.01it/s]\u001b[A\n",
      "548312it [00:45, 11995.22it/s]\u001b[A\n",
      "549512it [00:45, 11993.36it/s]\u001b[A\n",
      "550712it [00:45, 11992.08it/s]\u001b[A\n",
      "551913it [00:45, 11994.20it/s]\u001b[A\n",
      "553128it [00:45, 12037.24it/s]\u001b[A\n",
      "554339it [00:46, 12055.70it/s]\u001b[A\n",
      "555545it [00:46, 12053.72it/s]\u001b[A\n",
      "556753it [00:46, 12058.29it/s]\u001b[A\n",
      "557959it [00:46, 12055.52it/s]\u001b[A\n",
      "559173it [00:46, 12077.46it/s]\u001b[A\n",
      "560399it [00:46, 12128.36it/s]\u001b[A\n",
      "561612it [00:46, 12125.55it/s]\u001b[A\n",
      "562825it [00:46, 12087.31it/s]\u001b[A\n",
      "564034it [00:46, 12048.65it/s]\u001b[A\n",
      "565246it [00:46, 12066.68it/s]\u001b[A\n",
      "566453it [00:47, 12064.39it/s]\u001b[A\n",
      "567660it [00:47, 12062.78it/s]\u001b[A\n",
      "568867it [00:47, 12061.67it/s]\u001b[A\n",
      "570074it [00:47, 11743.74it/s]\u001b[A\n",
      "571283it [00:47, 11842.34it/s]\u001b[A\n",
      "572477it [00:47, 11868.25it/s]\u001b[A\n",
      "573665it [00:47, 11423.07it/s]\u001b[A\n",
      "574853it [00:47, 11553.34it/s]\u001b[A\n",
      "576062it [00:47, 11706.17it/s]\u001b[A\n",
      "577254it [00:47, 11766.34it/s]\u001b[A\n",
      "578440it [00:48, 11791.09it/s]\u001b[A\n",
      "579644it [00:48, 11861.48it/s]\u001b[A\n",
      "580856it [00:48, 11934.67it/s]\u001b[A\n",
      "582051it [00:48, 11936.00it/s]\u001b[A\n",
      "583256it [00:48, 11966.73it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "584476it [00:48, 12032.53it/s]\u001b[A\n",
      "585690it [00:48, 12061.30it/s]\u001b[A\n",
      "586900it [00:48, 12069.60it/s]\u001b[A\n",
      "588115it [00:48, 12090.33it/s]\u001b[A\n",
      "589327it [00:48, 12095.91it/s]\u001b[A\n",
      "590543it [00:49, 12111.77it/s]\u001b[A\n",
      "591755it [00:49, 12110.93it/s]\u001b[A\n",
      "592967it [00:49, 12074.13it/s]\u001b[A\n",
      "594175it [00:49, 11964.86it/s]\u001b[A\n",
      "595381it [00:49, 11989.99it/s]\u001b[A\n",
      "596589it [00:49, 12013.60it/s]\u001b[A\n",
      "597800it [00:49, 12039.09it/s]\u001b[A\n",
      "599005it [00:49, 12039.08it/s]\u001b[A\n",
      "600209it [00:49, 11928.66it/s]\u001b[A\n",
      "601403it [00:49, 11857.64it/s]\u001b[A\n",
      "602590it [00:50, 11822.65it/s]\u001b[A\n",
      "603773it [00:50, 11681.44it/s]\u001b[A\n",
      "604942it [00:50, 11680.81it/s]\u001b[A\n",
      "606147it [00:50, 11786.02it/s]\u001b[A\n",
      "607345it [00:50, 11840.36it/s]\u001b[A\n",
      "608530it [00:50, 11840.02it/s]\u001b[A\n",
      "609733it [00:50, 11893.18it/s]\u001b[A\n",
      "610924it [00:50, 11894.97it/s]\u001b[A\n",
      "612138it [00:50, 11964.21it/s]\u001b[A\n",
      "613342it [00:50, 11983.60it/s]\u001b[A\n",
      "614559it [00:51, 12035.66it/s]\u001b[A\n",
      "615772it [00:51, 12060.53it/s]\u001b[A\n",
      "616979it [00:51, 12024.02it/s]\u001b[A\n",
      "618184it [00:51, 12028.52it/s]\u001b[A\n",
      "619396it [00:51, 12052.54it/s]\u001b[A\n",
      "620603it [00:51, 12054.50it/s]\u001b[A\n",
      "621816it [00:51, 12073.76it/s]\u001b[A\n",
      "623024it [00:51, 12072.33it/s]\u001b[A\n",
      "624232it [00:51, 12035.22it/s]\u001b[A\n",
      "625436it [00:51, 11961.58it/s]\u001b[A\n",
      "626644it [00:52, 11993.62it/s]\u001b[A\n",
      "627847it [00:52, 12001.23it/s]\u001b[A\n",
      "629050it [00:52, 12006.59it/s]\u001b[A\n",
      "630255it [00:52, 12016.30it/s]\u001b[A\n",
      "631475it [00:52, 12067.56it/s]\u001b[A\n",
      "632686it [00:52, 12076.97it/s]\u001b[A\n",
      "633896it [00:52, 12080.59it/s]\u001b[A\n",
      "635111it [00:52, 12098.03it/s]\u001b[A\n",
      "636321it [00:52, 12095.33it/s]\u001b[A\n",
      "637542it [00:52, 12126.21it/s]\u001b[A\n",
      "638755it [00:53, 12124.05it/s]\u001b[A\n",
      "639968it [00:53, 12086.25it/s]\u001b[A\n",
      "641177it [00:53, 12084.08it/s]\u001b[A\n",
      "642392it [00:53, 12100.50it/s]\u001b[A\n",
      "643603it [00:53, 12100.04it/s]\u001b[A\n",
      "644814it [00:53, 12099.72it/s]\u001b[A\n",
      "646024it [00:53, 12096.51it/s]\u001b[A\n",
      "647234it [00:53, 11986.34it/s]\u001b[A\n",
      "648433it [00:53, 11912.66it/s]\u001b[A\n",
      "649633it [00:53, 11935.48it/s]\u001b[A\n",
      "650842it [00:54, 11978.18it/s]\u001b[A\n",
      "652041it [00:54, 11978.44it/s]\u001b[A\n",
      "653252it [00:54, 12014.36it/s]\u001b[A\n",
      "654462it [00:54, 12036.66it/s]\u001b[A\n",
      "655674it [00:54, 12058.26it/s]\u001b[A\n",
      "656881it [00:54, 12058.50it/s]\u001b[A\n",
      "658094it [00:54, 12076.57it/s]\u001b[A\n",
      "659313it [00:54, 12107.10it/s]\u001b[A\n",
      "660524it [00:54, 12104.67it/s]\u001b[A\n",
      "661735it [00:54, 12102.96it/s]\u001b[A\n",
      "662950it [00:55, 12113.74it/s]\u001b[A\n",
      "664162it [00:55, 12112.31it/s]\u001b[A\n",
      "665374it [00:55, 12003.25it/s]\u001b[A\n",
      "666583it [00:55, 12025.89it/s]\u001b[A\n",
      "667796it [00:55, 12053.66it/s]\u001b[A\n",
      "669002it [00:55, 12052.28it/s]\u001b[A\n",
      "670208it [00:55, 12051.31it/s]\u001b[A\n",
      "671418it [00:55, 12062.58it/s]\u001b[A\n",
      "672628it [00:55, 12070.50it/s]\u001b[A\n",
      "673836it [00:55, 11962.39it/s]\u001b[A\n",
      "675044it [00:56, 11994.18it/s]\u001b[A\n",
      "676252it [00:56, 12016.53it/s]\u001b[A\n",
      "677463it [00:56, 12041.15it/s]\u001b[A\n",
      "678668it [00:56, 12040.52it/s]\u001b[A\n",
      "679874it [00:56, 12043.07it/s]\u001b[A\n",
      "681092it [00:56, 12062.46it/s]\u001b[A\n",
      "682299it [00:56, 12061.43it/s]\u001b[A\n",
      "683506it [00:56, 12060.71it/s]\u001b[A\n",
      "684718it [00:56, 12075.16it/s]\u001b[A\n",
      "685935it [00:56, 12100.17it/s]\u001b[A\n",
      "687146it [00:57, 12099.81it/s]\u001b[A\n",
      "688363it [00:57, 12117.50it/s]\u001b[A\n",
      "689575it [00:57, 12114.93it/s]\u001b[A\n",
      "690787it [00:57, 12076.90it/s]\u001b[A\n",
      "691995it [00:57, 11966.79it/s]\u001b[A\n",
      "693204it [00:57, 12000.24it/s]\u001b[A\n",
      "694406it [00:57, 12002.87it/s]\u001b[A\n",
      "695612it [00:57, 12016.70it/s]\u001b[A\n",
      "696814it [00:57, 12014.40it/s]\u001b[A\n",
      "698018it [00:57, 12018.80it/s]\u001b[A\n",
      "699220it [00:58, 11335.37it/s]\u001b[A\n",
      "700421it [00:58, 11526.64it/s]\u001b[A\n",
      "701627it [00:58, 11678.53it/s]\u001b[A\n",
      "702805it [00:58, 11705.63it/s]\u001b[A\n",
      "704015it [00:58, 11818.05it/s]\u001b[A\n",
      "705204it [00:58, 11836.34it/s]\u001b[A\n",
      "706403it [00:58, 11878.81it/s]\u001b[A\n",
      "707593it [00:58, 11881.91it/s]\u001b[A\n",
      "708785it [00:58, 11890.09it/s]\u001b[A\n",
      "709991it [00:59, 11937.32it/s]\u001b[A\n",
      "711186it [00:59, 11937.87it/s]\u001b[A\n",
      "712382it [00:59, 11941.25it/s]\u001b[A\n",
      "713585it [00:59, 11964.48it/s]\u001b[A\n",
      "714784it [00:59, 11968.87it/s]\u001b[A\n",
      "715982it [00:59, 11897.54it/s]\u001b[A\n",
      "717174it [00:59, 11901.05it/s]\u001b[A\n",
      "718383it [00:59, 11953.88it/s]\u001b[A\n",
      "719595it [00:59, 11999.99it/s]\u001b[A\n",
      "720803it [00:59, 12020.62it/s]\u001b[A\n",
      "722020it [01:00, 12061.77it/s]\u001b[A\n",
      "723232it [01:00, 12075.91it/s]\u001b[A\n",
      "724449it [01:00, 12100.70it/s]\u001b[A\n",
      "725660it [01:00, 12100.18it/s]\u001b[A\n",
      "726871it [01:00, 12099.82it/s]\u001b[A\n",
      "728087it [01:00, 12114.52it/s]\u001b[A\n",
      "729303it [01:00, 12124.83it/s]\u001b[A\n",
      "730516it [01:00, 12086.80it/s]\u001b[A\n",
      "731725it [01:00, 12048.30it/s]\u001b[A\n",
      "732936it [01:00, 12063.46it/s]\u001b[A\n",
      "734150it [01:01, 12083.05it/s]\u001b[A\n",
      "735369it [01:01, 12111.63it/s]\u001b[A\n",
      "736585it [01:01, 12122.82it/s]\u001b[A\n",
      "737800it [01:01, 12127.66it/s]\u001b[A\n",
      "739014it [01:01, 12128.04it/s]\u001b[A\n",
      "740227it [01:01, 12052.97it/s]\u001b[A\n",
      "741433it [01:01, 12051.75it/s]\u001b[A\n",
      "742639it [01:01, 12050.97it/s]\u001b[A\n",
      "743850it [01:01, 12065.33it/s]\u001b[A\n",
      "745065it [01:01, 12087.33it/s]\u001b[A\n",
      "746274it [01:02, 12084.83it/s]\u001b[A\n",
      "747483it [01:02, 12083.07it/s]\u001b[A\n",
      "748695it [01:02, 12090.85it/s]\u001b[A\n",
      "749905it [01:02, 12090.29it/s]\u001b[A\n",
      "751115it [01:02, 12053.53it/s]\u001b[A\n",
      "752321it [01:02, 12052.41it/s]\u001b[A\n",
      "753527it [01:02, 12051.39it/s]\u001b[A\n",
      "754733it [01:02, 12050.67it/s]\u001b[A\n",
      "755939it [01:02, 11978.32it/s]\u001b[A\n",
      "757152it [01:02, 12020.17it/s]\u001b[A\n",
      "758364it [01:03, 12046.68it/s]\u001b[A\n",
      "759569it [01:03, 12044.39it/s]\u001b[A\n",
      "760776it [01:03, 12048.78it/s]\u001b[A\n",
      "761984it [01:03, 12054.83it/s]\u001b[A\n",
      "763198it [01:03, 12076.99it/s]\u001b[A\n",
      "764408it [01:03, 12080.58it/s]\u001b[A\n",
      "765618it [01:03, 12083.10it/s]\u001b[A\n",
      "766833it [01:03, 12099.81it/s]\u001b[A\n",
      "768044it [01:03, 12099.56it/s]\u001b[A\n",
      "769255it [01:03, 12099.40it/s]\u001b[A\n",
      "770467it [01:04, 12102.27it/s]\u001b[A\n",
      "771680it [01:04, 12107.27it/s]\u001b[A\n",
      "772891it [01:04, 12104.79it/s]\u001b[A\n",
      "774102it [01:04, 12103.05it/s]\u001b[A\n",
      "775313it [01:04, 12101.83it/s]\u001b[A\n",
      "776524it [01:04, 12100.96it/s]\u001b[A\n",
      "777735it [01:04, 12100.38it/s]\u001b[A\n",
      "778946it [01:04, 12063.77it/s]\u001b[A\n",
      "780154it [01:04, 12065.35it/s]\u001b[A\n",
      "781363it [01:04, 12069.44it/s]\u001b[A\n",
      "782570it [01:05, 12066.31it/s]\u001b[A\n",
      "783779it [01:05, 12070.12it/s]\u001b[A\n",
      "784987it [01:05, 12069.78it/s]\u001b[A\n",
      "786198it [01:05, 12078.54it/s]\u001b[A\n",
      "787406it [01:05, 12039.54it/s]\u001b[A\n",
      "788615it [01:05, 12051.36it/s]\u001b[A\n",
      "789825it [01:05, 12062.63it/s]\u001b[A\n",
      "791045it [01:05, 12100.23it/s]\u001b[A\n",
      "792256it [01:05, 12099.86it/s]\u001b[A\n",
      "793467it [01:05, 12099.61it/s]\u001b[A\n",
      "794677it [01:06, 12060.22it/s]\u001b[A\n",
      "795890it [01:06, 12077.79it/s]\u001b[A\n",
      "797103it [01:06, 12090.10it/s]\u001b[A\n",
      "798313it [01:06, 12089.77it/s]\u001b[A\n",
      "799525it [01:06, 12095.53it/s]\u001b[A\n",
      "800735it [01:06, 12057.39it/s]\u001b[A\n",
      "801941it [01:06, 12054.89it/s]\u001b[A\n",
      "803147it [01:06, 12017.07it/s]\u001b[A\n",
      "804359it [01:06, 12044.50it/s]\u001b[A\n",
      "805568it [01:06, 12054.82it/s]\u001b[A\n",
      "806788it [01:07, 12076.65it/s]\u001b[A\n",
      "807999it [01:07, 12083.35it/s]\u001b[A\n",
      "809213it [01:07, 12097.00it/s]\u001b[A\n",
      "810427it [01:07, 12106.57it/s]\u001b[A\n",
      "811646it [01:07, 12128.17it/s]\u001b[A\n",
      "812861it [01:07, 12131.41it/s]\u001b[A\n",
      "814075it [01:07, 11881.14it/s]\u001b[A\n",
      "815276it [01:07, 11916.28it/s]\u001b[A\n",
      "816469it [01:07, 11881.50it/s]\u001b[A\n",
      "817658it [01:07, 11809.94it/s]\u001b[A\n",
      "818858it [01:08, 11863.13it/s]\u001b[A\n",
      "820059it [01:08, 11903.58it/s]\u001b[A\n",
      "821270it [01:08, 11961.52it/s]\u001b[A\n",
      "822467it [01:08, 11960.83it/s]\u001b[A\n",
      "823674it [01:08, 11990.11it/s]\u001b[A\n",
      "824896it [01:08, 12054.93it/s]\u001b[A\n",
      "826106it [01:08, 12065.12it/s]\u001b[A\n",
      "827318it [01:08, 12078.26it/s]\u001b[A\n",
      "828528it [01:08, 12081.46it/s]\u001b[A\n",
      "829737it [01:08, 12044.60it/s]\u001b[A\n",
      "830942it [01:09, 12042.92it/s]\u001b[A\n",
      "832147it [01:09, 12041.77it/s]\u001b[A\n",
      "833352it [01:09, 12040.94it/s]\u001b[A\n",
      "834557it [01:09, 11968.57it/s]\u001b[A\n",
      "835754it [01:09, 11929.92it/s]\u001b[A\n",
      "836956it [01:09, 11953.55it/s]\u001b[A\n",
      "838174it [01:09, 12017.37it/s]\u001b[A\n",
      "839379it [01:09, 12023.85it/s]\u001b[A\n",
      "840595it [01:09, 12061.12it/s]\u001b[A\n",
      "841816it [01:09, 12102.12it/s]\u001b[A\n",
      "843027it [01:10, 12101.18it/s]\u001b[A\n",
      "844238it [01:10, 12100.52it/s]\u001b[A\n",
      "845449it [01:10, 12100.06it/s]\u001b[A\n",
      "846660it [01:10, 12099.74it/s]\u001b[A\n",
      "847870it [01:10, 12096.51it/s]\u001b[A\n",
      "849080it [01:10, 12094.26it/s]\u001b[A\n",
      "850290it [01:10, 12092.69it/s]\u001b[A\n",
      "851501it [01:10, 12094.57it/s]\u001b[A\n",
      "852711it [01:10, 12092.88it/s]\u001b[A\n",
      "853921it [01:10, 12055.56it/s]\u001b[A\n",
      "855131it [01:11, 12065.57it/s]\u001b[A\n",
      "856344it [01:11, 12081.55it/s]\u001b[A\n",
      "857554it [01:11, 12083.79it/s]\u001b[A\n",
      "858767it [01:11, 12094.31it/s]\u001b[A\n",
      "859982it [01:11, 12107.68it/s]\u001b[A\n",
      "861202it [01:11, 12131.93it/s]\u001b[A\n",
      "862416it [01:11, 12131.04it/s]\u001b[A\n",
      "863630it [01:11, 12130.42it/s]\u001b[A\n",
      "864844it [01:11, 12129.97it/s]\u001b[A\n",
      "866058it [01:11, 12129.67it/s]\u001b[A\n",
      "867271it [01:12, 12126.47it/s]\u001b[A\n",
      "868484it [01:12, 12124.21it/s]\u001b[A\n",
      "869697it [01:12, 12122.65it/s]\u001b[A\n",
      "870910it [01:12, 12085.27it/s]\u001b[A\n",
      "872119it [01:12, 12083.40it/s]\u001b[A\n",
      "873328it [01:12, 12082.09it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "874537it [01:12, 12045.02it/s]\u001b[A\n",
      "875742it [01:12, 12043.22it/s]\u001b[A\n",
      "876947it [01:12, 12041.97it/s]\u001b[A\n",
      "878158it [01:12, 12059.02it/s]\u001b[A\n",
      "879367it [01:13, 12065.01it/s]\u001b[A\n",
      "880578it [01:13, 12075.19it/s]\u001b[A\n",
      "881786it [01:13, 12073.32it/s]\u001b[A\n",
      "882994it [01:13, 12000.02it/s]\u001b[A\n",
      "884195it [01:13, 11963.84it/s]\u001b[A\n",
      "885399it [01:13, 11983.33it/s]\u001b[A\n",
      "886608it [01:13, 12011.88it/s]\u001b[A\n",
      "887822it [01:13, 12046.77it/s]\u001b[A\n",
      "889033it [01:13, 12062.38it/s]\u001b[A\n",
      "890241it [01:13, 12064.38it/s]\u001b[A\n",
      "891450it [01:14, 12068.77it/s]\u001b[A\n",
      "892657it [01:14, 12065.83it/s]\u001b[A\n",
      "893872it [01:14, 12087.69it/s]\u001b[A\n",
      "895081it [01:14, 12085.08it/s]\u001b[A\n",
      "896292it [01:14, 12089.26it/s]\u001b[A\n",
      "897511it [01:14, 12116.00it/s]\u001b[A\n",
      "898723it [01:14, 12113.90it/s]\u001b[A\n",
      "899938it [01:14, 12121.41it/s]\u001b[A\n",
      "901151it [01:14, 12120.67it/s]\u001b[A\n",
      "902364it [01:14, 12120.17it/s]\u001b[A\n",
      "903577it [01:15, 12119.81it/s]\u001b[A\n",
      "904794it [01:15, 12131.51it/s]\u001b[A\n",
      "906008it [01:15, 12130.76it/s]\u001b[A\n",
      "907222it [01:15, 12093.93it/s]\u001b[A\n",
      "908440it [01:15, 12116.31it/s]\u001b[A\n",
      "909652it [01:15, 12114.13it/s]\u001b[A\n",
      "910864it [01:15, 12076.34it/s]\u001b[A\n",
      "912072it [01:15, 11966.40it/s]\u001b[A\n",
      "913273it [01:15, 11976.20it/s]\u001b[A\n",
      "914483it [01:15, 12009.82it/s]\u001b[A\n",
      "915701it [01:16, 12057.10it/s]\u001b[A\n",
      "916908it [01:16, 12057.69it/s]\u001b[A\n",
      "918117it [01:16, 12064.08it/s]\u001b[A\n",
      "919324it [01:16, 11919.48it/s]\u001b[A\n",
      "920541it [01:16, 11990.32it/s]\u001b[A\n",
      "921754it [01:16, 12028.63it/s]\u001b[A\n",
      "922958it [01:16, 12028.76it/s]\u001b[A\n",
      "924170it [01:16, 12052.71it/s]\u001b[A\n",
      "925379it [01:16, 12060.58it/s]\u001b[A\n",
      "926593it [01:16, 12081.03it/s]\u001b[A\n",
      "927802it [01:17, 12080.42it/s]\u001b[A\n",
      "929013it [01:17, 12085.98it/s]\u001b[A\n",
      "930222it [01:17, 12083.89it/s]\u001b[A\n",
      "931433it [01:17, 12088.42it/s]\u001b[A\n",
      "932652it [01:17, 12097.26it/s]\u001b[A\n",
      "933862it [01:17, 12094.78it/s]\u001b[A\n",
      "935080it [01:17, 12116.93it/s]\u001b[A\n",
      "936296it [01:17, 12126.51it/s]\u001b[A\n",
      "937509it [01:17, 12124.25it/s]\u001b[A\n",
      "938722it [01:17, 12122.67it/s]\u001b[A\n",
      "939936it [01:18, 12124.56it/s]\u001b[A\n",
      "941152it [01:18, 12131.85it/s]\u001b[A\n",
      "942366it [01:18, 12130.99it/s]\u001b[A\n",
      "943580it [01:18, 12094.10it/s]\u001b[A\n",
      "944790it [01:18, 12092.57it/s]\u001b[A\n",
      "946000it [01:18, 12091.49it/s]\u001b[A\n",
      "947210it [01:18, 11982.89it/s]\u001b[A\n",
      "948409it [01:18, 11981.76it/s]\u001b[A\n",
      "949617it [01:18, 12007.80it/s]\u001b[A\n",
      "950825it [01:18, 12026.09it/s]\u001b[A\n",
      "952039it [01:19, 12056.77it/s]\u001b[A\n",
      "953250it [01:19, 12069.40it/s]\u001b[A\n",
      "954461it [01:19, 12078.26it/s]\u001b[A\n",
      "955669it [01:19, 12039.35it/s]\u001b[A\n",
      "956873it [01:19, 12036.27it/s]\u001b[A\n",
      "958079it [01:19, 12040.09it/s]\u001b[A\n",
      "959290it [01:19, 12057.70it/s]\u001b[A\n",
      "960496it [01:19, 12055.10it/s]\u001b[A\n",
      "961702it [01:19, 12053.28it/s]\u001b[A\n",
      "962908it [01:19, 12052.02it/s]\u001b[A\n",
      "964114it [01:20, 12015.07it/s]\u001b[A\n",
      "965316it [01:20, 11977.32it/s]\u001b[A\n",
      "966525it [01:20, 12007.65it/s]\u001b[A\n",
      "967738it [01:20, 12040.83it/s]\u001b[A\n",
      "968943it [01:20, 12040.29it/s]\u001b[A\n",
      "970148it [01:20, 12039.92it/s]\u001b[A\n",
      "971353it [01:20, 12003.65it/s]\u001b[A\n",
      "972554it [01:20, 11966.36it/s]\u001b[A\n",
      "973751it [01:20, 11964.20it/s]\u001b[A\n",
      "974959it [01:20, 11995.44it/s]\u001b[A\n",
      "976175it [01:21, 12041.08it/s]\u001b[A\n",
      "977392it [01:21, 12076.21it/s]\u001b[A\n",
      "978602it [01:21, 12080.05it/s]\u001b[A\n",
      "979811it [01:21, 12079.73it/s]\u001b[A\n",
      "981020it [01:21, 12079.51it/s]\u001b[A\n",
      "982231it [01:21, 12085.36it/s]\u001b[A\n",
      "983440it [01:21, 12083.45it/s]\u001b[A\n",
      "984649it [01:21, 12082.11it/s]\u001b[A\n",
      "985858it [01:21, 12081.18it/s]\u001b[A\n",
      "987067it [01:21, 12080.53it/s]\u001b[A\n",
      "988276it [01:22, 12043.94it/s]\u001b[A\n",
      "989481it [01:22, 12042.48it/s]\u001b[A\n",
      "990695it [01:22, 12068.29it/s]\u001b[A\n",
      "991905it [01:22, 12074.48it/s]\u001b[A\n",
      "993113it [01:22, 12072.86it/s]\u001b[A\n",
      "994321it [01:22, 12035.59it/s]\u001b[A\n",
      "995527it [01:22, 12039.62it/s]\u001b[A\n",
      "996737it [01:22, 12054.39it/s]\u001b[A\n",
      "997952it [01:22, 12079.64it/s]\u001b[A\n",
      "999165it [01:22, 12091.42it/s]\u001b[A\n",
      "1000381it [01:23, 12108.60it/s]\u001b[A\n",
      "1001596it [01:23, 12117.70it/s]\u001b[A\n",
      "1002808it [01:23, 12115.09it/s]\u001b[A\n",
      "1004020it [01:23, 12077.01it/s]\u001b[A\n",
      "1005228it [01:23, 12074.60it/s]\u001b[A\n",
      "1006436it [01:23, 12072.94it/s]\u001b[A\n",
      "1007644it [01:23, 12071.76it/s]\u001b[A\n",
      "1008852it [01:23, 12070.94it/s]\u001b[A\n",
      "1010060it [01:23, 12070.36it/s]\u001b[A\n",
      "1011269it [01:23, 12072.95it/s]\u001b[A\n",
      "1012477it [01:24, 12071.78it/s]\u001b[A\n",
      "1013686it [01:24, 12073.95it/s]\u001b[A\n",
      "1014901it [01:24, 12093.37it/s]\u001b[A\n",
      "1016111it [01:24, 12019.92it/s]\u001b[A\n",
      "1017321it [01:24, 12040.56it/s]\u001b[A\n",
      "1018530it [01:24, 12052.08it/s]\u001b[A\n",
      "1019742it [01:24, 12069.09it/s]\u001b[A\n",
      "1020955it [01:24, 12084.02it/s]\u001b[A\n",
      "1022164it [01:24, 12082.51it/s]\u001b[A\n",
      "1023373it [01:24, 12081.46it/s]\u001b[A\n",
      "1024594it [01:25, 12116.45it/s]\u001b[A\n",
      "1025806it [01:25, 12114.21it/s]\u001b[A\n",
      "1027018it [01:25, 12112.64it/s]\u001b[A\n",
      "1028236it [01:25, 12129.48it/s]\u001b[A\n",
      "1029454it [01:25, 12141.28it/s]\u001b[A\n",
      "1030669it [01:25, 12140.58it/s]\u001b[A\n",
      "1031884it [01:25, 12140.09it/s]\u001b[A\n",
      "1033099it [01:25, 12103.44it/s]\u001b[A\n",
      "1034310it [01:25, 12065.88it/s]\u001b[A\n",
      "1035517it [01:26, 12063.83it/s]\u001b[A\n",
      "1036724it [01:26, 12062.40it/s]\u001b[A\n",
      "1037931it [01:26, 12061.38it/s]\u001b[A\n",
      "1039142it [01:26, 12072.65it/s]\u001b[A\n",
      "1040350it [01:26, 12071.55it/s]\u001b[A\n",
      "1041562it [01:26, 12082.76it/s]\u001b[A\n",
      "1042771it [01:26, 12081.64it/s]\u001b[A\n",
      "1043980it [01:26, 12008.79it/s]\u001b[A\n",
      "1045181it [01:26, 11969.94it/s]\u001b[A\n",
      "1046385it [01:26, 11987.61it/s]\u001b[A\n",
      "1047603it [01:27, 12041.45it/s]\u001b[A\n",
      "1048808it [01:27, 12040.71it/s]\u001b[A\n",
      "1050021it [01:27, 12064.09it/s]\u001b[A\n",
      "1051228it [01:27, 11990.60it/s]\u001b[A\n",
      "1052441it [01:27, 12028.84it/s]\u001b[A\n",
      "1053660it [01:27, 12073.47it/s]\u001b[A\n",
      "1054868it [01:27, 12072.12it/s]\u001b[A\n",
      "1056076it [01:27, 12035.07it/s]\u001b[A\n",
      "1057280it [01:27, 12033.28it/s]\u001b[A\n",
      "1058484it [01:27, 12032.01it/s]\u001b[A\n",
      "1059689it [01:28, 12034.13it/s]\u001b[A\n",
      "1060896it [01:28, 12041.58it/s]\u001b[A\n",
      "1062101it [01:28, 12040.82it/s]\u001b[A\n",
      "1063308it [01:28, 12046.28it/s]\u001b[A\n",
      "1064517it [01:28, 12056.08it/s]\u001b[A\n",
      "1065732it [01:28, 12080.83it/s]\u001b[A\n",
      "1066941it [01:28, 12080.27it/s]\u001b[A\n",
      "1068150it [01:28, 12079.90it/s]\u001b[A\n",
      "1069358it [01:28, 12004.57it/s]\u001b[A\n",
      "1070570it [01:28, 12035.70it/s]\u001b[A\n",
      "1071774it [01:29, 12033.71it/s]\u001b[A\n",
      "1072992it [01:29, 12073.95it/s]\u001b[A\n",
      "1074205it [01:29, 12087.43it/s]\u001b[A\n",
      "1075414it [01:29, 12048.74it/s]\u001b[A\n",
      "1076626it [01:29, 12066.74it/s]\u001b[A\n",
      "1077833it [01:29, 11956.77it/s]\u001b[A\n",
      "1079046it [01:29, 12004.97it/s]\u001b[A\n",
      "1080263it [01:29, 12050.75it/s]\u001b[A\n",
      "1081481it [01:29, 12085.96it/s]\u001b[A\n",
      "1082690it [01:29, 12083.88it/s]\u001b[A\n",
      "1083899it [01:30, 12082.41it/s]\u001b[A\n",
      "1085108it [01:30, 10059.11it/s]\u001b[A\n",
      "1086236it [01:30, 10394.09it/s]\u001b[A\n",
      "1087426it [01:30, 10801.58it/s]\u001b[A\n",
      "1088626it [01:30, 11132.38it/s]\u001b[A\n",
      "1089823it [01:30, 11368.13it/s]\u001b[A\n",
      "1091036it [01:30, 11583.45it/s]\u001b[A\n",
      "1092252it [01:30, 11747.48it/s]\u001b[A\n",
      "1093464it [01:30, 11853.66it/s]\u001b[A\n",
      "1094669it [01:30, 11908.66it/s]\u001b[A\n",
      "1095874it [01:31, 11947.48it/s]\u001b[A\n",
      "1097074it [01:31, 11959.93it/s]\u001b[A\n",
      "1098288it [01:31, 11992.22it/s]\u001b[A\n",
      "1099497it [01:31, 12018.12it/s]\u001b[A\n",
      "1100704it [01:31, 12030.36it/s]\u001b[A\n",
      "1101909it [01:31, 12032.97it/s]\u001b[A\n",
      "1103127it [01:31, 12073.44it/s]\u001b[A\n",
      "1104335it [01:31, 12072.11it/s]\u001b[A\n",
      "1105543it [01:31, 12071.18it/s]\u001b[A\n",
      "1106751it [01:31, 12070.53it/s]\u001b[A\n",
      "1107959it [01:32, 11998.09it/s]\u001b[A\n",
      "1109160it [01:32, 11998.37it/s]\u001b[A\n",
      "1110360it [01:32, 11995.60it/s]\u001b[A\n",
      "1111565it [01:32, 12008.60it/s]\u001b[A\n",
      "1112772it [01:32, 12023.68it/s]\u001b[A\n",
      "1113977it [01:32, 12028.29it/s]\u001b[A\n",
      "1115186it [01:32, 12043.46it/s]\u001b[A\n",
      "1116404it [01:32, 12080.83it/s]\u001b[A\n",
      "1117613it [01:32, 12080.28it/s]\u001b[A\n",
      "1118822it [01:32, 12043.77it/s]\u001b[A\n",
      "1120027it [01:33, 12042.34it/s]\u001b[A\n",
      "1121242it [01:33, 12071.16it/s]\u001b[A\n",
      "1122456it [01:33, 12088.46it/s]\u001b[A\n",
      "1123665it [01:33, 12085.61it/s]\u001b[A\n",
      "1124874it [01:33, 12047.47it/s]\u001b[A\n",
      "1126086it [01:33, 12065.87it/s]\u001b[A\n",
      "1127293it [01:33, 12063.82it/s]\u001b[A\n",
      "1128512it [01:33, 12098.12it/s]\u001b[A\n",
      "1129722it [01:33, 12095.37it/s]\u001b[A\n",
      "1130932it [01:33, 12093.45it/s]\u001b[A\n",
      "1132142it [01:34, 12055.95it/s]\u001b[A\n",
      "1133351it [01:34, 12062.86it/s]\u001b[A\n",
      "1134558it [01:34, 12061.71it/s]\u001b[A\n",
      "1135765it [01:34, 12060.91it/s]\u001b[A\n",
      "1136972it [01:34, 12060.34it/s]\u001b[A\n",
      "1138179it [01:34, 12023.86it/s]\u001b[A\n",
      "1139382it [01:34, 12022.42it/s]\u001b[A\n",
      "1140585it [01:34, 12021.42it/s]\u001b[A\n",
      "1141788it [01:34, 12020.71it/s]\u001b[A\n",
      "1143001it [01:34, 12050.03it/s]\u001b[A\n",
      "1144208it [01:35, 12052.73it/s]\u001b[A\n",
      "1145419it [01:35, 12066.56it/s]\u001b[A\n",
      "1146638it [01:35, 12100.06it/s]\u001b[A\n",
      "1147856it [01:35, 12120.64it/s]\u001b[A\n",
      "1149069it [01:35, 12120.14it/s]\u001b[A\n",
      "1150282it [01:35, 12119.79it/s]\u001b[A\n",
      "1151494it [01:35, 12080.28it/s]\u001b[A\n",
      "1152706it [01:35, 12088.87it/s]\u001b[A\n",
      "1153926it [01:35, 12118.71it/s]\u001b[A\n",
      "1155138it [01:35, 12115.79it/s]\u001b[A\n",
      "1156350it [01:36, 12113.74it/s]\u001b[A\n",
      "1157562it [01:36, 12040.06it/s]\u001b[A\n",
      "1158767it [01:36, 12039.77it/s]\u001b[A\n",
      "1159972it [01:36, 12039.55it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1161185it [01:36, 12063.27it/s]\u001b[A\n",
      "1162395it [01:36, 12070.97it/s]\u001b[A\n",
      "1163603it [01:36, 11718.78it/s]\u001b[A\n",
      "1164778it [01:36, 11689.91it/s]\u001b[A\n",
      "1165978it [01:36, 11778.09it/s]\u001b[A\n",
      "1167192it [01:37, 11881.20it/s]\u001b[A\n",
      "1168402it [01:37, 11942.78it/s]\u001b[A\n",
      "1169598it [01:37, 11944.69it/s]\u001b[A\n",
      "1170814it [01:37, 12005.24it/s]\u001b[A\n",
      "1172023it [01:37, 12027.28it/s]\u001b[A\n",
      "1173227it [01:37, 12027.82it/s]\u001b[A\n",
      "1174431it [01:37, 12028.18it/s]\u001b[A\n",
      "1175634it [01:37, 11989.46it/s]\u001b[A\n",
      "1176851it [01:37, 12039.80it/s]\u001b[A\n",
      "1178063it [01:37, 12060.47it/s]\u001b[A\n",
      "1179275it [01:38, 12074.99it/s]\u001b[A\n",
      "1180490it [01:38, 12094.11it/s]\u001b[A\n",
      "1181708it [01:38, 12116.45it/s]\u001b[A\n",
      "1182920it [01:38, 12114.22it/s]\u001b[A\n",
      "1184132it [01:38, 12076.40it/s]\u001b[A\n",
      "1185340it [01:38, 12038.06it/s]\u001b[A\n",
      "1186544it [01:38, 12035.35it/s]\u001b[A\n",
      "1187748it [01:38, 11997.45it/s]\u001b[A\n",
      "1188948it [01:38, 11994.95it/s]\u001b[A\n",
      "1190148it [01:38, 11993.18it/s]\u001b[A\n",
      "1191348it [01:39, 11956.08it/s]\u001b[A\n",
      "1192556it [01:39, 11989.76it/s]\u001b[A\n",
      "1193760it [01:39, 12001.50it/s]\u001b[A\n",
      "1194968it [01:39, 12021.68it/s]\u001b[A\n",
      "1196171it [01:39, 12020.90it/s]\u001b[A\n",
      "1197386it [01:39, 12056.07it/s]\u001b[A\n",
      "1198601it [01:39, 12080.82it/s]\u001b[A\n",
      "1199810it [01:39, 12080.29it/s]\u001b[A\n",
      "1201019it [01:39, 12079.89it/s]\u001b[A\n",
      "1202228it [01:39, 12043.49it/s]\u001b[A\n",
      "1203433it [01:40, 11970.32it/s]\u001b[A\n",
      "1204644it [01:40, 12008.64it/s]\u001b[A\n",
      "1205850it [01:40, 12020.73it/s]\u001b[A\n",
      "1207055it [01:40, 12026.21it/s]\u001b[A\n",
      "1208269it [01:40, 12056.85it/s]\u001b[A\n",
      "1209487it [01:40, 12090.26it/s]\u001b[A\n",
      "1210704it [01:40, 12110.79it/s]\u001b[A\n",
      "1211916it [01:40, 12110.25it/s]\u001b[A\n",
      "1213128it [01:40, 12109.86it/s]\u001b[A\n",
      "1214340it [01:40, 12109.61it/s]\u001b[A\n",
      "1215551it [01:41, 12106.42it/s]\u001b[A\n",
      "1216765it [01:41, 12113.17it/s]\u001b[A\n",
      "1217977it [01:41, 12111.91it/s]\u001b[A\n",
      "1219189it [01:41, 12111.03it/s]\u001b[A\n",
      "1220401it [01:41, 12074.19it/s]\u001b[A\n",
      "1221609it [01:41, 12072.64it/s]\u001b[A\n",
      "1222819it [01:41, 12059.33it/s]\u001b[A\n",
      "1224026it [01:41, 12059.22it/s]\u001b[A\n",
      "1225240it [01:41, 12080.08it/s]\u001b[A\n",
      "1226457it [01:41, 12103.63it/s]\u001b[A\n",
      "1227668it [01:42, 12102.23it/s]\u001b[A\n",
      "1228879it [01:42, 12101.26it/s]\u001b[A\n",
      "1230099it [01:42, 12127.43it/s]\u001b[A\n",
      "1231316it [01:42, 12136.87it/s]\u001b[A\n",
      "1232530it [01:42, 12134.48it/s]\u001b[A\n",
      "1233744it [01:42, 12096.53it/s]\u001b[A\n",
      "1234954it [01:42, 12094.27it/s]\u001b[A\n",
      "1236164it [01:42, 12092.69it/s]\u001b[A\n",
      "1237376it [01:42, 12097.57it/s]\u001b[A\n",
      "1238597it [01:42, 12127.80it/s]\u001b[A\n",
      "1239813it [01:43, 12134.13it/s]\u001b[A\n",
      "1241027it [01:43, 12132.58it/s]\u001b[A\n",
      "1242241it [01:43, 12131.49it/s]\u001b[A\n",
      "1243455it [01:43, 11986.88it/s]\u001b[A\n",
      "1244662it [01:43, 12008.43it/s]\u001b[A\n",
      "1245877it [01:43, 12047.29it/s]\u001b[A\n",
      "1247087it [01:43, 12059.77it/s]\u001b[A\n",
      "1248294it [01:43, 12059.54it/s]\u001b[A\n",
      "1249501it [01:43, 12059.40it/s]\u001b[A\n",
      "1250708it [01:43, 12059.29it/s]\u001b[A\n",
      "1251914it [01:44, 12056.20it/s]\u001b[A\n",
      "1253120it [01:44, 12054.05it/s]\u001b[A\n",
      "1254331it [01:44, 12067.50it/s]\u001b[A\n",
      "1255544it [01:44, 12082.90it/s]\u001b[A\n",
      "1256760it [01:44, 12102.64it/s]\u001b[A\n",
      "1257971it [01:44, 12101.55it/s]\u001b[A\n",
      "1259183it [01:44, 12103.77it/s]\u001b[A\n",
      "1260400it [01:44, 12120.27it/s]\u001b[A\n",
      "1261613it [01:44, 12119.89it/s]\u001b[A\n",
      "1262825it [01:44, 12116.61it/s]\u001b[A\n",
      "1264037it [01:45, 12114.33it/s]\u001b[A\n",
      "1265249it [01:45, 12112.71it/s]\u001b[A\n",
      "1266461it [01:45, 12111.59it/s]\u001b[A\n",
      "1267673it [01:45, 12110.81it/s]\u001b[A\n",
      "1268885it [01:45, 12110.26it/s]\u001b[A\n",
      "1270097it [01:45, 12109.89it/s]\u001b[A\n",
      "1271308it [01:45, 12070.38it/s]\u001b[A\n",
      "1272516it [01:45, 12069.97it/s]\u001b[A\n",
      "1273724it [01:45, 12069.68it/s]\u001b[A\n",
      "1274935it [01:45, 12078.46it/s]\u001b[A\n",
      "1276143it [01:46, 12075.62it/s]\u001b[A\n",
      "1277351it [01:46, 12073.65it/s]\u001b[A\n",
      "1278559it [01:46, 12036.14it/s]\u001b[A\n",
      "1279774it [01:46, 12066.80it/s]\u001b[A\n",
      "1280990it [01:46, 12091.33it/s]\u001b[A\n",
      "1282210it [01:46, 12120.44it/s]\u001b[A\n",
      "1283423it [01:46, 12120.00it/s]\u001b[A\n",
      "1284636it [01:46, 12119.69it/s]\u001b[A\n",
      "1285848it [01:46, 12116.48it/s]\u001b[A\n",
      "1287060it [01:46, 12077.98it/s]\u001b[A\n",
      "1288269it [01:47, 12078.28it/s]\u001b[A\n",
      "1289477it [01:47, 12003.44it/s]\u001b[A\n",
      "1290690it [01:47, 12037.88it/s]\u001b[A\n",
      "1291900it [01:47, 12053.16it/s]\u001b[A\n",
      "1293106it [01:47, 12051.92it/s]\u001b[A\n",
      "1294321it [01:47, 12077.90it/s]\u001b[A\n",
      "1295542it [01:47, 12113.94it/s]\u001b[A\n",
      "1296754it [01:47, 12112.46it/s]\u001b[A\n",
      "1297966it [01:47, 12111.42it/s]\u001b[A\n",
      "1299178it [01:47, 12110.69it/s]\u001b[A\n",
      "1300390it [01:48, 12110.17it/s]\u001b[A\n",
      "1301602it [01:48, 12109.82it/s]\u001b[A\n",
      "1302813it [01:48, 12106.55it/s]\u001b[A\n",
      "1304024it [01:48, 12104.30it/s]\u001b[A\n",
      "1305235it [01:48, 12102.71it/s]\u001b[A\n",
      "1306446it [01:48, 12065.40it/s]\u001b[A\n",
      "1307653it [01:48, 12063.48it/s]\u001b[A\n",
      "1308861it [01:48, 12065.13it/s]\u001b[A\n",
      "1310078it [01:48, 12093.13it/s]\u001b[A\n",
      "1311288it [01:48, 12091.89it/s]\u001b[A\n",
      "1312505it [01:49, 12111.92it/s]\u001b[A\n",
      "1313719it [01:49, 12117.03it/s]\u001b[A\n",
      "1314932it [01:49, 12117.61it/s]\u001b[A\n",
      "1316144it [01:49, 12115.02it/s]\u001b[A\n",
      "1317356it [01:49, 12076.98it/s]\u001b[A\n",
      "1318568it [01:49, 12086.56it/s]\u001b[A\n",
      "1319778it [01:49, 12087.27it/s]\u001b[A\n",
      "1320993it [01:49, 12102.75it/s]\u001b[A\n",
      "1322209it [01:49, 12116.56it/s]\u001b[A\n",
      "1323426it [01:49, 12129.25it/s]\u001b[A\n",
      "1324641it [01:50, 12132.15it/s]\u001b[A\n",
      "1325855it [01:50, 12131.20it/s]\u001b[A\n",
      "1327069it [01:50, 12130.54it/s]\u001b[A\n",
      "1328283it [01:50, 12130.06it/s]\u001b[A\n",
      "1329497it [01:50, 12093.45it/s]\u001b[A\n",
      "1330707it [01:50, 12092.12it/s]\u001b[A\n",
      "1331923it [01:50, 12109.11it/s]\u001b[A\n",
      "1333137it [01:50, 12115.06it/s]\u001b[A\n",
      "1334351it [01:50, 12119.21it/s]\u001b[A\n",
      "1335563it [01:50, 12116.15it/s]\u001b[A\n",
      "1336775it [01:51, 12114.01it/s]\u001b[A\n",
      "1337989it [01:51, 12118.49it/s]\u001b[A\n",
      "1339201it [01:51, 12115.63it/s]\u001b[A\n",
      "1340413it [01:51, 12113.63it/s]\u001b[A\n",
      "1341625it [01:51, 12112.24it/s]\u001b[A\n",
      "1342837it [01:51, 12111.27it/s]\u001b[A\n",
      "1344049it [01:51, 12110.58it/s]\u001b[A\n",
      "1345261it [01:51, 12110.09it/s]\u001b[A\n",
      "1346473it [01:51, 12109.77it/s]\u001b[A\n",
      "1347689it [01:51, 12121.50it/s]\u001b[A\n",
      "1348903it [01:52, 12105.44it/s]\u001b[A\n",
      "1350114it [01:52, 12103.51it/s]\u001b[A\n",
      "1351325it [01:52, 12102.16it/s]\u001b[A\n",
      "1352536it [01:52, 12101.18it/s]\u001b[A\n",
      "1353748it [01:52, 12103.54it/s]\u001b[A\n",
      "1354959it [01:52, 12102.17it/s]\u001b[A\n",
      "1356175it [01:52, 12116.18it/s]\u001b[A\n",
      "1357387it [01:52, 12114.00it/s]\u001b[A\n",
      "1358599it [01:52, 12112.50it/s]\u001b[A\n",
      "1359811it [01:52, 12075.21it/s]\u001b[A\n",
      "1361019it [01:53, 12037.23it/s]\u001b[A\n",
      "1362225it [01:53, 12040.78it/s]\u001b[A\n",
      "1363443it [01:53, 12078.93it/s]\u001b[A\n",
      "1364651it [01:53, 12039.82it/s]\u001b[A\n",
      "1365856it [01:53, 11861.65it/s]\u001b[A\n",
      "1367055it [01:53, 11896.65it/s]\u001b[A\n",
      "1368264it [01:53, 11950.77it/s]\u001b[A\n",
      "1369478it [01:53, 12003.67it/s]\u001b[A\n",
      "1370693it [01:53, 12043.95it/s]\u001b[A\n",
      "1371905it [01:53, 12063.38it/s]\u001b[A\n",
      "1373112it [01:54, 12062.07it/s]\u001b[A\n",
      "1374319it [01:54, 12061.16it/s]\u001b[A\n",
      "1375526it [01:54, 12060.53it/s]\u001b[A\n",
      "1376733it [01:54, 12060.08it/s]\u001b[A\n",
      "1377940it [01:54, 12023.68it/s]\u001b[A\n",
      "1379155it [01:54, 12058.03it/s]\u001b[A\n",
      "1380368it [01:54, 12076.26it/s]\u001b[A\n",
      "1381577it [01:54, 12077.08it/s]\u001b[A\n",
      "1382786it [01:54, 12077.65it/s]\u001b[A\n",
      "1383994it [01:54, 12075.08it/s]\u001b[A\n",
      "1385206it [01:55, 12085.22it/s]\u001b[A\n",
      "1386429it [01:55, 12125.01it/s]\u001b[A\n",
      "1387644it [01:55, 12129.19it/s]\u001b[A\n",
      "1388857it [01:55, 12126.11it/s]\u001b[A\n",
      "1390070it [01:55, 12123.98it/s]\u001b[A\n",
      "1391283it [01:55, 12122.48it/s]\u001b[A\n",
      "1392496it [01:55, 12121.42it/s]\u001b[A\n",
      "1393709it [01:55, 12084.44it/s]\u001b[A\n",
      "1394920it [01:55, 12088.81it/s]\u001b[A\n",
      "1396129it [01:55, 12085.86it/s]\u001b[A\n",
      "1397347it [01:56, 12110.66it/s]\u001b[A\n",
      "1398559it [01:56, 10627.38it/s]\u001b[A\n",
      "1399755it [01:56, 10992.15it/s]\u001b[A\n",
      "1400964it [01:56, 11297.09it/s]\u001b[A\n",
      "1402174it [01:56, 11523.55it/s]\u001b[A\n",
      "1403377it [01:56, 11667.88it/s]\u001b[A\n",
      "1404586it [01:56, 11788.25it/s]\u001b[A\n",
      "1405809it [01:56, 11914.22it/s]\u001b[A\n",
      "1407028it [01:56, 11992.41it/s]\u001b[A\n",
      "1408244it [01:57, 12038.91it/s]\u001b[A\n",
      "1409457it [01:57, 12062.85it/s]\u001b[A\n",
      "1410669it [01:57, 12076.64it/s]\u001b[A\n",
      "1411883it [01:57, 12092.30it/s]\u001b[A\n",
      "1413098it [01:57, 12106.26it/s]\u001b[A\n",
      "1414313it [01:57, 12116.04it/s]\u001b[A\n",
      "1415527it [01:57, 12119.92it/s]\u001b[A\n",
      "1416740it [01:57, 12119.64it/s]\u001b[A\n",
      "1417960it [01:57, 12140.34it/s]\u001b[A\n",
      "1419175it [01:57, 12139.91it/s]\u001b[A\n",
      "1420390it [01:58, 12139.63it/s]\u001b[A\n",
      "1421605it [01:58, 12067.03it/s]\u001b[A\n",
      "1422818it [01:58, 12082.58it/s]\u001b[A\n",
      "1424028it [01:58, 12084.49it/s]\u001b[A\n",
      "1425238it [01:58, 12085.84it/s]\u001b[A\n",
      "1426447it [01:58, 12083.80it/s]\u001b[A\n",
      "1427656it [01:58, 12082.36it/s]\u001b[A\n",
      "1428865it [01:58, 12081.36it/s]\u001b[A\n",
      "1430080it [01:58, 12098.58it/s]\u001b[A\n",
      "1431299it [01:58, 12122.57it/s]\u001b[A\n",
      "1432512it [01:59, 12121.49it/s]\u001b[A\n",
      "1433725it [01:59, 12120.73it/s]\u001b[A\n",
      "1434941it [01:59, 12129.18it/s]\u001b[A\n",
      "1436154it [01:59, 12126.12it/s]\u001b[A\n",
      "1437368it [01:59, 12126.97it/s]\u001b[A\n",
      "1438583it [01:59, 12130.58it/s]\u001b[A\n",
      "1439797it [01:59, 12130.08it/s]\u001b[A\n",
      "1441011it [01:59, 12129.74it/s]\u001b[A\n",
      "1442224it [01:59, 12126.52it/s]\u001b[A\n",
      "1443437it [01:59, 12087.97it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1444646it [02:00, 12085.28it/s]\u001b[A\n",
      "1445855it [02:00, 12083.41it/s]\u001b[A\n",
      "1447064it [02:00, 12082.08it/s]\u001b[A\n",
      "1448273it [02:00, 12081.15it/s]\u001b[A\n",
      "1449482it [02:00, 12044.39it/s]\u001b[A\n",
      "1450689it [02:00, 12048.77it/s]\u001b[A\n",
      "1451895it [02:00, 12048.84it/s]\u001b[A\n",
      "1453110it [02:00, 12075.75it/s]\u001b[A\n",
      "1454318it [02:00, 12073.72it/s]\u001b[A\n",
      "1455526it [02:00, 12072.32it/s]\u001b[A\n",
      "1456741it [02:01, 12092.23it/s]\u001b[A\n",
      "1457957it [02:01, 12109.18it/s]\u001b[A\n",
      "1459175it [02:01, 12127.05it/s]\u001b[A\n",
      "1460391it [02:01, 12133.61it/s]\u001b[A\n",
      "1461605it [02:01, 12132.21it/s]\u001b[A\n",
      "1462819it [02:01, 12094.94it/s]\u001b[A\n",
      "1464038it [02:01, 12120.02it/s]\u001b[A\n",
      "1465251it [02:01, 12119.71it/s]\u001b[A\n",
      "1466463it [02:01, 12116.49it/s]\u001b[A\n",
      "1467675it [02:01, 12114.24it/s]\u001b[A\n",
      "1468887it [02:02, 12058.27it/s]\u001b[A\n",
      "1470101it [02:02, 12079.38it/s]\u001b[A\n",
      "1471310it [02:02, 12079.28it/s]\u001b[A\n",
      "1472523it [02:02, 12091.16it/s]\u001b[A\n",
      "1473744it [02:02, 12123.28it/s]\u001b[A\n",
      "1474957it [02:02, 12121.98it/s]\u001b[A\n",
      "1476170it [02:02, 12121.08it/s]\u001b[A\n",
      "1477383it [02:02, 12120.46it/s]\u001b[A\n",
      "1478596it [02:02, 12120.00it/s]\u001b[A\n",
      "1479809it [02:02, 12119.69it/s]\u001b[A\n",
      "1481021it [02:03, 12116.48it/s]\u001b[A\n",
      "1482233it [02:03, 12114.24it/s]\u001b[A\n",
      "1483449it [02:03, 12124.62it/s]\u001b[A\n",
      "1484672it [02:03, 12152.74it/s]\u001b[A\n",
      "1485888it [02:03, 12151.61it/s]\u001b[A\n",
      "1487115it [02:03, 12183.59it/s]\u001b[A\n",
      "1488334it [02:03, 12145.73it/s]\u001b[A\n",
      "1489553it [02:03, 12155.67it/s]\u001b[A\n",
      "1490770it [02:03, 12156.66it/s]\u001b[A\n",
      "1491986it [02:03, 12154.34it/s]\u001b[A\n",
      "1493202it [02:04, 12116.36it/s]\u001b[A\n",
      "1494415it [02:04, 12117.15it/s]\u001b[A\n",
      "1495627it [02:04, 12114.70it/s]\u001b[A\n",
      "1496839it [02:04, 12112.99it/s]\u001b[A\n",
      "1498051it [02:04, 12111.77it/s]\u001b[A\n",
      "1499263it [02:04, 12110.93it/s]\u001b[A\n",
      "1500480it [02:04, 12125.30it/s]\u001b[A\n",
      "1501693it [02:04, 12123.40it/s]\u001b[A\n",
      "1502906it [02:04, 12122.06it/s]\u001b[A\n",
      "1504119it [02:04, 12121.15it/s]\u001b[A\n",
      "1505333it [02:05, 12123.49it/s]\u001b[A\n",
      "1506557it [02:05, 12154.91it/s]\u001b[A\n",
      "1507773it [02:05, 12153.12it/s]\u001b[A\n",
      "1508989it [02:05, 12151.86it/s]\u001b[A\n",
      "1510205it [02:05, 12151.00it/s]\u001b[A\n",
      "1511421it [02:05, 12114.03it/s]\u001b[A\n",
      "1512633it [02:05, 12112.51it/s]\u001b[A\n",
      "1513852it [02:05, 12132.37it/s]\u001b[A\n",
      "1515067it [02:05, 12134.33it/s]\u001b[A\n",
      "1516281it [02:05, 12132.73it/s]\u001b[A\n",
      "1517495it [02:06, 12095.29it/s]\u001b[A\n",
      "1518707it [02:06, 12099.41it/s]\u001b[A\n",
      "1519917it [02:06, 12096.29it/s]\u001b[A\n",
      "1521127it [02:06, 12094.09it/s]\u001b[A\n",
      "1522337it [02:06, 12092.56it/s]\u001b[A\n",
      "1523547it [02:06, 12091.50it/s]\u001b[A\n",
      "1524757it [02:06, 12054.59it/s]\u001b[A\n",
      "1525974it [02:06, 12085.70it/s]\u001b[A\n",
      "1527187it [02:06, 12095.66it/s]\u001b[A\n",
      "1528400it [02:06, 12102.65it/s]\u001b[A\n",
      "1529611it [02:07, 12101.55it/s]\u001b[A\n",
      "1530822it [02:07, 12100.77it/s]\u001b[A\n",
      "1532033it [02:07, 12064.06it/s]\u001b[A\n",
      "1533240it [02:07, 12062.54it/s]\u001b[A\n",
      "1534455it [02:07, 12085.36it/s]\u001b[A\n",
      "1535674it [02:07, 12113.28it/s]\u001b[A\n",
      "1536891it [02:07, 12126.94it/s]\u001b[A\n",
      "1538104it [02:07, 12124.56it/s]\u001b[A\n",
      "1539317it [02:07, 12086.60it/s]\u001b[A\n",
      "1540526it [02:07, 12084.33it/s]\u001b[A\n",
      "1541735it [02:08, 12082.73it/s]\u001b[A\n",
      "1542947it [02:08, 12090.60it/s]\u001b[A\n",
      "1544161it [02:08, 12102.08it/s]\u001b[A\n",
      "1545380it [02:08, 12125.03it/s]\u001b[A\n",
      "1546596it [02:08, 12132.19it/s]\u001b[A\n",
      "1547810it [02:08, 12131.22it/s]\u001b[A\n",
      "1549024it [02:08, 12130.55it/s]\u001b[A\n",
      "1550238it [02:08, 12130.07it/s]\u001b[A\n",
      "1551452it [02:08, 12093.45it/s]\u001b[A\n",
      "1552662it [02:08, 12092.13it/s]\u001b[A\n",
      "1553873it [02:09, 12094.19it/s]\u001b[A\n",
      "1555098it [02:09, 12137.22it/s]\u001b[A\n",
      "1556312it [02:09, 12134.75it/s]\u001b[A\n",
      "1557527it [02:09, 12136.01it/s]\u001b[A\n",
      "1558741it [02:09, 12061.50it/s]\u001b[A\n",
      "1559948it [02:09, 12060.75it/s]\u001b[A\n",
      "1561157it [02:09, 12066.23it/s]\u001b[A\n",
      "1562368it [02:09, 12076.04it/s]\u001b[A\n",
      "1563582it [02:09, 12091.87it/s]\u001b[A\n",
      "1564795it [02:09, 12099.99it/s]\u001b[A\n",
      "1566017it [02:10, 12132.45it/s]\u001b[A\n",
      "1567231it [02:10, 12131.41it/s]\u001b[A\n",
      "1568445it [02:10, 12130.67it/s]\u001b[A\n",
      "1569659it [02:10, 12130.16it/s]\u001b[A\n",
      "1570873it [02:10, 12129.81it/s]\u001b[A\n",
      "1572086it [02:10, 12126.56it/s]\u001b[A\n",
      "1573299it [02:10, 12124.27it/s]\u001b[A\n",
      "1574512it [02:10, 12086.42it/s]\u001b[A\n",
      "1575721it [02:10, 12084.19it/s]\u001b[A\n",
      "1576930it [02:10, 12082.64it/s]\u001b[A\n",
      "1578139it [02:11, 12081.54it/s]\u001b[A\n",
      "1579348it [02:11, 12080.78it/s]\u001b[A\n",
      "1580557it [02:11, 12044.11it/s]\u001b[A\n",
      "1581762it [02:11, 12042.59it/s]\u001b[A\n",
      "1582967it [02:11, 12005.51it/s]\u001b[A\n",
      "1584186it [02:11, 12057.01it/s]\u001b[A\n",
      "1585393it [02:11, 12057.62it/s]\u001b[A\n",
      "1586601it [02:11, 12061.04it/s]\u001b[A\n",
      "1587815it [02:11, 12081.33it/s]\u001b[A\n",
      "1589025it [02:11, 12083.63it/s]\u001b[A\n",
      "1590235it [02:12, 12085.24it/s]\u001b[A\n",
      "1591448it [02:12, 12095.34it/s]\u001b[A\n",
      "1592658it [02:12, 12093.44it/s]\u001b[A\n",
      "1593868it [02:12, 12092.10it/s]\u001b[A\n",
      "1595083it [02:12, 12087.92it/s]\u001b[A\n",
      "1596292it [02:12, 12085.23it/s]\u001b[A\n",
      "1597506it [02:12, 12098.31it/s]\u001b[A\n",
      "1598724it [02:12, 12119.42it/s]\u001b[A\n",
      "1599936it [02:12, 12116.28it/s]\u001b[A\n",
      "1601148it [02:12, 12114.11it/s]\u001b[A\n",
      "1602360it [02:13, 12112.56it/s]\u001b[A\n",
      "1603572it [02:13, 12039.24it/s]\u001b[A\n",
      "1604777it [02:13, 12003.17it/s]\u001b[A\n",
      "1605979it [02:13, 12004.93it/s]\u001b[A\n",
      "1607188it [02:13, 12027.06it/s]\u001b[A\n",
      "1608403it [02:13, 12060.42it/s]\u001b[A\n",
      "1609622it [02:13, 12095.73it/s]\u001b[A\n",
      "1610833it [02:13, 12096.71it/s]\u001b[A\n",
      "1612050it [02:13, 12115.30it/s]\u001b[A\n",
      "1613274it [02:13, 12149.15it/s]\u001b[A\n",
      "1614492it [02:14, 12155.09it/s]\u001b[A\n",
      "1615715it [02:14, 12174.15it/s]\u001b[A\n",
      "1616933it [02:14, 12172.59it/s]\u001b[A\n",
      "1618151it [02:14, 12171.49it/s]\u001b[A\n",
      "1619369it [02:14, 12134.31it/s]\u001b[A\n",
      "1620583it [02:14, 12132.70it/s]\u001b[A\n",
      "1621797it [02:14, 12095.30it/s]\u001b[A\n",
      "1623007it [02:14, 12093.40it/s]\u001b[A\n",
      "1624219it [02:14, 12098.07it/s]\u001b[A\n",
      "1625431it [02:14, 12101.34it/s]\u001b[A\n",
      "1626644it [02:15, 12106.63it/s]\u001b[A\n",
      "1627866it [02:15, 12137.12it/s]\u001b[A\n",
      "1629080it [02:15, 12098.37it/s]\u001b[A\n",
      "1630290it [02:15, 12095.56it/s]\u001b[A\n",
      "1631500it [02:15, 12093.58it/s]\u001b[A\n",
      "1632717it [02:15, 12113.12it/s]\u001b[A\n",
      "1633932it [02:15, 12120.86it/s]\u001b[A\n",
      "1635145it [02:15, 12120.29it/s]\u001b[A\n",
      "1636358it [02:15, 12083.65it/s]\u001b[A\n",
      "1637567it [02:15, 12082.24it/s]\u001b[A\n",
      "1638780it [02:16, 12093.25it/s]\u001b[A\n",
      "1639992it [02:16, 12097.96it/s]\u001b[A\n",
      "1641204it [02:16, 12101.26it/s]\u001b[A\n",
      "1642418it [02:16, 12109.57it/s]\u001b[A\n",
      "1643629it [02:16, 12106.38it/s]\u001b[A\n",
      "1644840it [02:16, 12104.17it/s]\u001b[A\n",
      "1646051it [02:16, 12102.62it/s]\u001b[A\n",
      "1647262it [02:16, 12065.32it/s]\u001b[A\n",
      "1648471it [02:16, 12069.41it/s]\u001b[A\n",
      "1649678it [02:16, 12066.31it/s]\u001b[A\n",
      "1650901it [02:17, 12111.67it/s]\u001b[A\n",
      "1652113it [02:17, 12110.87it/s]\u001b[A\n",
      "1653325it [02:17, 12110.31it/s]\u001b[A\n",
      "1654537it [02:17, 12109.90it/s]\u001b[A\n",
      "1655749it [02:17, 12109.63it/s]\u001b[A\n",
      "1656960it [02:17, 12106.44it/s]\u001b[A\n",
      "1658171it [02:17, 11925.25it/s]\u001b[A\n",
      "1659365it [02:17, 11926.42it/s]\u001b[A\n",
      "1660566it [02:17, 11948.12it/s]\u001b[A\n",
      "1661779it [02:17, 11998.87it/s]\u001b[A\n",
      "1662996it [02:18, 12046.45it/s]\u001b[A\n",
      "1664212it [02:18, 12077.01it/s]\u001b[A\n",
      "1665428it [02:18, 12098.50it/s]\u001b[A\n",
      "1666638it [02:18, 12095.66it/s]\u001b[A\n",
      "1667848it [02:18, 12093.64it/s]\u001b[A\n",
      "1669058it [02:18, 12056.07it/s]\u001b[A\n",
      "1670273it [02:18, 12080.82it/s]\u001b[A\n",
      "1671488it [02:18, 12098.21it/s]\u001b[A\n",
      "1672700it [02:18, 12101.43it/s]\u001b[A\n",
      "1673911it [02:18, 12100.71it/s]\u001b[A\n",
      "1675127it [02:19, 12115.14it/s]\u001b[A\n",
      "1676339it [02:19, 12113.28it/s]\u001b[A\n",
      "1677551it [02:19, 12111.98it/s]\u001b[A\n",
      "1678763it [02:19, 12111.09it/s]\u001b[A\n",
      "1679975it [02:19, 12074.23it/s]\u001b[A\n",
      "1681183it [02:19, 12072.67it/s]\u001b[A\n",
      "1682394it [02:19, 12080.55it/s]\u001b[A\n",
      "1683617it [02:19, 12121.71it/s]\u001b[A\n",
      "1684830it [02:19, 12120.90it/s]\u001b[A\n",
      "1686043it [02:19, 12084.07it/s]\u001b[A\n",
      "1687252it [02:20, 12082.55it/s]\u001b[A\n",
      "1688461it [02:20, 12081.49it/s]\u001b[A\n",
      "1689670it [02:20, 12080.74it/s]\u001b[A\n",
      "1690885it [02:20, 12098.14it/s]\u001b[A\n",
      "1692095it [02:20, 12095.41it/s]\u001b[A\n",
      "1693305it [02:20, 12021.34it/s]\u001b[A\n",
      "1694514it [02:20, 12038.57it/s]\u001b[A\n",
      "1695722it [02:20, 12047.69it/s]\u001b[A\n",
      "1696931it [02:20, 12057.07it/s]\u001b[A\n",
      "1698142it [02:20, 12069.62it/s]\u001b[A\n",
      "1699353it [02:21, 12078.40it/s]\u001b[A\n",
      "1700565it [02:21, 12087.58it/s]\u001b[A\n",
      "1701776it [02:21, 12090.99it/s]\u001b[A\n",
      "1702986it [02:21, 12090.40it/s]\u001b[A\n",
      "1704196it [02:21, 12053.82it/s]\u001b[A\n",
      "1705402it [02:21, 12052.38it/s]\u001b[A\n",
      "1706608it [02:21, 12015.32it/s]\u001b[A\n",
      "1707810it [02:21, 12013.44it/s]\u001b[A\n",
      "1709028it [02:21, 12059.67it/s]\u001b[A\n",
      "1710242it [02:21, 12080.38it/s]\u001b[A\n",
      "1711453it [02:22, 12085.96it/s]\u001b[A\n",
      "1712662it [02:22, 12047.72it/s]\u001b[A\n",
      "1713867it [02:22, 12045.11it/s]\u001b[A\n",
      "1715074it [02:22, 12049.28it/s]\u001b[A\n",
      "1716283it [02:22, 12058.18it/s]\u001b[A\n",
      "1717493it [02:22, 12067.41it/s]\u001b[A\n",
      "1718707it [02:22, 12085.82it/s]\u001b[A\n",
      "1719925it [02:22, 12110.63it/s]\u001b[A\n",
      "1721145it [02:22, 12115.78it/s]\u001b[A\n",
      "1722357it [02:22, 12077.51it/s]\u001b[A\n",
      "1723565it [02:23, 12074.96it/s]\u001b[A\n",
      "1724773it [02:23, 12037.04it/s]\u001b[A\n",
      "1725977it [02:23, 12034.64it/s]\u001b[A\n",
      "1727181it [02:23, 12032.97it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1728392it [02:23, 12052.70it/s]\u001b[A\n",
      "1729603it [02:23, 12066.55it/s]\u001b[A\n",
      "1730813it [02:23, 12073.28it/s]\u001b[A\n",
      "1732021it [02:23, 12072.00it/s]\u001b[A\n",
      "1733229it [02:23, 12071.11it/s]\u001b[A\n",
      "1734437it [02:23, 12070.48it/s]\u001b[A\n",
      "1735653it [02:24, 12093.93it/s]\u001b[A\n",
      "1736868it [02:24, 12107.38it/s]\u001b[A\n",
      "1738079it [02:24, 12104.87it/s]\u001b[A\n",
      "1739290it [02:24, 12066.89it/s]\u001b[A\n",
      "1740497it [02:24, 12064.53it/s]\u001b[A\n",
      "1741708it [02:24, 12074.86it/s]\u001b[A\n",
      "1742921it [02:24, 12088.05it/s]\u001b[A\n",
      "1744137it [02:24, 12106.25it/s]\u001b[A\n",
      "1745348it [02:24, 12067.86it/s]\u001b[A\n",
      "1746555it [02:24, 12065.21it/s]\u001b[A\n",
      "1747762it [02:25, 12063.35it/s]\u001b[A\n",
      "1748969it [02:25, 12062.06it/s]\u001b[A\n",
      "1750178it [02:25, 12067.15it/s]\u001b[A\n",
      "1751395it [02:25, 12094.53it/s]\u001b[A\n",
      "1752607it [02:25, 12098.86it/s]\u001b[A\n",
      "1753820it [02:25, 12104.89it/s]\u001b[A\n",
      "1755044it [02:25, 12141.82it/s]\u001b[A\n",
      "1756259it [02:25, 12140.96it/s]\u001b[A\n",
      "1757474it [02:25, 12104.04it/s]\u001b[A\n",
      "1758685it [02:25, 12102.53it/s]\u001b[A\n",
      "1759896it [02:26, 12101.46it/s]\u001b[A\n",
      "1761107it [02:26, 11957.22it/s]\u001b[A\n",
      "1762312it [02:26, 11981.65it/s]\u001b[A\n",
      "1763521it [02:26, 12010.69it/s]\u001b[A\n",
      "1764730it [02:26, 12031.11it/s]\u001b[A\n",
      "1765934it [02:26, 12030.49it/s]\u001b[A\n",
      "1767144it [02:26, 12047.98it/s]\u001b[A\n",
      "1768358it [02:26, 12072.17it/s]\u001b[A\n",
      "1769566it [02:26, 12035.12it/s]\u001b[A\n",
      "1770780it [02:26, 12063.10it/s]\u001b[A\n",
      "1771988it [02:27, 12064.89it/s]\u001b[A\n",
      "1773195it [02:27, 12063.13it/s]\u001b[A\n",
      "1774402it [02:27, 12061.91it/s]\u001b[A\n",
      "1775615it [02:27, 12078.96it/s]\u001b[A\n",
      "1776831it [02:27, 12099.86it/s]\u001b[A\n",
      "1778042it [02:27, 12099.61it/s]\u001b[A\n",
      "1779252it [02:27, 12096.42it/s]\u001b[A\n",
      "1780462it [02:27, 12094.19it/s]\u001b[A\n",
      "1781672it [02:27, 12092.64it/s]\u001b[A\n",
      "1782882it [02:27, 12091.54it/s]\u001b[A\n",
      "1784092it [02:28, 12054.62it/s]\u001b[A\n",
      "1785303it [02:28, 12067.90it/s]\u001b[A\n",
      "1786510it [02:28, 12065.22it/s]\u001b[A\n",
      "1787717it [02:28, 12063.39it/s]\u001b[A\n",
      "1788929it [02:28, 12077.02it/s]\u001b[A\n",
      "1790145it [02:28, 12098.50it/s]\u001b[A\n",
      "1791355it [02:28, 12059.45it/s]\u001b[A\n",
      "1792561it [02:28, 12056.33it/s]\u001b[A\n",
      "1793767it [02:28, 12054.14it/s]\u001b[A\n",
      "1794980it [02:28, 12073.51it/s]\u001b[A\n",
      "1796188it [02:29, 12072.17it/s]\u001b[A\n",
      "1797396it [02:29, 12071.22it/s]\u001b[A\n",
      "1798604it [02:29, 12070.57it/s]\u001b[A\n",
      "1799816it [02:29, 12082.06it/s]\u001b[A\n",
      "1801025it [02:29, 11937.86it/s]\u001b[A\n",
      "1802245it [02:29, 12012.09it/s]\u001b[A\n",
      "1803448it [02:29, 12014.18it/s]\u001b[A\n",
      "1804659it [02:29, 12039.50it/s]\u001b[A\n",
      "1805874it [02:29, 12069.17it/s]\u001b[A\n",
      "1807084it [02:29, 12075.11it/s]\u001b[A\n",
      "1808296it [02:30, 12085.25it/s]\u001b[A\n",
      "1809507it [02:30, 12089.37it/s]\u001b[A\n",
      "1810716it [02:30, 12086.25it/s]\u001b[A\n",
      "1811925it [02:30, 12084.09it/s]\u001b[A\n",
      "1813134it [02:30, 12082.56it/s]\u001b[A\n",
      "1814343it [02:30, 12081.50it/s]\u001b[A\n",
      "1815552it [02:30, 12044.62it/s]\u001b[A\n",
      "1816757it [02:30, 12042.93it/s]\u001b[A\n",
      "1817962it [02:30, 12005.75it/s]\u001b[A\n",
      "1819165it [02:30, 12009.75it/s]\u001b[A\n",
      "1820377it [02:31, 12039.34it/s]\u001b[A\n",
      "1821589it [02:31, 12060.15it/s]\u001b[A\n",
      "1822807it [02:31, 12092.59it/s]\u001b[A\n",
      "1824018it [02:31, 12094.50it/s]\u001b[A\n",
      "1825228it [02:31, 12092.85it/s]\u001b[A\n",
      "1826438it [02:31, 12055.52it/s]\u001b[A\n",
      "1827653it [02:31, 12080.43it/s]\u001b[A\n",
      "1828863it [02:31, 12082.99it/s]\u001b[A\n",
      "1830074it [02:31, 12087.80it/s]\u001b[A\n",
      "1831292it [02:32, 12112.02it/s]\u001b[A\n",
      "1832504it [02:32, 12111.10it/s]\u001b[A\n",
      "1833716it [02:32, 12110.47it/s]\u001b[A\n",
      "1834928it [02:32, 11826.18it/s]\u001b[A\n",
      "1836131it [02:32, 11883.38it/s]\u001b[A\n",
      "1837325it [02:32, 11897.08it/s]\u001b[A\n",
      "1838523it [02:32, 11918.59it/s]\u001b[A\n",
      "1839734it [02:32, 11972.14it/s]\u001b[A\n",
      "1840944it [02:32, 12006.97it/s]\u001b[A\n",
      "1842152it [02:32, 12025.51it/s]\u001b[A\n",
      "1843367it [02:33, 12059.35it/s]\u001b[A\n",
      "1844574it [02:33, 12059.24it/s]\u001b[A\n",
      "1845781it [02:33, 12059.17it/s]\u001b[A\n",
      "1846988it [02:33, 12040.95it/s]\u001b[A\n",
      "1848193it [02:33, 12004.36it/s]\u001b[A\n",
      "1849396it [02:33, 12008.76it/s]\u001b[A\n",
      "1850603it [02:33, 12023.79it/s]\u001b[A\n",
      "1851813it [02:33, 12043.29it/s]\u001b[A\n",
      "1853024it [02:33, 12059.94it/s]\u001b[A\n",
      "1854235it [02:33, 12071.63it/s]\u001b[A\n",
      "1855457it [02:34, 12112.49it/s]\u001b[A\n",
      "1856670it [02:34, 12114.42it/s]\u001b[A\n",
      "1857883it [02:34, 12115.80it/s]\u001b[A\n",
      "1859097it [02:34, 12119.74it/s]\u001b[A\n",
      "1860309it [02:34, 12116.51it/s]\u001b[A\n",
      "1861521it [02:34, 12114.26it/s]\u001b[A\n",
      "1862733it [02:34, 12112.68it/s]\u001b[A\n",
      "1863945it [02:34, 12075.32it/s]\u001b[A\n",
      "1865153it [02:34, 12073.44it/s]\u001b[A\n",
      "1866361it [02:34, 12072.11it/s]\u001b[A\n",
      "1867574it [02:35, 12086.12it/s]\u001b[A\n",
      "1868783it [02:35, 12084.00it/s]\u001b[A\n",
      "1869992it [02:35, 12082.50it/s]\u001b[A\n",
      "1871201it [02:35, 12081.45it/s]\u001b[A\n",
      "1872410it [02:35, 12080.74it/s]\u001b[A\n",
      "1873619it [02:35, 12080.19it/s]\u001b[A\n",
      "1874828it [02:35, 12079.85it/s]\u001b[A\n",
      "1876036it [02:35, 12076.60it/s]\u001b[A\n",
      "1877244it [02:35, 12038.18it/s]\u001b[A\n",
      "1878448it [02:35, 12035.46it/s]\u001b[A\n",
      "1879652it [02:36, 12033.53it/s]\u001b[A\n",
      "1880859it [02:36, 12041.18it/s]\u001b[A\n",
      "1882075it [02:36, 12073.30it/s]\u001b[A\n",
      "1883294it [02:36, 12104.79it/s]\u001b[A\n",
      "1884505it [02:36, 12103.06it/s]\u001b[A\n",
      "1885716it [02:36, 12101.83it/s]\u001b[A\n",
      "1886927it [02:36, 12100.99it/s]\u001b[A\n",
      "1888138it [02:36, 12064.19it/s]\u001b[A\n",
      "1889350it [02:36, 12077.59it/s]\u001b[A\n",
      "1890558it [02:36, 12002.96it/s]\u001b[A\n",
      "1891759it [02:37, 12001.80it/s]\u001b[A\n",
      "1892980it [02:37, 12060.24it/s]\u001b[A\n",
      "1894187it [02:37, 12059.89it/s]\u001b[A\n",
      "1895394it [02:37, 12059.63it/s]\u001b[A\n",
      "1896601it [02:37, 12059.46it/s]\u001b[A\n",
      "1897807it [02:37, 12056.33it/s]\u001b[A\n",
      "1899013it [02:37, 12018.05it/s]\u001b[A\n",
      "1900215it [02:37, 11979.41it/s]\u001b[A\n",
      "1901417it [02:37, 11988.30it/s]\u001b[A\n",
      "1902624it [02:37, 12009.43it/s]\u001b[A\n",
      "1903837it [02:38, 12042.08it/s]\u001b[A\n",
      "1905042it [02:38, 12041.18it/s]\u001b[A\n",
      "1906247it [02:38, 12040.53it/s]\u001b[A\n",
      "1907457it [02:38, 12055.04it/s]\u001b[A\n",
      "1908675it [02:38, 12088.97it/s]\u001b[A\n",
      "1909884it [02:38, 12085.99it/s]\u001b[A\n",
      "1911093it [02:38, 12083.90it/s]\u001b[A\n",
      "1912312it [02:38, 12112.25it/s]\u001b[A\n",
      "1913524it [02:38, 12075.03it/s]\u001b[A\n",
      "1914732it [02:38, 12073.23it/s]\u001b[A\n",
      "1915940it [02:39, 12071.96it/s]\u001b[A\n",
      "1917148it [02:39, 11753.67it/s]\u001b[A\n",
      "1918358it [02:39, 11852.30it/s]\u001b[A\n",
      "1919563it [02:39, 11907.71it/s]\u001b[A\n",
      "1920773it [02:39, 11961.52it/s]\u001b[A\n",
      "1921990it [02:39, 12020.08it/s]\u001b[A\n",
      "1923198it [02:39, 12034.70it/s]\u001b[A\n",
      "1924416it [02:39, 12074.68it/s]\u001b[A\n",
      "1925629it [02:39, 12087.92it/s]\u001b[A\n",
      "1926843it [02:39, 12100.20it/s]\u001b[A\n",
      "1928056it [02:40, 12105.84it/s]\u001b[A\n",
      "1929267it [02:40, 12067.56it/s]\u001b[A\n",
      "1930474it [02:40, 12065.02it/s]\u001b[A\n",
      "1931681it [02:40, 12063.21it/s]\u001b[A\n",
      "1932888it [02:40, 12061.94it/s]\u001b[A\n",
      "1934095it [02:40, 12061.09it/s]\u001b[A\n",
      "1935302it [02:40, 12060.46it/s]\u001b[A\n",
      "1936509it [02:40, 12060.02it/s]\u001b[A\n",
      "1937716it [02:40, 12059.73it/s]\u001b[A\n",
      "1938930it [02:40, 12080.41it/s]\u001b[A\n",
      "1940139it [02:41, 12080.00it/s]\u001b[A\n",
      "1941348it [02:41, 12079.70it/s]\u001b[A\n",
      "1942556it [02:41, 12076.49it/s]\u001b[A\n",
      "1943764it [02:41, 12074.25it/s]\u001b[A\n",
      "1944972it [02:41, 12072.68it/s]\u001b[A\n",
      "1946180it [02:41, 12071.59it/s]\u001b[A\n",
      "1947388it [02:41, 12070.82it/s]\u001b[A\n",
      "1948596it [02:41, 12034.17it/s]\u001b[A\n",
      "1949809it [02:41, 12059.48it/s]\u001b[A\n",
      "1951015it [02:41, 12056.34it/s]\u001b[A\n",
      "1952221it [02:42, 12054.15it/s]\u001b[A\n",
      "1953427it [02:42, 12052.63it/s]\u001b[A\n",
      "1954635it [02:42, 12057.53it/s]\u001b[A\n",
      "1955842it [02:42, 12057.98it/s]\u001b[A\n",
      "1957051it [02:42, 12064.28it/s]\u001b[A\n",
      "1958260it [02:42, 12068.70it/s]\u001b[A\n",
      "1959475it [02:42, 12089.70it/s]\u001b[A\n",
      "1960685it [02:42, 12089.49it/s]\u001b[A\n",
      "1961896it [02:42, 12092.32it/s]\u001b[A\n",
      "1963106it [02:42, 12091.34it/s]\u001b[A\n",
      "1964319it [02:43, 12099.60it/s]\u001b[A\n",
      "1965529it [02:43, 12060.23it/s]\u001b[A\n",
      "1966736it [02:43, 12059.88it/s]\u001b[A\n",
      "1967943it [02:43, 12059.63it/s]\u001b[A\n",
      "1969152it [02:43, 12065.41it/s]\u001b[A\n",
      "1970366it [02:43, 12084.42it/s]\u001b[A\n",
      "1971575it [02:43, 12082.79it/s]\u001b[A\n",
      "1972786it [02:43, 12087.65it/s]\u001b[A\n",
      "1974005it [02:43, 12096.71it/s]\u001b[A\n",
      "1975215it [02:43, 12094.40it/s]\u001b[A\n",
      "1976425it [02:44, 12092.79it/s]\u001b[A\n",
      "1977635it [02:44, 12091.65it/s]\u001b[A\n",
      "1978845it [02:44, 12054.68it/s]\u001b[A\n",
      "1980051it [02:44, 12052.99it/s]\u001b[A\n",
      "1981258it [02:44, 12054.80it/s]\u001b[A\n",
      "1982467it [02:44, 12062.06it/s]\u001b[A\n",
      "1983679it [02:44, 12076.09it/s]\u001b[A\n",
      "1984887it [02:44, 12073.97it/s]\u001b[A\n",
      "1986095it [02:44, 12036.36it/s]\u001b[A\n",
      "1987299it [02:44, 12034.16it/s]\u001b[A\n",
      "1988513it [02:45, 12062.45it/s]\u001b[A\n",
      "1989720it [02:45, 12061.43it/s]\u001b[A\n",
      "1990927it [02:45, 12060.72it/s]\u001b[A\n",
      "1992138it [02:45, 12072.17it/s]\u001b[A\n",
      "1993352it [02:45, 12089.15it/s]\u001b[A\n",
      "1994566it [02:45, 12101.07it/s]\u001b[A\n",
      "1995777it [02:45, 12100.44it/s]\u001b[A\n",
      "1996988it [02:45, 12100.00it/s]\u001b[A\n",
      "1998199it [02:45, 12099.71it/s]\u001b[A\n",
      "1999409it [02:45, 12096.49it/s]\u001b[A\n",
      "2000619it [02:46, 12094.24it/s]\u001b[A\n",
      "2001829it [02:46, 12092.66it/s]\u001b[A\n",
      "2003039it [02:46, 12055.40it/s]\u001b[A\n",
      "2004251it [02:46, 12071.43it/s]\u001b[A\n",
      "2005460it [02:46, 12073.69it/s]\u001b[A\n",
      "2006671it [02:46, 12081.27it/s]\u001b[A\n",
      "2007885it [02:46, 12095.55it/s]\u001b[A\n",
      "2009095it [02:46, 12093.58it/s]\u001b[A\n",
      "2010305it [02:46, 12092.20it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2011515it [02:46, 11983.37it/s]\u001b[A\n",
      "2012726it [02:47, 12017.83it/s]\u001b[A\n",
      "2013939it [02:47, 12047.99it/s]\u001b[A\n",
      "2015144it [02:47, 12045.31it/s]\u001b[A\n",
      "2016357it [02:47, 12067.31it/s]\u001b[A\n",
      "2017571it [02:47, 12085.74it/s]\u001b[A\n",
      "2018783it [02:47, 12092.70it/s]\u001b[A\n",
      "2019997it [02:47, 12103.56it/s]\u001b[A\n",
      "2021208it [02:47, 12102.19it/s]\u001b[A\n",
      "2022419it [02:47, 12101.23it/s]\u001b[A\n",
      "2023630it [02:47, 12100.56it/s]\u001b[A\n",
      "2024841it [02:48, 12100.09it/s]\u001b[A\n",
      "2026056it [02:48, 12111.72it/s]\u001b[A\n",
      "2027268it [02:48, 12110.90it/s]\u001b[A\n",
      "2028480it [02:48, 12110.33it/s]\u001b[A\n",
      "2029692it [02:48, 12109.92it/s]\u001b[A\n",
      "2030903it [02:48, 12070.41it/s]\u001b[A\n",
      "2032114it [02:48, 12078.97it/s]\u001b[A\n",
      "2033328it [02:48, 12093.93it/s]\u001b[A\n",
      "2034542it [02:48, 12104.41it/s]\u001b[A\n",
      "2035764it [02:48, 12135.58it/s]\u001b[A\n",
      "2036985it [02:49, 12154.51it/s]\u001b[A\n",
      "2038201it [02:49, 12152.83it/s]\u001b[A\n",
      "2039417it [02:49, 12151.66it/s]\u001b[A\n",
      "2040633it [02:49, 12150.85it/s]\u001b[A\n",
      "2041849it [02:49, 12113.93it/s]\u001b[A\n",
      "2043061it [02:49, 12112.45it/s]\u001b[A\n",
      "2044273it [02:49, 12111.41it/s]\u001b[A\n",
      "2045485it [02:49, 12110.68it/s]\u001b[A\n",
      "2046697it [02:49, 12110.18it/s]\u001b[A\n",
      "2047909it [02:49, 12109.81it/s]\u001b[A\n",
      "2049120it [02:50, 12106.56it/s]\u001b[A\n",
      "2050331it [02:50, 12068.08it/s]\u001b[A\n",
      "2051546it [02:50, 12089.25it/s]\u001b[A\n",
      "2052755it [02:50, 12086.17it/s]\u001b[A\n",
      "2053964it [02:50, 12084.02it/s]\u001b[A\n",
      "2055173it [02:50, 12082.52it/s]\u001b[A\n",
      "2056382it [02:50, 12081.47it/s]\u001b[A\n",
      "2057591it [02:50, 12080.73it/s]\u001b[A\n",
      "2058800it [02:50, 11936.95it/s]\u001b[A\n",
      "2059997it [02:50, 11943.60it/s]\u001b[A\n",
      "2061205it [02:51, 11980.95it/s]\u001b[A\n",
      "2062408it [02:51, 11992.36it/s]\u001b[A\n",
      "2063608it [02:51, 11991.37it/s]\u001b[A\n",
      "2064808it [02:51, 11954.82it/s]\u001b[A\n",
      "2066008it [02:51, 11965.09it/s]\u001b[A\n",
      "2067205it [02:51, 11963.30it/s]\u001b[A\n",
      "2068402it [02:51, 11820.17it/s]\u001b[A\n",
      "2069585it [02:51, 11819.89it/s]\u001b[A\n",
      "2070794it [02:51, 11896.46it/s]\u001b[A\n",
      "2071993it [02:51, 11921.12it/s]\u001b[A\n",
      "2073186it [02:52, 11920.52it/s]\u001b[A\n",
      "2074382it [02:52, 11929.11it/s]\u001b[A\n",
      "2075588it [02:52, 11964.83it/s]\u001b[A\n",
      "2076796it [02:52, 11995.89it/s]\u001b[A\n",
      "2078011it [02:52, 12038.46it/s]\u001b[A\n",
      "2079217it [02:52, 12041.63it/s]\u001b[A\n",
      "2080422it [02:52, 12040.86it/s]\u001b[A\n",
      "2081639it [02:52, 12076.04it/s]\u001b[A\n",
      "2082847it [02:52, 12073.92it/s]\u001b[A\n",
      "2084055it [02:52, 12072.46it/s]\u001b[A\n",
      "2085263it [02:53, 12071.43it/s]\u001b[A\n",
      "2086471it [02:53, 12070.71it/s]\u001b[A\n",
      "2087683it [02:53, 12082.16it/s]\u001b[A\n",
      "2088892it [02:53, 12045.08it/s]\u001b[A\n",
      "2090097it [02:53, 12043.26it/s]\u001b[A\n",
      "2091302it [02:53, 12042.00it/s]\u001b[A\n",
      "2092507it [02:53, 12041.11it/s]\u001b[A\n",
      "2093719it [02:53, 12061.39it/s]\u001b[A\n",
      "2094929it [02:53, 12069.66it/s]\u001b[A\n",
      "2096141it [02:53, 12081.43it/s]\u001b[A\n",
      "2097358it [02:54, 12104.58it/s]\u001b[A\n",
      "2098577it [02:54, 12126.79it/s]\u001b[A\n",
      "2099799it [02:54, 12133.03it/s]\u001b[A\n",
      "2101013it [02:54, 12023.58it/s]\u001b[A\n",
      "2102226it [02:54, 12052.03it/s]\u001b[A\n",
      "2103432it [02:54, 12051.13it/s]\u001b[A\n",
      "2104649it [02:54, 12083.28it/s]\u001b[A\n",
      "2105863it [02:54, 12096.94it/s]\u001b[A\n",
      "2107074it [02:54, 12097.56it/s]\u001b[A\n",
      "2108286it [02:54, 12100.98it/s]\u001b[A\n",
      "2109502it [02:55, 12115.32it/s]\u001b[A\n",
      "2110714it [02:55, 12077.19it/s]\u001b[A\n",
      "2111922it [02:55, 12074.73it/s]\u001b[A\n",
      "2113130it [02:55, 12073.02it/s]\u001b[A\n",
      "2114342it [02:55, 12083.79it/s]\u001b[A\n",
      "2115560it [02:55, 12109.20it/s]\u001b[A\n",
      "2116771it [02:55, 12106.13it/s]\u001b[A\n",
      "2117982it [02:55, 12104.01it/s]\u001b[A\n",
      "2119193it [02:55, 12102.49it/s]\u001b[A\n",
      "2120404it [02:55, 12101.44it/s]\u001b[A\n",
      "2121624it [02:56, 12127.55it/s]\u001b[A\n",
      "2122837it [02:56, 12124.98it/s]\u001b[A\n",
      "2124050it [02:56, 12123.18it/s]\u001b[A\n",
      "2125265it [02:56, 12127.90it/s]\u001b[A\n",
      "2126478it [02:56, 12125.21it/s]\u001b[A\n",
      "2127694it [02:56, 12132.34it/s]\u001b[A\n",
      "2128908it [02:56, 12131.32it/s]\u001b[A\n",
      "2130126it [02:56, 12142.59it/s]\u001b[A\n",
      "2131341it [02:56, 12141.49it/s]\u001b[A\n",
      "2132556it [02:56, 12104.41it/s]\u001b[A\n",
      "2133768it [02:57, 12105.79it/s]\u001b[A\n",
      "2134979it [02:57, 12103.74it/s]\u001b[A\n",
      "2136190it [02:57, 12102.32it/s]\u001b[A\n",
      "2137401it [02:57, 12101.32it/s]\u001b[A\n",
      "2138612it [02:57, 12100.62it/s]\u001b[A\n",
      "2139823it [02:57, 12063.93it/s]\u001b[A\n",
      "2141030it [02:57, 12026.38it/s]\u001b[A\n",
      "2142235it [02:57, 12030.18it/s]\u001b[A\n",
      "2143444it [02:57, 12044.79it/s]\u001b[A\n",
      "2144651it [02:57, 12049.05it/s]\u001b[A\n",
      "2145859it [02:58, 12055.04it/s]\u001b[A\n",
      "2147065it [02:58, 12053.24it/s]\u001b[A\n",
      "2148271it [02:58, 12051.98it/s]\u001b[A\n",
      "2149477it [02:58, 12051.10it/s]\u001b[A\n",
      "2150693it [02:58, 12080.29it/s]\u001b[A\n",
      "2151910it [02:58, 12103.77it/s]\u001b[A\n",
      "2153121it [02:58, 12102.34it/s]\u001b[A\n",
      "2154332it [02:58, 12101.33it/s]\u001b[A\n",
      "2155543it [02:58, 12064.43it/s]\u001b[A\n",
      "2156750it [02:58, 12062.80it/s]\u001b[A\n",
      "2157957it [02:59, 12025.59it/s]\u001b[A\n",
      "2159161it [02:59, 12026.63it/s]\u001b[A\n",
      "2160377it [02:59, 12063.06it/s]\u001b[A\n",
      "2161584it [02:59, 12025.77it/s]\u001b[A\n",
      "2162791it [02:59, 12035.73it/s]\u001b[A\n",
      "2163999it [02:59, 12045.70it/s]\u001b[A\n",
      "2165215it [02:59, 12076.49it/s]\u001b[A\n",
      "2166426it [02:59, 12083.24it/s]\u001b[A\n",
      "2167641it [02:59, 12099.89it/s]\u001b[A\n",
      "2168852it [02:59, 12099.61it/s]\u001b[A\n",
      "2170070it [03:00, 12120.33it/s]\u001b[A\n",
      "2171283it [03:00, 12119.93it/s]\u001b[A\n",
      "2172496it [03:00, 12119.64it/s]\u001b[A\n",
      "2173708it [03:00, 12080.18it/s]\u001b[A\n",
      "2174917it [03:00, 12079.82it/s]\u001b[A\n",
      "2176129it [03:00, 12088.55it/s]\u001b[A\n",
      "2177338it [03:00, 12085.70it/s]\u001b[A\n",
      "2178547it [03:00, 12083.69it/s]\u001b[A\n",
      "2179758it [03:00, 12088.26it/s]\u001b[A\n",
      "2180967it [03:00, 12085.50it/s]\u001b[A\n",
      "2182182it [03:01, 12101.48it/s]\u001b[A\n",
      "2183393it [03:01, 12100.74it/s]\u001b[A\n",
      "2184604it [03:01, 12100.21it/s]\u001b[A\n",
      "2185819it [03:01, 12111.82it/s]\u001b[A\n",
      "2187031it [03:01, 12110.97it/s]\u001b[A\n",
      "2188254it [03:01, 12143.13it/s]\u001b[A\n",
      "2189469it [03:01, 12105.55it/s]\u001b[A\n",
      "2190680it [03:01, 12103.59it/s]\u001b[A\n",
      "2191895it [03:01, 12114.17it/s]\u001b[A\n",
      "2193109it [03:01, 12118.61it/s]\u001b[A\n",
      "2194322it [03:02, 12118.72it/s]\u001b[A\n",
      "2195997it [03:02, 12050.74it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2195864 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Glove 벡터 로드\n",
    "embeddings_index = {}\n",
    "f = open('./input/glove.840B.300d.txt', 'rt', encoding='UTF8')\n",
    "for line in tqdm(f):\n",
    "    try:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    except:\n",
    "        f.__next__()\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "imposed-charleston",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T11:48:19.025626Z",
     "start_time": "2021-03-10T11:48:19.014616Z"
    }
   },
   "outputs": [],
   "source": [
    "# 전체 문장에 대해 정규화된 벡터를 생성하는 함수\n",
    "def sent2vec(s):\n",
    "    words = str(s).lower()\n",
    "    words = word_tokenize(words)\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    M = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            M.append(embeddings_index[w])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.array(M) \n",
    "    v = M.sum(axis=0)\n",
    "    if type(v) != np.ndarray:\n",
    "        return np.zeros(300)\n",
    "    return v / np.sqrt((v ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "liberal-greenhouse",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T11:48:23.882041Z",
     "start_time": "2021-03-10T11:48:19.564116Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                        | 0/17621 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|█▎                                                                          | 301/17621 [00:00<00:05, 3007.26it/s]\u001b[A\n",
      "  4%|███▏                                                                        | 743/17621 [00:00<00:05, 3325.52it/s]\u001b[A\n",
      "  7%|█████▏                                                                     | 1211/17621 [00:00<00:04, 3640.94it/s]\u001b[A\n",
      "  9%|███████                                                                    | 1671/17621 [00:00<00:04, 3882.97it/s]\u001b[A\n",
      " 12%|█████████▏                                                                 | 2144/17621 [00:00<00:03, 4102.45it/s]\u001b[A\n",
      " 15%|███████████                                                                | 2585/17621 [00:00<00:03, 4189.03it/s]\u001b[A\n",
      " 17%|█████████████                                                              | 3057/17621 [00:00<00:03, 4334.25it/s]\u001b[A\n",
      " 20%|███████████████                                                            | 3532/17621 [00:00<00:03, 4449.99it/s]\u001b[A\n",
      " 23%|████████████████▉                                                          | 3987/17621 [00:00<00:03, 4478.32it/s]\u001b[A\n",
      " 25%|███████████████████                                                        | 4468/17621 [00:01<00:02, 4571.74it/s]\u001b[A\n",
      " 28%|████████████████████▉                                                      | 4921/17621 [00:01<00:02, 4516.94it/s]\u001b[A\n",
      " 31%|██████████████████████▉                                                    | 5384/17621 [00:01<00:02, 4549.05it/s]\u001b[A\n",
      " 33%|████████████████████████▊                                                  | 5837/17621 [00:01<00:02, 4514.89it/s]\u001b[A\n",
      " 36%|██████████████████████████▊                                                | 6292/17621 [00:01<00:02, 4524.14it/s]\u001b[A\n",
      " 38%|████████████████████████████▋                                              | 6745/17621 [00:01<00:02, 4524.66it/s]\u001b[A\n",
      " 41%|██████████████████████████████▋                                            | 7210/17621 [00:01<00:02, 4560.33it/s]\u001b[A\n",
      " 44%|████████████████████████████████▋                                          | 7666/17621 [00:01<00:02, 4531.78it/s]\u001b[A\n",
      " 46%|██████████████████████████████████▌                                        | 8128/17621 [00:01<00:02, 4556.66it/s]\u001b[A\n",
      " 49%|████████████████████████████████████▌                                      | 8596/17621 [00:01<00:01, 4591.74it/s]\u001b[A\n",
      " 51%|██████████████████████████████████████▌                                    | 9072/17621 [00:02<00:01, 4639.71it/s]\u001b[A\n",
      " 54%|████████████████████████████████████████▌                                  | 9537/17621 [00:02<00:01, 4627.67it/s]\u001b[A\n",
      " 57%|██████████████████████████████████████████                                | 10008/17621 [00:02<00:01, 4650.81it/s]\u001b[A\n",
      " 59%|███████████████████████████████████████████▉                              | 10474/17621 [00:02<00:01, 4597.17it/s]\u001b[A\n",
      " 62%|█████████████████████████████████████████████▉                            | 10934/17621 [00:02<00:01, 4596.76it/s]\u001b[A\n",
      " 65%|███████████████████████████████████████████████▊                          | 11394/17621 [00:02<00:01, 4528.54it/s]\u001b[A\n",
      " 67%|█████████████████████████████████████████████████▊                        | 11860/17621 [00:02<00:01, 4565.97it/s]\u001b[A\n",
      " 70%|███████████████████████████████████████████████████▋                      | 12317/17621 [00:02<00:01, 4565.94it/s]\u001b[A\n",
      " 73%|█████████████████████████████████████████████████████▋                    | 12777/17621 [00:02<00:01, 4574.86it/s]\u001b[A\n",
      " 75%|███████████████████████████████████████████████████████▌                  | 13235/17621 [00:02<00:00, 4561.47it/s]\u001b[A\n",
      " 78%|█████████████████████████████████████████████████████████▌                | 13692/17621 [00:03<00:00, 4549.15it/s]\u001b[A\n",
      " 80%|███████████████████████████████████████████████████████████▍              | 14148/17621 [00:03<00:00, 4551.15it/s]\u001b[A\n",
      " 83%|█████████████████████████████████████████████████████████████▍            | 14628/17621 [00:03<00:00, 4621.84it/s]\u001b[A\n",
      " 86%|███████████████████████████████████████████████████████████████▍          | 15104/17621 [00:03<00:00, 4661.19it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████████████████████████████████▍        | 15571/17621 [00:03<00:00, 4662.56it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████████████████████████████████▎      | 16038/17621 [00:03<00:00, 4567.65it/s]\u001b[A\n",
      " 94%|█████████████████████████████████████████████████████████████████████▎    | 16496/17621 [00:03<00:00, 4570.10it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████████████████████████████████████▏  | 16954/17621 [00:03<00:00, 4517.65it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 17621/17621 [00:03<00:00, 4543.22it/s]\u001b[A\n",
      "\n",
      "  0%|                                                                                         | 0/1958 [00:00<?, ?it/s]\u001b[A\n",
      " 23%|█████████████████▉                                                           | 455/1958 [00:00<00:00, 4545.85it/s]\u001b[A\n",
      " 46%|███████████████████████████████████▋                                         | 908/1958 [00:00<00:00, 4539.85it/s]\u001b[A\n",
      " 69%|████████████████████████████████████████████████████▋                       | 1357/1958 [00:00<00:00, 4523.53it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1958/1958 [00:00<00:00, 4549.35it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# 훈련/테스트 셋을 위 함수를 사용하여 문장 벡터 생성\n",
    "xtrain_glove = [sent2vec(x) for x in tqdm(xtrain)]\n",
    "xvalid_glove = [sent2vec(x) for x in tqdm(xvalid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "acknowledged-martin",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T11:50:04.471030Z",
     "start_time": "2021-03-10T11:50:04.444006Z"
    }
   },
   "outputs": [],
   "source": [
    "xtrain_glove = np.array(xtrain_glove)\n",
    "xvalid_glove = np.array(xvalid_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-postage",
   "metadata": {},
   "source": [
    "glove 피쳐에 대한 xgboost의 성능을 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "referenced-quarter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T11:52:10.115797Z",
     "start_time": "2021-03-10T11:52:00.502554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.797\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(nthread=10, silent=False)\n",
    "clf.fit(xtrain_glove, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_glove)\n",
    "\n",
    "print('logloss: %0.3f' %multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-kazakhstan",
   "metadata": {},
   "source": [
    "## Deep Learning\n",
    "하지만 지금은 딥러닝의 시대입니다. 우리는 LSTM과 glove 기능에 대한 단순 dense 네트워크를 교육할 것입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "threaded-mongolia",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T11:59:37.937586Z",
     "start_time": "2021-03-10T11:59:37.830489Z"
    }
   },
   "outputs": [],
   "source": [
    "# 신경망 구축 전 데이터 스케일링\n",
    "scl = preprocessing.StandardScaler()\n",
    "xtrain_glove_scl = scl.fit_transform(xtrain_glove)\n",
    "xvalid_glove_scl = scl.transform(xvalid_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "requested-accreditation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T11:59:42.858563Z",
     "start_time": "2021-03-10T11:59:42.852558Z"
    }
   },
   "outputs": [],
   "source": [
    "# 신경망을 위한 이진 레이블 생성\n",
    "ytrain_enc = np_utils.to_categorical(ytrain)\n",
    "yvalid_enc = np_utils.to_categorical(yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "arranged-xerox",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T11:59:43.161839Z",
     "start_time": "2021-03-10T11:59:43.059746Z"
    }
   },
   "outputs": [],
   "source": [
    "# 간단한 3 시퀀셜 신경망 구축\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(300, input_dim=300, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "turkish-protocol",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T11:59:48.149373Z",
     "start_time": "2021-03-10T11:59:44.195779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "276/276 [==============================] - 1s 2ms/step - loss: 0.9061 - val_loss: 0.7119\n",
      "Epoch 2/5\n",
      "276/276 [==============================] - 0s 2ms/step - loss: 0.6951 - val_loss: 0.6713\n",
      "Epoch 3/5\n",
      "276/276 [==============================] - 1s 2ms/step - loss: 0.6373 - val_loss: 0.6760\n",
      "Epoch 4/5\n",
      "276/276 [==============================] - 1s 2ms/step - loss: 0.5945 - val_loss: 0.6594\n",
      "Epoch 5/5\n",
      "276/276 [==============================] - 1s 2ms/step - loss: 0.5609 - val_loss: 0.6639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27c50448d48>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_glove_scl, y=ytrain_enc, batch_size=64,\n",
    "          epochs=5, verbose=1,\n",
    "          validation_data=(xvalid_glove_scl, yvalid_enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-huntington",
   "metadata": {},
   "source": [
    "더 나은 결과를 얻기 위해서는 신경망의 파라미터를 조정하고, 더 많은 레이어를 추가하고, 드롭아웃을 늘려야 합니다. 여기서는 xgboost보다 구현 및 실행이 빠르며 더 나은 결과를 보여주는 것을 최적화 없이 보여줍니다.\n",
    "\n",
    "더 나아가, LSTM을 이용하여 텍스트 데이터를 토큰화해야합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fuzzy-shower",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T12:02:13.596144Z",
     "start_time": "2021-03-10T12:02:12.886499Z"
    }
   },
   "outputs": [],
   "source": [
    "token = text.Tokenizer(num_words=None)\n",
    "max_len = 70\n",
    "\n",
    "token.fit_on_texts(list(xtrain) + list(xvalid))\n",
    "xtrain_seq = token.texts_to_sequences(xtrain)\n",
    "xvalid_seq = token.texts_to_sequences(xvalid)\n",
    "\n",
    "xtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\n",
    "xvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen=max_len)\n",
    "\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "thousand-amplifier",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T12:03:52.294407Z",
     "start_time": "2021-03-10T12:03:52.212332Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 25943/25943 [00:00<00:00, 381169.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# 임베딩 매트릭스 생성\n",
    "embedding_matrix = np.zeros((len(word_index)+1, 300))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "removable-original",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T12:06:40.646999Z",
     "start_time": "2021-03-10T12:06:40.358737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                    300,\n",
    "                    weights = [embedding_matrix],\n",
    "                    input_length = max_len,\n",
    "                    trainable = False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "collaborative-brisbane",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T12:20:11.247482Z",
     "start_time": "2021-03-10T12:07:28.540051Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 [==============================] - 8s 216ms/step - loss: 1.0623 - val_loss: 0.9204\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.8977 - val_loss: 0.7766\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.8208 - val_loss: 0.7158\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.7806 - val_loss: 0.6874\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.7593 - val_loss: 0.6595\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.7368 - val_loss: 0.6864\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.7258 - val_loss: 0.6341\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.7044 - val_loss: 0.6233\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.6896 - val_loss: 0.6194\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.6667 - val_loss: 0.5994\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.6488 - val_loss: 0.6010\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.6280 - val_loss: 0.5882\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.6126 - val_loss: 0.5610\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.5944 - val_loss: 0.5582\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.5785 - val_loss: 0.5719\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.5712 - val_loss: 0.5497\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.5498 - val_loss: 0.5390\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.5403 - val_loss: 0.5359\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 8s 216ms/step - loss: 0.5340 - val_loss: 0.5308\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.5150 - val_loss: 0.5099\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.4994 - val_loss: 0.5365\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.4873 - val_loss: 0.5124\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.4965 - val_loss: 0.5131\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.4708 - val_loss: 0.5207\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 7s 214ms/step - loss: 0.4650 - val_loss: 0.5192\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.4490 - val_loss: 0.5287\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.4386 - val_loss: 0.5415\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 8s 222ms/step - loss: 0.4450 - val_loss: 0.5212\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.4229 - val_loss: 0.4997\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 7s 214ms/step - loss: 0.4205 - val_loss: 0.5177\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.4174 - val_loss: 0.5437\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.4113 - val_loss: 0.4967\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.3956 - val_loss: 0.5020\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.3883 - val_loss: 0.4898\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.3863 - val_loss: 0.4978\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 7s 214ms/step - loss: 0.3818 - val_loss: 0.4987\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.3713 - val_loss: 0.5064\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.3679 - val_loss: 0.4992\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.3631 - val_loss: 0.5133\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.3629 - val_loss: 0.5049\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.3501 - val_loss: 0.4908\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.3422 - val_loss: 0.5081\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.3443 - val_loss: 0.4986\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.3435 - val_loss: 0.5025\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 8s 215ms/step - loss: 0.3370 - val_loss: 0.5222\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.3335 - val_loss: 0.5308\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.3210 - val_loss: 0.5030\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.3228 - val_loss: 0.5035\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.3142 - val_loss: 0.5133\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.3225 - val_loss: 0.5237\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.2981 - val_loss: 0.5271\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.3028 - val_loss: 0.5219\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 8s 218ms/step - loss: 0.3024 - val_loss: 0.5412\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.2997 - val_loss: 0.5312\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.2949 - val_loss: 0.5477\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 7s 214ms/step - loss: 0.2942 - val_loss: 0.5428\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.2952 - val_loss: 0.5397\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.2878 - val_loss: 0.5562\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.2831 - val_loss: 0.5424\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.2776 - val_loss: 0.5295\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.2827 - val_loss: 0.5431\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.2722 - val_loss: 0.5556\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.2682 - val_loss: 0.5585\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.2726 - val_loss: 0.5181\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.2655 - val_loss: 0.5341\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.2608 - val_loss: 0.5288\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.2604 - val_loss: 0.5495\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.2663 - val_loss: 0.5448\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.2566 - val_loss: 0.5510\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.2517 - val_loss: 0.5670\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 8s 215ms/step - loss: 0.2520 - val_loss: 0.5372\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.2400 - val_loss: 0.5463\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.2541 - val_loss: 0.5747\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.2466 - val_loss: 0.5526\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.2465 - val_loss: 0.5566\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.2430 - val_loss: 0.5976\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 7s 214ms/step - loss: 0.2414 - val_loss: 0.5811\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.2284 - val_loss: 0.5619\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.2394 - val_loss: 0.5774\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.2384 - val_loss: 0.5635\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 7s 211ms/step - loss: 0.2212 - val_loss: 0.5724\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.2321 - val_loss: 0.5951\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 7s 214ms/step - loss: 0.2339 - val_loss: 0.5741\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.2331 - val_loss: 0.5850\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.2308 - val_loss: 0.5776\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.2094 - val_loss: 0.5787\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.2153 - val_loss: 0.5792\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.2285 - val_loss: 0.5526\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.2192 - val_loss: 0.5987\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.2185 - val_loss: 0.5867\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.2138 - val_loss: 0.5768\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 7s 212ms/step - loss: 0.2181 - val_loss: 0.5549\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.2208 - val_loss: 0.5555\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 7s 214ms/step - loss: 0.2203 - val_loss: 0.5736\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.2165 - val_loss: 0.5867\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.2070 - val_loss: 0.5982\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 7s 210ms/step - loss: 0.2076 - val_loss: 0.6173\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 7s 213ms/step - loss: 0.2063 - val_loss: 0.6123\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 7s 211ms/step - loss: 0.2010 - val_loss: 0.5956\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 8s 216ms/step - loss: 0.2019 - val_loss: 0.6030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27e856a3248>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100, verbose=1, validation_data=(xvalid_pad, yvalid_enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-brief",
   "metadata": {},
   "source": [
    "점수가 0.5보다 낮아졌습니다. 조기중지 없이 전체 에포크에 대해 진행했으나, 최적의 반복에서 중지하는 것이 좋습니다. 조기중지를 사용하여 다시한번 진행해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eastern-laugh",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T12:24:18.103505Z",
     "start_time": "2021-03-10T12:20:25.963866Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 9s 267ms/step - loss: 1.0338 - val_loss: 0.8416\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 9s 264ms/step - loss: 0.8430 - val_loss: 0.7186\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 9s 257ms/step - loss: 0.8066 - val_loss: 0.7265\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 9s 256ms/step - loss: 0.7719 - val_loss: 0.6812\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 9s 251ms/step - loss: 0.7636 - val_loss: 0.6661\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 9s 249ms/step - loss: 0.7349 - val_loss: 0.6496\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 9s 248ms/step - loss: 0.7037 - val_loss: 0.6664\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 9s 260ms/step - loss: 0.6824 - val_loss: 0.6242\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 9s 253ms/step - loss: 0.6661 - val_loss: 0.6138\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 9s 248ms/step - loss: 0.6457 - val_loss: 0.5923\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 9s 250ms/step - loss: 0.6122 - val_loss: 0.5891\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 9s 249ms/step - loss: 0.5937 - val_loss: 0.5555\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 9s 257ms/step - loss: 0.5631 - val_loss: 0.5536\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 9s 250ms/step - loss: 0.5577 - val_loss: 0.5663\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 9s 257ms/step - loss: 0.5437 - val_loss: 0.5580\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 9s 254ms/step - loss: 0.5093 - val_loss: 0.5369\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 9s 250ms/step - loss: 0.4960 - val_loss: 0.5444\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 9s 250ms/step - loss: 0.4790 - val_loss: 0.5214\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 9s 249ms/step - loss: 0.4701 - val_loss: 0.5073\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 9s 249ms/step - loss: 0.4430 - val_loss: 0.5178\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 9s 258ms/step - loss: 0.4291 - val_loss: 0.4965\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 9s 262ms/step - loss: 0.4261 - val_loss: 0.4926\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 9s 262ms/step - loss: 0.4024 - val_loss: 0.5361\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 9s 263ms/step - loss: 0.3855 - val_loss: 0.5186\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 9s 263ms/step - loss: 0.3786 - val_loss: 0.5102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27e8d438f88>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                    300,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length = max_len,\n",
    "                    trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(LSTM(300, dropout=0.3, recurrent_dropout=0.3))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# 조기 중지 콜백을 사용하여 모델 적합\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100,\n",
    "          verbose=1, validation_data=(xvalid_pad, yvalid_enc),\n",
    "          callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-concern",
   "metadata": {},
   "source": [
    "드롭아웃의 비중을 크게 하는 이유는 적게 할 시 과적합의 가능성이 있기 때문입니다.\n",
    "\n",
    "Bi-directional LSTM이 더 나은 결과를 가져오는 것을 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "israeli-pressure",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T12:34:37.475844Z",
     "start_time": "2021-03-10T12:28:22.054357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 18s 515ms/step - loss: 1.0405 - val_loss: 0.8333\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 17s 488ms/step - loss: 0.8591 - val_loss: 0.7521\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 17s 492ms/step - loss: 0.8045 - val_loss: 0.7096\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 16s 466ms/step - loss: 0.7749 - val_loss: 0.6992\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 17s 488ms/step - loss: 0.7446 - val_loss: 0.6596\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 17s 496ms/step - loss: 0.7233 - val_loss: 0.6598\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 18s 502ms/step - loss: 0.7253 - val_loss: 0.6402\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 17s 498ms/step - loss: 0.6903 - val_loss: 0.6458\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 17s 489ms/step - loss: 0.6576 - val_loss: 0.5961\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 17s 487ms/step - loss: 0.6255 - val_loss: 0.5712\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 17s 489ms/step - loss: 0.6029 - val_loss: 0.5897\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 17s 492ms/step - loss: 0.5830 - val_loss: 0.5456\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 17s 486ms/step - loss: 0.5578 - val_loss: 0.5413\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 17s 487ms/step - loss: 0.5469 - val_loss: 0.5557\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 17s 485ms/step - loss: 0.5271 - val_loss: 0.5419\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 17s 490ms/step - loss: 0.5103 - val_loss: 0.5312\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 17s 490ms/step - loss: 0.4890 - val_loss: 0.5374\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 17s 485ms/step - loss: 0.4628 - val_loss: 0.5035\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 17s 490ms/step - loss: 0.4506 - val_loss: 0.5125\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 17s 499ms/step - loss: 0.4422 - val_loss: 0.5128\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 17s 490ms/step - loss: 0.4215 - val_loss: 0.5225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27e97660848>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                    300,\n",
    "                    weights = [embedding_matrix],\n",
    "                    input_length = max_len,\n",
    "                    trainable = False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(Bidirectional(LSTM(300, dropout=0.3, recurrent_dropout=0.3)))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "\n",
    "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100,\n",
    "          verbose=1, validation_data=(xvalid_pad, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-viewer",
   "metadata": {},
   "source": [
    "GRU를 사용해서 진행해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "first-niger",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T12:46:46.387251Z",
     "start_time": "2021-03-10T12:39:37.050206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "35/35 [==============================] - 16s 462ms/step - loss: 1.0480 - val_loss: 0.8984\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 16s 448ms/step - loss: 0.8908 - val_loss: 0.7694\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 16s 459ms/step - loss: 0.8284 - val_loss: 0.7305\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 16s 454ms/step - loss: 0.8034 - val_loss: 0.7335\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 16s 465ms/step - loss: 0.7672 - val_loss: 0.6813\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 16s 460ms/step - loss: 0.7400 - val_loss: 0.6810\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 16s 454ms/step - loss: 0.7123 - val_loss: 0.6215\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 16s 452ms/step - loss: 0.6845 - val_loss: 0.6327\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 16s 450ms/step - loss: 0.6695 - val_loss: 0.6039\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 16s 443ms/step - loss: 0.6368 - val_loss: 0.6030\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 16s 444ms/step - loss: 0.6282 - val_loss: 0.5561\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 16s 443ms/step - loss: 0.6038 - val_loss: 0.5466\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 16s 446ms/step - loss: 0.5860 - val_loss: 0.5412\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 16s 443ms/step - loss: 0.5640 - val_loss: 0.5196\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 16s 444ms/step - loss: 0.5443 - val_loss: 0.5224\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 16s 445ms/step - loss: 0.5246 - val_loss: 0.5280\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 16s 443ms/step - loss: 0.5085 - val_loss: 0.5099\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 16s 446ms/step - loss: 0.5103 - val_loss: 0.5102\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 16s 446ms/step - loss: 0.4835 - val_loss: 0.5065\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 16s 450ms/step - loss: 0.4653 - val_loss: 0.4883\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 16s 468ms/step - loss: 0.4724 - val_loss: 0.5329\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 16s 466ms/step - loss: 0.4538 - val_loss: 0.4991\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 16s 469ms/step - loss: 0.4354 - val_loss: 0.4765\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 16s 467ms/step - loss: 0.4415 - val_loss: 0.4903\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 16s 466ms/step - loss: 0.4125 - val_loss: 0.4960\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 16s 465ms/step - loss: 0.3986 - val_loss: 0.5151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27e9c82a088>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index)+1,\n",
    "                    300,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=max_len,\n",
    "                    trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(GRU(300, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))\n",
    "model.add(GRU(300, dropout=0.3, recurrent_dropout=0.3))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "\n",
    "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100,\n",
    "          verbose=1, validation_data=(xvalid_pad, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-consumer",
   "metadata": {},
   "source": [
    "더 나은 결과를 보여줍니다. 지속적으로 최적화를 해서 성능을 향상시키면 됩니다. \n",
    "\n",
    "높은 점수를 얻기 위해서는 모델을 앙상블 해야합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-gentleman",
   "metadata": {},
   "source": [
    "## Ensembling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "special-answer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T12:56:09.230889Z",
     "start_time": "2021-03-10T12:56:09.221881Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import sys\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fundamental-greenhouse",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T13:24:22.407780Z",
     "start_time": "2021-03-10T13:24:22.387762Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"[%(asctime)s] %(levelname)s %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\", stream=sys.stdout)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class Ensembler(object):\n",
    "    def __init__(self, model_dict, num_folds=3, task_type='classification', optimize=roc_auc_score,\n",
    "                 lower_is_better=False, save_path=None):\n",
    "        \"\"\"\n",
    "        Ensembler init function\n",
    "        :param model_dict: model dictionary, see README for its format\n",
    "        :param num_folds: the number of folds for ensembling\n",
    "        :param task_type: classification or regression\n",
    "        :param optimize: the function to optimize for, e.g. AUC, logloss, etc. Must have two arguments y_test and y_pred\n",
    "        :param lower_is_better: is lower value of optimization function better or higher\n",
    "        :param save_path: path to which model pickles will be dumped to along with generated predictions, or None\n",
    "        \"\"\"\n",
    "\n",
    "        self.model_dict = model_dict\n",
    "        self.levels = len(self.model_dict)\n",
    "        self.num_folds = num_folds\n",
    "        self.task_type = task_type\n",
    "        self.optimize = optimize\n",
    "        self.lower_is_better = lower_is_better\n",
    "        self.save_path = save_path\n",
    "\n",
    "        self.training_data = None\n",
    "        self.test_data = None\n",
    "        self.y = None\n",
    "        self.lbl_enc = None\n",
    "        self.y_enc = None\n",
    "        self.train_prediction_dict = None\n",
    "        self.test_prediction_dict = None\n",
    "        self.num_classes = None\n",
    "\n",
    "    def fit(self, training_data, y, lentrain):\n",
    "        \"\"\"\n",
    "        :param training_data: training data in tabular format\n",
    "        :param y: binary, multi-class or regression\n",
    "        :return: chain of models to be used in prediction\n",
    "        \"\"\"\n",
    "\n",
    "        self.training_data = training_data\n",
    "        self.y = y\n",
    "\n",
    "        if self.task_type == 'classification':\n",
    "            self.num_classes = len(np.unique(self.y))\n",
    "            logger.info(\"Found %d classes\", self.num_classes)\n",
    "            self.lbl_enc = LabelEncoder()\n",
    "            self.y_enc = self.lbl_enc.fit_transform(self.y)\n",
    "            kf = StratifiedKFold(n_splits=self.num_folds)\n",
    "            train_prediction_shape = (lentrain, self.num_classes)\n",
    "        else:\n",
    "            self.num_classes = -1\n",
    "            self.y_enc = self.y\n",
    "            kf = KFold(n_splits=self.num_folds)\n",
    "            train_prediction_shape = (lentrain, 1)\n",
    "\n",
    "        self.train_prediction_dict = {}\n",
    "        for level in range(self.levels):\n",
    "            self.train_prediction_dict[level] = np.zeros((train_prediction_shape[0],\n",
    "                                                          train_prediction_shape[1] * len(self.model_dict[level])))\n",
    "\n",
    "        for level in range(self.levels):\n",
    "\n",
    "            if level == 0:\n",
    "                temp_train = self.training_data\n",
    "            else:\n",
    "                temp_train = self.train_prediction_dict[level - 1]\n",
    "\n",
    "            for model_num, model in enumerate(self.model_dict[level]):\n",
    "                validation_scores = []\n",
    "                foldnum = 1\n",
    "                for train_index, valid_index in kf.split(self.train_prediction_dict[0], self.y_enc):\n",
    "                    logger.info(\"Training Level %d Fold # %d. Model # %d\", level, foldnum, model_num)\n",
    "\n",
    "                    if level != 0:\n",
    "                        l_training_data = temp_train[train_index]\n",
    "                        l_validation_data = temp_train[valid_index]\n",
    "                        model.fit(l_training_data, self.y_enc[train_index])\n",
    "                    else:\n",
    "                        l0_training_data = temp_train[0][model_num]\n",
    "                        if type(l0_training_data) == list:\n",
    "                            l_training_data = [x[train_index] for x in l0_training_data]\n",
    "                            l_validation_data = [x[valid_index] for x in l0_training_data]\n",
    "                        else:\n",
    "                            l_training_data = l0_training_data[train_index]\n",
    "                            l_validation_data = l0_training_data[valid_index]\n",
    "                        model.fit(l_training_data, self.y_enc[train_index])\n",
    "\n",
    "                    logger.info(\"Predicting Level %d. Fold # %d. Model # %d\", level, foldnum, model_num)\n",
    "\n",
    "                    if self.task_type == 'classification':\n",
    "                        temp_train_predictions = model.predict_proba(l_validation_data)\n",
    "                        self.train_prediction_dict[level][valid_index,\n",
    "                        (model_num * self.num_classes):(model_num * self.num_classes) +\n",
    "                                                       self.num_classes] = temp_train_predictions\n",
    "\n",
    "                    else:\n",
    "                        temp_train_predictions = model.predict(l_validation_data)\n",
    "                        self.train_prediction_dict[level][valid_index, model_num] = temp_train_predictions\n",
    "                    validation_score = self.optimize(self.y_enc[valid_index], temp_train_predictions)\n",
    "                    validation_scores.append(validation_score)\n",
    "                    logger.info(\"Level %d. Fold # %d. Model # %d. Validation Score = %f\", level, foldnum, model_num,\n",
    "                                validation_score)\n",
    "                    foldnum += 1\n",
    "                avg_score = np.mean(validation_scores)\n",
    "                std_score = np.std(validation_scores)\n",
    "                logger.info(\"Level %d. Model # %d. Mean Score = %f. Std Dev = %f\", level, model_num,\n",
    "                            avg_score, std_score)\n",
    "\n",
    "            logger.info(\"Saving predictions for level # %d\", level)\n",
    "            train_predictions_df = pd.DataFrame(self.train_prediction_dict[level])\n",
    "            train_predictions_df.to_csv(os.path.join(self.save_path, \"train_predictions_level_\" + str(level) + \".csv\"),\n",
    "                                        index=False, header=None)\n",
    "\n",
    "        return self.train_prediction_dict\n",
    "\n",
    "    def predict(self, test_data, lentest):\n",
    "        self.test_data = test_data\n",
    "        if self.task_type == 'classification':\n",
    "            test_prediction_shape = (lentest, self.num_classes)\n",
    "        else:\n",
    "            test_prediction_shape = (lentest, 1)\n",
    "\n",
    "        self.test_prediction_dict = {}\n",
    "        for level in range(self.levels):\n",
    "            self.test_prediction_dict[level] = np.zeros((test_prediction_shape[0],\n",
    "                                                         test_prediction_shape[1] * len(self.model_dict[level])))\n",
    "        self.test_data = test_data\n",
    "        for level in range(self.levels):\n",
    "            if level == 0:\n",
    "                temp_train = self.training_data\n",
    "                temp_test = self.test_data\n",
    "            else:\n",
    "                temp_train = self.train_prediction_dict[level - 1]\n",
    "                temp_test = self.test_prediction_dict[level - 1]\n",
    "\n",
    "            for model_num, model in enumerate(self.model_dict[level]):\n",
    "\n",
    "                logger.info(\"Training Fulldata Level %d. Model # %d\", level, model_num)\n",
    "                if level == 0:\n",
    "                    model.fit(temp_train[0][model_num], self.y_enc)\n",
    "                else:\n",
    "                    model.fit(temp_train, self.y_enc)\n",
    "\n",
    "                logger.info(\"Predicting Test Level %d. Model # %d\", level, model_num)\n",
    "\n",
    "                if self.task_type == 'classification':\n",
    "                    if level == 0:\n",
    "                        temp_test_predictions = model.predict_proba(temp_test[0][model_num])\n",
    "                    else:\n",
    "                        temp_test_predictions = model.predict_proba(temp_test)\n",
    "                    self.test_prediction_dict[level][:, (model_num * self.num_classes): (model_num * self.num_classes) +\n",
    "                                                                                        self.num_classes] = temp_test_predictions\n",
    "\n",
    "                else:\n",
    "                    if level == 0:\n",
    "                        temp_test_predictions = model.predict(temp_test[0][model_num])\n",
    "                    else:\n",
    "                        temp_test_predictions = model.predict(temp_test)\n",
    "                    self.test_prediction_dict[level][:, model_num] = temp_test_predictions\n",
    "\n",
    "            test_predictions_df = pd.DataFrame(self.test_prediction_dict[level])\n",
    "            test_predictions_df.to_csv(os.path.join(self.save_path, \"test_predictions_level_\" + str(level) + \".csv\"),\n",
    "                                       index=False, header=None)\n",
    "\n",
    "        return self.test_prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "allied-miller",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T13:25:29.140001Z",
     "start_time": "2021-03-10T13:24:22.884213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:24:22] INFO Found 3 classes\n",
      "[22:24:22] INFO Training Level 0 Fold # 1. Model # 0\n",
      "[22:24:23] INFO Predicting Level 0. Fold # 1. Model # 0\n",
      "[22:24:23] INFO Level 0. Fold # 1. Model # 0. Validation Score = 0.626621\n",
      "[22:24:23] INFO Training Level 0 Fold # 2. Model # 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tens_2g\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:24:24] INFO Predicting Level 0. Fold # 2. Model # 0\n",
      "[22:24:24] INFO Level 0. Fold # 2. Model # 0. Validation Score = 0.616474\n",
      "[22:24:24] INFO Training Level 0 Fold # 3. Model # 0\n",
      "[22:24:24] INFO Predicting Level 0. Fold # 3. Model # 0\n",
      "[22:24:24] INFO Level 0. Fold # 3. Model # 0. Validation Score = 0.619633\n",
      "[22:24:24] INFO Level 0. Model # 0. Mean Score = 0.620909. Std Dev = 0.004239\n",
      "[22:24:24] INFO Training Level 0 Fold # 1. Model # 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tens_2g\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:24:34] INFO Predicting Level 0. Fold # 1. Model # 1\n",
      "[22:24:34] INFO Level 0. Fold # 1. Model # 1. Validation Score = 0.573485\n",
      "[22:24:34] INFO Training Level 0 Fold # 2. Model # 1\n",
      "[22:24:44] INFO Predicting Level 0. Fold # 2. Model # 1\n",
      "[22:24:44] INFO Level 0. Fold # 2. Model # 1. Validation Score = 0.563451\n",
      "[22:24:44] INFO Training Level 0 Fold # 3. Model # 1\n",
      "[22:24:54] INFO Predicting Level 0. Fold # 3. Model # 1\n",
      "[22:24:54] INFO Level 0. Fold # 3. Model # 1. Validation Score = 0.567765\n",
      "[22:24:54] INFO Level 0. Model # 1. Mean Score = 0.568233. Std Dev = 0.004110\n",
      "[22:24:54] INFO Training Level 0 Fold # 1. Model # 2\n",
      "[22:24:54] INFO Predicting Level 0. Fold # 1. Model # 2\n",
      "[22:24:54] INFO Level 0. Fold # 1. Model # 2. Validation Score = 0.463292\n",
      "[22:24:54] INFO Training Level 0 Fold # 2. Model # 2\n",
      "[22:24:54] INFO Predicting Level 0. Fold # 2. Model # 2\n",
      "[22:24:54] INFO Level 0. Fold # 2. Model # 2. Validation Score = 0.456477\n",
      "[22:24:54] INFO Training Level 0 Fold # 3. Model # 2\n",
      "[22:24:54] INFO Predicting Level 0. Fold # 3. Model # 2\n",
      "[22:24:54] INFO Level 0. Fold # 3. Model # 2. Validation Score = 0.461664\n",
      "[22:24:54] INFO Level 0. Model # 2. Mean Score = 0.460478. Std Dev = 0.002906\n",
      "[22:24:54] INFO Training Level 0 Fold # 1. Model # 3\n",
      "[22:24:54] INFO Predicting Level 0. Fold # 1. Model # 3\n",
      "[22:24:54] INFO Level 0. Fold # 1. Model # 3. Validation Score = 0.472378\n",
      "[22:24:54] INFO Training Level 0 Fold # 2. Model # 3\n",
      "[22:24:54] INFO Predicting Level 0. Fold # 2. Model # 3\n",
      "[22:24:54] INFO Level 0. Fold # 2. Model # 3. Validation Score = 0.473229\n",
      "[22:24:54] INFO Training Level 0 Fold # 3. Model # 3\n",
      "[22:24:54] INFO Predicting Level 0. Fold # 3. Model # 3\n",
      "[22:24:54] INFO Level 0. Fold # 3. Model # 3. Validation Score = 0.479033\n",
      "[22:24:54] INFO Level 0. Model # 3. Mean Score = 0.474880. Std Dev = 0.002957\n",
      "[22:24:54] INFO Saving predictions for level # 0\n",
      "[22:24:55] INFO Training Level 1 Fold # 1. Model # 0\n",
      "[22:25:00] INFO Predicting Level 1. Fold # 1. Model # 0\n",
      "[22:25:00] INFO Level 1. Fold # 1. Model # 0. Validation Score = 0.433847\n",
      "[22:25:00] INFO Training Level 1 Fold # 2. Model # 0\n",
      "[22:25:05] INFO Predicting Level 1. Fold # 2. Model # 0\n",
      "[22:25:05] INFO Level 1. Fold # 2. Model # 0. Validation Score = 0.424219\n",
      "[22:25:05] INFO Training Level 1 Fold # 3. Model # 0\n",
      "[22:25:10] INFO Predicting Level 1. Fold # 3. Model # 0\n",
      "[22:25:10] INFO Level 1. Fold # 3. Model # 0. Validation Score = 0.437201\n",
      "[22:25:10] INFO Level 1. Model # 0. Mean Score = 0.431756. Std Dev = 0.005502\n",
      "[22:25:10] INFO Saving predictions for level # 1\n",
      "[22:25:10] INFO Training Fulldata Level 0. Model # 0\n",
      "[22:25:11] INFO Predicting Test Level 0. Model # 0\n",
      "[22:25:11] INFO Training Fulldata Level 0. Model # 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tens_2g\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:25:21] INFO Predicting Test Level 0. Model # 1\n",
      "[22:25:21] INFO Training Fulldata Level 0. Model # 2\n",
      "[22:25:21] INFO Predicting Test Level 0. Model # 2\n",
      "[22:25:21] INFO Training Fulldata Level 0. Model # 3\n",
      "[22:25:21] INFO Predicting Test Level 0. Model # 3\n",
      "[22:25:21] INFO Training Fulldata Level 1. Model # 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tens_2g\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:25:29] INFO Predicting Test Level 1. Model # 0\n"
     ]
    }
   ],
   "source": [
    "train_data_dict = {0: [xtrain_tfv, xtrain_ctv, xtrain_tfv, xtrain_ctv], 1: [xtrain_glove]}\n",
    "test_data_dict = {0: [xvalid_tfv, xvalid_ctv, xvalid_tfv, xvalid_ctv], 1: [xvalid_glove]}\n",
    "\n",
    "model_dict = {0: [LogisticRegression(), LogisticRegression(), MultinomialNB(alpha=0.1), MultinomialNB()],\n",
    "              1: [xgb.XGBClassifier(silent=True, n_estimators=120, max_depth=7)]}\n",
    "ens = Ensembler(model_dict=model_dict, num_folds=3, task_type='classification',\n",
    "                optimize=multiclass_logloss, lower_is_better=True, save_path='')\n",
    "\n",
    "ens.fit(train_data_dict, ytrain, lentrain=xtrain_glove.shape[0])\n",
    "preds = ens.predict(test_data_dict, lentest=xvalid_glove.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "grateful-equality",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T13:26:51.617015Z",
     "start_time": "2021-03-10T13:26:51.611010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42416139841997214"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 에러 확인\n",
    "multiclass_logloss(yvalid, preds[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-permit",
   "metadata": {},
   "source": [
    "앙상블 기법이 점수를 많이 향상시켰습니다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
