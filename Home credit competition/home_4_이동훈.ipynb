{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Study 12일차 - 2 (home_credit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드출처 : https://www.kaggle.com/jsaguiar/lightgbm-7th-place-solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KAGGLE HOME CREDIT DEFAULT RISK COMPETITION  \n",
    "7위 솔루션 앙상블에 사용된 모델 중 하나에서 개조되었습니다.\n",
    " 솔루션에 대한 자세한 내용은 이 토론을 참조하십시오.  \n",
    " \n",
    "링크 : https://www.kaggle.com/c/home-credit-default-risk/discussion/64580\n",
    "\n",
    "GitHub에서도 유사한 다른 버전을 사용할 수 있습니다.  \n",
    "링크 : https://github.com/js-aguiar/home-credit-default-competition\n",
    "\n",
    "이 모델은 애플리케이션의 범주형 기능에 gos 및 레이블 인코딩과 함께 LightGBM을 사용합니다. 다른 테이블에서는 평균, 합계 및 몇 가지 다른 함수를 사용하여 집계하는 원핫 인코딩을 사용하고 있습니다. 주요 아이디어는 지난 애플리케이션 및 지난 X개월 집계와 같은 더 많은 시간 관련 기능을 추가하는 것이었습니다.\n",
    "특정 대출 유형 및 상태에 대한 집계뿐만 아니라 테이블 간 비율도 있습니다. 구성은 라인 785입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T08:01:42.678510Z",
     "start_time": "2021-02-02T08:01:37.467357Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from contextlib import contextmanager\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "from scipy.stats import kurtosis, iqr, skew\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T08:01:42.692417Z",
     "start_time": "2021-02-02T08:01:42.680422Z"
    }
   },
   "outputs": [],
   "source": [
    "def main(debug=False):\n",
    "    num_rows = 30000 if debug else None\n",
    "    with timer('application_train and applicatin_test'):\n",
    "        df = get_train_test(DATA_DIRECTORY,num_rows=num_rows)\n",
    "        print('Application dataframe shape: ',df.shape)\n",
    "    with timer('Bureau and bureau_balance data'):\n",
    "        bureau_df = get_bureau(DATA_DIRECTORY,num_rows=num_rows)\n",
    "        df = pd.merge(df, bureau_df,on='SK_ID_CURR',how='left')\n",
    "        print('Bureau dataframe shape: ',bureau_df.shape)\n",
    "        del bureau_df; gc.collect()\n",
    "    with timer('previous_application'):\n",
    "        prev_df = get_previous_applications(DATA_DIRECTORY,num_rows)\n",
    "        df = pd.merge(df, prev_df,on='SK_ID_CURR',how='left')\n",
    "        print('Previous dataframe shape: ',prev_df.shape)\n",
    "        del prev_df; gc.collect()\n",
    "    with timer('previous applications balances'):\n",
    "        pos = get_pos_cash(DATA_DIRECTORY,num_rows)\n",
    "        df = pd.merge(df, pos,on='SK_ID_CURR',how='left')\n",
    "        print('Pos-cash dataframe shape: ',pos.shape)\n",
    "        del pos; gc.collect()\n",
    "        ins = get_installment_payments(DATA_DIRECTORY,num_rows)\n",
    "        df = pd.merge(df, ins,on='SK_ID_CURR',how='left')\n",
    "        print('Installment dataframe shape: ',ins.shape)\n",
    "        del ins; gc.collect()\n",
    "        cc = get_credit_card(DATA_DIRECTORY,num_rows)\n",
    "        df = pd.merge(df, cc,on='SK_ID_CURR',how='left')\n",
    "        print('Credit card dataframe shape: ',cc.shape)\n",
    "        del cc; gc.collect()\n",
    "    # 비율을 추가하고 다른 테이블 사이를 그룹화\n",
    "    df = add_ratios_features(df)\n",
    "    df = reduce_memory(df)\n",
    "    lgbm_categorical_feat = ['CODE_GENDER', 'FLAG_OWN_CAR', 'NAME_CONTRACT_TYPE', \n",
    "                             'NAME_EDUCATION_TYPE','NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE',\n",
    "                             'NAME_INCOME_TYPE', 'OCCUPATION_TYPE','ORGANIZATION_TYPE',\n",
    "                             'WEEKDAY_APPR_PROCESS_START', 'NAME_TYPE_SUITE', 'WALLSMATERIAL_MODE']\n",
    "    with timer(\"Run LightGBM\"):\n",
    "        feat_importance = kfold_lightgb_sklearn(df,lgbm_categorical_feat)\n",
    "        print(feat_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T08:01:42.703360Z",
     "start_time": "2021-02-02T08:01:42.694383Z"
    }
   },
   "outputs": [],
   "source": [
    " def add_ratios_features(df):\n",
    "    # 신용 대 소득 비율\n",
    "    df['BUREAU_INCOME_CREDIT_RATIO'] = df['BUREAU_AMT_CREDIT_SUM_MEAN'] / df['AMT_INCOME_TOTAL']\n",
    "    df['BUREAU_ACTIVE_CREDIT_TO_INCOME_RATIO'] = df['BUREAU_ACTIVE_AMT_CREDIT_SUM_SUM'] / df['AMT_INCOME_TOTAL']\n",
    "    # 이전부터 현재까지의 신용 비율\n",
    "    df['CURRENT_TO_APPROVED_CREDIT_MIN_RATIO'] = df['APPROVED_AMT_CREDIT_MIN'] / df['AMT_CREDIT']\n",
    "    df['CURRENT_TO_APPROVED_CREDIT_MAX_RATIO'] = df['APPROVED_AMT_CREDIT_MAX'] / df['AMT_CREDIT']\n",
    "    df['CURRENT_TO_APPROVED_CREDIT_MEAN_RATIO'] = df['APPROVED_AMT_CREDIT_MEAN'] / df['AMT_CREDIT']\n",
    "    # 이전부터 현재까지의 연금 비율\n",
    "    df['CURRENT_TO_APPROVED_ANNUITY_MAX_RATIO'] = df['APPROVED_AMT_ANNUITY_MAX'] / df['AMT_ANNUITY']\n",
    "    df['CURRENT_TO_APPROVED_ANNUITY_MEAN_RATIO'] = df['APPROVED_AMT_ANNUITY_MEAN'] / df['AMT_ANNUITY']\n",
    "    df['PAYMENT_MIN_TO_ANNUITY_RATIO'] = df['INS_AMT_PAYMENT_MIN'] / df['AMT_ANNUITY']\n",
    "    df['PAYMENT_MAX_TO_ANNUITY_RATIO'] = df['INS_AMT_PAYMENT_MAX'] / df['AMT_ANNUITY']\n",
    "    df['PAYMENT_MEAN_TO_ANNUITY_RATIO'] = df['INS_AMT_PAYMENT_MEAN'] / df['AMT_ANNUITY']\n",
    "    # 이전부터 현재까지의 연금 대비 신용 비율\n",
    "    df['CTA_CREDIT_TO_ANNUITY_MAX_RATIO'] = df['APPROVED_CREDIT_TO_ANNUITY_RATIO_MAX'] / df[\n",
    "        'CREDIT_TO_ANNUITY_RATIO']\n",
    "    df['CTA_CREDIT_TO_ANNUITY_MEAN_RATIO'] = df['APPROVED_CREDIT_TO_ANNUITY_RATIO_MEAN'] / df[\n",
    "        'CREDIT_TO_ANNUITY_RATIO']\n",
    "    # 하루마다의 비율 평균\n",
    "    df['DAYS_DECISION_MEAN_TO_BIRTH'] = df['APPROVED_DAYS_DECISION_MEAN'] / df['DAYS_BIRTH']\n",
    "    df['DAYS_CREDIT_MEAN_TO_BIRTH'] = df['BUREAU_DAYS_CREDIT_MEAN'] / df['DAYS_BIRTH']\n",
    "    df['DAYS_DECISION_MEAN_TO_EMPLOYED'] = df['APPROVED_DAYS_DECISION_MEAN'] / df['DAYS_EMPLOYED']\n",
    "    df['DAYS_CREDIT_MEAN_TO_EMPLOYED'] = df['BUREAU_DAYS_CREDIT_MEAN'] / df['DAYS_EMPLOYED']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIGHTGBM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T08:01:42.727332Z",
     "start_time": "2021-02-02T08:01:42.705355Z"
    }
   },
   "outputs": [],
   "source": [
    "def kfold_lightgbm_sklearn(data,categorical_feature=None):\n",
    "    df = data[data['TARGET'].notnull()]\n",
    "    test = data[data['TARGET'].isnull()]\n",
    "    print('Train/valid shape: {},test shape: {}'.format(df.shape,test.shape))\n",
    "    del_features = ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index','level_0']\n",
    "    predictors = list(filter(lambda v:v not in del_features,df.columns))\n",
    "    \n",
    "    if not STRATIFIED_KFOLD:\n",
    "        folds = KFold(n_splits=NUM_FOLDS,shuffle=True,random_state=RANDOM_SEED)\n",
    "    else:\n",
    "        folds = StratifiedKFold(n_splits=NUM_FOLDS,shuffle=True,random_state=RANDOM_SEED)\n",
    "        \n",
    "    oof_preds = np.zeros(df.shape[0])\n",
    "    sub_preds = np.zeros(test.shape[0])\n",
    "    importance_df = pd.DataFrame()\n",
    "    eval_results = dict()\n",
    "    \n",
    "    for n_fold,(train_idx,valid_idx) in enumerate(folds.split(df[predictors],df['TARGET'])):\n",
    "        train_x, train_y = df[predict].iloc[train_idx], df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = df[predict].iloc[valid_idx], df['TARGET'].iloc[valid_idx]\n",
    "        \n",
    "        params = {'random_state':RANDOM_SEED,'nthread':NUM_THREADS}\n",
    "        clf = LGBMClassifier(**{**params,**LIGHTGBM_PARAMS})\n",
    "        if not categorical_feature:\n",
    "            clf.fit(train_x,train_y,eval_set=[(train_x,train_y),(valid_x,valid_y)],\n",
    "                   eval_metirc='auc',verbose=400,early_stopping_rounds=EARLY_STOPPING)\n",
    "        else:\n",
    "            clf.fit(train_x,train_y,eval_set=[(train_x,train_y),(valid_x,valid_y)],\n",
    "                   eval_metirc='auc',verbose=400,early_stopping_rounds=EARLY_STOPPING,\n",
    "                   feature_name = list(df[predictors].columns),categorical_feature=categorical_feature)\n",
    "        \n",
    "        oof_pred[valid_idx] = clf.predict_proba(valid_x,num_iteration=clfbest_iteration_)[:,1]\n",
    "        sub_pred += clf.predict_proba(test[predictors],num_iteration=clfbest_iteration_)[:,1]/folds.n_splits\n",
    "        \n",
    "        # Gain(게인) 및 SLIP(분할)에 의한 기능 중요도\n",
    "        fold_importance = pd.DataFrame()\n",
    "        fold_importance['feature'] = predictors\n",
    "        fold_importance['gain'] = clf.booster_.feature_importance(importance_type='gain')\n",
    "        fold_importance['split'] = clf.booster_.feature_importance(importance_type='split')\n",
    "        importance_df = pd.concat([importance_df,fold_importance],axis=0)\n",
    "        eval_results['train_{}'.format(n_fold+1)] = clf.evals_result_['training']['auc']\n",
    "        eval_results['valid_{}'.format(n_fold+1)] = clf.evals_result_['valid_1']['auc']\n",
    "        \n",
    "        print('Fold %2d AUC : %.6f'%(n_fold+1,roc_auc_score(valid_y,oof_preds[valid_idx])))\n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "    \n",
    "    print('Full AUC score %.6f' % roc_auc_score(df['TARGET'],oof_preds))\n",
    "    test['TARGET'] = sub_preds.copy()\n",
    "    \n",
    "    # 접기(fold) 사이의 평균 특성 중요도를 구하기\n",
    "    mean_importance = importance_df.gorupby('feature').mena().reset_index()\n",
    "    mean_importance.sort_values(by='gain',ascending=False,iplace=True)\n",
    "    \n",
    "    # 기능 중요도, 테스트 예측 및 oof 예측을 csv로 저장\n",
    "    if GENERATE_SUBMISSION_FILES:\n",
    "        oof = pd.DataFrame()\n",
    "        oof['SK_ID_CURR'] = df['SK_ID_CURR'].copy()\n",
    "        df['PREDICTIONS'] = oof_preds.copy()\n",
    "        df['TARGET'] = df['TARGET'].copy()\n",
    "        df.to_csv('oof{}.csv'.format(SUBMISSION_SUFIX), index=False)\n",
    "\n",
    "        test[['SK_ID_CURR', 'TARGET']].to_csv('submission{}.csv'.format(SUBMISSION_SUFIX), index=False)\n",
    "        mean_importance.to_csv('feature_importance{}.csv'.format(SUBMISSION_SUFIX), index=False)\n",
    "    return mean_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPLICATION PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T08:01:42.775167Z",
     "start_time": "2021-02-02T08:01:42.729289Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_train_test(path, num_rows = None):\n",
    "    \n",
    "    train = pd.read_csv(os.path.join(path, 'application_train.csv'), nrows= num_rows)\n",
    "    test = pd.read_csv(os.path.join(path, 'application_test.csv'), nrows= num_rows)\n",
    "    df = train.append(test)\n",
    "    del train, test; gc.collect()\n",
    "    \n",
    "    # 데이터 정리\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']  # code gender가 XNA 인 4명 제외\n",
    "    df = df[df['AMT_INCOME_TOTAL'] < 20000000]  #테스트의 최대 수입은 4M이었음(train은 117M)\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "    df['DAYS_LAST_PHONE_CHANGE'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "    # 플래그_문서 특징 - 개수 및 첨도\n",
    "    docs = [f for f in df.columns if 'FLAG_DOC' in f]\n",
    "    df['DOCUMENT_COUNT'] = df[docs].sum(axis=1)\n",
    "    df['NEW_DOC_KURT'] = df[docs].kurtosis(axis=1)\n",
    "    \n",
    "    # 나이 범주 - 목표값=1 그림을 기반으로\n",
    "    df['AGE_RANGE'] = df['DAYS_BIRTH'].apply(lambda x: get_age_label(x))\n",
    "\n",
    "    # 외부 소스를 기반으로 하는 새로운 기능\n",
    "    df['EXT_SOURCES_PROD'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_2'] * df['EXT_SOURCE_3']\n",
    "    df['EXT_SOURCES_WEIGHTED'] = df.EXT_SOURCE_1 * 2 + df.EXT_SOURCE_2 * 1 + df.EXT_SOURCE_3 * 3\n",
    "    np.warnings.filterwarnings('ignore', r'All-NaN (slice|axis) encountered')\n",
    "    for function_name in ['min', 'max', 'mean', 'nanmedian', 'var']:\n",
    "        feature_name = 'EXT_SOURCES_{}'.format(function_name.upper())\n",
    "        df[feature_name] = eval('np.{}'.format(function_name))(\n",
    "            df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']], axis=1)\n",
    "\n",
    "    # 신용비율\n",
    "    df['CREDIT_TO_ANNUITY_RATIO'] = df['AMT_CREDIT'] / df['AMT_ANNUITY']\n",
    "    df['CREDIT_TO_GOODS_RATIO'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']\n",
    "    # 수입 비율\n",
    "    df['ANNUITY_TO_INCOME_RATIO'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    df['CREDIT_TO_INCOME_RATIO'] = df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL']\n",
    "    df['INCOME_TO_EMPLOYED_RATIO'] = df['AMT_INCOME_TOTAL'] / df['DAYS_EMPLOYED']\n",
    "    df['INCOME_TO_BIRTH_RATIO'] = df['AMT_INCOME_TOTAL'] / df['DAYS_BIRTH']\n",
    "    # 시간당 비율\n",
    "    df['EMPLOYED_TO_BIRTH_RATIO'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    df['ID_TO_BIRTH_RATIO'] = df['DAYS_ID_PUBLISH'] / df['DAYS_BIRTH']\n",
    "    df['CAR_TO_BIRTH_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_BIRTH']\n",
    "    df['CAR_TO_EMPLOYED_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_EMPLOYED']\n",
    "    df['PHONE_TO_BIRTH_RATIO'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_BIRTH']\n",
    "\n",
    "    # 그룹화 기준: 동일한 그룹의 응용 프로그램에 대한 통계\n",
    "    group = ['ORGANIZATION_TYPE', 'NAME_EDUCATION_TYPE', 'OCCUPATION_TYPE', 'AGE_RANGE', 'CODE_GENDER']\n",
    "    df = do_median(df, group, 'EXT_SOURCES_MEAN', 'GROUP_EXT_SOURCES_MEDIAN')\n",
    "    df = do_std(df, group, 'EXT_SOURCES_MEAN', 'GROUP_EXT_SOURCES_STD')\n",
    "    df = do_mean(df, group, 'AMT_INCOME_TOTAL', 'GROUP_INCOME_MEAN')\n",
    "    df = do_std(df, group, 'AMT_INCOME_TOTAL', 'GROUP_INCOME_STD')\n",
    "    df = do_mean(df, group, 'CREDIT_TO_ANNUITY_RATIO', 'GROUP_CREDIT_TO_ANNUITY_MEAN')\n",
    "    df = do_std(df, group, 'CREDIT_TO_ANNUITY_RATIO', 'GROUP_CREDIT_TO_ANNUITY_STD')\n",
    "    df = do_mean(df, group, 'AMT_CREDIT', 'GROUP_CREDIT_MEAN')\n",
    "    df = do_mean(df, group, 'AMT_ANNUITY', 'GROUP_ANNUITY_MEAN')\n",
    "    df = do_std(df, group, 'AMT_ANNUITY', 'GROUP_ANNUITY_STD')\n",
    "\n",
    "    # 범주형 기능을 인코딩(LabelEncoder).\n",
    "    df, le_encoded_cols = label_encoder(df, None)\n",
    "    df = drop_application_columns(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T08:01:42.785183Z",
     "start_time": "2021-02-02T08:01:42.776166Z"
    }
   },
   "outputs": [],
   "source": [
    "def drop_application_columns(df):\n",
    "    drop_list =['CNT_CHILDREN', 'CNT_FAM_MEMBERS', 'HOUR_APPR_PROCESS_START',\n",
    "        'FLAG_EMP_PHONE', 'FLAG_MOBIL', 'FLAG_CONT_MOBILE', 'FLAG_EMAIL', 'FLAG_PHONE',\n",
    "        'FLAG_OWN_REALTY', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION',\n",
    "        'REG_CITY_NOT_WORK_CITY', 'OBS_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE',\n",
    "        'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_YEAR', \n",
    "        'COMMONAREA_MODE', 'NONLIVINGAREA_MODE', 'ELEVATORS_MODE', 'NONLIVINGAREA_AVG',\n",
    "        'FLOORSMIN_MEDI', 'LANDAREA_MODE', 'NONLIVINGAREA_MEDI', 'LIVINGAPARTMENTS_MODE',\n",
    "        'FLOORSMIN_AVG', 'LANDAREA_AVG', 'FLOORSMIN_MODE', 'LANDAREA_MEDI',\n",
    "        'COMMONAREA_MEDI', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'BASEMENTAREA_AVG',\n",
    "        'BASEMENTAREA_MODE', 'NONLIVINGAPARTMENTS_MEDI', 'BASEMENTAREA_MEDI', \n",
    "        'LIVINGAPARTMENTS_AVG', 'ELEVATORS_AVG', 'YEARS_BUILD_MEDI', 'ENTRANCES_MODE',\n",
    "        'NONLIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'LIVINGAPARTMENTS_MEDI',\n",
    "        'YEARS_BUILD_MODE', 'YEARS_BEGINEXPLUATATION_AVG', 'ELEVATORS_MEDI', 'LIVINGAREA_MEDI',\n",
    "        'YEARS_BEGINEXPLUATATION_MODE', 'NONLIVINGAPARTMENTS_AVG', 'HOUSETYPE_MODE',\n",
    "        'FONDKAPREMONT_MODE', 'EMERGENCYSTATE_MODE']\n",
    "    # 대부분의 플래그 문서 열을 삭제\n",
    "    for doc_num in [2,4,5,6,7,9,10,11,12,13,14,15,16,17,19,20,21]:\n",
    "        drop_list.append('FLAG_DOCUMENT_{}'.format(doc_num))\n",
    "    df.drop(drop_list,axis=1,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T08:01:42.793119Z",
     "start_time": "2021-02-02T08:01:42.786138Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_age_label(days_birth):\n",
    "    age_years= -days_birth /365\n",
    "    if age_years <27: return 1\n",
    "    elif age_years <40: return 2\n",
    "    elif age_years <50: return 3\n",
    "    elif age_years <65: return 4\n",
    "    elif age_years <99: return 5\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUREAU PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T08:01:42.812097Z",
     "start_time": "2021-02-02T08:01:42.795113Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_bureau(path, num_rows= None):\n",
    "    bureau = pd.read_csv(os.path.join(path, 'bureau.csv'), nrows= num_rows)\n",
    "    # 신용기간 및 신용/계좌 종료 일 차이\n",
    "    bureau['CREDIT_DURATION'] = -bureau['DAYS_CREDIT'] + bureau['DAYS_CREDIT_ENDDATE']\n",
    "    bureau['ENDDATE_DIF'] = bureau['DAYS_CREDIT_ENDDATE'] - bureau['DAYS_ENDDATE_FACT']\n",
    "    # 신용 대 부채 비율 및 차이\n",
    "    bureau['DEBT_PERCENTAGE'] = bureau['AMT_CREDIT_SUM'] / bureau['AMT_CREDIT_SUM_DEBT']\n",
    "    bureau['DEBT_CREDIT_DIFF'] = bureau['AMT_CREDIT_SUM'] - bureau['AMT_CREDIT_SUM_DEBT']\n",
    "    bureau['CREDIT_TO_ANNUITY_RATIO'] = bureau['AMT_CREDIT_SUM'] / bureau['AMT_ANNUITY']\n",
    "    \n",
    "    # One-hot 인코더\n",
    "    bureau, categorical_cols = one_hot_encoder(bureau, nan_as_category= False)\n",
    "    # bureau balance features 결합\n",
    "    bureau = bureau.merge(get_bureau_balance(path, num_rows), how='left', on='SK_ID_BUREAU')\n",
    "    # 연체된 월(만기가 지난 날)을 플래그\n",
    "    bureau['STATUS_12345'] = 0\n",
    "    for i in range(1,6):\n",
    "        bureau['STATUS_12345'] += bureau['STATUS_{}'.format(i)]\n",
    "\n",
    "    # 잔액 개월수 기준 집계 후 bureau(대출기간 agg)과 병합\n",
    "    features = ['AMT_CREDIT_MAX_OVERDUE', 'AMT_CREDIT_SUM_OVERDUE', 'AMT_CREDIT_SUM',\n",
    "        'AMT_CREDIT_SUM_DEBT', 'DEBT_PERCENTAGE', 'DEBT_CREDIT_DIFF', 'STATUS_0', 'STATUS_12345']\n",
    "    agg_length = bureau.groupby('MONTHS_BALANCE_SIZE')[features].mean().reset_index()\n",
    "    agg_length.rename({feat: 'LL_' + feat for feat in features}, axis=1, inplace=True)\n",
    "    bureau = bureau.merge(agg_length, how='left', on='MONTHS_BALANCE_SIZE')\n",
    "    del agg_length; gc.collect()\n",
    "\n",
    "   # 일반대출집계\n",
    "    agg_bureau = group(bureau, 'BUREAU_', BUREAU_AGG)\n",
    "    \n",
    "    # 활성(Active) 및 폐쇄형(Closed) 대출 집계\n",
    "    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
    "    agg_bureau = group_and_merge(active,agg_bureau,'BUREAU_ACTIVE_',BUREAU_ACTIVE_AGG)\n",
    "    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
    "    agg_bureau = group_and_merge(closed,agg_bureau,'BUREAU_CLOSED_',BUREAU_CLOSED_AGG)\n",
    "    del active, closed; gc.collect()\n",
    "    \n",
    "    # 주요 대출 유형에 대한 집계\n",
    "    for credit_type in ['Consumer credit', 'Credit card', 'Mortgage', 'Car loan', 'Microloan']:\n",
    "        type_df = bureau[bureau['CREDIT_TYPE_' + credit_type] == 1]\n",
    "        prefix = 'BUREAU_' + credit_type.split(' ')[0].upper() + '_'\n",
    "        agg_bureau = group_and_merge(type_df, agg_bureau, prefix, BUREAU_LOAN_TYPE_AGG)\n",
    "        del type_df; gc.collect()\n",
    "        \n",
    "    # 시간 기반 집계: 지난 x개월\n",
    "    for time_frame in [6, 12]:\n",
    "        prefix = \"BUREAU_LAST{}M_\".format(time_frame)\n",
    "        time_frame_df = bureau[bureau['DAYS_CREDIT'] >= -30*time_frame]\n",
    "        agg_bureau = group_and_merge(time_frame_df, agg_bureau, prefix, BUREAU_TIME_AGG)\n",
    "        del time_frame_df; gc.collect()\n",
    "\n",
    "    #최종 대출 최대 연체\n",
    "    sort_bureau = bureau.sort_values(by=['DAYS_CREDIT'])\n",
    "    gr = sort_bureau.groupby('SK_ID_CURR')['AMT_CREDIT_MAX_OVERDUE'].last().reset_index()\n",
    "    gr.rename({'AMT_CREDIT_MAX_OVERDUE': 'BUREAU_LAST_LOAN_MAX_OVERDUE'}, inplace=True)\n",
    "    agg_bureau = agg_bureau.merge(gr, on='SK_ID_CURR', how='left')\n",
    "    \n",
    "    # 비율: 총부채/총신용 및 활성대출부채/활성대출신용입니다.\n",
    "    agg_bureau['BUREAU_DEBT_OVER_CREDIT'] = \\\n",
    "        agg_bureau['BUREAU_AMT_CREDIT_SUM_DEBT_SUM']/agg_bureau['BUREAU_AMT_CREDIT_SUM_SUM']\n",
    "    agg_bureau['BUREAU_ACTIVE_DEBT_OVER_CREDIT'] = \\\n",
    "        agg_bureau['BUREAU_ACTIVE_AMT_CREDIT_SUM_DEBT_SUM']/agg_bureau['BUREAU_ACTIVE_AMT_CREDIT_SUM_SUM']\n",
    "    return agg_bureau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T08:01:42.820067Z",
     "start_time": "2021-02-02T08:01:42.814063Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_bureau_balance(path,num_rows=None):\n",
    "    bb = pd.read_csv(os.path.join(path, 'bureau_balance.csv'), nrows= num_rows)\n",
    "    bb,categorical_cols = one_hot_encoder(bb,nan_as_category= False)\n",
    "    # 붕괴(decay) 있는 각 범주의 비율을 계산\n",
    "    bb_processed = bb.groupby('SK_ID_BUREAU')[categorical_cols].mean().reset_index()\n",
    "    # 최소, 최대, 개수 및 평균 지불 기간(개월) 계산\n",
    "    agg={'MONTHS_BALANCE':['min','max','mean','size']}\n",
    "    bb_processed = group_and_merge(bb,bb_processed,'',agg,'SK_ID_BUREAU')\n",
    "    del bb;gc.collect()\n",
    "    return bb_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREVIOUS PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T08:01:42.842985Z",
     "start_time": "2021-02-02T08:01:42.822043Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_previous_applications(path, num_rows= None):\n",
    "    prev = pd.read_csv(os.path.join(path, 'previous_application.csv'), nrows= num_rows)\n",
    "    pay = pd.read_csv(os.path.join(path, 'installments_payments.csv'), nrows= num_rows)\n",
    "\n",
    "    # 가장 중요한 범주형 기능을 one-hot 인코딩\n",
    "    ohe_columns = [\n",
    "        'NAME_CONTRACT_STATUS', 'NAME_CONTRACT_TYPE', 'CHANNEL_TYPE',\n",
    "        'NAME_TYPE_SUITE', 'NAME_YIELD_GROUP', 'PRODUCT_COMBINATION',\n",
    "        'NAME_PRODUCT_TYPE', 'NAME_CLIENT_TYPE']\n",
    "    prev, categorical_cols = one_hot_encoder(prev, ohe_columns, nan_as_category= False)\n",
    "\n",
    "    # 특성 공학: 비율 및 차이점\n",
    "    prev['APPLICATION_CREDIT_DIFF'] = prev['AMT_APPLICATION'] - prev['AMT_CREDIT']\n",
    "    prev['APPLICATION_CREDIT_RATIO'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "    prev['CREDIT_TO_ANNUITY_RATIO'] = prev['AMT_CREDIT']/prev['AMT_ANNUITY']\n",
    "    prev['DOWN_PAYMENT_TO_CREDIT'] = prev['AMT_DOWN_PAYMENT'] / prev['AMT_CREDIT']\n",
    "    \n",
    "    # 이전 적용 시 이자율(간소화)\n",
    "    total_payment = prev['AMT_ANNUITY'] * prev['CNT_PAYMENT']\n",
    "    prev['SIMPLE_INTERESTS'] = (total_payment/prev['AMT_CREDIT'] - 1)/prev['CNT_PAYMENT']\n",
    "\n",
    "    # 활성 대출 - 승인되었지만 아직 완료되지 않음(last_due 365243).\n",
    "    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "    active_df = approved[approved['DAYS_LAST_DUE'] == 365243]\n",
    "    \n",
    "    # 활성 대출에서 이미 지불된 금액을 찾습니다(할부 csv 사용).\n",
    "    active_pay = pay[pay['SK_ID_PREV'].isin(active_df['SK_ID_PREV'])]\n",
    "    active_pay_agg = active_pay.groupby('SK_ID_PREV')[['AMT_INSTALMENT', 'AMT_PAYMENT']].sum()\n",
    "    active_pay_agg.reset_index(inplace= True)\n",
    "    \n",
    "    # 활성대출: 납부한 금액과 할부의 차이\n",
    "    active_pay_agg['INSTALMENT_PAYMENT_DIFF'] = active_pay_agg['AMT_INSTALMENT'] - active_pay_agg['AMT_PAYMENT']\n",
    "    \n",
    "    # active_df와 병합\n",
    "    active_df = active_df.merge(active_pay_agg, on= 'SK_ID_PREV', how= 'left')\n",
    "    active_df['REMAINING_DEBT'] = active_df['AMT_CREDIT'] - active_df['AMT_PAYMENT']\n",
    "    active_df['REPAYMENT_RATIO'] = active_df['AMT_PAYMENT'] / active_df['AMT_CREDIT']\n",
    "    \n",
    "    # 활성 애플리케이션에 대한 집계를 수행\n",
    "    active_agg_df = group(active_df, 'PREV_ACTIVE_', PREVIOUS_ACTIVE_AGG)\n",
    "    active_agg_df['TOTAL_REPAYMENT_RATIO'] = active_agg_df['PREV_ACTIVE_AMT_PAYMENT_SUM']/\\\n",
    "                                             active_agg_df['PREV_ACTIVE_AMT_CREDIT_SUM']\n",
    "    del active_pay, active_pay_agg, active_df; gc.collect()\n",
    "\n",
    "    # 365.243을 nan으로 변경 (결측치로 지정)\n",
    "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
    "    \n",
    "    # 마감일차(예정 x 완료)\n",
    "    prev['DAYS_LAST_DUE_DIFF'] = prev['DAYS_LAST_DUE_1ST_VERSION'] - prev['DAYS_LAST_DUE']\n",
    "    approved['DAYS_LAST_DUE_DIFF'] = approved['DAYS_LAST_DUE_1ST_VERSION'] - approved['DAYS_LAST_DUE']\n",
    "\n",
    "    # 범주형 특징\n",
    "    categorical_agg = {key: ['mean'] for key in categorical_cols}\n",
    "    \n",
    "    # 일반 집계를 수행합니다.\n",
    "    agg_prev = group(prev, 'PREV_', {**PREVIOUS_AGG, **categorical_agg})\n",
    "    \n",
    "    # agg_prev에서 활성 대출 데이터 프레임을 병합\n",
    "    agg_prev = agg_prev.merge(active_agg_df, how='left', on='SK_ID_CURR')\n",
    "    del active_agg_df; gc.collect()\n",
    "    \n",
    "    # 승인 및 거부된 대출에 대한 집계\n",
    "    agg_prev = group_and_merge(approved, agg_prev, 'APPROVED_', PREVIOUS_APPROVED_AGG)\n",
    "    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "    agg_prev = group_and_merge(refused, agg_prev, 'REFUSED_', PREVIOUS_REFUSED_AGG)\n",
    "    del approved, refused; gc.collect()\n",
    "    \n",
    "    # 소비자 대출 및 현금 대출을 위한 집계입니다.\n",
    "    for loan_type in ['Consumer loans', 'Cash loans']:\n",
    "        type_df = prev[prev['NAME_CONTRACT_TYPE_{}'.format(loan_type)] == 1]\n",
    "        prefix = 'PREV_' + loan_type.split(\" \")[0] + '_'\n",
    "        agg_prev = group_and_merge(type_df, agg_prev, prefix, PREVIOUS_LOAN_TYPE_AGG)\n",
    "        del type_df; gc.collect()\n",
    "\n",
    "    # 연체 대출(만기일 경과)에 대해 SK_ID_PREV를 구하기\n",
    "    pay['LATE_PAYMENT'] = pay['DAYS_ENTRY_PAYMENT'] - pay['DAYS_INSTALMENT']\n",
    "    pay['LATE_PAYMENT'] = pay['LATE_PAYMENT'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    dpd_id = pay[pay['LATE_PAYMENT'] > 0]['SK_ID_PREV'].unique()\n",
    "\n",
    "    # 연체 대출에 대한 집계\n",
    "    agg_dpd = group_and_merge(prev[prev['SK_ID_PREV'].isin(dpd_id)], agg_prev,\n",
    "                                    'PREV_LATE_', PREVIOUS_LATE_PAYMENTS_AGG)\n",
    "    del agg_dpd, dpd_id; gc.collect()\n",
    "    \n",
    "    # 지난 x개월 동안의 대출 집계\n",
    "    for time_frame in [12, 24]:\n",
    "        time_frame_df = prev[prev['DAYS_DECISION'] >= -30*time_frame]\n",
    "        prefix = 'PREV_LAST{}M_'.format(time_frame)\n",
    "        agg_prev = group_and_merge(time_frame_df, agg_prev, prefix, PREVIOUS_TIME_AGG)\n",
    "        del time_frame_df; gc.collect()\n",
    "    del prev; gc.collect()\n",
    "    return agg_prev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS-CASH PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T08:01:42.856983Z",
     "start_time": "2021-02-02T08:01:42.843984Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pos_cash(path, num_rows= None):\n",
    "    pos = pd.read_csv(os.path.join(path, 'POS_CASH_balance.csv'), nrows= num_rows)\n",
    "    pos, categorical_cols = one_hot_encoder(pos, nan_as_category= False)\n",
    "    \n",
    "    # 지연 지급으로 월을 표시\n",
    "    pos['LATE_PAYMENT'] = pos['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    # SK_ID_CURR 종합\n",
    "    categorical_agg = {key: ['mean'] for key in categorical_cols}\n",
    "    pos_agg = group(pos, 'POS_', {**POS_CASH_AGG, **categorical_agg})\n",
    "    \n",
    "    # SK_ID_PREV 정렬 및 그룹화\n",
    "    sort_pos = pos.sort_values(by=['SK_ID_PREV', 'MONTHS_BALANCE'])\n",
    "    gp = sort_pos.groupby('SK_ID_PREV')\n",
    "    df = pd.DataFrame()\n",
    "    df['SK_ID_CURR'] = gp['SK_ID_CURR'].first()\n",
    "    df['MONTHS_BALANCE_MAX'] = gp['MONTHS_BALANCE'].max()\n",
    "    \n",
    "    #초기 이전에 완료된 이전 대출의 비율\n",
    "    df['POS_LOAN_COMPLETED_MEAN'] = gp['NAME_CONTRACT_STATUS_Completed'].mean()\n",
    "    df['POS_COMPLETED_BEFORE_MEAN'] = gp['CNT_INSTALMENT'].first() - gp['CNT_INSTALMENT'].last()\n",
    "    df['POS_COMPLETED_BEFORE_MEAN'] = df.apply(lambda x: 1 if x['POS_COMPLETED_BEFORE_MEAN'] > 0\n",
    "                                                and x['POS_LOAN_COMPLETED_MEAN'] > 0 else 0, axis=1)\n",
    "    \n",
    "    # 남은 할부 건수(향후 할부)와 총액에서 차지하는 비율\n",
    "    df['POS_REMAINING_INSTALMENTS'] = gp['CNT_INSTALMENT_FUTURE'].last()\n",
    "    df['POS_REMAINING_INSTALMENTS_RATIO'] = gp['CNT_INSTALMENT_FUTURE'].last()/gp['CNT_INSTALMENT'].last()\n",
    "    \n",
    "    # SK_ID_CURR로 그룹화 및 병합\n",
    "    df_gp = df.groupby('SK_ID_CURR').sum().reset_index()\n",
    "    df_gp.drop(['MONTHS_BALANCE_MAX'], axis=1, inplace= True)\n",
    "    pos_agg = pd.merge(pos_agg, df_gp, on= 'SK_ID_CURR', how= 'left')\n",
    "    del df, gp, df_gp, sort_pos; gc.collect()\n",
    "\n",
    "    # 최근 3개 애플리케이션의 연체율입니다.\n",
    "    pos = do_sum(pos, ['SK_ID_PREV'], 'LATE_PAYMENT', 'LATE_PAYMENT_SUM')\n",
    "    # 각 신청서의 마지막 달\n",
    "    last_month_df = pos.groupby('SK_ID_PREV')['MONTHS_BALANCE'].idxmax()\n",
    "    # 최근 애플리케이션(마지막 3개)\n",
    "    sort_pos = pos.sort_values(by=['SK_ID_PREV', 'MONTHS_BALANCE'])\n",
    "    gp = sort_pos.iloc[last_month_df].groupby('SK_ID_CURR').tail(3)\n",
    "    gp_mean = gp.groupby('SK_ID_CURR').mean().reset_index()\n",
    "    pos_agg = pd.merge(pos_agg, gp_mean[['SK_ID_CURR','LATE_PAYMENT_SUM']], on='SK_ID_CURR', how='left')\n",
    "\n",
    "    # 쓸모없는 범주적 특징을 몇 가지 삭제\n",
    "    drop_features = [\n",
    "        'POS_NAME_CONTRACT_STATUS_Canceled_MEAN', 'POS_NAME_CONTRACT_STATUS_Amortized debt_MEAN',\n",
    "        'POS_NAME_CONTRACT_STATUS_XNA_MEAN']\n",
    "    pos_agg.drop(drop_features, axis=1, inplace=True)\n",
    "    return pos_agg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSTALLMENTS PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T08:01:42.872939Z",
     "start_time": "2021-02-02T08:01:42.857946Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_installment_payments(path, num_rows= None):\n",
    "    \n",
    "    pay = pd.read_csv(os.path.join(path, 'installments_payments.csv'), nrows= num_rows)\n",
    "    \n",
    "    # 결제를 그룹화하고 차액을 구함.\n",
    "    pay = do_sum(pay, ['SK_ID_PREV', 'NUM_INSTALMENT_NUMBER'], 'AMT_PAYMENT', 'AMT_PAYMENT_GROUPED')\n",
    "    pay['PAYMENT_DIFFERENCE'] = pay['AMT_INSTALMENT'] - pay['AMT_PAYMENT_GROUPED']\n",
    "    pay['PAYMENT_RATIO'] = pay['AMT_INSTALMENT'] / pay['AMT_PAYMENT_GROUPED']\n",
    "    pay['PAID_OVER_AMOUNT'] = pay['AMT_PAYMENT'] - pay['AMT_INSTALMENT']\n",
    "    pay['PAID_OVER'] = (pay['PAID_OVER_AMOUNT'] > 0).astype(int)\n",
    "    \n",
    "    # 지급 항목: 지급 기한이 경과한 날 및 지불 기한이 경과한 날\n",
    "    pay['DPD'] = pay['DAYS_ENTRY_PAYMENT'] - pay['DAYS_INSTALMENT']\n",
    "    pay['DPD'] = pay['DPD'].apply(lambda x: 0 if x <= 0 else x)\n",
    "    pay['DBD'] = pay['DAYS_INSTALMENT'] - pay['DAYS_ENTRY_PAYMENT']\n",
    "    pay['DBD'] = pay['DBD'].apply(lambda x: 0 if x <= 0 else x)\n",
    "    \n",
    "    # 지연 지급 표시\n",
    "    pay['LATE_PAYMENT'] = pay['DBD'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    # 연체 비율\n",
    "    pay['INSTALMENT_PAYMENT_RATIO'] = pay['AMT_PAYMENT'] / pay['AMT_INSTALMENT']\n",
    "    pay['LATE_PAYMENT_RATIO'] = pay.apply(lambda x: x['INSTALMENT_PAYMENT_RATIO'] if x['LATE_PAYMENT'] == 1 else 0, axis=1)\n",
    "    \n",
    "    # 상당한 금액이 있는 연체금을 표시\n",
    "    pay['SIGNIFICANT_LATE_PAYMENT'] = pay['LATE_PAYMENT_RATIO'].apply(lambda x: 1 if x > 0.05 else 0)\n",
    "    \n",
    "    # 지연 지급 임계값에 플래그가 표시\n",
    "    pay['DPD_7'] = pay['DPD'].apply(lambda x: 1 if x >= 7 else 0)\n",
    "    pay['DPD_15'] = pay['DPD'].apply(lambda x: 1 if x >= 15 else 0)\n",
    "    \n",
    "    # SK_ID_CURR 종합\n",
    "    pay_agg = group(pay, 'INS_', INSTALLMENTS_AGG)\n",
    "\n",
    "    # 지난 x개월 동안 할부\n",
    "    for months in [36, 60]:\n",
    "        recent_prev_id = pay[pay['DAYS_INSTALMENT'] >= -30*months]['SK_ID_PREV'].unique()\n",
    "        pay_recent = pay[pay['SK_ID_PREV'].isin(recent_prev_id)]\n",
    "        prefix = 'INS_{}M_'.format(months)\n",
    "        pay_agg = group_and_merge(pay_recent, pay_agg, prefix, INSTALLMENTS_TIME_AGG)\n",
    "\n",
    "    # 마지막 x 기간의 추세 특징\n",
    "    group_features = ['SK_ID_CURR', 'SK_ID_PREV', 'DPD', 'LATE_PAYMENT',\n",
    "                      'PAID_OVER_AMOUNT', 'PAID_OVER', 'DAYS_INSTALMENT']\n",
    "    gp = pay[group_features].groupby('SK_ID_CURR')\n",
    "    func = partial(trend_in_last_k_instalment_features, periods= INSTALLMENTS_LAST_K_TREND_PERIODS)\n",
    "    g = parallel_apply(gp, func, index_name='SK_ID_CURR', chunk_size=10000).reset_index()\n",
    "    pay_agg = pay_agg.merge(g, on='SK_ID_CURR', how='left')\n",
    "\n",
    "    # 마지막 대출 특징\n",
    "    g = parallel_apply(gp, installments_last_loan_features, index_name='SK_ID_CURR', chunk_size=10000).reset_index()\n",
    "    pay_agg = pay_agg.merge(g, on='SK_ID_CURR', how='left')\n",
    "    return pay_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T08:01:42.881906Z",
     "start_time": "2021-02-02T08:01:42.873903Z"
    }
   },
   "outputs": [],
   "source": [
    "def trend_in_last_k_instalment_features(gr, periods):\n",
    "    gr_ = gr.copy()\n",
    "    gr_.sort_values(['DAYS_INSTALMENT'], ascending=False, inplace=True)\n",
    "    features = {}\n",
    "\n",
    "    for period in periods:\n",
    "        gr_period = gr_.iloc[:period]\n",
    "        features = add_trend_feature(features, gr_period, 'DPD',\n",
    "                                           '{}_TREND_'.format(period))\n",
    "        features = add_trend_feature(features, gr_period, 'PAID_OVER_AMOUNT',\n",
    "                                           '{}_TREND_'.format(period))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T08:01:42.889860Z",
     "start_time": "2021-02-02T08:01:42.883875Z"
    }
   },
   "outputs": [],
   "source": [
    "def installments_last_loan_features(gr):\n",
    "    gr_ = gr.copy()\n",
    "    gr_.sort_values(['DAYS_INSTALMENT'], ascending=False, inplace=True)\n",
    "    last_installment_id = gr_['SK_ID_PREV'].iloc[0]\n",
    "    gr_ = gr_[gr_['SK_ID_PREV'] == last_installment_id]\n",
    "\n",
    "    features = {}\n",
    "    features = add_features_in_group(features, gr_, 'DPD',\n",
    "                                     ['sum', 'mean', 'max', 'std'],\n",
    "                                     'LAST_LOAN_')\n",
    "    features = add_features_in_group(features, gr_, 'LATE_PAYMENT',\n",
    "                                     ['count', 'mean'],\n",
    "                                     'LAST_LOAN_')\n",
    "    features = add_features_in_group(features, gr_, 'PAID_OVER_AMOUNT',\n",
    "                                     ['sum', 'mean', 'max', 'min', 'std'],\n",
    "                                     'LAST_LOAN_')\n",
    "    features = add_features_in_group(features, gr_, 'PAID_OVER',\n",
    "                                     ['count', 'mean'],\n",
    "                                     'LAST_LOAN_')\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREDIT CARD PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T08:01:42.899869Z",
     "start_time": "2021-02-02T08:01:42.890859Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_credit_card(path,num_rows=None):\n",
    "    cc = pd.read_csv(os.path.join(path, 'credit_card_balance.csv'), nrows= num_rows)\n",
    "    cc, cat_cols = one_hot_encoder(cc,nan_as_category=False)\n",
    "    cc.rename(columns={'AMT_RECIVABLE':'AMT_RECIVABLE'},inplace=True)\n",
    "    # 한도초과금액\n",
    "    cc['LIMIT_USE'] = cc['AMT_BALANCE'] / cc['AMT_CREDIT_LIMIT_ACTUAL']\n",
    "    # 현재결제 / 최소결제\n",
    "    cc['PAYMENT_DIV_MIN'] = cc['AMT_PAYMENT_CURRENT'] /  cc['AMT_INST_MIN_REGULARITY']\n",
    "    # 후불(late payment)\n",
    "    cc['LATE_PAYMENT'] = cc['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    # 한계의 도면은 얼마인지 계산\n",
    "    cc['DRAWING_LIMIT_RATIO'] = cc['AMT_DRAWINGS_ATM_CURRENT'] / cc['AMT_CREDIT_LIMIT_ACTUAL']\n",
    "    # SK_ID_CURR과 통합\n",
    "    cc_agg = cc.groupby('SK_ID_CURR').agg(CREDIT_CARD_AGG)\n",
    "    cc_agg.columns = pd.Index(['CC_'+e[0]+'_'+e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "    cc_agg.reset_index(inplace=True)\n",
    "    \n",
    "    # 각 신용카드 신청서의 지난달 잔액\n",
    "    last_ids = cc.groupby('SK_ID_PREV')['MONTHS_BALANCE'].idxmax()\n",
    "    last_months_df=cc[cc.index.isin(last_ids)]                                    \n",
    "    cc_agg=group_and_merge(last_months_df,cc_agg,'CC_LAST_',{'AMT_BALANCE':['mean','max']})\n",
    "    \n",
    "    # 지난 x개월 동안의 집계\n",
    "    for months in [12, 24, 48]:\n",
    "        cc_prev_id = cc[cc['MONTHS_BALANCE'] >= -months]['SK_ID_PREV'].unique()\n",
    "        cc_recent = cc[cc['SK_ID_PREV'].isin(cc_prev_id)]\n",
    "        prefix = 'INS_{}M_'.format(months)\n",
    "        cc_agg = group_and_merge(cc_recent, cc_agg, prefix, CREDIT_CARD_TIME_AGG)\n",
    "    return cc_agg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UTILITY FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T08:01:42.946708Z",
     "start_time": "2021-02-02T08:01:42.901829Z"
    }
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(name, time.time() - t0))\n",
    "\n",
    "\n",
    "def group(df_to_agg, prefix, aggregations, aggregate_by= 'SK_ID_CURR'):\n",
    "    agg_df = df_to_agg.groupby(aggregate_by).agg(aggregations)\n",
    "    agg_df.columns = pd.Index(['{}{}_{}'.format(prefix, e[0], e[1].upper())\n",
    "                               for e in agg_df.columns.tolist()])\n",
    "    return agg_df.reset_index()\n",
    "\n",
    "\n",
    "def group_and_merge(df_to_agg, df_to_merge, prefix, aggregations, aggregate_by= 'SK_ID_CURR'):\n",
    "    agg_df = group(df_to_agg, prefix, aggregations, aggregate_by= aggregate_by)\n",
    "    return df_to_merge.merge(agg_df, how='left', on= aggregate_by)\n",
    "\n",
    "\n",
    "def do_mean(df, group_cols, counted, agg_name):\n",
    "    gp = df[group_cols + [counted]].groupby(group_cols)[counted].mean().reset_index().rename(\n",
    "        columns={counted: agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "\n",
    "def do_median(df, group_cols, counted, agg_name):\n",
    "    gp = df[group_cols + [counted]].groupby(group_cols)[counted].median().reset_index().rename(\n",
    "        columns={counted: agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "\n",
    "def do_std(df, group_cols, counted, agg_name):\n",
    "    gp = df[group_cols + [counted]].groupby(group_cols)[counted].std().reset_index().rename(\n",
    "        columns={counted: agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "\n",
    "def do_sum(df, group_cols, counted, agg_name):\n",
    "    gp = df[group_cols + [counted]].groupby(group_cols)[counted].sum().reset_index().rename(\n",
    "        columns={counted: agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "\n",
    "def one_hot_encoder(df, categorical_columns=None, nan_as_category=True):\n",
    "    \"\"\"Create a new column for each categorical value in categorical columns. \"\"\"\n",
    "    original_columns = list(df.columns)\n",
    "    if not categorical_columns:\n",
    "        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns=categorical_columns, dummy_na=nan_as_category)\n",
    "    categorical_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, categorical_columns\n",
    "\n",
    "\n",
    "def label_encoder(df, categorical_columns=None):\n",
    "    \"\"\"Encode categorical values as integers (0,1,2,3...) with pandas.factorize. \"\"\"\n",
    "    if not categorical_columns:\n",
    "        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    for col in categorical_columns:\n",
    "        df[col], uniques = pd.factorize(df[col])\n",
    "    return df, categorical_columns\n",
    "\n",
    "\n",
    "def add_features(feature_name, aggs, features, feature_names, groupby):\n",
    "    feature_names.extend(['{}_{}'.format(feature_name, agg) for agg in aggs])\n",
    "\n",
    "    for agg in aggs:\n",
    "        if agg == 'kurt':\n",
    "            agg_func = kurtosis\n",
    "        elif agg == 'iqr':\n",
    "            agg_func = iqr\n",
    "        else:\n",
    "            agg_func = agg\n",
    "\n",
    "        g = groupby[feature_name].agg(agg_func).reset_index().rename(index=str,\n",
    "                                                                     columns={feature_name: '{}_{}'.format(feature_name,agg)})\n",
    "        features = features.merge(g, on='SK_ID_CURR', how='left')\n",
    "    return features, feature_names\n",
    "\n",
    "\n",
    "def add_features_in_group(features, gr_, feature_name, aggs, prefix):\n",
    "    for agg in aggs:\n",
    "        if agg == 'sum':\n",
    "            features['{}{}_sum'.format(prefix, feature_name)] = gr_[feature_name].sum()\n",
    "        elif agg == 'mean':\n",
    "            features['{}{}_mean'.format(prefix, feature_name)] = gr_[feature_name].mean()\n",
    "        elif agg == 'max':\n",
    "            features['{}{}_max'.format(prefix, feature_name)] = gr_[feature_name].max()\n",
    "        elif agg == 'min':\n",
    "            features['{}{}_min'.format(prefix, feature_name)] = gr_[feature_name].min()\n",
    "        elif agg == 'std':\n",
    "            features['{}{}_std'.format(prefix, feature_name)] = gr_[feature_name].std()\n",
    "        elif agg == 'count':\n",
    "            features['{}{}_count'.format(prefix, feature_name)] = gr_[feature_name].count()\n",
    "        elif agg == 'skew':\n",
    "            features['{}{}_skew'.format(prefix, feature_name)] = skew(gr_[feature_name])\n",
    "        elif agg == 'kurt':\n",
    "            features['{}{}_kurt'.format(prefix, feature_name)] = kurtosis(gr_[feature_name])\n",
    "        elif agg == 'iqr':\n",
    "            features['{}{}_iqr'.format(prefix, feature_name)] = iqr(gr_[feature_name])\n",
    "        elif agg == 'median':\n",
    "            features['{}{}_median'.format(prefix, feature_name)] = gr_[feature_name].median()\n",
    "    return features\n",
    "\n",
    "\n",
    "def add_trend_feature(features, gr, feature_name, prefix):\n",
    "    y = gr[feature_name].values\n",
    "    try:\n",
    "        x = np.arange(0, len(y)).reshape(-1, 1)\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(x, y)\n",
    "        trend = lr.coef_[0]\n",
    "    except:\n",
    "        trend = np.nan\n",
    "    features['{}{}'.format(prefix, feature_name)] = trend\n",
    "    return features\n",
    "\n",
    "\n",
    "def parallel_apply(groups, func, index_name='Index', num_workers=0, chunk_size=100000):\n",
    "    if num_workers <= 0: num_workers = NUM_THREADS\n",
    "    #n_chunks = np.ceil(1.0 * groups.ngroups / chunk_size)\n",
    "    indeces, features = [], []\n",
    "    for index_chunk, groups_chunk in chunk_groups(groups, chunk_size):\n",
    "        with mp.pool.Pool(num_workers) as executor:\n",
    "            features_chunk = executor.map(func, groups_chunk)\n",
    "        features.extend(features_chunk)\n",
    "        indeces.extend(index_chunk)\n",
    "\n",
    "    features = pd.DataFrame(features)\n",
    "    features.index = indeces\n",
    "    features.index.name = index_name\n",
    "    return features\n",
    "\n",
    "\n",
    "def chunk_groups(groupby_object, chunk_size):\n",
    "    n_groups = groupby_object.ngroups\n",
    "    group_chunk, index_chunk = [], []\n",
    "    for i, (index, df) in enumerate(groupby_object):\n",
    "        group_chunk.append(df)\n",
    "        index_chunk.append(index)\n",
    "        if (i + 1) % chunk_size == 0 or i + 1 == n_groups:\n",
    "            group_chunk_, index_chunk_ = group_chunk.copy(), index_chunk.copy()\n",
    "            group_chunk, index_chunk = [], []\n",
    "            yield index_chunk_, group_chunk_\n",
    "\n",
    "\n",
    "def reduce_memory(df):\n",
    "    \"\"\"Reduce memory usage of a dataframe by setting data types. \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print('Initial df memory usage is {:.2f} MB for {} columns'\n",
    "          .format(start_mem, len(df.columns)))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type != object:\n",
    "            cmin = df[col].min()\n",
    "            cmax = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                # Can use unsigned int here too\n",
    "                if cmin > np.iinfo(np.int8).min and cmax < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif cmin > np.iinfo(np.int16).min and cmax < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif cmin > np.iinfo(np.int32).min and cmax < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif cmin > np.iinfo(np.int64).min and cmax < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if cmin > np.finfo(np.float16).min and cmax < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif cmin > np.finfo(np.float32).min and cmax < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    memory_reduction = 100 * (start_mem - end_mem) / start_mem\n",
    "    print('Final memory usage is: {:.2f} MB - decreased by {:.1f}%'.format(end_mem, memory_reduction))\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIGURATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T08:01:42.953718Z",
     "start_time": "2021-02-02T08:01:42.947707Z"
    }
   },
   "outputs": [],
   "source": [
    "# 일반 구성\n",
    "NUM_THREADS = 4\n",
    "DATA_DIRECTORY = \"C:/Users/이동훈/Desktop/github/kaggle/kagglestudy/Data/home_credit/\"\n",
    "SUBMISSION_SUFIX = \"_model2_04\"\n",
    "\n",
    "# 할부 추세 기간\n",
    "INSTALLMENTS_LAST_K_TREND_PERIODS =  [12, 24, 60, 120]\n",
    "\n",
    "# LightGBM 구성 및 하이퍼 파라미터입니다.\n",
    "GENERATE_SUBMISSION_FILES = True\n",
    "STRATIFIED_KFOLD = False\n",
    "RANDOM_SEED = 737851\n",
    "NUM_FOLDS = 10\n",
    "EARLY_STOPPING = 100\n",
    "\n",
    "LIGHTGBM_PARAMS = {\n",
    "    'boosting_type': 'goss',\n",
    "    'n_estimators': 10000,\n",
    "    'learning_rate': 0.005134,\n",
    "    'num_leaves': 54,\n",
    "    'max_depth': 10,\n",
    "    'subsample_for_bin': 240000,\n",
    "    'reg_alpha': 0.436193,\n",
    "    'reg_lambda': 0.479169,\n",
    "    'colsample_bytree': 0.508716,\n",
    "    'min_split_gain': 0.024766,\n",
    "    'subsample': 1,\n",
    "    'is_unbalance': False,\n",
    "    'silent':-1,\n",
    "    'verbose':-1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T08:01:42.966689Z",
     "start_time": "2021-02-02T08:01:42.954688Z"
    }
   },
   "outputs": [],
   "source": [
    "BUREAU_AGG = {\n",
    "    'SK_ID_BUREAU': ['nunique'],\n",
    "    'DAYS_CREDIT': ['min', 'max', 'mean'],\n",
    "    'DAYS_CREDIT_ENDDATE': ['min', 'max'],\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n",
    "    'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['max', 'mean', 'sum'],\n",
    "    'AMT_ANNUITY': ['mean'],\n",
    "    'DEBT_CREDIT_DIFF': ['mean', 'sum'],\n",
    "    'MONTHS_BALANCE_MEAN': ['mean', 'var'],\n",
    "    'MONTHS_BALANCE_SIZE': ['mean', 'sum'],\n",
    "    # Categorical\n",
    "    'STATUS_0': ['mean'],\n",
    "    'STATUS_1': ['mean'],\n",
    "    'STATUS_12345': ['mean'],\n",
    "    'STATUS_C': ['mean'],\n",
    "    'STATUS_X': ['mean'],\n",
    "    'CREDIT_ACTIVE_Active': ['mean'],\n",
    "    'CREDIT_ACTIVE_Closed': ['mean'],\n",
    "    'CREDIT_ACTIVE_Sold': ['mean'],\n",
    "    'CREDIT_TYPE_Consumer credit': ['mean'],\n",
    "    'CREDIT_TYPE_Credit card': ['mean'],\n",
    "    'CREDIT_TYPE_Car loan': ['mean'],\n",
    "    'CREDIT_TYPE_Mortgage': ['mean'],\n",
    "    'CREDIT_TYPE_Microloan': ['mean'],\n",
    "    # Group by loan duration features (months)\n",
    "    'LL_AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "    'LL_DEBT_CREDIT_DIFF': ['mean'],\n",
    "    'LL_STATUS_12345': ['mean'],\n",
    "}\n",
    "\n",
    "BUREAU_ACTIVE_AGG = {\n",
    "    'DAYS_CREDIT': ['max', 'mean'],\n",
    "    'DAYS_CREDIT_ENDDATE': ['min', 'max'],\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n",
    "    'AMT_CREDIT_SUM': ['max', 'sum'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['max', 'mean'],\n",
    "    'DAYS_CREDIT_UPDATE': ['min', 'mean'],\n",
    "    'DEBT_PERCENTAGE': ['mean'],\n",
    "    'DEBT_CREDIT_DIFF': ['mean'],\n",
    "    'CREDIT_TO_ANNUITY_RATIO': ['mean'],\n",
    "    'MONTHS_BALANCE_MEAN': ['mean', 'var'],\n",
    "    'MONTHS_BALANCE_SIZE': ['mean', 'sum'],\n",
    "}\n",
    "\n",
    "BUREAU_CLOSED_AGG = {\n",
    "    'DAYS_CREDIT': ['max', 'var'],\n",
    "    'DAYS_CREDIT_ENDDATE': ['max'],\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "    'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['max', 'sum'],\n",
    "    'DAYS_CREDIT_UPDATE': ['max'],\n",
    "    'ENDDATE_DIF': ['mean'],\n",
    "    'STATUS_12345': ['mean'],\n",
    "}\n",
    "\n",
    "BUREAU_LOAN_TYPE_AGG = {\n",
    "    'DAYS_CREDIT': ['mean', 'max'],\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['mean', 'max'],\n",
    "    'AMT_CREDIT_SUM': ['mean', 'max'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['mean', 'max'],\n",
    "    'DEBT_PERCENTAGE': ['mean'],\n",
    "    'DEBT_CREDIT_DIFF': ['mean'],\n",
    "    'DAYS_CREDIT_ENDDATE': ['max'],\n",
    "}\n",
    "\n",
    "BUREAU_TIME_AGG = {\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "    'AMT_CREDIT_SUM': ['max', 'sum'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['mean', 'sum'],\n",
    "    'DEBT_PERCENTAGE': ['mean'],\n",
    "    'DEBT_CREDIT_DIFF': ['mean'],\n",
    "    'STATUS_0': ['mean'],\n",
    "    'STATUS_12345': ['mean'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T08:01:42.982647Z",
     "start_time": "2021-02-02T08:01:42.967653Z"
    }
   },
   "outputs": [],
   "source": [
    "PREVIOUS_AGG = {\n",
    "    'SK_ID_PREV': ['nunique'],\n",
    "    'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "    'AMT_DOWN_PAYMENT': ['max', 'mean'],\n",
    "    'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "    'RATE_DOWN_PAYMENT': ['max', 'mean'],\n",
    "    'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "    'CNT_PAYMENT': ['max', 'mean'],\n",
    "    'DAYS_TERMINATION': ['max'],\n",
    "    # Engineered features\n",
    "    'CREDIT_TO_ANNUITY_RATIO': ['mean', 'max'],\n",
    "    'APPLICATION_CREDIT_DIFF': ['min', 'max', 'mean'],\n",
    "    'APPLICATION_CREDIT_RATIO': ['min', 'max', 'mean', 'var'],\n",
    "    'DOWN_PAYMENT_TO_CREDIT': ['mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_ACTIVE_AGG = {\n",
    "    'SK_ID_PREV': ['nunique'],\n",
    "    'SIMPLE_INTERESTS': ['mean'],\n",
    "    'AMT_ANNUITY': ['max', 'sum'],\n",
    "    'AMT_APPLICATION': ['max', 'mean'],\n",
    "    'AMT_CREDIT': ['sum'],\n",
    "    'AMT_DOWN_PAYMENT': ['max', 'mean'],\n",
    "    'DAYS_DECISION': ['min', 'mean'],\n",
    "    'CNT_PAYMENT': ['mean', 'sum'],\n",
    "    'DAYS_LAST_DUE_1ST_VERSION': ['min', 'max', 'mean'],\n",
    "    # Engineered features\n",
    "    'AMT_PAYMENT': ['sum'],\n",
    "    'INSTALMENT_PAYMENT_DIFF': ['mean', 'max'],\n",
    "    'REMAINING_DEBT': ['max', 'mean', 'sum'],\n",
    "    'REPAYMENT_RATIO': ['mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_APPROVED_AGG = {\n",
    "    'SK_ID_PREV': ['nunique'],\n",
    "    'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "    'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "    'AMT_DOWN_PAYMENT': ['max'],\n",
    "    'AMT_GOODS_PRICE': ['max'],\n",
    "    'HOUR_APPR_PROCESS_START': ['min', 'max'],\n",
    "    'DAYS_DECISION': ['min', 'mean'],\n",
    "    'CNT_PAYMENT': ['max', 'mean'],\n",
    "    'DAYS_TERMINATION': ['mean'],\n",
    "    # Engineered features\n",
    "    'CREDIT_TO_ANNUITY_RATIO': ['mean', 'max'],\n",
    "    'APPLICATION_CREDIT_DIFF': ['max'],\n",
    "    'APPLICATION_CREDIT_RATIO': ['min', 'max', 'mean'],\n",
    "    # The following features are only for approved applications\n",
    "    'DAYS_FIRST_DRAWING': ['max', 'mean'],\n",
    "    'DAYS_FIRST_DUE': ['min', 'mean'],\n",
    "    'DAYS_LAST_DUE_1ST_VERSION': ['min', 'max', 'mean'],\n",
    "    'DAYS_LAST_DUE': ['max', 'mean'],\n",
    "    'DAYS_LAST_DUE_DIFF': ['min', 'max', 'mean'],\n",
    "    'SIMPLE_INTERESTS': ['min', 'max', 'mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_REFUSED_AGG = {\n",
    "    'AMT_APPLICATION': ['max', 'mean'],\n",
    "    'AMT_CREDIT': ['min', 'max'],\n",
    "    'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "    'CNT_PAYMENT': ['max', 'mean'],\n",
    "    # Engineered features\n",
    "    'APPLICATION_CREDIT_DIFF': ['min', 'max', 'mean', 'var'],\n",
    "    'APPLICATION_CREDIT_RATIO': ['min', 'mean'],\n",
    "    'NAME_CONTRACT_TYPE_Consumer loans': ['mean'],\n",
    "    'NAME_CONTRACT_TYPE_Cash loans': ['mean'],\n",
    "    'NAME_CONTRACT_TYPE_Revolving loans': ['mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_LATE_PAYMENTS_AGG = {\n",
    "    'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "    'DAYS_LAST_DUE_1ST_VERSION': ['min', 'max', 'mean'],\n",
    "    # Engineered features\n",
    "    'APPLICATION_CREDIT_DIFF': ['min'],\n",
    "    'NAME_CONTRACT_TYPE_Consumer loans': ['mean'],\n",
    "    'NAME_CONTRACT_TYPE_Cash loans': ['mean'],\n",
    "    'NAME_CONTRACT_TYPE_Revolving loans': ['mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_LOAN_TYPE_AGG = {\n",
    "    'AMT_CREDIT': ['sum'],\n",
    "    'AMT_ANNUITY': ['mean', 'max'],\n",
    "    'SIMPLE_INTERESTS': ['min', 'mean', 'max', 'var'],\n",
    "    'APPLICATION_CREDIT_DIFF': ['min', 'var'],\n",
    "    'APPLICATION_CREDIT_RATIO': ['min', 'max', 'mean'],\n",
    "    'DAYS_DECISION': ['max'],\n",
    "    'DAYS_LAST_DUE_1ST_VERSION': ['max', 'mean'],\n",
    "    'CNT_PAYMENT': ['mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_TIME_AGG = {\n",
    "    'AMT_CREDIT': ['sum'],\n",
    "    'AMT_ANNUITY': ['mean', 'max'],\n",
    "    'SIMPLE_INTERESTS': ['mean', 'max'],\n",
    "    'DAYS_DECISION': ['min', 'mean'],\n",
    "    'DAYS_LAST_DUE_1ST_VERSION': ['min', 'max', 'mean'],\n",
    "    # Engineered features\n",
    "    'APPLICATION_CREDIT_DIFF': ['min'],\n",
    "    'APPLICATION_CREDIT_RATIO': ['min', 'max', 'mean'],\n",
    "    'NAME_CONTRACT_TYPE_Consumer loans': ['mean'],\n",
    "    'NAME_CONTRACT_TYPE_Cash loans': ['mean'],\n",
    "    'NAME_CONTRACT_TYPE_Revolving loans': ['mean'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T08:01:42.990591Z",
     "start_time": "2021-02-02T08:01:42.983609Z"
    }
   },
   "outputs": [],
   "source": [
    "POS_CASH_AGG = {\n",
    "    'SK_ID_PREV': ['nunique'],\n",
    "    'MONTHS_BALANCE': ['min', 'max', 'size'],\n",
    "    'SK_DPD': ['max', 'mean', 'sum', 'var'],\n",
    "    'SK_DPD_DEF': ['max', 'mean', 'sum'],\n",
    "    'LATE_PAYMENT': ['mean']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T08:01:42.999590Z",
     "start_time": "2021-02-02T08:01:42.991588Z"
    }
   },
   "outputs": [],
   "source": [
    "INSTALLMENTS_AGG = {\n",
    "    'SK_ID_PREV': ['size', 'nunique'],\n",
    "    'DAYS_ENTRY_PAYMENT': ['min', 'max', 'mean'],\n",
    "    'AMT_INSTALMENT': ['min', 'max', 'mean', 'sum'],\n",
    "    'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "    'DPD': ['max', 'mean', 'var'],\n",
    "    'DBD': ['max', 'mean', 'var'],\n",
    "    'PAYMENT_DIFFERENCE': ['mean'],\n",
    "    'PAYMENT_RATIO': ['mean'],\n",
    "    'LATE_PAYMENT': ['mean', 'sum'],\n",
    "    'SIGNIFICANT_LATE_PAYMENT': ['mean', 'sum'],\n",
    "    'LATE_PAYMENT_RATIO': ['mean'],\n",
    "    'DPD_7': ['mean'],\n",
    "    'DPD_15': ['mean'],\n",
    "    'PAID_OVER': ['mean']\n",
    "}\n",
    "\n",
    "INSTALLMENTS_TIME_AGG = {\n",
    "    'SK_ID_PREV': ['size'],\n",
    "    'DAYS_ENTRY_PAYMENT': ['min', 'max', 'mean'],\n",
    "    'AMT_INSTALMENT': ['min', 'max', 'mean', 'sum'],\n",
    "    'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "    'DPD': ['max', 'mean', 'var'],\n",
    "    'DBD': ['max', 'mean', 'var'],\n",
    "    'PAYMENT_DIFFERENCE': ['mean'],\n",
    "    'PAYMENT_RATIO': ['mean'],\n",
    "    'LATE_PAYMENT': ['mean'],\n",
    "    'SIGNIFICANT_LATE_PAYMENT': ['mean'],\n",
    "    'LATE_PAYMENT_RATIO': ['mean'],\n",
    "    'DPD_7': ['mean'],\n",
    "    'DPD_15': ['mean'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T08:01:43.006563Z",
     "start_time": "2021-02-02T08:01:43.000564Z"
    }
   },
   "outputs": [],
   "source": [
    "CREDIT_CARD_AGG = {\n",
    "    'MONTHS_BALANCE': ['min'],\n",
    "    'AMT_BALANCE': ['max'],\n",
    "    'AMT_CREDIT_LIMIT_ACTUAL': ['max'],\n",
    "    'AMT_DRAWINGS_ATM_CURRENT': ['max', 'sum'],\n",
    "    'AMT_DRAWINGS_CURRENT': ['max', 'sum'],\n",
    "    'AMT_DRAWINGS_POS_CURRENT': ['max', 'sum'],\n",
    "    'AMT_INST_MIN_REGULARITY': ['max', 'mean'],\n",
    "    'AMT_PAYMENT_TOTAL_CURRENT': ['max', 'mean', 'sum', 'var'],\n",
    "    'AMT_TOTAL_RECEIVABLE': ['max', 'mean'],\n",
    "    'CNT_DRAWINGS_ATM_CURRENT': ['max', 'mean', 'sum'],\n",
    "    'CNT_DRAWINGS_CURRENT': ['max', 'mean', 'sum'],\n",
    "    'CNT_DRAWINGS_POS_CURRENT': ['mean'],\n",
    "    'SK_DPD': ['mean', 'max', 'sum'],\n",
    "    'SK_DPD_DEF': ['max', 'sum'],\n",
    "    'LIMIT_USE': ['max', 'mean'],\n",
    "    'PAYMENT_DIV_MIN': ['min', 'mean'],\n",
    "    'LATE_PAYMENT': ['max', 'sum'],\n",
    "}\n",
    "\n",
    "CREDIT_CARD_TIME_AGG = {\n",
    "    'CNT_DRAWINGS_ATM_CURRENT': ['mean'],\n",
    "    'SK_DPD': ['max', 'sum'],\n",
    "    'AMT_BALANCE': ['mean', 'max'],\n",
    "    'LIMIT_USE': ['max', 'mean']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-02T08:01:37.508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application dataframe shape:  (356250, 83)\n",
      "application_train and applicatin_test - done in 47s\n",
      "Bureau dataframe shape:  (305811, 156)\n",
      "Bureau and bureau_balance data - done in 45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\user\\lib\\site-packages\\ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous dataframe shape:  (338857, 225)\n",
      "previous_application - done in 60s\n",
      "Pos-cash dataframe shape:  (337252, 24)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pd.set_option('display.max_rows', 60)\n",
    "    pd.set_option('display.max_columns', 100)\n",
    "    with timer(\"Pipeline total time\"):\n",
    "        main(debug= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
