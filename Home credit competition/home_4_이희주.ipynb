{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- competition/dataset : [https://www.kaggle.com/c/home-credit-default-risk/data](https://www.kaggle.com/c/home-credit-default-risk/data)\n",
    "- date : 2021/02/02\n",
    "- original : [https://www.kaggle.com/jsaguiar/lightgbm-7th-place-solution](https://www.kaggle.com/jsaguiar/lightgbm-7th-place-solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM 7th place solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-19T23:23:23.804833Z",
     "iopub.status.busy": "2021-01-19T23:23:23.803834Z",
     "iopub.status.idle": "2021-01-19T23:23:23.811814Z",
     "shell.execute_reply": "2021-01-19T23:23:23.810817Z",
     "shell.execute_reply.started": "2021-01-19T23:23:23.804833Z"
    }
   },
   "source": [
    "**✏ 필사 1회** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7번째 솔루션 앙상블에서 사용된 모델 중 하나를 개조했습니다. 더 자세한 사항은 [디스커션](https://www.kaggle.com/c/home-credit-default-risk/discussion/64580)을 참고하세요.  \n",
    "\n",
    "이 모델은 대출 신청의 범주형 변수들을 GOSS(Gradient-based One-Sided Sampling) 및 레이블 인코딩이 포함된 LightGBM을 사용합니다. 다른 테이블들은 평균, 합계, 집계를 위한 다른 함수들과 원핫인코딩을 사용합니다. 핵심 내용은 지난 대출 신청과 지난 n개월간의 집계와 같은 시간에 관련된 feature들을 추가하는 것입니다. 테이블간의 비율뿐만 아니라 구체적인 대출 타입 및 상태에 대한 집계도 포함되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:51.744636Z",
     "iopub.status.busy": "2021-02-02T10:26:51.744636Z",
     "iopub.status.idle": "2021-02-02T10:26:51.754609Z",
     "shell.execute_reply": "2021-02-02T10:26:51.753613Z",
     "shell.execute_reply.started": "2021-02-02T10:26:51.744636Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from contextlib import contextmanager\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "from scipy.stats import kurtosis, iqr, skew\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:51.756604Z",
     "iopub.status.busy": "2021-02-02T10:26:51.755606Z",
     "iopub.status.idle": "2021-02-02T10:26:51.767573Z",
     "shell.execute_reply": "2021-02-02T10:26:51.767573Z",
     "shell.execute_reply.started": "2021-02-02T10:26:51.755606Z"
    }
   },
   "outputs": [],
   "source": [
    "def main(debug=False):\n",
    "    num_rows=30000 if debug else None\n",
    "    with timer('application_train and application_test'):\n",
    "        df = get_train_test(DATA_DIRECTORY, num_rows=num_rows)\n",
    "        print('Application dataframe shape:', df.shape)\n",
    "    with timer('Bureau and bureau_balance data'):\n",
    "        bureau_df = get_bureau(DATA_DIRECTORY, num_rows=num_rows)\n",
    "        print('Bureau dataframe shape:', bureau_df.shape)\n",
    "        del bureau_df\n",
    "        gc.collect()\n",
    "    with timer('previous_application'):\n",
    "        prev_df = get_previous_applications(DATA_DIRECTORY, num_rows)\n",
    "        df = pd.merge(df, prev_df, on='SK_ID_CURR', how='left')\n",
    "        print('Previous dataframe shape:', prev_df.shape)\n",
    "        del prev_df\n",
    "        gc.collect()\n",
    "    with timer('previous application balances'):\n",
    "        pos = get_pos_cash(DATA_DIRECTORY, num_rows)\n",
    "        df = pd.merge(df, pos, on='SK_ID_CURR', how='left')\n",
    "        print('Pos-cash dataframe shape:', pos.shape)\n",
    "        del pos\n",
    "        gc.collect()\n",
    "        ins = get_installment_payments(DATA_DIRECTORY, num_rows)\n",
    "        df = pd.merge(df, ins, on='SK_ID_CURR', how='left')\n",
    "        print('Installments dataframe shape:', ins.shape)\n",
    "        del ins\n",
    "        gc.collect()\n",
    "        cc = get_credit_card(DATA_DIRECTORY, num_rows)\n",
    "        df = pd.merge(df, cc, on='SK_ID_CURR', how='left')\n",
    "        print('Credit card dataframe shape:', cc.shape)\n",
    "        del cc\n",
    "        gc.collect()\n",
    "    df = add_ratios_features(df)\n",
    "    df = reduce_memory(df)\n",
    "    lgbm_categorical_feat = [\n",
    "        'CODE_GENDER', 'FLAG_OWN_CAR', 'NAME_CONTRACT_TYPE', 'NAME_EDUCATION_TYPE',\n",
    "        'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'NAME_INCOME_TYPE', 'OCCUPATION_TYPE',\n",
    "        'ORGANIZATION_TYPE', 'WEEKDAY_APPR_PROCESS_START', 'NAME_TYPE_SUITE', 'WALLSMATERIAL_MODE'\n",
    "    ]\n",
    "    with timer('Run LightGBM'):\n",
    "        feat_importance = kfold_lightgbm_sklearn(df, lgbm_categorical_feat)\n",
    "        print(feat_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:51.770566Z",
     "iopub.status.busy": "2021-02-02T10:26:51.769569Z",
     "iopub.status.idle": "2021-02-02T10:26:51.780538Z",
     "shell.execute_reply": "2021-02-02T10:26:51.780538Z",
     "shell.execute_reply.started": "2021-02-02T10:26:51.769569Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_ratios_features(df):\n",
    "    # 신용 대 소득 비율\n",
    "    df['BUREAU_INCOME_CREDIT_RATIO'] = df['BUREAU_AMT_CREDIT_SUM_MEAN'] / df['AMT_INCOME_TOTAL']\n",
    "    df['BUREAU_ACTIVE_CREDIT_TO_INCOME_RATIO'] = df['BUREAU_ACTIVE_AMT_CREDIT_SUM_SUM'] / df['AMT_INCOME_TOTAL']\n",
    "    # 이전 대 현재 신용 비율\n",
    "    df['CURRENT_TO_APPROVED_CREDIT_MIN_RATIO'] = df['APPROVED_AMT_CREDIT_MIN'] / df['AMT_CREDIT']\n",
    "    df['CURRENT_TO_APPROVED_CREDIT_MAX_RATIO'] = df['APPROVED_AMT_CREDIT_MAX'] / df['AMT_CREDIT']\n",
    "    df['CURRENT_TO_APPROVED_CREDIT_MEAN_RATIO'] = df['APPROVED_AMT_CREDIT_MEAN'] / df['AMT_CREDIT']\n",
    "    # 이전 대 현재 연금 비율\n",
    "    df['CURRENT_TO_APPROVED_ANNUITY_MAX_RATIO'] = df['APPROVED_AMT_ANNUITY_MAX'] / df['AMT_ANNUITY']\n",
    "    df['CURRENT_TO_APPROVED_ANNUITY_MEAN_RATIO'] = df['APPROVED_AMT_ANNUITY_MEAN'] / df['AMT_ANNUITY']\n",
    "    df['PAYMENT_MIN_TO_ANNUITY_RATIO'] = df['INS_AMT_PAYMENT_MIN'] / df['AMT_ANNUITY']\n",
    "    df['PAYMENT_MAX_TO_ANNUITY_RATIO'] = df['INS_AMT_PAYMENT_MAX'] / df['AMT_ANNUITY']\n",
    "    df['PAYMENT_MEAN_TO_ANNUITY_RATIO'] = df['INS_AMT_PAYMENT_MEAN'] / df['AMT_ANNUITY']\n",
    "    # 이전 대 현재 신용 대 연금 비율\n",
    "    df['CTA_CREDIT_TO_ANNUITY_MAX_RATIO'] = df['APPROVED_CREDIT_TO_ANNUITY_RATIO_MAX'] / df['CREDIT_TO_ANNUITY_RATIO']\n",
    "    df['CTA_CREDIT_TO_ANNUITY_MEAN_RATIO'] = df['APPROVED_CREDIT_TO_ANNUITY_RATIO_MEAN'] / df['CREDIT_TO_ANNUITY_RATIO']\n",
    "    # 날짜의 차이와 비율\n",
    "    df['DAYS_DECISION_MEAN_TO_BIRTH'] = df['APPROVED_DAYS_DECISION_MEAN'] / df['DAYS_BIRTH']\n",
    "    df['DAYS_CREDIT_MEAN_TO_BIRTH'] = df['BUREAU_DAYS_CREDIT_MEAN'] / df['DAYS_BIRTH']\n",
    "    df['DAYS_DECISION_MEAN_TO_EMPLOYED'] = df['APPROVED_DAYS_DICISION_MEAN'] / df['DAYS_EMPLOYED']\n",
    "    df['DAYS_CREDIT_MEAN_TO_EMPLOYED'] = df['BUREAU_DAYS_CREDIT_MEAN'] / df['DAYS_EMPLOYED']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- lightGBM model ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:51.782534Z",
     "iopub.status.busy": "2021-02-02T10:26:51.782534Z",
     "iopub.status.idle": "2021-02-02T10:26:51.800485Z",
     "shell.execute_reply": "2021-02-02T10:26:51.800485Z",
     "shell.execute_reply.started": "2021-02-02T10:26:51.782534Z"
    }
   },
   "outputs": [],
   "source": [
    "def kfold_lightgbm_sklearn(data, categorical_feature=None):\n",
    "    df = data[data['TARGET'].notnull()]\n",
    "    test = data[data['TARGET'].isnull()]\n",
    "    print('Train/valid shape: {}, test shape: {}'.format(df.shape, test.shape))\n",
    "    del_features = ['TARGET', 'SK_ID_CURR', 'SK_ID_BUREAU', 'SK_ID_PREV', 'index', 'level_0']\n",
    "    predictors = list(filter(lambda v: v not in del_features, df.columns))\n",
    "    \n",
    "    if not STRATIFIED_KFOLD:\n",
    "        folds = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=RANDOM_SEED)\n",
    "    else:\n",
    "        folds = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=Ture, random_state=RANDOM_SEED)\n",
    "    \n",
    "    # oof predictions, test predictions, 변수 중요도, 트레이닝/검증 auc\n",
    "    oof_preds = np.zeros(df.shape[0])\n",
    "    sub_preds = np.zeros(test.shape[0])\n",
    "    importance_df = pd.DataFrame()\n",
    "    eval_results = dict()\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(df[predictors], df['TARGET'])):\n",
    "        train_x, train_y = df[predictors].iloc[train_idx], df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = df[predictors].iloc[valid_idx], df['TARGET'].iloc[valid_idx]\n",
    "        \n",
    "        params = {'random_state':RANDOM_SEED, 'nthread':NUM_THREADS}\n",
    "        clf = LGBMClassifier(**{**params, **LIGHTGBM_PARAMS})\n",
    "        if not categorical_feature:\n",
    "            clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "                    eval_metric='auc', verbose=400, early_stopping_rounds=EARLY_STOPPING)\n",
    "        else:\n",
    "            clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "                   eval_metric='auc', verbose=400, early_stopping_raounds=EARLY_STOPING,\n",
    "                   feature_name=list(df[predictors].columns), categorical_feature=categorica_feature)\n",
    "        \n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test[predictors], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "        \n",
    "        # gain과 split에 의한 변수 중요도\n",
    "        fold_importance = pd.DataFrame()\n",
    "        fold_importance['feature'] = predictors\n",
    "        fold_importance['gain'] = clf.booster_.feature_importance(importance_type='gain')\n",
    "        fold_importance['split'] = clf.booster_.feature_importance(importance_type='split')\n",
    "        importance_df = pd.concat([importance_df, fold_importance], axis=0)\n",
    "        eval_results['train_{}'.format(n_fold+1)] = clf.evals_result_['training']['auc']\n",
    "        eval_results['valid_{}'.format(n_fold+1)] = clf.evals_result_['vaild_1']['auc']\n",
    "        \n",
    "        print('Fold %2d AUC : %.6f'%(n_fold+1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        go.collect()\n",
    "    \n",
    "    print('Full AUC score %.6f'%roc_auc_score(df['TARGET'], oof_preds))\n",
    "    test['TARGET'] = sub_preds.copy()\n",
    "    \n",
    "    # 폴드 간 평균 변수 중요도 얻기\n",
    "    mean_importance = importance_df.groupby('feature').mean().reset_index()\n",
    "    mean_importance.sort_values(by='gain', ascending=False, inplace=True)\n",
    "    \n",
    "    # 변수 중요도, 테스트 예측값, oof 예측값 저장\n",
    "    if GENERATE_SUBMISSION_FILES:\n",
    "        # oof csv 생성\n",
    "        oof = pd.DataFrame()\n",
    "        oof['SK_ID_CURR'] = df['SK_ID_CURR'].copy()\n",
    "        df['PREDICTIONS'] = oof_preds.copy()\n",
    "        df['TARGET'] = df['TARGET'].copy()\n",
    "        df.to_csv('data/submission_4_oof{}.csv'.format(SUBMISSION_SUFIX), index=False)\n",
    "        test[['SK_ID_CURR', 'TARGET']].to_csv('data/submission_4_submission{}.csv'.format(SUBMISSION_SUFIX), index=False)\n",
    "        mean_importance.to_csv('data/submission_4_feature_importance{}.csv'.format(SUBMISSION_SUFIX), index=False)\n",
    "    return mean_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T07:57:21.574202Z",
     "iopub.status.busy": "2021-02-02T07:57:21.574202Z",
     "iopub.status.idle": "2021-02-02T07:57:21.583177Z",
     "shell.execute_reply": "2021-02-02T07:57:21.582179Z",
     "shell.execute_reply.started": "2021-02-02T07:57:21.574202Z"
    }
   },
   "source": [
    "--- application 파이프라인 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:51.802480Z",
     "iopub.status.busy": "2021-02-02T10:26:51.801482Z",
     "iopub.status.idle": "2021-02-02T10:26:51.816443Z",
     "shell.execute_reply": "2021-02-02T10:26:51.816443Z",
     "shell.execute_reply.started": "2021-02-02T10:26:51.802480Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_train_test(path, num_rows=None):\n",
    "    # application_train.csv와 application_test.csv처리 및 판다스 데이터프레임으로 리턴\n",
    "    train = pd.read_csv(os.path.join(path, 'application_train.csv'), nrows=num_rows)\n",
    "    test = pd.read_csv(os.path.join(path, 'application_test.csv'), nrows=num_rows)\n",
    "    df = train.append(test)\n",
    "    del train, test\n",
    "    gc.collect()\n",
    "    \n",
    "    # 데이터 정제\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']  # XNA 4명 있음\n",
    "    df = df[df['AMT_INCOME_TOTAL'] < 20000000]  # 테스트 셋에서 최대수입은 4M, 트레이닝 셋에서는 117M\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "    df['DAYS_LAST_PHONE_CHANGE'].replace(0, np.nan, inplace=True)\n",
    "    \n",
    "    # flag_document의 변수 - count, kurtosis(첨도)\n",
    "    docs = [f for f in df.columns if 'FLAG_DOC' in f]\n",
    "    df['DOCUMENT_COUNT'] = df[docs].sum(axis=1)\n",
    "    df['NEW_DOC_KURT'] = df[docs].kurtosis(axis=1)\n",
    "    # 범주형 나이 - target=1 플롯 기준\n",
    "    df['AGE_RANGE'] = df['DAYS_BIRTH'].apply(lambda x: get_age_label(x))\n",
    "    \n",
    "    # 외부 소스에 근거한 새로운 변수들\n",
    "    df['EXT_SOURCES_PROD'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_2'] * df['EXT_SOURCE_3']\n",
    "    df['EXT_SOURCES_WEIGHTED'] = df['EXT_SOURCE_1']*2 + df['EXT_SOURCE_2']*1 + df['EXT_SOURCE_3']*3\n",
    "    np.warnings.filterwarnings('ignore', r'All-NaN (slice|axis) encountered')\n",
    "    for function_name in ['min', 'max', 'mean', 'nanmedian', 'var']:\n",
    "        feature_name = 'EXT_SOURCES_{}'.format(function_name.upper())\n",
    "        df[feature_name] = eval('np.{}'.format(function_name))(df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']], axis=1)\n",
    "    \n",
    "    # 신용 비율\n",
    "    df['CREDIT_TO_ANNUITY_RATIO'] = df['AMT_CREDIT'] / df['AMT_ANNUITY']\n",
    "    df['CREDIT_TO_GOODS_RATIO'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']\n",
    "    # 수입 비율\n",
    "    df['ANNUITY_TO_INCOME_RATIO'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    df['CREDIT_TO_INCOME_RATIO'] = df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL']\n",
    "    df['INCOME_TO_EMPLOYED_RATIO'] = df['AMT_INCOME_TOTAL'] / df['DAYS_EMPLOYED']\n",
    "    df['INCOME_TO_BIRTH_RATIO'] = df['AMT_INCOME_TOTAL'] / df['DAYS_BIRTH']\n",
    "    # 시간 비율\n",
    "    df['EMPLOYED_TO_BIRTH_RATIO'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    df['ID_TO_BIRTH_RATIO'] = df['DAYS_ID_PUBLISH'] / df['DAYS_BIRTH']\n",
    "    df['CAR_TO_BIRTH_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_BIRTH']\n",
    "    df['CAR_TO_EMPLOYED_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_EMPLOYED']\n",
    "    df['PHONE_TO_BIRTH_RATIO'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_BIRTH']\n",
    "    \n",
    "    # groupby: 동일 그룹의 신청 내역에 대한 통계\n",
    "    group = ['ORGANIZATION_TYPE', 'NAME_EDUCATION_TYPE', 'OCCUPATION_TYPE', 'AGE_RANGE', 'CODE_GENDER']\n",
    "    df = do_median(df, group, 'EXT_SOURCES_MEAN', 'GROUP_EXT_SOURCES_MEDIAN')\n",
    "    df = do_std(df, group, 'EXT_SOURCES_MEAN', 'GROUP_EXT_SOURCES_STD')\n",
    "    df = do_mean(df, group, 'AMT_INCOME_TOTAL', 'GROUP_INCOME_MEAN')\n",
    "    df = do_std(df, group, 'AMT_INCOME_TOTAL', 'GROUP_INCOME_STD')\n",
    "    df = do_mean(df, group, 'CREDIT_TO_ANNUITY_RATIO', 'GROUP_CREDIT_TO_ANNUITY_MEAN')\n",
    "    df = do_std(df, group, 'CREDIT_TO_ANNUITY_RATIO', 'GROUP_CREDIT_TO_ANNUITY_STD')\n",
    "    df = do_mean(df, group, 'AMT_CREDIT', 'GROUP_CREDIT_MEAN')\n",
    "    df = do_mean(df, group, 'AMT_ANNUITY', 'GROUP_ANNUITY_MEAN')\n",
    "    df = do_std(df, group, 'AMT_ANNUITY', 'GROUP_ANNUITY_STD')\n",
    "    \n",
    "    # 범주형 변수 레이블인코딩\n",
    "    df, le_encoded_cols = label_encoder(df, None)\n",
    "    df = drop_application_columns(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:51.818439Z",
     "iopub.status.busy": "2021-02-02T10:26:51.818439Z",
     "iopub.status.idle": "2021-02-02T10:26:51.826416Z",
     "shell.execute_reply": "2021-02-02T10:26:51.825419Z",
     "shell.execute_reply.started": "2021-02-02T10:26:51.818439Z"
    }
   },
   "outputs": [],
   "source": [
    "def drop_application_columns(df):\n",
    "    # 순열 변수 중요도에 따라 변수 제거\n",
    "    drop_list = [\n",
    "        'CNT_CHILDREN', 'CNT_FAM_MEMBERS', 'HOUR_APPR_PROCESS_START', 'FLAG_EMP_PHONE', \n",
    "        'FLAG_MOBIL', 'FLAG_CONT_MOBILE', 'FLAG_EMAIL', 'FLAG_PHONE', 'FLAG_OWN_REALTY', \n",
    "        'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_WORK_CITY', \n",
    "        'OBS_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'AMT_REQ_CREDIT_BUREAU_DAY', \n",
    "        'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_YEAR', 'COMMONAREA_MODE', 'NONLIVINGAREA_MODE', \n",
    "        'ELEVATORS_MODE', 'NONLIVINGAREA_AVG', 'FLOORSMIN_MEDI', 'LANDAREA_MODE', \n",
    "        'NONLIVINGAREA_MEDI', 'LIVINGAPARTMENTS_MODE', 'FLOORSMIN_AVG', 'LANDAREA_AVG', \n",
    "        'FLOORSMIN_MODE', 'LANDAREA_MEDI', 'COMMONAREA_MEDI', 'YEARS_BUILD_AVG', \n",
    "        'COMMONAREA_AVG', 'BASEMENTAREA_AVG', 'BASEMENTAREA_MODE', 'NONLIVINGAPARTMENTS_MEDI', \n",
    "        'BASEMENTAREA_MEDI', 'LIVINGAPARTMENTS_AVG', 'ELEVATORS_AVG', 'YEARS_BUILD_MEDI',\n",
    "        'ENTRANCES_MODE', 'NONLIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'LIVINGAPARTMENTS_MEDI',\n",
    "        'YEARS_BUILD_MODE', 'YEARS_BEGINEXPLUATATION_AVG', 'ELEVATORS_MEDI', 'LIVINGAREA_MEDI',\n",
    "        'YEARS_BEGINEXPLUATATION_MODE', 'NONLIVINGAPARTMENTS_AVG', 'HOUSETYPE_MODE',\n",
    "        'FONDKAPREMONT_MODE', 'EMERGENCYSTATE_MODE'\n",
    "    ]\n",
    "    \n",
    "    # 대부분의 flag document 컬럼 제거\n",
    "    for doc_num in [2, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21]:\n",
    "        drop_list.append('FLAG_DOCUMENT_{}'.format(doc_num))\n",
    "    df.drop(drop_list, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:51.827413Z",
     "iopub.status.busy": "2021-02-02T10:26:51.827413Z",
     "iopub.status.idle": "2021-02-02T10:26:51.833397Z",
     "shell.execute_reply": "2021-02-02T10:26:51.833397Z",
     "shell.execute_reply.started": "2021-02-02T10:26:51.827413Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_age_label(days_birth):\n",
    "    # 연령 그룹 레이블 리턴 (int)\n",
    "    age_years = -days_birth/365\n",
    "    if age_years < 27: return 1\n",
    "    elif age_years < 40: return 2\n",
    "    elif age_years < 50: return 3\n",
    "    elif age_years < 65: return 4\n",
    "    elif age_years < 99: return 5\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- bureau 파이프라인 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:51.836389Z",
     "iopub.status.busy": "2021-02-02T10:26:51.836389Z",
     "iopub.status.idle": "2021-02-02T10:26:51.850353Z",
     "shell.execute_reply": "2021-02-02T10:26:51.849354Z",
     "shell.execute_reply.started": "2021-02-02T10:26:51.836389Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_bureau(path, num_rows=None):\n",
    "    # bureau.csv와 bureau_balance.csv 처리 및 판다스 데이터프레임 리턴\n",
    "    bureau = pd.read_csv(os.path.join(path, 'bureau.csv'), nrows=num_rows)\n",
    "    # 신용 기간과 신용/계좌 종료일 차이\n",
    "    bureau['CREDIT_DURATION'] = -bureau['DAYS_CREDIT'] + bureau['DAYS_CREDIT_ENDDATE']\n",
    "    bureau['ENDDATE_DIF'] = bureau['DAYS_CREDIT_ENDDATE'] - bureau['DAYS_ENDDATE_FACT']\n",
    "    # 신용과 부채 비율 및 차이\n",
    "    bureau['DEBT_PERCENTAGE'] = bureau['AMT_CREDIT_SUM'] / bureau['AMT_CREDIT_SUM_DEBT']\n",
    "    bureau['DEBT_CREDIT_DIFF'] = bureau['AMT_CREDIT_SUM'] - bureau['AMT_CREDIT_SUM_DEBT']\n",
    "    bureau['CREDIT_TO_ANNUITY_RATIO'] = bureau['AMT_CREDIT_SUM'] / bureau['AMT_ANNUITY']\n",
    "    \n",
    "    # 원핫인코딩\n",
    "    bureau, categorical_cols = one_hot_encoder(bureau, nan_as_category=False)\n",
    "    # bureau balance 변수와 조인\n",
    "    bureau = bureau.merge(get_bureau_balance(path, num_rows), how='left', on='SK_ID_BUREAU')\n",
    "    # 지연된 상환이 있는 달 체크\n",
    "    bureau['STATUS_12345'] = 0\n",
    "    for i in range(1, 6):\n",
    "        bureau['STATUS_12345'] += bureau['STATUS_{}'.format(i)]\n",
    "    \n",
    "    # 잔금이 있는 개월 수 집계 및 bureau와 병합\n",
    "    features = ['AMT_CREDIT_MAX_OVERDUE', 'AMT_CREDIT_SUM_OVERDUE', 'AMT_CREDIT_SUM',\n",
    "                'AMT_CREDIT_SUM_DEBT', 'DEBT_PERCENTAGE', 'DEBT_CREDIT_DIFF', 'STATUS_0', 'STATUS_12345']\n",
    "    agg_length = bureau.groupby('MONTHS_BALANCE_SIZE')[features].mean().reset_index()\n",
    "    agg_length.rename({feat: 'LL_' + feat for feat in features}, axis=1, inplace=True)\n",
    "    bureau = bureau.merge(agg_length, how='left', on='MONTHS_BALANCE_SIZE')\n",
    "    del agg_length\n",
    "    gc.collect()\n",
    "    \n",
    "    # 일반 대출 집계\n",
    "    agg_bureau = group(bureau, 'BUREAU_', BUREAU_AGG)\n",
    "    # 대출 집계 활성화 및 종료\n",
    "    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
    "    agg_bureau = group_and_merge(active, agg_bureau, 'BUREAU_ACTIVE_', BUREAU_ACTIVE_AGG)\n",
    "    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
    "    agg_bureau = group_and_merge(closed, agg_bureau, 'BUREAU_CLOSED_', BUREAU_CLOSED_AGG)\n",
    "    del active, closed\n",
    "    gc.collect()\n",
    "    # 주 대출 타입 집계\n",
    "    for credit_type in ['Consumer credit', 'Credit card', 'Mortgage', 'Car loan', 'Microloan']:\n",
    "        type_df = bureau[bureau['CREDIT_TYPE_'+credit_type] == 1]\n",
    "        prefix = 'BUREAU_' + credit_type.split(' ')[0].upper() + '_'\n",
    "        agg_bureau = group_and_merge(type_df, agg_bureau, prefix, BUREAU_LOAN_TYPE_AGG)\n",
    "        del type_df\n",
    "        gc.collect()\n",
    "    # 시간과 관련된 집계\n",
    "    for time_frame in [6, 12]:\n",
    "        prefix = 'BUREAU_LAST{}M_'.format(time_frame)\n",
    "        time_frame_df = bureau[bureau['DAYS_CREDIT'] >= -30*time_frame]\n",
    "        agg_bureau = group_and_merge(time_frame_df, agg_bureau, prefix, BUREAU_TIME_AGG)\n",
    "        del time_frame_df\n",
    "        gc.collect()\n",
    "        \n",
    "    # 지난 대출 중 최대 연체\n",
    "    sort_bureau = bureau.sort_values(by=['DAYS_CREDIT'])\n",
    "    gr = sort_bureau.groupby('SK_ID_CURR')['AMT_CREDIT_MAX_OVERDUE'].last().reset_index()\n",
    "    gr.rename({'AMT_CREDIT_MAX_OVERDUE':'BUREAU_LAST_LOAN_MAX_OVERDUE'}, inplace=True)\n",
    "    agg_bureau = agg_bureau.merge(gr, on='SK_ID_CURR', how='left')\n",
    "    # 비율: (전체 부채)/(전체 신용), (진행중인 대출 부채)/(진행중인 대출 신용)\n",
    "    agg_bureau['BUREAU_DEBT_OVER_CREDIT'] =\\\n",
    "        agg_bureau['BUREAU_AMT_CREDIT_SUM_DEBT_SUM']/agg_bureau['BUREAU_AMT_CREDIT_SUM_SUM']\n",
    "    agg_bureau['BUREAU_ACTIVE_DEBT_OVER_CREDIT'] =\\\n",
    "        agg_bureau['BUREAU_ACTIVE_AMT_CREDIT_SUM_DEBT_SUM']/agg_bureau['BUREAU_ACTIVE_AMT_CREDIT_SUM_SUM']\n",
    "    return agg_bureau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:51.852346Z",
     "iopub.status.busy": "2021-02-02T10:26:51.851350Z",
     "iopub.status.idle": "2021-02-02T10:26:51.859327Z",
     "shell.execute_reply": "2021-02-02T10:26:51.858331Z",
     "shell.execute_reply.started": "2021-02-02T10:26:51.852346Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_bureau_balance(path, num_rows=None):\n",
    "    bb = pd.read_csv(os.path.join(path, 'bureau_balance.csv'), nrows=num_rows)\n",
    "    bb, categorical_cols = one_hot_encoder(bb, nan_as_category=False)\n",
    "    # 붕괴가 있는 각 범주의 비율 계산\n",
    "    bb_processed = bb.groupby('SK_ID_BUREAU')[categorical_cols].mean().reset_index()\n",
    "    # 상환 기간에 대한 최솟값, 최댓값, 개수, 평균값\n",
    "    agg = {'MONTHS_BALANCE': ['min', 'max', 'mean', 'size']}\n",
    "    bb_processed = group_and_merge(bb, bb_processed, '', agg, 'SK_ID_BUREAU')\n",
    "    del bb\n",
    "    gc.collect()\n",
    "    return bb_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- previous 파이프라인 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:51.861324Z",
     "iopub.status.busy": "2021-02-02T10:26:51.860326Z",
     "iopub.status.idle": "2021-02-02T10:26:51.885260Z",
     "shell.execute_reply": "2021-02-02T10:26:51.884261Z",
     "shell.execute_reply.started": "2021-02-02T10:26:51.861324Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_previous_applications(path, num_rows=None):\n",
    "    prev = pd.read_csv(os.path.join(path, 'previous_application.csv'), nrows=num_rows)\n",
    "    pay = pd.read_csv(os.path.join(path, 'installments_payments.csv'), nrows=num_rows)\n",
    "    \n",
    "    # 중요한 범주형 변수들 원핫인코딩\n",
    "    ohe_columns = [\n",
    "        'NAME_CONTRACT_STATUS', 'NAME_CONTRACT_TYPE', 'CHANNEL_TYPE', 'NAME_TYPE_SUITE',\n",
    "        'NAME_YIELD_GROUP', 'PRODUCT_COMBINATION', 'NAME_PRODUCT_TYPE', 'NAME_CLIENT_TYPE'\n",
    "    ]\n",
    "    prev, categorical_cols = one_hot_encoder(prev, ohe_columns, nan_as_category=False)\n",
    "    \n",
    "    # feature engineering: 비율, 차이\n",
    "    prev['APPLICATION_CREDIT_DIFF'] = prev['AMT_APPLICATION'] - prev['AMT_CREDIT']\n",
    "    prev['APPLICATION_CREDIT_RATIO'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "    prev['CREDIT_TO_ANNUITY_RATIO'] = prev['AMT_CREDIT']/prev['AMT_ANNUITY']\n",
    "    prev['DOWN_PAYMENT_TO_CREDIT'] = prev['AMT_DOWN_PAYMENT'] / prev['AMT_CREDIT']\n",
    "    # 이자율\n",
    "    total_payment = prev['AMT_ANNUITY'] * prev['CNT_PAYMENT']\n",
    "    prev['SIMPLE_INTERESTS'] = (total_payment/prev['AMT_CREDIT'] - 1)/prev['CNT_PAYMENT']\n",
    "    \n",
    "    # 진행중인 대출 - 승인되었으나 끝나지 않은 대출\n",
    "    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "    active_df = approved[approved['DAYS_LAST_DUE'] == 365243]\n",
    "    # 진행중인 대출에 대해 얼마나 상환했는지 파악\n",
    "    active_pay = pay[pay['SK_ID_PREV'].isin(active_df['SK_ID_PREV'])]\n",
    "    active_pay_agg = active_pay.groupby('SK_ID_PREV')[['AMT_INSTALMENT', 'AMT_PAYMENT']].sum()\n",
    "    active_pay_agg.reset_index(inplace= True)\n",
    "    # 진행중인 대출: 지불된 금액과 분할된 금액의 차이(?)\n",
    "    active_pay_agg['INSTALMENT_PAYMENT_DIFF'] = active_pay_agg['AMT_INSTALMENT']-active_pay_agg['AMT_PAYMENT']\n",
    "    # active_df에 합치기\n",
    "    active_df = active_df.merge(active_pay_agg, on='SK_ID_PREV', how='left')\n",
    "    active_df['REMAINING_DEBT'] = active_df['AMT_CREDIT']-active_df['AMT_PAYMENT']\n",
    "    active_df['REPAYMENT_RATIO'] = active_df['AMT_PAYMENT']/active_df['AMT_CREDIT']\n",
    "    # 진행중인 대출에 대한 집계\n",
    "    active_agg_df = group(active_df, 'PREV_ACTIVE_', PREVIOUS_ACTIVE_AGG)\n",
    "    active_agg_df['TOTAL_REPAYMENT_RATIO'] =\\\n",
    "        active_agg_df['PREV_ACTIVE_AMT_PAYMENT_SUM']/active_agg_df['PREV_ACTIVE_AMT_CREDIT_SUM']\n",
    "    del active_pay, active_pay_agg, active_df\n",
    "    gc.collect()\n",
    "    \n",
    "    # 365,243 값은 nan으로 대체\n",
    "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace=True)\n",
    "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace=True)\n",
    "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace=True)\n",
    "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace=True)\n",
    "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace=True)\n",
    "    # 최종 기한일로부터 남은 일수\n",
    "    prev['DAYS_LAST_DUE_DIFF'] = prev['DAYS_LAST_DUE_1ST_VERSION'] - prev['DAYS_LAST_DUE']\n",
    "    approved['DAYS_LAST_DUE_DIFF'] = approved['DAYS_LAST_DUE_1ST_VERSION'] - approved['DAYS_LAST_DUE']\n",
    "    \n",
    "    # 범주형 변수\n",
    "    categorical_agg = {key: ['mean'] for key in categorical_cols}\n",
    "    # 일반 집계\n",
    "    agg_prev = group(prev, 'PREV_', {**PREVIOUS_AGG, **categorical_agg})\n",
    "    # agg_prev에 진행중인 대출 데이터프레임 합치기\n",
    "    agg_prev = agg_prev.merge(active_agg_df, how='left', on='SK_ID_CURR')\n",
    "    del active_agg_df\n",
    "    gc.collect()\n",
    "    # 승인된 대출과 거절된 대출 집계\n",
    "    agg_prev = group_and_merge(approved, agg_prev, 'APPROVED_', PREVIOUS_APPROVED_AGG)\n",
    "    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "    agg_prev = group_and_merge(refused, agg_prev, 'REFUSED_', PREVIOUS_REFUSED_AGG)\n",
    "    del approved, refused\n",
    "    gc.collect()\n",
    "    \n",
    "    # 소비자 대출과 현금 대출 집계\n",
    "    for loan_type in ['Consumer loans', 'Cash loans']:\n",
    "        type_df = prev[prev['NAME_CONTRACT_TYPE_{}'.format(loan_type)] == 1]\n",
    "        prefix = 'PREV_' + loan_type.split(' ')[0] + '_'\n",
    "        agg_prev = group_and_merge(type_df, agg_prev, prefix, PREVIOUS_LOAN_TYPE_AGG)\n",
    "        del type_df\n",
    "        gc.collect()\n",
    "    \n",
    "    # 연체된 대출에 대한 SK_ID_PREV\n",
    "    pay['LATE_PAYMENT'] = pay['DAYS_ENTRY_PAYMENT'] - pay['DAYS_INSTALMENT']\n",
    "    pay['LATE_PAYMENT'] = pay['LATE_PAYMENT'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    dpd_id = pay[pay['LATE_PAYMENT'] > 0]['SK_ID_PREV'].unique()\n",
    "    # 연제된 대출 집계\n",
    "    agg_dpd = group_and_merge(prev[prev['SK_ID_PREV'].isin(dpd_id)], agg_prev, 'PREV_LATE_', PREVIOUS_LATE_PAYMENTS_AGG)\n",
    "    del agg_dpd, dpd_id\n",
    "    gc.collect()\n",
    "    # 지난 대출에 대한 집계\n",
    "    for time_frame in [12, 24]:\n",
    "        time_frame_df = prev[prev['DAYS_DECISION'] >= -30*time_frame]\n",
    "        prefix = 'PREV_LAST{}M_'.format(time_frame)\n",
    "        agg_prev = group_and_merge(time_frame_df, agg_prev, prefix, PREVIOUS_TIME_AGG)\n",
    "        del time_frame_df\n",
    "        gc.collect()\n",
    "    del prev\n",
    "    gc.collect()\n",
    "    return agg_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- POS-CASH 파이프라인 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:51.886256Z",
     "iopub.status.busy": "2021-02-02T10:26:51.886256Z",
     "iopub.status.idle": "2021-02-02T10:26:51.899222Z",
     "shell.execute_reply": "2021-02-02T10:26:51.899222Z",
     "shell.execute_reply.started": "2021-02-02T10:26:51.886256Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pos_cash(path, num_rows=None):\n",
    "    pos = pd.read_csv(os.path.join(path, 'POS_CASH_balance.csv'), nrows=num_rows)\n",
    "    pos, categorical_cols = one_hot_encoder(pos, nan_as_category=False)\n",
    "    # 늦게 상환한 달\n",
    "    pos['LATE_PAYMENT'] = pos['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    # SK_ID_CURR에 대해 집계\n",
    "    categorical_agg = {key: ['mean'] for key in categorical_cols}\n",
    "    pos_agg = group(pos, 'POS_', {**POS_CASH_AGG, **categorical_agg})\n",
    "    # SK_ID_PREV를 기준으로 정렬 및 그룹화\n",
    "    sort_pos = pos.sort_values(by=['SK_ID_PREV', 'MONTHS_BALANCE'])\n",
    "    gp = sort_pos.groupby('SK_ID_PREV')\n",
    "    df = pd.DataFrame()\n",
    "    df['SK_ID_CURR'] = gp['SK_ID_CURR'].first()\n",
    "    df['MONTHS_BALANCE_MAX'] = gp['MONTHS_BALANCE'].max()\n",
    "    # 최초 시점 이전에 완료된 이전 대출의 백분율(?)\n",
    "    df['POS_LOAN_COMPLETED_MEAN'] = gp['NAME_CONTRACT_STATUS_Completed'].mean()\n",
    "    df['POS_COMPLETED_BEFORE_MEAN'] = gp['CNT_INSTALMENT'].first() - gp['CNT_INSTALMENT'].last()\n",
    "    df['POS_COMPLETED_BEFORE_MEAN'] = df.apply(lambda x: 1 if x['POS_COMPLETED_BEFORE_MEAN'] > 0\n",
    "                                               and x['POS_LOAN_COMPLETED_MEAN'] > 0 else 0, axis=1)\n",
    "    # 전체 중 남은 상환 횟수 및 비율\n",
    "    df['POS_REMAINING_INSTALMENTS'] = gp['CNT_INSTALMENT_FUTURE'].last()\n",
    "    df['POS_REMAINING_INSTALMENTS_RATIO'] = gp['CNT_INSTALMENT_FUTURE'].last()/gp['CNT_INSTALMENT'].last()\n",
    "    # SK_ID_CURR을 기준으로 그룹화 및 합치기\n",
    "    df_gp = df.groupby('SK_ID_CURR').sum().reset_index()\n",
    "    df_gp.drop(['MONTHS_BALANCE_MAX'], axis=1, inplace=True)\n",
    "    pos_agg = pd.merge(pos_agg, df_gp, on='SK_ID_CURR', how='left')\n",
    "    del df, gp, df_gp, sort_pos\n",
    "    gc.collect()\n",
    "\n",
    "    # 최근 3번의 대출 중 늦게 상환환 비율\n",
    "    pos = do_sum(pos, ['SK_ID_PREV'], 'LATE_PAYMENT', 'LATE_PAYMENT_SUM')\n",
    "    # 각 대출의 마지막 달\n",
    "    last_month_df = pos.groupby('SK_ID_PREV')['MONTHS_BALANCE'].idxmax()\n",
    "    # 가장 최근 대출 (3개)\n",
    "    sort_pos = pos.sort_values(by=['SK_ID_PREV', 'MONTHS_BALANCE'])\n",
    "    gp = sort_pos.iloc[last_month_df].groupby('SK_ID_CURR').tail(3)\n",
    "    gp_mean = gp.groupby('SK_ID_CURR').mean().reset_index()\n",
    "    pos_agg = pd.merge(pos_agg, gp_mean[['SK_ID_CURR','LATE_PAYMENT_SUM']], on='SK_ID_CURR', how='left')\n",
    "\n",
    "    # 필요없는 범주형 변수 제거\n",
    "    drop_features = [\n",
    "        'POS_NAME_CONTRACT_STATUS_Canceled_MEAN', 'POS_NAME_CONTRACT_STATUS_Amortized debt_MEAN',\n",
    "        'POS_NAME_CONTRACT_STATUS_XNA_MEAN']\n",
    "    pos_agg.drop(drop_features, axis=1, inplace=True)\n",
    "    return pos_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- installments 파이프라인 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:51.901216Z",
     "iopub.status.busy": "2021-02-02T10:26:51.900219Z",
     "iopub.status.idle": "2021-02-02T10:26:51.919167Z",
     "shell.execute_reply": "2021-02-02T10:26:51.918170Z",
     "shell.execute_reply.started": "2021-02-02T10:26:51.901216Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_installment_payments(path, num_rows=None):\n",
    "    pay = pd.read_csv(os.path.join(path, 'installments_payments.csv'), nrows=num_rows)\n",
    "    # 그룹 payment와 개별 payment의 차이\n",
    "    pay = do_sum(pay, ['SK_ID_PREV', 'NUM_INSTALMENT_NUMBER'], 'AMT_PAYMENT', 'AMT_PAYMENT_GROUPED')\n",
    "    pay['PAYMENT_DIFFERENCE'] = pay['AMT_INSTALMENT'] - pay['AMT_PAYMENT_GROUPED']\n",
    "    pay['PAYMENT_RATIO'] = pay['AMT_INSTALMENT'] / pay['AMT_PAYMENT_GROUPED']\n",
    "    pay['PAID_OVER_AMOUNT'] = pay['AMT_PAYMENT'] - pay['AMT_INSTALMENT']\n",
    "    pay['PAID_OVER'] = (pay['PAID_OVER_AMOUNT'] > 0).astype(int)\n",
    "    # 결제 항목: 기한이 지난 일수와 기한이 지나지 않은 일수\n",
    "    pay['DPD'] = pay['DAYS_ENTRY_PAYMENT'] - pay['DAYS_INSTALMENT']\n",
    "    pay['DPD'] = pay['DPD'].apply(lambda x: 0 if x <= 0 else x)\n",
    "    pay['DBD'] = pay['DAYS_INSTALMENT'] - pay['DAYS_ENTRY_PAYMENT']\n",
    "    pay['DBD'] = pay['DBD'].apply(lambda x: 0 if x <= 0 else x)\n",
    "    # 늦게 상환한 정보 체크\n",
    "    pay['LATE_PAYMENT'] = pay['DBD'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    # 늦게 지불한 비율\n",
    "    pay['INSTALMENT_PAYMENT_RATIO'] = pay['AMT_PAYMENT'] / pay['AMT_INSTALMENT']\n",
    "    pay['LATE_PAYMENT_RATIO'] = pay.apply(lambda x: x['INSTALMENT_PAYMENT_RATIO'] if x['LATE_PAYMENT'] == 1 else 0, axis=1)\n",
    "    # 늦게 지불한 횟수가 많은 경우 체크\n",
    "    pay['SIGNIFICANT_LATE_PAYMENT'] = pay['LATE_PAYMENT_RATIO'].apply(lambda x: 1 if x > 0.05 else 0)\n",
    "    # 늦게 지불한 횟수에 대한 임계값 설정\n",
    "    pay['DPD_7'] = pay['DPD'].apply(lambda x: 1 if x >= 7 else 0)\n",
    "    pay['DPD_15'] = pay['DPD'].apply(lambda x: 1 if x >= 15 else 0)\n",
    "    # SK_ID_CURR에 대해 집계\n",
    "    pay_agg = group(pay, 'INS_', INSTALLMENTS_AGG)\n",
    "\n",
    "    # \n",
    "    for months in [36, 60]:\n",
    "        recent_prev_id = pay[pay['DAYS_INSTALMENT'] >= -30*months]['SK_ID_PREV'].unique()\n",
    "        pay_recent = pay[pay['SK_ID_PREV'].isin(recent_prev_id)]\n",
    "        prefix = 'INS_{}M_'.format(months)\n",
    "        pay_agg = group_and_merge(pay_recent, pay_agg, prefix, INSTALLMENTS_TIME_AGG)\n",
    "\n",
    "    # 지난 기간동안 경향\n",
    "    group_features = ['SK_ID_CURR', 'SK_ID_PREV', 'DPD', 'LATE_PAYMENT',\n",
    "                      'PAID_OVER_AMOUNT', 'PAID_OVER', 'DAYS_INSTALMENT']\n",
    "    gp = pay[group_features].groupby('SK_ID_CURR')\n",
    "    func = partial(trend_in_last_k_instalment_features, periods= INSTALLMENTS_LAST_K_TREND_PERIODS)\n",
    "    g = parallel_apply(gp, func, index_name='SK_ID_CURR', chunk_size=10000).reset_index()\n",
    "    pay_agg = pay_agg.merge(g, on='SK_ID_CURR', how='left')\n",
    "\n",
    "    # 지난 대출에 대한 변수\n",
    "    g = parallel_apply(gp, installments_last_loan_features, index_name='SK_ID_CURR', chunk_size=10000).reset_index()\n",
    "    pay_agg = pay_agg.merge(g, on='SK_ID_CURR', how='left')\n",
    "    return pay_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:51.920165Z",
     "iopub.status.busy": "2021-02-02T10:26:51.920165Z",
     "iopub.status.idle": "2021-02-02T10:26:51.928144Z",
     "shell.execute_reply": "2021-02-02T10:26:51.927147Z",
     "shell.execute_reply.started": "2021-02-02T10:26:51.920165Z"
    }
   },
   "outputs": [],
   "source": [
    "def trend_in_last_k_instalment_features(gr, periods):\n",
    "    gr_ = gr.copy()\n",
    "    gr_.sort_values(['DAYS_INSTALMENT'], ascending=False, inplace=True)\n",
    "    features = {}\n",
    "\n",
    "    for period in periods:\n",
    "        gr_period = gr_.iloc[:period]\n",
    "        features = add_trend_feature(features, gr_period, 'DPD', '{}_TREND_'.format(period))\n",
    "        features = add_trend_feature(features, gr_period, 'PAID_OVER_AMOUNT', '{}_TREND_'.format(period))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:51.930140Z",
     "iopub.status.busy": "2021-02-02T10:26:51.929142Z",
     "iopub.status.idle": "2021-02-02T10:26:51.939114Z",
     "shell.execute_reply": "2021-02-02T10:26:51.938117Z",
     "shell.execute_reply.started": "2021-02-02T10:26:51.929142Z"
    }
   },
   "outputs": [],
   "source": [
    "def installments_last_loan_features(gr):\n",
    "    gr_ = gr.copy()\n",
    "    gr_.sort_values(['DAYS_INSTALMENT'], ascending=False, inplace=True)\n",
    "    last_installment_id = gr_['SK_ID_PREV'].iloc[0]\n",
    "    gr_ = gr_[gr_['SK_ID_PREV'] == last_installment_id]\n",
    "\n",
    "    features = {}\n",
    "    features = add_features_in_group(features, gr_, 'DPD', ['sum', 'mean', 'max', 'std'], 'LAST_LOAN_')\n",
    "    features = add_features_in_group(features, gr_, 'LATE_PAYMENT', ['count', 'mean'], 'LAST_LOAN_')\n",
    "    features = add_features_in_group(features, gr_, 'PAID_OVER_AMOUNT', ['sum', 'mean', 'max', 'min', 'std'], 'LAST_LOAN_')\n",
    "    features = add_features_in_group(features, gr_, 'PAID_OVER', ['count', 'mean'], 'LAST_LOAN_')\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- credit card 파이프라인 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:51.940113Z",
     "iopub.status.busy": "2021-02-02T10:26:51.940113Z",
     "iopub.status.idle": "2021-02-02T10:26:51.951082Z",
     "shell.execute_reply": "2021-02-02T10:26:51.950085Z",
     "shell.execute_reply.started": "2021-02-02T10:26:51.940113Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_credit_card(path, num_rows=None):\n",
    "    cc = pd.read_csv(os.path.join(path, 'credit_card_balance.csv'), nrows=num_rows)\n",
    "    cc, cat_cols = one_hot_encoder(cc, nan_as_category=False)\n",
    "    cc.rename(columns={'AMT_RECIVABLE': 'AMT_RECEIVABLE'}, inplace=True)\n",
    "    # 한도초과금액\n",
    "    cc['LIMIT_USE'] = cc['AMT_BALANCE'] / cc['AMT_CREDIT_LIMIT_ACTUAL']\n",
    "    # 현재 상환 / 최소 상환\n",
    "    cc['PAYMENT_DIV_MIN'] = cc['AMT_PAYMENT_CURRENT'] / cc['AMT_INST_MIN_REGULARITY']\n",
    "    # 최근 상환\n",
    "    cc['LATE_PAYMENT'] = cc['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    # 한도액\n",
    "    cc['DRAWING_LIMIT_RATIO'] = cc['AMT_DRAWINGS_ATM_CURRENT'] / cc['AMT_CREDIT_LIMIT_ACTUAL']\n",
    "    # SK_ID_CURR를 기준으로 집계\n",
    "    cc_agg = cc.groupby('SK_ID_CURR').agg(CREDIT_CARD_AGG)\n",
    "    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "    cc_agg.reset_index(inplace=True)\n",
    "\n",
    "    # 각 신용카드 신청의 지난달 잔액\n",
    "    last_ids = cc.groupby('SK_ID_PREV')['MONTHS_BALANCE'].idxmax()\n",
    "    last_months_df = cc[cc.index.isin(last_ids)]\n",
    "    cc_agg = group_and_merge(last_months_df,cc_agg,'CC_LAST_', {'AMT_BALANCE':['mean', 'max']})\n",
    "\n",
    "    # 지난 수 개월 집계\n",
    "    for months in [12, 24, 48]:\n",
    "        cc_prev_id = cc[cc['MONTHS_BALANCE'] >= -months]['SK_ID_PREV'].unique()\n",
    "        cc_recent = cc[cc['SK_ID_PREV'].isin(cc_prev_id)]\n",
    "        prefix = 'INS_{}M_'.format(months)\n",
    "        cc_agg = group_and_merge(cc_recent, cc_agg, prefix, CREDIT_CARD_TIME_AGG)\n",
    "    return cc_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- utility functions ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:51.952080Z",
     "iopub.status.busy": "2021-02-02T10:26:51.952080Z",
     "iopub.status.idle": "2021-02-02T10:26:51.958065Z",
     "shell.execute_reply": "2021-02-02T10:26:51.957067Z",
     "shell.execute_reply.started": "2021-02-02T10:26:51.952080Z"
    }
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(name, time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:51.959062Z",
     "iopub.status.busy": "2021-02-02T10:26:51.959062Z",
     "iopub.status.idle": "2021-02-02T10:26:51.965046Z",
     "shell.execute_reply": "2021-02-02T10:26:51.964049Z",
     "shell.execute_reply.started": "2021-02-02T10:26:51.959062Z"
    }
   },
   "outputs": [],
   "source": [
    "def group(df_to_agg, prefix, aggregations, aggregate_by='SK_ID_CURR'):\n",
    "    agg_df = df_to_agg.groupby(aggregate_by).agg(aggregations)\n",
    "    agg_df.columns = pd.Index(['{}{}_{}'.format(prefix, e[0], e[1].upper()) for e in agg_df.columns.tolist()])\n",
    "    return agg_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:51.966043Z",
     "iopub.status.busy": "2021-02-02T10:26:51.966043Z",
     "iopub.status.idle": "2021-02-02T10:26:51.972027Z",
     "shell.execute_reply": "2021-02-02T10:26:51.971030Z",
     "shell.execute_reply.started": "2021-02-02T10:26:51.966043Z"
    }
   },
   "outputs": [],
   "source": [
    "def group_and_merge(df_to_agg, df_to_merge, prefix, aggregations, aggregate_by='SK_ID_CURR'):\n",
    "    agg_df = group(df_to_agg, prefix, aggregations, aggregate_by=aggregate_by)\n",
    "    return df_to_merge.merge(agg_df, how='left', on=aggregate_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:51.973023Z",
     "iopub.status.busy": "2021-02-02T10:26:51.973023Z",
     "iopub.status.idle": "2021-02-02T10:26:51.979008Z",
     "shell.execute_reply": "2021-02-02T10:26:51.978012Z",
     "shell.execute_reply.started": "2021-02-02T10:26:51.973023Z"
    }
   },
   "outputs": [],
   "source": [
    "def do_mean(df, group_cols, counted, agg_name):\n",
    "    gp = df[group_cols + [counted]].groupby(group_cols)[counted].mean().reset_index().rename(\n",
    "        columns={counted: agg_name}\n",
    "    )\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:51.980005Z",
     "iopub.status.busy": "2021-02-02T10:26:51.980005Z",
     "iopub.status.idle": "2021-02-02T10:26:51.984993Z",
     "shell.execute_reply": "2021-02-02T10:26:51.984993Z",
     "shell.execute_reply.started": "2021-02-02T10:26:51.980005Z"
    }
   },
   "outputs": [],
   "source": [
    "def do_median(df, group_cols, counted, agg_name):\n",
    "    gp = df[group_cols + [counted]].groupby(group_cols)[counted].median().reset_index().rename(\n",
    "        columns={counted: agg_name}\n",
    "    )\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:51.986987Z",
     "iopub.status.busy": "2021-02-02T10:26:51.985989Z",
     "iopub.status.idle": "2021-02-02T10:26:51.994964Z",
     "shell.execute_reply": "2021-02-02T10:26:51.994964Z",
     "shell.execute_reply.started": "2021-02-02T10:26:51.986987Z"
    }
   },
   "outputs": [],
   "source": [
    "def do_std(df, group_cols, counted, agg_name):\n",
    "    gp = df[group_cols + [counted]].groupby(group_cols)[counted].std().reset_index().rename(\n",
    "        columns={counted: agg_name}\n",
    "    )\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:51.996960Z",
     "iopub.status.busy": "2021-02-02T10:26:51.995962Z",
     "iopub.status.idle": "2021-02-02T10:26:52.003941Z",
     "shell.execute_reply": "2021-02-02T10:26:52.003941Z",
     "shell.execute_reply.started": "2021-02-02T10:26:51.996960Z"
    }
   },
   "outputs": [],
   "source": [
    "def do_sum(df, group_cols, counted, agg_name):\n",
    "    gp = df[group_cols + [counted]].groupby(group_cols)[counted].sum().reset_index().rename(\n",
    "        columns={counted: agg_name}\n",
    "    )\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:52.007930Z",
     "iopub.status.busy": "2021-02-02T10:26:52.006933Z",
     "iopub.status.idle": "2021-02-02T10:26:52.013914Z",
     "shell.execute_reply": "2021-02-02T10:26:52.013914Z",
     "shell.execute_reply.started": "2021-02-02T10:26:52.007930Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_encoder(df, categorical_columns=None, nan_as_category=True):\n",
    "    original_columns = list(df.columns)\n",
    "    if not categorical_columns:\n",
    "        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns=categorical_columns, dummy_na=nan_as_category)\n",
    "    categorical_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:52.015910Z",
     "iopub.status.busy": "2021-02-02T10:26:52.015910Z",
     "iopub.status.idle": "2021-02-02T10:26:52.023888Z",
     "shell.execute_reply": "2021-02-02T10:26:52.023888Z",
     "shell.execute_reply.started": "2021-02-02T10:26:52.015910Z"
    }
   },
   "outputs": [],
   "source": [
    "def label_encoder(df, categorical_columns=None):\n",
    "    if not categorical_columns:\n",
    "        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    for col in categorical_columns:\n",
    "        df[col], uniques = pd.factorize(df[col])\n",
    "    return df, categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:52.025883Z",
     "iopub.status.busy": "2021-02-02T10:26:52.024885Z",
     "iopub.status.idle": "2021-02-02T10:26:52.034859Z",
     "shell.execute_reply": "2021-02-02T10:26:52.033861Z",
     "shell.execute_reply.started": "2021-02-02T10:26:52.025883Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_features(feature_name, aggs, features, feature_names, groupby):\n",
    "    feature_names.extend(['{}_{}'.format(feature_name, agg) for agg in aggs])\n",
    "\n",
    "    for agg in aggs:\n",
    "        if agg == 'kurt':\n",
    "            agg_func = kurtosis\n",
    "        elif agg == 'iqr':\n",
    "            agg_func = iqr\n",
    "        else:\n",
    "            agg_func = agg\n",
    "\n",
    "        g = groupby[feature_name].agg(agg_func).reset_index().rename(\n",
    "            index=str, columns={feature_name: '{}_{}'.format(feature_name,agg)}\n",
    "        )\n",
    "        features = features.merge(g, on='SK_ID_CURR', how='left')\n",
    "    return features, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:52.035857Z",
     "iopub.status.busy": "2021-02-02T10:26:52.035857Z",
     "iopub.status.idle": "2021-02-02T10:26:52.045829Z",
     "shell.execute_reply": "2021-02-02T10:26:52.045829Z",
     "shell.execute_reply.started": "2021-02-02T10:26:52.035857Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_features_in_group(features, gr_, feature_name, aggs, prefix):\n",
    "    for agg in aggs:\n",
    "        if agg == 'sum':\n",
    "            features['{}{}_sum'.format(prefix, feature_name)] = gr_[feature_name].sum()\n",
    "        elif agg == 'mean':\n",
    "            features['{}{}_mean'.format(prefix, feature_name)] = gr_[feature_name].mean()\n",
    "        elif agg == 'max':\n",
    "            features['{}{}_max'.format(prefix, feature_name)] = gr_[feature_name].max()\n",
    "        elif agg == 'min':\n",
    "            features['{}{}_min'.format(prefix, feature_name)] = gr_[feature_name].min()\n",
    "        elif agg == 'std':\n",
    "            features['{}{}_std'.format(prefix, feature_name)] = gr_[feature_name].std()\n",
    "        elif agg == 'count':\n",
    "            features['{}{}_count'.format(prefix, feature_name)] = gr_[feature_name].count()\n",
    "        elif agg == 'skew':\n",
    "            features['{}{}_skew'.format(prefix, feature_name)] = skew(gr_[feature_name])\n",
    "        elif agg == 'kurt':\n",
    "            features['{}{}_kurt'.format(prefix, feature_name)] = kurtosis(gr_[feature_name])\n",
    "        elif agg == 'iqr':\n",
    "            features['{}{}_iqr'.format(prefix, feature_name)] = iqr(gr_[feature_name])\n",
    "        elif agg == 'median':\n",
    "            features['{}{}_median'.format(prefix, feature_name)] = gr_[feature_name].median()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:52.047824Z",
     "iopub.status.busy": "2021-02-02T10:26:52.047824Z",
     "iopub.status.idle": "2021-02-02T10:26:52.054805Z",
     "shell.execute_reply": "2021-02-02T10:26:52.053807Z",
     "shell.execute_reply.started": "2021-02-02T10:26:52.047824Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_trend_feature(features, gr, feature_name, prefix):\n",
    "    y = gr[feature_name].values\n",
    "    try:\n",
    "        x = np.arange(0, len(y)).reshape(-1, 1)\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(x, y)\n",
    "        trend = lr.coef_[0]\n",
    "    except:\n",
    "        trend = np.nan\n",
    "    features['{}{}'.format(prefix, feature_name)] = trend\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:52.055802Z",
     "iopub.status.busy": "2021-02-02T10:26:52.055802Z",
     "iopub.status.idle": "2021-02-02T10:26:52.062784Z",
     "shell.execute_reply": "2021-02-02T10:26:52.062784Z",
     "shell.execute_reply.started": "2021-02-02T10:26:52.055802Z"
    }
   },
   "outputs": [],
   "source": [
    "def parallel_apply(groups, func, index_name='Index', num_workers=0, chunk_size=100000):\n",
    "    if num_workers <= 0: num_workers = NUM_THREADS\n",
    "    n_chunks = np.ceil(1.0 * groups.ngroups / chunk_size)\n",
    "    indeces, features = [], []\n",
    "    for index_chunk, groups_chunk in chunk_groups(groups, chunk_size):\n",
    "        with mp.pool.Pool(num_workers) as executor:\n",
    "            features_chunk = executor.map(func, groups_chunk)\n",
    "        features.extend(features_chunk)\n",
    "        indeces.extend(index_chunk)\n",
    "\n",
    "    features = pd.DataFrame(features)\n",
    "    features.index = indeces\n",
    "    features.index.name = index_name\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:52.064780Z",
     "iopub.status.busy": "2021-02-02T10:26:52.064780Z",
     "iopub.status.idle": "2021-02-02T10:26:52.070762Z",
     "shell.execute_reply": "2021-02-02T10:26:52.070762Z",
     "shell.execute_reply.started": "2021-02-02T10:26:52.064780Z"
    }
   },
   "outputs": [],
   "source": [
    "def chunk_groups(groupby_object, chunk_size):\n",
    "    n_groups = groupby_object.ngroups\n",
    "    group_chunk, index_chunk = [], []\n",
    "    for i, (index, df) in enumerate(groupby_object):\n",
    "        group_chunk.append(df)\n",
    "        index_chunk.append(index)\n",
    "        if (i + 1) % chunk_size == 0 or i + 1 == n_groups:\n",
    "            group_chunk_, index_chunk_ = group_chunk.copy(), index_chunk.copy()\n",
    "            group_chunk, index_chunk = [], []\n",
    "            yield index_chunk_, group_chunk_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:52.072757Z",
     "iopub.status.busy": "2021-02-02T10:26:52.072757Z",
     "iopub.status.idle": "2021-02-02T10:26:52.084725Z",
     "shell.execute_reply": "2021-02-02T10:26:52.084725Z",
     "shell.execute_reply.started": "2021-02-02T10:26:52.072757Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_memory(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print('Initial df memory usage is {:.2f} MB for {} columns'\n",
    "          .format(start_mem, len(df.columns)))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type != object:\n",
    "            cmin = df[col].min()\n",
    "            cmax = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                # Can use unsigned int here too\n",
    "                if cmin > np.iinfo(np.int8).min and cmax < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif cmin > np.iinfo(np.int16).min and cmax < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif cmin > np.iinfo(np.int32).min and cmax < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif cmin > np.iinfo(np.int64).min and cmax < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if cmin > np.finfo(np.float16).min and cmax < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif cmin > np.finfo(np.float32).min and cmax < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    memory_reduction = 100 * (start_mem - end_mem) / start_mem\n",
    "    print('Final memory usage is: {:.2f} MB - decreased by {:.1f}%'.format(end_mem, memory_reduction))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- 환경설정 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:52.086720Z",
     "iopub.status.busy": "2021-02-02T10:26:52.086720Z",
     "iopub.status.idle": "2021-02-02T10:26:52.093702Z",
     "shell.execute_reply": "2021-02-02T10:26:52.092705Z",
     "shell.execute_reply.started": "2021-02-02T10:26:52.086720Z"
    }
   },
   "outputs": [],
   "source": [
    "# GENERAL CONFIGURATIONS\n",
    "NUM_THREADS = 4\n",
    "DATA_DIRECTORY = \"data/\"\n",
    "SUBMISSION_SUFIX = \"_model2_04\"\n",
    "\n",
    "# INSTALLMENTS TREND PERIODS\n",
    "INSTALLMENTS_LAST_K_TREND_PERIODS =  [12, 24, 60, 120]\n",
    "\n",
    "# LIGHTGBM CONFIGURATION AND HYPER-PARAMETERS\n",
    "GENERATE_SUBMISSION_FILES = True\n",
    "STRATIFIED_KFOLD = False\n",
    "RANDOM_SEED = 737851\n",
    "NUM_FOLDS = 10\n",
    "EARLY_STOPPING = 100\n",
    "\n",
    "LIGHTGBM_PARAMS = {\n",
    "    'boosting_type': 'goss',\n",
    "    'n_estimators': 10000,\n",
    "    'learning_rate': 0.005134,\n",
    "    'num_leaves': 54,\n",
    "    'max_depth': 10,\n",
    "    'subsample_for_bin': 240000,\n",
    "    'reg_alpha': 0.436193,\n",
    "    'reg_lambda': 0.479169,\n",
    "    'colsample_bytree': 0.508716,\n",
    "    'min_split_gain': 0.024766,\n",
    "    'subsample': 1,\n",
    "    'is_unbalance': False,\n",
    "    'silent':-1,\n",
    "    'verbose':-1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:52.094700Z",
     "iopub.status.busy": "2021-02-02T10:26:52.094700Z",
     "iopub.status.idle": "2021-02-02T10:26:52.127610Z",
     "shell.execute_reply": "2021-02-02T10:26:52.126614Z",
     "shell.execute_reply.started": "2021-02-02T10:26:52.094700Z"
    }
   },
   "outputs": [],
   "source": [
    "# AGGREGATIONS\n",
    "BUREAU_AGG = {\n",
    "    'SK_ID_BUREAU': ['nunique'],\n",
    "    'DAYS_CREDIT': ['min', 'max', 'mean'],\n",
    "    'DAYS_CREDIT_ENDDATE': ['min', 'max'],\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n",
    "    'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['max', 'mean', 'sum'],\n",
    "    'AMT_ANNUITY': ['mean'],\n",
    "    'DEBT_CREDIT_DIFF': ['mean', 'sum'],\n",
    "    'MONTHS_BALANCE_MEAN': ['mean', 'var'],\n",
    "    'MONTHS_BALANCE_SIZE': ['mean', 'sum'],\n",
    "    # Categorical\n",
    "    'STATUS_0': ['mean'],\n",
    "    'STATUS_1': ['mean'],\n",
    "    'STATUS_12345': ['mean'],\n",
    "    'STATUS_C': ['mean'],\n",
    "    'STATUS_X': ['mean'],\n",
    "    'CREDIT_ACTIVE_Active': ['mean'],\n",
    "    'CREDIT_ACTIVE_Closed': ['mean'],\n",
    "    'CREDIT_ACTIVE_Sold': ['mean'],\n",
    "    'CREDIT_TYPE_Consumer credit': ['mean'],\n",
    "    'CREDIT_TYPE_Credit card': ['mean'],\n",
    "    'CREDIT_TYPE_Car loan': ['mean'],\n",
    "    'CREDIT_TYPE_Mortgage': ['mean'],\n",
    "    'CREDIT_TYPE_Microloan': ['mean'],\n",
    "    # Group by loan duration features (months)\n",
    "    'LL_AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "    'LL_DEBT_CREDIT_DIFF': ['mean'],\n",
    "    'LL_STATUS_12345': ['mean'],\n",
    "}\n",
    "\n",
    "BUREAU_ACTIVE_AGG = {\n",
    "    'DAYS_CREDIT': ['max', 'mean'],\n",
    "    'DAYS_CREDIT_ENDDATE': ['min', 'max'],\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n",
    "    'AMT_CREDIT_SUM': ['max', 'sum'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['max', 'mean'],\n",
    "    'DAYS_CREDIT_UPDATE': ['min', 'mean'],\n",
    "    'DEBT_PERCENTAGE': ['mean'],\n",
    "    'DEBT_CREDIT_DIFF': ['mean'],\n",
    "    'CREDIT_TO_ANNUITY_RATIO': ['mean'],\n",
    "    'MONTHS_BALANCE_MEAN': ['mean', 'var'],\n",
    "    'MONTHS_BALANCE_SIZE': ['mean', 'sum'],\n",
    "}\n",
    "\n",
    "BUREAU_CLOSED_AGG = {\n",
    "    'DAYS_CREDIT': ['max', 'var'],\n",
    "    'DAYS_CREDIT_ENDDATE': ['max'],\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "    'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['max', 'sum'],\n",
    "    'DAYS_CREDIT_UPDATE': ['max'],\n",
    "    'ENDDATE_DIF': ['mean'],\n",
    "    'STATUS_12345': ['mean'],\n",
    "}\n",
    "\n",
    "BUREAU_LOAN_TYPE_AGG = {\n",
    "    'DAYS_CREDIT': ['mean', 'max'],\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['mean', 'max'],\n",
    "    'AMT_CREDIT_SUM': ['mean', 'max'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['mean', 'max'],\n",
    "    'DEBT_PERCENTAGE': ['mean'],\n",
    "    'DEBT_CREDIT_DIFF': ['mean'],\n",
    "    'DAYS_CREDIT_ENDDATE': ['max'],\n",
    "}\n",
    "\n",
    "BUREAU_TIME_AGG = {\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "    'AMT_CREDIT_SUM': ['max', 'sum'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['mean', 'sum'],\n",
    "    'DEBT_PERCENTAGE': ['mean'],\n",
    "    'DEBT_CREDIT_DIFF': ['mean'],\n",
    "    'STATUS_0': ['mean'],\n",
    "    'STATUS_12345': ['mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_AGG = {\n",
    "    'SK_ID_PREV': ['nunique'],\n",
    "    'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "    'AMT_DOWN_PAYMENT': ['max', 'mean'],\n",
    "    'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "    'RATE_DOWN_PAYMENT': ['max', 'mean'],\n",
    "    'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "    'CNT_PAYMENT': ['max', 'mean'],\n",
    "    'DAYS_TERMINATION': ['max'],\n",
    "    # Engineered features\n",
    "    'CREDIT_TO_ANNUITY_RATIO': ['mean', 'max'],\n",
    "    'APPLICATION_CREDIT_DIFF': ['min', 'max', 'mean'],\n",
    "    'APPLICATION_CREDIT_RATIO': ['min', 'max', 'mean', 'var'],\n",
    "    'DOWN_PAYMENT_TO_CREDIT': ['mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_ACTIVE_AGG = {\n",
    "    'SK_ID_PREV': ['nunique'],\n",
    "    'SIMPLE_INTERESTS': ['mean'],\n",
    "    'AMT_ANNUITY': ['max', 'sum'],\n",
    "    'AMT_APPLICATION': ['max', 'mean'],\n",
    "    'AMT_CREDIT': ['sum'],\n",
    "    'AMT_DOWN_PAYMENT': ['max', 'mean'],\n",
    "    'DAYS_DECISION': ['min', 'mean'],\n",
    "    'CNT_PAYMENT': ['mean', 'sum'],\n",
    "    'DAYS_LAST_DUE_1ST_VERSION': ['min', 'max', 'mean'],\n",
    "    # Engineered features\n",
    "    'AMT_PAYMENT': ['sum'],\n",
    "    'INSTALMENT_PAYMENT_DIFF': ['mean', 'max'],\n",
    "    'REMAINING_DEBT': ['max', 'mean', 'sum'],\n",
    "    'REPAYMENT_RATIO': ['mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_APPROVED_AGG = {\n",
    "    'SK_ID_PREV': ['nunique'],\n",
    "    'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "    'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "    'AMT_DOWN_PAYMENT': ['max'],\n",
    "    'AMT_GOODS_PRICE': ['max'],\n",
    "    'HOUR_APPR_PROCESS_START': ['min', 'max'],\n",
    "    'DAYS_DECISION': ['min', 'mean'],\n",
    "    'CNT_PAYMENT': ['max', 'mean'],\n",
    "    'DAYS_TERMINATION': ['mean'],\n",
    "    # Engineered features\n",
    "    'CREDIT_TO_ANNUITY_RATIO': ['mean', 'max'],\n",
    "    'APPLICATION_CREDIT_DIFF': ['max'],\n",
    "    'APPLICATION_CREDIT_RATIO': ['min', 'max', 'mean'],\n",
    "    # The following features are only for approved applications\n",
    "    'DAYS_FIRST_DRAWING': ['max', 'mean'],\n",
    "    'DAYS_FIRST_DUE': ['min', 'mean'],\n",
    "    'DAYS_LAST_DUE_1ST_VERSION': ['min', 'max', 'mean'],\n",
    "    'DAYS_LAST_DUE': ['max', 'mean'],\n",
    "    'DAYS_LAST_DUE_DIFF': ['min', 'max', 'mean'],\n",
    "    'SIMPLE_INTERESTS': ['min', 'max', 'mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_REFUSED_AGG = {\n",
    "    'AMT_APPLICATION': ['max', 'mean'],\n",
    "    'AMT_CREDIT': ['min', 'max'],\n",
    "    'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "    'CNT_PAYMENT': ['max', 'mean'],\n",
    "    # Engineered features\n",
    "    'APPLICATION_CREDIT_DIFF': ['min', 'max', 'mean', 'var'],\n",
    "    'APPLICATION_CREDIT_RATIO': ['min', 'mean'],\n",
    "    'NAME_CONTRACT_TYPE_Consumer loans': ['mean'],\n",
    "    'NAME_CONTRACT_TYPE_Cash loans': ['mean'],\n",
    "    'NAME_CONTRACT_TYPE_Revolving loans': ['mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_LATE_PAYMENTS_AGG = {\n",
    "    'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "    'DAYS_LAST_DUE_1ST_VERSION': ['min', 'max', 'mean'],\n",
    "    # Engineered features\n",
    "    'APPLICATION_CREDIT_DIFF': ['min'],\n",
    "    'NAME_CONTRACT_TYPE_Consumer loans': ['mean'],\n",
    "    'NAME_CONTRACT_TYPE_Cash loans': ['mean'],\n",
    "    'NAME_CONTRACT_TYPE_Revolving loans': ['mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_LOAN_TYPE_AGG = {\n",
    "    'AMT_CREDIT': ['sum'],\n",
    "    'AMT_ANNUITY': ['mean', 'max'],\n",
    "    'SIMPLE_INTERESTS': ['min', 'mean', 'max', 'var'],\n",
    "    'APPLICATION_CREDIT_DIFF': ['min', 'var'],\n",
    "    'APPLICATION_CREDIT_RATIO': ['min', 'max', 'mean'],\n",
    "    'DAYS_DECISION': ['max'],\n",
    "    'DAYS_LAST_DUE_1ST_VERSION': ['max', 'mean'],\n",
    "    'CNT_PAYMENT': ['mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_TIME_AGG = {\n",
    "    'AMT_CREDIT': ['sum'],\n",
    "    'AMT_ANNUITY': ['mean', 'max'],\n",
    "    'SIMPLE_INTERESTS': ['mean', 'max'],\n",
    "    'DAYS_DECISION': ['min', 'mean'],\n",
    "    'DAYS_LAST_DUE_1ST_VERSION': ['min', 'max', 'mean'],\n",
    "    # Engineered features\n",
    "    'APPLICATION_CREDIT_DIFF': ['min'],\n",
    "    'APPLICATION_CREDIT_RATIO': ['min', 'max', 'mean'],\n",
    "    'NAME_CONTRACT_TYPE_Consumer loans': ['mean'],\n",
    "    'NAME_CONTRACT_TYPE_Cash loans': ['mean'],\n",
    "    'NAME_CONTRACT_TYPE_Revolving loans': ['mean'],\n",
    "}\n",
    "\n",
    "POS_CASH_AGG = {\n",
    "    'SK_ID_PREV': ['nunique'],\n",
    "    'MONTHS_BALANCE': ['min', 'max', 'size'],\n",
    "    'SK_DPD': ['max', 'mean', 'sum', 'var'],\n",
    "    'SK_DPD_DEF': ['max', 'mean', 'sum'],\n",
    "    'LATE_PAYMENT': ['mean']\n",
    "}\n",
    "\n",
    "INSTALLMENTS_AGG = {\n",
    "    'SK_ID_PREV': ['size', 'nunique'],\n",
    "    'DAYS_ENTRY_PAYMENT': ['min', 'max', 'mean'],\n",
    "    'AMT_INSTALMENT': ['min', 'max', 'mean', 'sum'],\n",
    "    'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "    'DPD': ['max', 'mean', 'var'],\n",
    "    'DBD': ['max', 'mean', 'var'],\n",
    "    'PAYMENT_DIFFERENCE': ['mean'],\n",
    "    'PAYMENT_RATIO': ['mean'],\n",
    "    'LATE_PAYMENT': ['mean', 'sum'],\n",
    "    'SIGNIFICANT_LATE_PAYMENT': ['mean', 'sum'],\n",
    "    'LATE_PAYMENT_RATIO': ['mean'],\n",
    "    'DPD_7': ['mean'],\n",
    "    'DPD_15': ['mean'],\n",
    "    'PAID_OVER': ['mean']\n",
    "}\n",
    "\n",
    "INSTALLMENTS_TIME_AGG = {\n",
    "    'SK_ID_PREV': ['size'],\n",
    "    'DAYS_ENTRY_PAYMENT': ['min', 'max', 'mean'],\n",
    "    'AMT_INSTALMENT': ['min', 'max', 'mean', 'sum'],\n",
    "    'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "    'DPD': ['max', 'mean', 'var'],\n",
    "    'DBD': ['max', 'mean', 'var'],\n",
    "    'PAYMENT_DIFFERENCE': ['mean'],\n",
    "    'PAYMENT_RATIO': ['mean'],\n",
    "    'LATE_PAYMENT': ['mean'],\n",
    "    'SIGNIFICANT_LATE_PAYMENT': ['mean'],\n",
    "    'LATE_PAYMENT_RATIO': ['mean'],\n",
    "    'DPD_7': ['mean'],\n",
    "    'DPD_15': ['mean'],\n",
    "}\n",
    "\n",
    "CREDIT_CARD_AGG = {\n",
    "    'MONTHS_BALANCE': ['min'],\n",
    "    'AMT_BALANCE': ['max'],\n",
    "    'AMT_CREDIT_LIMIT_ACTUAL': ['max'],\n",
    "    'AMT_DRAWINGS_ATM_CURRENT': ['max', 'sum'],\n",
    "    'AMT_DRAWINGS_CURRENT': ['max', 'sum'],\n",
    "    'AMT_DRAWINGS_POS_CURRENT': ['max', 'sum'],\n",
    "    'AMT_INST_MIN_REGULARITY': ['max', 'mean'],\n",
    "    'AMT_PAYMENT_TOTAL_CURRENT': ['max', 'mean', 'sum', 'var'],\n",
    "    'AMT_TOTAL_RECEIVABLE': ['max', 'mean'],\n",
    "    'CNT_DRAWINGS_ATM_CURRENT': ['max', 'mean', 'sum'],\n",
    "    'CNT_DRAWINGS_CURRENT': ['max', 'mean', 'sum'],\n",
    "    'CNT_DRAWINGS_POS_CURRENT': ['mean'],\n",
    "    'SK_DPD': ['mean', 'max', 'sum'],\n",
    "    'SK_DPD_DEF': ['max', 'sum'],\n",
    "    'LIMIT_USE': ['max', 'mean'],\n",
    "    'PAYMENT_DIV_MIN': ['min', 'mean'],\n",
    "    'LATE_PAYMENT': ['max', 'sum'],\n",
    "}\n",
    "\n",
    "CREDIT_CARD_TIME_AGG = {\n",
    "    'CNT_DRAWINGS_ATM_CURRENT': ['mean'],\n",
    "    'SK_DPD': ['max', 'sum'],\n",
    "    'AMT_BALANCE': ['mean', 'max'],\n",
    "    'LIMIT_USE': ['max', 'mean']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-02T10:26:52.128608Z",
     "iopub.status.busy": "2021-02-02T10:26:52.128608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application dataframe shape: (356250, 83)\n",
      "application_train and application_test - done in 64s\n",
      "Bureau dataframe shape: (305811, 156)\n",
      "Bureau and bureau_balance data - done in 58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-109-a0c325ad0837>:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  approved['DAYS_LAST_DUE_DIFF'] = approved['DAYS_LAST_DUE_1ST_VERSION'] - approved['DAYS_LAST_DUE']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous dataframe shape: (338857, 225)\n",
      "previous_application - done in 85s\n",
      "Pos-cash dataframe shape: (337252, 24)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pd.set_option('display.max_rows', 60)\n",
    "    pd.set_option('display.max_columns', 100)\n",
    "    with timer(\"Pipeline total time\"):\n",
    "        main(debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
