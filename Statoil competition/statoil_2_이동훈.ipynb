{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kaggle study 18일차(Statoil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T05:07:38.764278Z",
     "start_time": "2021-02-10T05:07:38.758292Z"
    }
   },
   "source": [
    "코드출처 : https://www.kaggle.com/devm2024/transfer-learning-with-vgg-16-cnn-aug-lb-0-1712"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TL;DR입니다.\n",
    "GPU에서 실행 CPU와의 호환성 문제가 있습니다.\n",
    "\n",
    "1. 딥 러닝의 하이퍼 파라미터는 여러 가지가 있으며, 이를 조정하려면 몇 주 또는 몇 달이 걸립니다. 일반적으로 연구자들은 이 튜닝을 수행하고 다른 아키텍처보다 성능이 뛰어난 멋진 아키텍처 세트를 발견하면 논문을 발표합니다.\n",
    "\n",
    "2. 사전 교육을 받은 모델이기 때문에 매우 빠르게 수렴되고 사용자도 GPU를 사용해야 합니다. 일부 라이브러리 문제로 인해 CPU에서 작동하지 않습니다.\n",
    "\n",
    "3. 우리의 목적을 위해, 우리는 연구원들이 이용할 수 있는 그런 건축물을 사용할 수 있습니다.\n",
    "\n",
    "4. 이미 기능을 추출하는 방법을 알고 있는 미리 훈련된 네트워크를 사용하면 하이퍼 파라미터를 조정할 필요가 없습니다. 이미 일부 데이터 세트(이미지넷이라고 함)에 대해 교육을 받았기 때문에 미리 훈련된 가중치는 가중치의 초기화를 잘 제공하며, 이로 인해 우리의 Convnet은 매우 빠르게 수렴되며 그렇지 않으면 이러한 심층 아키텍처에 며칠이 걸릴 수 있습니다. 그것이 Transfer Learning의 아이디어입니다. 그 예로는 VGG16, InceptionNet, google, Resnet 등이 있습니다.\n",
    "\n",
    "5. 이 커널에서는 작은 크기의 이미지에서 매우 우수한 성능을 발휘하는 사전 훈련된 VGG-16 네트워크를 사용할 것입니다.\n",
    "\n",
    "VGG 아키텍처가 작은 크기의 이미지에서도 잘 작동하는 것으로 입증되었습니다(CIFAR-10). 이 데이터 세트에서도 잘 작동할 것으로 예상했습니다.\n",
    "\n",
    "1. 이 코드에는 데이터 확대 단계도 포함되어 있으므로 성능이 상당히 개선됩니다.\n",
    "\n",
    "2. GPU가 필요합니다.\n",
    "\n",
    "관심이 있으시다면 여기 연구 논문의 링크가 있습니다. https://arxiv.org/pdf/1409.1556.pdf\n",
    "\n",
    "또한 keras 라이브러리(https://keras.io/applications/#vg16)도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T05:13:44.438562Z",
     "start_time": "2021-02-10T05:13:37.201682Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from os.path import join as opj\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pylab\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T05:17:52.613025Z",
     "start_time": "2021-02-10T05:16:43.427583Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('C:/Users/이동훈/Desktop/github/kaggle/kagglestudy/Data/statoil/train.json')\n",
    "target_train=train['is_iceberg']\n",
    "test = pd.read_json('C:/Users/이동훈/Desktop/github/kaggle/kagglestudy/Data/statoil/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras는 사전 훈련된 VGG의 구현을 제공합니다. 그것은 라이브러리에 있으므로 우리는 직접 네트워크를 구축할 필요가 없습니다. 여기서는 VGG의 마지막 레이어를 제거하고 이진 예측을 위한 시그모이드 레이어를 배치합니다.\n",
    "\n",
    "다음 코드는 작동하지 않습니다. 카글 노트북에서는 모델의 가중치를 다운로드할 수 없지만, 자신의 노트북에 코드를 복사하여 붙여넣을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T05:46:26.771637Z",
     "start_time": "2021-02-10T05:45:25.617265Z"
    }
   },
   "outputs": [],
   "source": [
    "target_train=train['is_iceberg']\n",
    "test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "train['inc_angle']=pd.to_numeric(train['inc_angle'], errors='coerce')#We have only 133 NAs.\n",
    "train['inc_angle']=train['inc_angle'].fillna(method='pad')\n",
    "X_angle=train['inc_angle']\n",
    "test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "X_test_angle=test['inc_angle']\n",
    "\n",
    "#교육 데이터를 생성\n",
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "X_band_3=(X_band_1+X_band_2)/2\n",
    "#X_band_3=np.array([np.full((75, 75), angel).astype(np.float32) for angel in train[\"inc_angle\"]])\n",
    "X_train = np.concatenate([X_band_1[:, :, :, np.newaxis]\n",
    "                          , X_band_2[:, :, :, np.newaxis]\n",
    "                         , X_band_3[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "X_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "X_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "X_band_test_3=(X_band_test_1+X_band_test_2)/2\n",
    "#X_band_test_3=np.array([np.full((75, 75), angel).astype(np.float32) for angel in test[\"inc_angle\"]])\n",
    "X_test = np.concatenate([X_band_test_1[:, :, :, np.newaxis]\n",
    "                          , X_band_test_2[:, :, :, np.newaxis]\n",
    "                         , X_band_test_3[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\t\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "batch_size=64\n",
    "\n",
    "# 이미지 변환을 정의\n",
    "gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                         vertical_flip = True,\n",
    "                         width_shift_range = 0.,\n",
    "                         height_shift_range = 0.,\n",
    "                         channel_shift_range=0,\n",
    "                         zoom_range = 0.2,\n",
    "                         rotation_range = 10)\n",
    "\n",
    "# 두 generator를 병합하도록 함.\n",
    "# 우리는 동일한 랜덤 시드를 가진 정확히 동일한 생성기를 그들과 각도 배열에 사용\n",
    "def gen_flow_for_two_inputs(X1, X2, y):\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            #어시스트 어레이는 동일합니다. 이는 마음의 평화를 위한 것이었지만 훈련 속도는 느려짐\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield [X1i[0], X2i[1]], X1i[1]\n",
    "\n",
    "def get_callbacks(filepath, patience=2):\n",
    "   es = EarlyStopping('val_loss', patience=10, mode=\"min\")\n",
    "   msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "   return [es, msave]\n",
    "\n",
    "\n",
    "def getVggAngleModel():\n",
    "    input_2 = Input(shape=[1], name=\"angle\")\n",
    "    angle_layer = Dense(1, )(input_2)\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, \n",
    "                 input_shape=X_train.shape[1:], classes=1)\n",
    "    x = base_model.get_layer('block5_pool').output\n",
    "    \n",
    "\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    merge_one = concatenate([x, angle_layer])\n",
    "    merge_one = Dense(512, activation='relu', name='fc2')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    merge_one = Dense(512, activation='relu', name='fc3')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    \n",
    "    predictions = Dense(1, activation='sigmoid')(merge_one)\n",
    "    \n",
    "    model = Model([base_model.input, input_2],predictions)\n",
    "    \n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "#데이터 확대와 함께 K-폴드 교차 검증을 사용.\n",
    "def myAngleCV(X_train, X_angle, X_test):\n",
    "    K=3\n",
    "    folds = list(StratifiedKFold(n_splits=K, shuffle=True, random_state=16).split(X_train, target_train))\n",
    "    y_test_pred_log = 0\n",
    "    y_train_pred_log=0\n",
    "    y_valid_pred_log = 0.0*target_train\n",
    "    for j, (train_idx, test_idx) in enumerate(folds):\n",
    "        print('\\n===================FOLD=',j)\n",
    "        X_train_cv = X_train[train_idx]\n",
    "        y_train_cv = target_train[train_idx]\n",
    "        X_holdout = X_train[test_idx]\n",
    "        Y_holdout= target_train[test_idx]\n",
    "        \n",
    "        X_angle_cv=X_angle[train_idx]\n",
    "        X_angle_hold=X_angle[test_idx]\n",
    "\n",
    "        #파일 경로를 지정하고 콜백을 받음.\n",
    "        file_path = \"%s_aug_model_weights.hdf5\"%j\n",
    "        callbacks = get_callbacks(filepath=file_path, patience=5)\n",
    "        gen_flow = gen_flow_for_two_inputs(X_train_cv, X_angle_cv, y_train_cv)\n",
    "        galaxyModel= getVggAngleModel()\n",
    "        galaxyModel.fit_generator(\n",
    "                gen_flow,\n",
    "                steps_per_epoch=24,\n",
    "                epochs=100,\n",
    "                shuffle=True,\n",
    "                verbose=1,\n",
    "                validation_data=([X_holdout,X_angle_hold], Y_holdout),\n",
    "                callbacks=callbacks)\n",
    "\n",
    "        #제일 좋은 모델 구하기\n",
    "        galaxyModel.load_weights(filepath=file_path)\n",
    "        #train 스코어 구하기\n",
    "        score = galaxyModel.evaluate([X_train_cv,X_angle_cv], y_train_cv, verbose=0)\n",
    "        print('Train loss:', score[0])\n",
    "        print('Train accuracy:', score[1])\n",
    "        #test 스코어 구하기\n",
    "        score = galaxyModel.evaluate([X_holdout,X_angle_hold], Y_holdout, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "\n",
    "        #validation 스코어 구하기\n",
    "        pred_valid=galaxyModel.predict([X_holdout,X_angle_hold])\n",
    "        y_valid_pred_log[test_idx] = pred_valid.reshape(pred_valid.shape[0])\n",
    "\n",
    "        #test 스코어 구하기\n",
    "        temp_test=galaxyModel.predict([X_test, X_test_angle])\n",
    "        y_test_pred_log+=temp_test.reshape(temp_test.shape[0])\n",
    "    \n",
    "        #train 스코어 구하기\n",
    "        temp_train=galaxyModel.predict([X_train, X_angle])\n",
    "        y_train_pred_log+=temp_train.reshape(temp_train.shape[0])\n",
    "\n",
    "    y_test_pred_log=y_test_pred_log/K\n",
    "    y_train_pred_log=y_train_pred_log/K\n",
    "\n",
    "    print('\\n Train Log Loss Validation= ',log_loss(target_train, y_train_pred_log))\n",
    "    print(' Test Log Loss Validation= ',log_loss(target_train, y_valid_pred_log))\n",
    "    return y_test_pred_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T08:00:28.117575Z",
     "start_time": "2021-02-10T05:46:26.840486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================FOLD= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\이동훈\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24/24 [==============================] - 200s 8s/step - loss: 1.0535 - accuracy: 0.5648 - val_loss: 0.4676 - val_accuracy: 0.7738\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 101s 4s/step - loss: 0.5410 - accuracy: 0.7494 - val_loss: 0.3094 - val_accuracy: 0.8579\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 98s 4s/step - loss: 0.3659 - accuracy: 0.8290 - val_loss: 0.2948 - val_accuracy: 0.8673\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 97s 4s/step - loss: 0.3031 - accuracy: 0.8709 - val_loss: 0.2736 - val_accuracy: 0.8766\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 98s 4s/step - loss: 0.2916 - accuracy: 0.8666 - val_loss: 0.2807 - val_accuracy: 0.8804\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 99s 4s/step - loss: 0.2903 - accuracy: 0.8686 - val_loss: 0.2377 - val_accuracy: 0.8916\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 98s 4s/step - loss: 0.2559 - accuracy: 0.8746 - val_loss: 0.2368 - val_accuracy: 0.8972\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 97s 4s/step - loss: 0.2438 - accuracy: 0.9015 - val_loss: 0.2351 - val_accuracy: 0.9065\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 98s 4s/step - loss: 0.1983 - accuracy: 0.9138 - val_loss: 0.2368 - val_accuracy: 0.9084\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 97s 4s/step - loss: 0.1997 - accuracy: 0.9195 - val_loss: 0.2544 - val_accuracy: 0.9065\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 102s 4s/step - loss: 0.2008 - accuracy: 0.9081 - val_loss: 0.2359 - val_accuracy: 0.9159\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 106s 4s/step - loss: 0.2143 - accuracy: 0.9103 - val_loss: 0.2322 - val_accuracy: 0.9140\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 105s 4s/step - loss: 0.1604 - accuracy: 0.9358 - val_loss: 0.2425 - val_accuracy: 0.9009\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 106s 4s/step - loss: 0.1638 - accuracy: 0.9324 - val_loss: 0.3010 - val_accuracy: 0.8879\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 104s 4s/step - loss: 0.1851 - accuracy: 0.9294 - val_loss: 0.2750 - val_accuracy: 0.9065\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 106s 4s/step - loss: 0.1923 - accuracy: 0.9195 - val_loss: 0.2771 - val_accuracy: 0.8897\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 107s 4s/step - loss: 0.1487 - accuracy: 0.9441 - val_loss: 0.2446 - val_accuracy: 0.9103\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 107s 4s/step - loss: 0.1716 - accuracy: 0.9342 - val_loss: 0.2706 - val_accuracy: 0.9047\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 107s 4s/step - loss: 0.1784 - accuracy: 0.9252 - val_loss: 0.2568 - val_accuracy: 0.9215\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 105s 4s/step - loss: 0.1758 - accuracy: 0.9229 - val_loss: 0.2499 - val_accuracy: 0.9178\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 107s 4s/step - loss: 0.1412 - accuracy: 0.9437 - val_loss: 0.3140 - val_accuracy: 0.9140\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 193s 8s/step - loss: 0.1795 - accuracy: 0.9250 - val_loss: 0.2646 - val_accuracy: 0.9178\n",
      "Train loss: 0.13482452929019928\n",
      "Train accuracy: 0.9457436800003052\n",
      "Test loss: 0.2322431355714798\n",
      "Test accuracy: 0.9140186905860901\n",
      "\n",
      "===================FOLD= 1\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 110s 5s/step - loss: 0.9238 - accuracy: 0.5269 - val_loss: 0.8694 - val_accuracy: 0.6411\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 103s 4s/step - loss: 0.5077 - accuracy: 0.7607 - val_loss: 0.3560 - val_accuracy: 0.8299\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 102s 4s/step - loss: 0.3524 - accuracy: 0.8498 - val_loss: 0.2487 - val_accuracy: 0.8879\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 106s 4s/step - loss: 0.3609 - accuracy: 0.8465 - val_loss: 0.2546 - val_accuracy: 0.8841\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 104s 4s/step - loss: 0.3107 - accuracy: 0.8636 - val_loss: 0.2325 - val_accuracy: 0.8935\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 106s 4s/step - loss: 0.2646 - accuracy: 0.8724 - val_loss: 0.2457 - val_accuracy: 0.8822\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 105s 4s/step - loss: 0.2564 - accuracy: 0.8923 - val_loss: 0.2096 - val_accuracy: 0.9121\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 104s 4s/step - loss: 0.2251 - accuracy: 0.9018 - val_loss: 0.2166 - val_accuracy: 0.9084\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 105s 4s/step - loss: 0.2504 - accuracy: 0.8972 - val_loss: 0.2205 - val_accuracy: 0.9084\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 112s 5s/step - loss: 0.2346 - accuracy: 0.9124 - val_loss: 0.2111 - val_accuracy: 0.8935\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 105s 4s/step - loss: 0.2167 - accuracy: 0.9195 - val_loss: 0.2142 - val_accuracy: 0.9065\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 106s 4s/step - loss: 0.1958 - accuracy: 0.9188 - val_loss: 0.2126 - val_accuracy: 0.9234\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 106s 4s/step - loss: 0.2038 - accuracy: 0.9193 - val_loss: 0.2100 - val_accuracy: 0.9047\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 105s 4s/step - loss: 0.2168 - accuracy: 0.9132 - val_loss: 0.2116 - val_accuracy: 0.9028\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 111s 5s/step - loss: 0.1741 - accuracy: 0.9220 - val_loss: 0.2010 - val_accuracy: 0.9215\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 107s 4s/step - loss: 0.1645 - accuracy: 0.9336 - val_loss: 0.2255 - val_accuracy: 0.9178\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 193s 8s/step - loss: 0.1811 - accuracy: 0.9298 - val_loss: 0.2805 - val_accuracy: 0.9065\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 113s 5s/step - loss: 0.1663 - accuracy: 0.9376 - val_loss: 0.2002 - val_accuracy: 0.9234\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 112s 5s/step - loss: 0.1530 - accuracy: 0.9401 - val_loss: 0.2177 - val_accuracy: 0.9047\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 112s 5s/step - loss: 0.1783 - accuracy: 0.9277 - val_loss: 0.2204 - val_accuracy: 0.9084\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 110s 5s/step - loss: 0.1657 - accuracy: 0.9325 - val_loss: 0.2083 - val_accuracy: 0.9103\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 108s 5s/step - loss: 0.1482 - accuracy: 0.9421 - val_loss: 0.2211 - val_accuracy: 0.9084\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 110s 5s/step - loss: 0.1629 - accuracy: 0.9356 - val_loss: 0.2092 - val_accuracy: 0.9178\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 110s 5s/step - loss: 0.1260 - accuracy: 0.9493 - val_loss: 0.2201 - val_accuracy: 0.9103\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 109s 5s/step - loss: 0.1479 - accuracy: 0.9455 - val_loss: 0.2113 - val_accuracy: 0.9121\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 112s 5s/step - loss: 0.1132 - accuracy: 0.9541 - val_loss: 0.2485 - val_accuracy: 0.9047\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 109s 5s/step - loss: 0.1521 - accuracy: 0.9347 - val_loss: 0.2133 - val_accuracy: 0.9159\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 112s 5s/step - loss: 0.1102 - accuracy: 0.9613 - val_loss: 0.2998 - val_accuracy: 0.8897\n",
      "Train loss: 0.12710383534431458\n",
      "Train accuracy: 0.9550982117652893\n",
      "Test loss: 0.20017465949058533\n",
      "Test accuracy: 0.9233644604682922\n",
      "\n",
      "===================FOLD= 2\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 112s 5s/step - loss: 0.7573 - accuracy: 0.5576 - val_loss: 0.4189 - val_accuracy: 0.7940\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 112s 5s/step - loss: 0.3653 - accuracy: 0.8343 - val_loss: 0.2983 - val_accuracy: 0.8427\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 186s 8s/step - loss: 0.3110 - accuracy: 0.8382 - val_loss: 0.3220 - val_accuracy: 0.8577\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 112s 5s/step - loss: 0.2759 - accuracy: 0.8838 - val_loss: 0.2677 - val_accuracy: 0.8858\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 119s 5s/step - loss: 0.2706 - accuracy: 0.8780 - val_loss: 0.3307 - val_accuracy: 0.8502\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 112s 5s/step - loss: 0.2104 - accuracy: 0.9073 - val_loss: 0.2788 - val_accuracy: 0.8858\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 111s 5s/step - loss: 0.2197 - accuracy: 0.8959 - val_loss: 0.2530 - val_accuracy: 0.8951\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 111s 5s/step - loss: 0.2047 - accuracy: 0.9181 - val_loss: 0.2874 - val_accuracy: 0.8783\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 111s 5s/step - loss: 0.2031 - accuracy: 0.9214 - val_loss: 0.2783 - val_accuracy: 0.8933\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 119s 5s/step - loss: 0.2000 - accuracy: 0.9208 - val_loss: 0.2632 - val_accuracy: 0.9064\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 119s 5s/step - loss: 0.1830 - accuracy: 0.9300 - val_loss: 0.2978 - val_accuracy: 0.8783\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 125s 5s/step - loss: 0.1761 - accuracy: 0.9301 - val_loss: 0.3029 - val_accuracy: 0.8858\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 117s 5s/step - loss: 0.2069 - accuracy: 0.9184 - val_loss: 0.2813 - val_accuracy: 0.8989\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 119s 5s/step - loss: 0.1645 - accuracy: 0.9367 - val_loss: 0.2696 - val_accuracy: 0.9026\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 116s 5s/step - loss: 0.1606 - accuracy: 0.9264 - val_loss: 0.2585 - val_accuracy: 0.9064\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 124s 5s/step - loss: 0.1212 - accuracy: 0.9518 - val_loss: 0.2835 - val_accuracy: 0.8933\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 124s 5s/step - loss: 0.1736 - accuracy: 0.9300 - val_loss: 0.2984 - val_accuracy: 0.9026\n",
      "Train loss: 0.16521641612052917\n",
      "Train accuracy: 0.9327102899551392\n",
      "Test loss: 0.2530277967453003\n",
      "Test accuracy: 0.8951311111450195\n",
      "\n",
      " Train Log Loss Validation=  0.15247908800527132\n",
      " Test Log Loss Validation=  0.22846650263782284\n"
     ]
    }
   ],
   "source": [
    "preds=myAngleCV(X_train, X_angle, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T08:03:29.310208Z",
     "start_time": "2021-02-10T08:03:28.864381Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id']=test['id']\n",
    "submission['is_iceberg']=preds\n",
    "submission.to_csv('sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
