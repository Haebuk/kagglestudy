{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- competition/dataset : [https://www.kaggle.com/c/statoil-iceberg-classifier-challenge/overview](https://www.kaggle.com/c/statoil-iceberg-classifier-challenge/overview)\n",
    "- date : 2021/02/10\n",
    "- original : [https://www.kaggle.com/devm2024/transfer-learning-with-vgg-16-cnn-aug-lb-0-1712](https://www.kaggle.com/devm2024/transfer-learning-with-vgg-16-cnn-aug-lb-0-1712)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning with VGG-16 CNN+AUG LB 0.1712"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-19T23:23:23.804833Z",
     "iopub.status.busy": "2021-01-19T23:23:23.803834Z",
     "iopub.status.idle": "2021-01-19T23:23:23.811814Z",
     "shell.execute_reply": "2021-01-19T23:23:23.810817Z",
     "shell.execute_reply.started": "2021-01-19T23:23:23.804833Z"
    }
   },
   "source": [
    "**✏ 필사 1회** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TL;DR\n",
    "**GPU에서 실행**해야 하며, CPU에서는 호환성의 문제가 있습니다:\n",
    "1. 딥러닝에서 하이퍼파라미터는 매우 많으며, 튜닝하기 위해서는 몇 주~몇 달이 걸립니다. 일반적으로 연구원들은 튜닝을 수행한 뒤 다른 것보다 우수한 구조의 셋을 발견하면 논문을 발표합니다.\n",
    "2. 모델에 대해 사전훈련이 되었기 때문에 빠르게 실행되나 여전히 GPU가 필요합니다. 몇 가지 라이브러리의 이슈 때문에 CPU에서는 작동하지 않습니다.\n",
    "3. 우리의 목적을 위해 연구원들이 우리에게 사용할 수 있도록 한 구조물들을 사용할 수 있습니다.\n",
    "4. 이미 feature를 추출하는 방법을 알고 있는 미리 훈련된 네트워크와 레이어를 사용하면 하이퍼파라미터를 튜닝하지 않아도 됩니다. 이미 데이터 셋 일부에 대해 훈련되었기 때문에 이미 훈련된 가중치는 좋은 가중치 초기화를 제공하여 우리의 Convnet은 매우 빠르게 수렴되며, 그렇지 않으면 이 심층 구조에 대해 며칠이 걸릴 수 있습니다.\n",
    "5. 이 커널에서는 사전학습된 VGG-16 네트워크를 사용할 것이며, 이것은 작은 크기의 이미지에 매우 좋습니다.  \n",
    "\n",
    "**VGG 구조가 작은 크기의 이미지(CIFAR-10)에서 잘 작동한다는 것은 이미 증명되었습니다.** 우리가 가진 데이터 셋에도 잘 작용할 것이라고 기대합니다:\n",
    "1. 이 코드는 데이터 확대 단계도 포함하고 있기 때문에 상당히 성능이 향상될 것입니다. \n",
    "2. GPU는 반드시 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T13:46:18.069326Z",
     "iopub.status.busy": "2021-02-10T13:46:18.068329Z",
     "iopub.status.idle": "2021-02-10T13:46:22.224509Z",
     "shell.execute_reply": "2021-02-10T13:46:22.223546Z",
     "shell.execute_reply.started": "2021-02-10T13:46:18.069326Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from os.path import join as opj\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pylab\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T13:46:27.914463Z",
     "iopub.status.busy": "2021-02-10T13:46:27.913464Z",
     "iopub.status.idle": "2021-02-10T13:47:46.758118Z",
     "shell.execute_reply": "2021-02-10T13:47:46.750149Z",
     "shell.execute_reply.started": "2021-02-10T13:46:27.914463Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('data/train.json')\n",
    "test = pd.read_json('data/test.json')\n",
    "\n",
    "target_train = train['is_iceberg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras는 사전훈련된 VGG의 구현을 제공하며, 라이브러리에 있기 때문에 우리가 직접 네트워크를 구축할 필요가 없습니다. 여기서 우리는 VGG의 마지막 레이어는 지우고 이진 분류를 위해 sigmoid 레이어를 넣습니다.  \n",
    "\n",
    "다음 코드는 kaggle 노트북에서는 모델의 가중치에 대해 다운로드되어 있지 않기 때문에 작동하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T01:11:42.012030Z",
     "iopub.status.busy": "2021-02-10T01:11:42.012030Z",
     "iopub.status.idle": "2021-02-10T01:11:42.365086Z",
     "shell.execute_reply": "2021-02-10T01:11:42.358103Z",
     "shell.execute_reply.started": "2021-02-10T01:11:42.012030Z"
    }
   },
   "outputs": [],
   "source": [
    "train['inc_angle'] = pd.to_numeric(train['inc_angle'], errors='coerce')\n",
    "x_angle = train['inc_angle']\n",
    "\n",
    "test['inc_angle'] = pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "x_test_angle = test['inc_angle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T01:11:42.385032Z",
     "iopub.status.busy": "2021-02-10T01:11:42.384035Z",
     "iopub.status.idle": "2021-02-10T01:11:46.226477Z",
     "shell.execute_reply": "2021-02-10T01:11:46.220496Z",
     "shell.execute_reply.started": "2021-02-10T01:11:42.385032Z"
    }
   },
   "outputs": [],
   "source": [
    "x_band_1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train['band_1']])\n",
    "x_band_2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train['band_2']])\n",
    "x_band_3 = (x_band_1 + x_band_2) / 2\n",
    "x_train = np.concatenate([\n",
    "    x_band_1[:, :, :, np.newaxis],\n",
    "    x_band_2[:, :, :, np.newaxis],\n",
    "    x_band_3[:, :, :, np.newaxis]\n",
    "], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T01:11:46.232460Z",
     "iopub.status.busy": "2021-02-10T01:11:46.230467Z",
     "iopub.status.idle": "2021-02-10T01:12:00.776245Z",
     "shell.execute_reply": "2021-02-10T01:12:00.767267Z",
     "shell.execute_reply.started": "2021-02-10T01:11:46.232460Z"
    }
   },
   "outputs": [],
   "source": [
    "x_band_1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test['band_1']])\n",
    "x_band_2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test['band_2']])\n",
    "x_band_3 = (x_band_1 + x_band_2) / 2\n",
    "x_test = np.concatenate([\n",
    "    x_band_1[:, :, :, np.newaxis],\n",
    "    x_band_2[:, :, :, np.newaxis],\n",
    "    x_band_3[:, :, :, np.newaxis]\n",
    "], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T01:12:00.792201Z",
     "iopub.status.busy": "2021-02-10T01:12:00.789209Z",
     "iopub.status.idle": "2021-02-10T01:12:39.574330Z",
     "shell.execute_reply": "2021-02-10T01:12:39.570340Z",
     "shell.execute_reply.started": "2021-02-10T01:12:00.791205Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation, GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras import initializers\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Concatenate, LSTM, concatenate\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T01:13:08.485957Z",
     "iopub.status.busy": "2021-02-10T01:13:08.484969Z",
     "iopub.status.idle": "2021-02-10T01:13:08.503910Z",
     "shell.execute_reply": "2021-02-10T01:13:08.499920Z",
     "shell.execute_reply.started": "2021-02-10T01:13:08.485957Z"
    }
   },
   "outputs": [],
   "source": [
    "# data augmentation(데이터 증가) for multi-input\n",
    "batch_size = 64\n",
    "# 이미지 변환 정의\n",
    "gen = ImageDataGenerator(\n",
    "    horizontal_flip=True, vertical_flip=True,\n",
    "    width_shift_range=0., height_shift_range=0., channel_shift_range=0.,\n",
    "    zoom_range=0.2, rotation_range=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T01:13:08.931764Z",
     "iopub.status.busy": "2021-02-10T01:13:08.930791Z",
     "iopub.status.idle": "2021-02-10T01:13:08.946737Z",
     "shell.execute_reply": "2021-02-10T01:13:08.944729Z",
     "shell.execute_reply.started": "2021-02-10T01:13:08.931764Z"
    }
   },
   "outputs": [],
   "source": [
    "# 두 generator merge하는 함수 정의\n",
    "# y와 angle array에 대해 동일한 생성자와 동일한 random seed를 사용\n",
    "def gen_flow_for_two_inputs(x1, x2, y):\n",
    "    genx1 = gen.flow(x1, y, batch_size=batch_size, seed=55)\n",
    "    genx2 = gen.flow(x1, x2, batch_size=batch_size, seed=55)\n",
    "    while True:\n",
    "        x1i = genx1.next()\n",
    "        x2i = genx2.next()\n",
    "        # 두 배열이 동일한지 평가\n",
    "        # np.testing.assert_array_equal(x1i[0], x2i[0]) # 오래걸림\n",
    "        yield [x1i[0], x2i[1]], x1i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T01:13:10.061170Z",
     "iopub.status.busy": "2021-02-10T01:13:10.059176Z",
     "iopub.status.idle": "2021-02-10T01:13:10.073137Z",
     "shell.execute_reply": "2021-02-10T01:13:10.070146Z",
     "shell.execute_reply.started": "2021-02-10T01:13:10.060173Z"
    }
   },
   "outputs": [],
   "source": [
    "# generator 생성 함수 정의\n",
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode='min')\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T01:13:10.276440Z",
     "iopub.status.busy": "2021-02-10T01:13:10.275471Z",
     "iopub.status.idle": "2021-02-10T01:13:10.291400Z",
     "shell.execute_reply": "2021-02-10T01:13:10.288436Z",
     "shell.execute_reply.started": "2021-02-10T01:13:10.276440Z"
    }
   },
   "outputs": [],
   "source": [
    "def getVggAngleModel():\n",
    "    input_2 = Input(shape=[1], name='angle')\n",
    "    angle_layer = Dense(1, )(input_2)\n",
    "    base_model = VGG16(\n",
    "        weights='imagenet', include_top=False, input_shape=x_train.shape[1:], classes=1\n",
    "    )\n",
    "    x = base_model.get_layer('block5_pool').output\n",
    "    \n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    merge_one = concatenate([x, angle_layer])\n",
    "    merge_one = Dense(512, activation='relu', name='fc2')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    merge_one = Dense(512, activation='relu', name='fc3')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    \n",
    "    predictions = Dense(1, activation='sigmoid')(merge_one)\n",
    "    \n",
    "    model = Model([base_model.input, input_2], predictions)\n",
    "    \n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-10T01:13:10.697315Z",
     "iopub.status.busy": "2021-02-10T01:13:10.695319Z",
     "iopub.status.idle": "2021-02-10T01:13:10.718286Z",
     "shell.execute_reply": "2021-02-10T01:13:10.714305Z",
     "shell.execute_reply.started": "2021-02-10T01:13:10.697315Z"
    }
   },
   "outputs": [],
   "source": [
    "# data augmentation에 대한 K-fold 교차검증 함수 생성\n",
    "def myAngleCV(x_train, x_angle, x_test):\n",
    "    K = 3\n",
    "    folds = list(StratifiedKFold(n_splits=K, shuffle=True, random_state=16).split(x_train, target_train))\n",
    "    y_test_pred_log = 0\n",
    "    y_train_pred_log = 0\n",
    "    y_valid_pred_log = 0.0 * target_train\n",
    "    for j, (train_idx, test_idx) in enumerate(folds):\n",
    "        print(f'\\n===================FOLD={j}')\n",
    "        x_train_cv = x_train[train_idx]\n",
    "        y_train_cv = target_train[train_idx]\n",
    "        x_holdout = x_train[test_idx]\n",
    "        y_holdout = target_train[test_idx]\n",
    "        \n",
    "        # Angle\n",
    "        x_angle_cv = x_angle[train_idx]\n",
    "        x_angle_hold = x_angle[test_idx]\n",
    "        \n",
    "        # file paht 지정 및 get callbacks 실행\n",
    "        file_path = 'data/%s_aug_model_weights.hdf5'%j\n",
    "        callbacks = get_callbacks(filepath=file_path, patience=5)\n",
    "        gen_flow = gen_flow_for_two_inputs(x_train_cv, x_angle_cv, y_train_cv)\n",
    "        galaxyModel = getVggAngleModel()\n",
    "        galaxyModel.fit_generator(\n",
    "            gen_flow,\n",
    "            steps_per_epoch=24, epochs=100,\n",
    "            shuffle=True, verbose=1,\n",
    "            validation_data=([x_holdout, x_angle_hold], y_holdout),\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        \n",
    "        # 최적 모델\n",
    "        galaxyModel.load_weights(filepath=file_path)\n",
    "        \n",
    "        # 트레이닝 점수\n",
    "        score = galaxyModel.evaluate([x_train_cv, x_angle_cv], y_train_cv, verbose=0)\n",
    "        print('Train loss:', score[0])\n",
    "        print('Train accuracy:', score[1])\n",
    "        \n",
    "        # 테스트 점수\n",
    "        score = galaxyModel.evaluate([x_holdout, x_angle_hold], y_holdout, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "        \n",
    "        # 검증 점수\n",
    "        pred_valid = galaxyModel.predict([x_holdout, x_angle_hold])\n",
    "        y_valid_pred_log[test_idx] = pred_valid.reshape(pred_valid.shape[0])\n",
    "        \n",
    "        # 테스트 점수\n",
    "        temp_test = galaxyModel.predict([x_test, x_test_angle])\n",
    "        y_test_pred_log += temp_test.reshape(temp_test.shape[0])\n",
    "        \n",
    "        # 트레인 점수\n",
    "        temp_train = galaxyModel.predict([x_train, x_angle])\n",
    "        y_train_pred_log += temp_train.reshape(temp_train.shape[0])\n",
    "    \n",
    "    y_test_pred_log = y_test_pred_log / K\n",
    "    y_train_pred_log = y_train_pred_log / K\n",
    "    print('\\n Train Log Loss Validation =', log_loss(target_train, y_train_pred_log))\n",
    "    print(' Test Log Loss Validation =', log_loss(target_train, y_valid_pred_log))\n",
    "    return y_train_pred_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = myAngleCV(x_train, x_angle, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['Id'] = test['id']\n",
    "subsmission['is_iceberg'] = preds\n",
    "submission.to_csv('data/submission_2_sub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
