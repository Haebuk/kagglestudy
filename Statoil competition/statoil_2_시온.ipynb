{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "august-digit",
   "metadata": {},
   "source": [
    "# Kaggle study day 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-density",
   "metadata": {},
   "source": [
    "Transfer Learning with VGG-16 CNN+AUG LB 0.1712 : https://www.kaggle.com/devm2024/transfer-learning-with-vgg-16-cnn-aug-lb-0-1712"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-artist",
   "metadata": {},
   "source": [
    "### TL;DR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-andrew",
   "metadata": {},
   "source": [
    "GPU에서 실행한다. CPU와는 호환성 문제가 있다.\n",
    "\n",
    "1. 딥러닝의 하이퍼파라미터는 여러가지가 있으며, 이를 조정하려면 오래 걸린다(몇 주/달). 일반적으로 연구자들은 이 튜닝을 하고 다른 아키텍쳐보다 성능이 높은 아키텍쳐 세트를 발견하면 논문을 발표한다.\n",
    "2. 이 모델은 사전 학습을 했기 때문에 빠르게 수렴되고 사용자도 CPU를 사용해야한다. 일부 라이브러리 문제로 CPU에선 작동하지 않는다.\n",
    "3. 목적을 위해, 연구원들에 의해 이용할 수 있는 아키텍쳐를 사용할 수 있다.\n",
    "4. 이미 변수 추출 방법을 '알고'있는 레이어인 pertrained nets을 사용하면, 하이퍼파라미터를 튜닝하지 않아도 된다. 이미 일부 데이터셋을 학습했기 때문에(imagenet), 사전 학습된 가중치는 좋은 가중치 초기화를 제공하고 이로 인해 Convnet은 빠르게 수렴된다(그렇지 않으면 이 심층 아키텍쳐에 며칠이 걸릴 수 있다). 예시로, VGG16, InceptionNet, googlenet, Resnet 등이 있다.\n",
    "5. 이 커널에서는, 작은 크기의 이미지에서 매우 우수한 성능을 보이는 사전 학습된 VGG-16을 사용한다.\n",
    "\n",
    "VGG 아키텍처는 작은 크기의 이미지(CIFAR-10)에서 잘 작동한다. 이 데이터셋에서도 잘 작동할 것이다. 이 코드엔 데이터 augmentation 단계도 포함되어 있으므로 성능이 상당히 개선된다.\n",
    "(### augmentation : 원래 데이터를 부풀려서 성능 향상시킴)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rising-africa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T14:17:56.510008Z",
     "start_time": "2021-02-10T14:17:53.922417Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mandatory imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from os.path import join as opj\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pylab\n",
    "plt.rcParams['figure.figsize'] = 10,10\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "measured-mirror",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T14:18:07.399330Z",
     "start_time": "2021-02-10T14:17:56.515001Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('../input/train.json')\n",
    "target_train = train['is_iceberg']\n",
    "test = pd.read_json('../input/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-contrast",
   "metadata": {},
   "source": [
    "Keras는 사전학습된 VGG 구현을 제공한다. 라이브러리에 있으므로 직접 네트워크를 구축할 필요가 없다. 여기서 VGG의 마지막 레이어를 제거하고 이진예측을 위해 시그모이드 레이어를 넣을 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "south-stone",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T14:18:07.414883Z",
     "start_time": "2021-02-10T14:18:07.402915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       43.9239\n",
       "1       38.1562\n",
       "2       45.2859\n",
       "3       43.8306\n",
       "4       35.6256\n",
       "         ...   \n",
       "1599         na\n",
       "1600         na\n",
       "1601         na\n",
       "1602         na\n",
       "1603         na\n",
       "Name: inc_angle, Length: 1604, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['inc_angle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "focused-gallery",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T16:47:59.421370Z",
     "start_time": "2021-02-10T16:47:52.654603Z"
    }
   },
   "outputs": [],
   "source": [
    "target_train = train['is_iceberg']\n",
    "### inc_angle은 위에서 보이듯 object 타입이므로 numeric으로 변환\n",
    "test['inc_angle'] = pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "train['inc_angle'] = pd.to_numeric(train['inc_angle'], errors='coerce')#We have only 133 NAs.\n",
    "train['inc_angle'] = train['inc_angle'].fillna(method='pad')\n",
    "X_angle = train['inc_angle']\n",
    "test['inc_angle'] = pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "X_test_angle = test['inc_angle']\n",
    "\n",
    "# train 데이터 생성\n",
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "X_band_3=(X_band_1 + X_band_2) / 2\n",
    "#X_band_3=np.array([np.full((75, 75), angel).astype(np.float32) for angel in train[\"inc_angle\"]])\n",
    "X_train = np.concatenate([X_band_1[:,:,:,np.newaxis], \n",
    "                          X_band_2[:,:,:,np.newaxis], \n",
    "                          X_band_3[:,:,:,np.newaxis]], axis=-1)\n",
    "\n",
    "X_band_test_1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "X_band_test_2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "X_band_test_3 = (X_band_test_1 + X_band_test_2) / 2\n",
    "#X_band_test_3=np.array([np.full((75, 75), angel).astype(np.float32) for angel in test[\"inc_angle\"]])\n",
    "X_test = np.concatenate([X_band_test_1[:,:,:,np.newaxis]\n",
    "                          , X_band_test_2[:,:,:,np.newaxis]\n",
    "                         , X_band_test_3[:,:,:,np.newaxis]], axis=-1)\n",
    "\n",
    "# import Keras\n",
    "from matplotlib import pyplot\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# Data Aug for multi-input\n",
    "batch_size = 64\n",
    "# 이미지 변환 정의\n",
    "gen = ImageDataGenerator(horizontal_flip = True, vertical_flip = True, width_shift_range = 0., height_shift_range = 0.,\n",
    "                         channel_shift_range=0, zoom_range = 0.2, rotation_range = 10)\n",
    "\n",
    "# 두 생성자를 병합하는 함수\n",
    "# 동일한 랜덤 시드를 가진 동일한 생성자를 y와 angle 배열에 모두 사용\n",
    "def gen_flow_for_two_inputs(X1, X2, y):\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        X2i = genX2.next()\n",
    "        # 배열이 동일하다고 가정 - 마음의 평화를 위한 것이지만 학습속도를 늦춘다\n",
    "        # np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "        yield [X1i[0], X2i[1]], X1i[1]\n",
    "        \n",
    "    \n",
    "# 최종적으로 생성자 생성\n",
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping('val_loss', patience=10, mode='min')\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave]\n",
    "\n",
    "def getVggAngleModel():\n",
    "    input_2 = Input(shape=[1], name='angle')\n",
    "    angle_layer = Dense(1,)(input_2)\n",
    "    base_model = VGG16(weights='imagenet', include_top=False,\n",
    "                      input_shape=X_train.shape[1:], classes=1)\n",
    "    x = base_model.get_layer('block5_pool').output\n",
    "    \n",
    "    x = GlobalMaxPooling2D()(x)  ### GlobalMaxPooling : 차원을 급격히 줄임. 각 레이어에서 Max값 하나만 추출\n",
    "    merge_one = concatenate([x, angle_layer])\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    merge_one = Dense(512, activation='relu', name='fc2')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    \n",
    "    predictions = Dense(1, activation='sigmoid')(merge_one)\n",
    "    \n",
    "    model = Model([base_model.input, input_2], predictions)\n",
    "    \n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Data Augmentation과 함께 K-fold Cross Validation 사용\n",
    "def myAngleCV(X_train, X_angle, X_test):\n",
    "    K = 3\n",
    "    folds = list(StratifiedKFold(n_splits=K, shuffle=True, random_state=16).split(X_train, target_train))\n",
    "    y_test_pred_log = 0\n",
    "    y_train_pred_log = 0\n",
    "    y_valid_pred_log = 0.0 * target_train\n",
    "    \n",
    "    for j, (train_idx, test_idx) in enumerate(folds):\n",
    "        print('\\n==================FOLD=',j)\n",
    "        X_train_cv = X_train[train_idx]\n",
    "        y_train_cv = target_train[train_idx]\n",
    "        X_holdout = X_train[test_idx]\n",
    "        Y_holdout = target_train[test_idx]\n",
    "        \n",
    "        # Angle\n",
    "        X_angle_cv = X_angle[train_idx]\n",
    "        X_angle_hold = X_angle[test_idx]\n",
    "        \n",
    "        # 파일 경로 정의 및 callbacks \n",
    "        file_path = '%s_aug_model_weights.hdf5'%j\n",
    "        callbacks = get_callbacks(filepath=file_path, patience=5)\n",
    "        gen_flow = gen_flow_for_two_inputs(X_train_cv, X_angle_cv, y_train_cv)\n",
    "        galaxyModel = getVggAngleModel()\n",
    "        galaxyModel.fit_generator(gen_flow,\n",
    "                                 steps_per_epoch=24, epochs=100, shuffle=True, verbose=1,\n",
    "                                 validation_data=([X_holdout, X_angle_hold], Y_holdout), callbacks=callbacks)\n",
    "        \n",
    "        # 최적 모델 얻기\n",
    "        galaxyModel.load_weights(filepath=file_path)\n",
    "        # train score\n",
    "        score = galaxyModel.evaluate([X_train_cv, X_angle_cv], y_train_cv, verbose=0)\n",
    "        print('Train loss :', score[0])\n",
    "        print('Train accuracy :', score[1])\n",
    "        # test score\n",
    "        score = galaxyModel.evaluate([X_holdout, X_angle_hold], Y_holdout, verbose=0)\n",
    "        print('Test loss :', score[0])\n",
    "        print('Test accuracy :', score[1])\n",
    "        # Validation score\n",
    "        pred_valid = galaxyModel.predict([X_holdout, X_angle_hold])\n",
    "        y_valid_pred_log[test_idx] = pred_valid.reshape(pred_valid.shape[0])\n",
    "        \n",
    "        # test scores\n",
    "        temp_test = galaxyModel.predict([X_test, X_test_angle])\n",
    "        y_test_pred_log += temp_test.reshape(temp_test.shape[0])\n",
    "        # train scores\n",
    "        temp_train = galaxyModel.predict([X_train, X_angle])\n",
    "        y_train_pred_log += temp_train.reshape(temp_train.shape[0])\n",
    "        \n",
    "    y_test_pred_log = y_test_pred_log / K\n",
    "    y_train_pred_log = y_train_pred_log / K\n",
    "    \n",
    "    print('\\n Train Log Loss Validation = ', log_loss(target_train, y_train_pred_log))\n",
    "    print(' Test Log Loss Validation = ', log_loss(target_train, y_valid_pred_log))\n",
    "    \n",
    "    return y_test_pred_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "precise-danish",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T23:54:25.254714Z",
     "start_time": "2021-02-10T16:48:02.517135Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================FOLD= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\study\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24/24 [==============================] - 266s 11s/step - loss: 1.7824 - accuracy: 0.5000 - val_loss: 0.7628 - val_accuracy: 0.5308\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 278s 11s/step - loss: 0.8393 - accuracy: 0.5274 - val_loss: 0.7070 - val_accuracy: 0.5308\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 285s 12s/step - loss: 0.7662 - accuracy: 0.5169 - val_loss: 0.6605 - val_accuracy: 0.5308\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 284s 12s/step - loss: 0.6653 - accuracy: 0.5996 - val_loss: 0.5342 - val_accuracy: 0.6841\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 292s 12s/step - loss: 0.5603 - accuracy: 0.6445 - val_loss: 0.4830 - val_accuracy: 0.8056\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 294s 12s/step - loss: 0.4761 - accuracy: 0.7587 - val_loss: 0.4008 - val_accuracy: 0.8262\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 298s 13s/step - loss: 0.4594 - accuracy: 0.7964 - val_loss: 0.3900 - val_accuracy: 0.8486\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 291s 12s/step - loss: 0.4215 - accuracy: 0.8196 - val_loss: 0.4125 - val_accuracy: 0.8355\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 297s 13s/step - loss: 0.3859 - accuracy: 0.8277 - val_loss: 0.3769 - val_accuracy: 0.8654\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 296s 13s/step - loss: 0.3496 - accuracy: 0.8494 - val_loss: 0.3855 - val_accuracy: 0.8150\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 297s 13s/step - loss: 0.3270 - accuracy: 0.8644 - val_loss: 0.3198 - val_accuracy: 0.8579\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 297s 13s/step - loss: 0.3260 - accuracy: 0.8490 - val_loss: 0.3324 - val_accuracy: 0.8654\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 289s 12s/step - loss: 0.2794 - accuracy: 0.8723 - val_loss: 0.3187 - val_accuracy: 0.8579\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 286s 12s/step - loss: 0.2776 - accuracy: 0.8703 - val_loss: 0.2634 - val_accuracy: 0.8804\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 285s 12s/step - loss: 0.2935 - accuracy: 0.8661 - val_loss: 0.2923 - val_accuracy: 0.8841\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 290s 12s/step - loss: 0.2743 - accuracy: 0.8814 - val_loss: 0.2850 - val_accuracy: 0.8598\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 290s 12s/step - loss: 0.2403 - accuracy: 0.8890 - val_loss: 0.2485 - val_accuracy: 0.8804\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 311s 13s/step - loss: 0.2372 - accuracy: 0.8964 - val_loss: 0.3117 - val_accuracy: 0.8542\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 334s 14s/step - loss: 0.2282 - accuracy: 0.8983 - val_loss: 0.2237 - val_accuracy: 0.9103\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 341s 14s/step - loss: 0.2597 - accuracy: 0.8863 - val_loss: 0.2816 - val_accuracy: 0.8785\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 336s 14s/step - loss: 0.2576 - accuracy: 0.8929 - val_loss: 0.2305 - val_accuracy: 0.9084\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 336s 14s/step - loss: 0.2349 - accuracy: 0.8976 - val_loss: 0.2442 - val_accuracy: 0.8916\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 330s 14s/step - loss: 0.2365 - accuracy: 0.8874 - val_loss: 0.2213 - val_accuracy: 0.9065\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 333s 14s/step - loss: 0.2414 - accuracy: 0.9036 - val_loss: 0.2418 - val_accuracy: 0.8935\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 334s 14s/step - loss: 0.2275 - accuracy: 0.8958 - val_loss: 0.2776 - val_accuracy: 0.8879\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 329s 14s/step - loss: 0.2200 - accuracy: 0.9038 - val_loss: 0.2405 - val_accuracy: 0.9065\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 348s 14s/step - loss: 0.2022 - accuracy: 0.9087 - val_loss: 0.2291 - val_accuracy: 0.8972\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 330s 14s/step - loss: 0.2130 - accuracy: 0.9062 - val_loss: 0.2352 - val_accuracy: 0.8991\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 323s 14s/step - loss: 0.2308 - accuracy: 0.9034 - val_loss: 0.2286 - val_accuracy: 0.8991\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 317s 13s/step - loss: 0.2077 - accuracy: 0.9049 - val_loss: 0.2279 - val_accuracy: 0.9009\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 332s 14s/step - loss: 0.2145 - accuracy: 0.9011 - val_loss: 0.2295 - val_accuracy: 0.9065\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 358s 15s/step - loss: 0.2230 - accuracy: 0.8999 - val_loss: 0.2582 - val_accuracy: 0.9009\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 401s 17s/step - loss: 0.1901 - accuracy: 0.9174 - val_loss: 0.2382 - val_accuracy: 0.9084\n",
      "Train loss : 0.18163172900676727\n",
      "Train accuracy : 0.9232928156852722\n",
      "Test loss : 0.2212992161512375\n",
      "Test accuracy : 0.9065420627593994\n",
      "\n",
      "==================FOLD= 1\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 339s 13s/step - loss: 1.2888 - accuracy: 0.5270 - val_loss: 0.7647 - val_accuracy: 0.5308\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 301s 13s/step - loss: 0.6394 - accuracy: 0.6768 - val_loss: 0.3557 - val_accuracy: 0.8318\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 284s 12s/step - loss: 0.4317 - accuracy: 0.7863 - val_loss: 0.2889 - val_accuracy: 0.8692\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 300s 12s/step - loss: 0.3729 - accuracy: 0.8295 - val_loss: 0.2787 - val_accuracy: 0.8523\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 289s 12s/step - loss: 0.3573 - accuracy: 0.8303 - val_loss: 0.2846 - val_accuracy: 0.8748\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 302s 12s/step - loss: 0.3204 - accuracy: 0.8529 - val_loss: 0.2540 - val_accuracy: 0.8692\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 301s 12s/step - loss: 0.3154 - accuracy: 0.8637 - val_loss: 0.2621 - val_accuracy: 0.8729\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 294s 12s/step - loss: 0.2747 - accuracy: 0.8802 - val_loss: 0.2385 - val_accuracy: 0.9084\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 299s 12s/step - loss: 0.2903 - accuracy: 0.8642 - val_loss: 0.2320 - val_accuracy: 0.9065\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 294s 12s/step - loss: 0.2903 - accuracy: 0.8767 - val_loss: 0.2668 - val_accuracy: 0.8561\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 294s 12s/step - loss: 0.2713 - accuracy: 0.8865 - val_loss: 0.2127 - val_accuracy: 0.9084\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 292s 12s/step - loss: 0.2352 - accuracy: 0.9003 - val_loss: 0.2159 - val_accuracy: 0.8935\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 287s 12s/step - loss: 0.2119 - accuracy: 0.9162 - val_loss: 0.2161 - val_accuracy: 0.9028\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 290s 12s/step - loss: 0.2250 - accuracy: 0.9079 - val_loss: 0.2178 - val_accuracy: 0.9178\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 296s 12s/step - loss: 0.2077 - accuracy: 0.9100 - val_loss: 0.2259 - val_accuracy: 0.8972\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 312s 13s/step - loss: 0.1935 - accuracy: 0.9182 - val_loss: 0.2577 - val_accuracy: 0.9140\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 300s 12s/step - loss: 0.2197 - accuracy: 0.9142 - val_loss: 0.2780 - val_accuracy: 0.8991\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 317s 13s/step - loss: 0.1920 - accuracy: 0.9221 - val_loss: 0.2177 - val_accuracy: 0.8991\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 306s 13s/step - loss: 0.1917 - accuracy: 0.9196 - val_loss: 0.2136 - val_accuracy: 0.8972\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 310s 13s/step - loss: 0.1936 - accuracy: 0.9255 - val_loss: 0.2165 - val_accuracy: 0.8972\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 324s 13s/step - loss: 0.1707 - accuracy: 0.9345 - val_loss: 0.2230 - val_accuracy: 0.8935\n",
      "Train loss : 0.1929612159729004\n",
      "Train accuracy : 0.915809154510498\n",
      "Test loss : 0.2127491533756256\n",
      "Test accuracy : 0.9084112048149109\n",
      "\n",
      "==================FOLD= 2\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 303s 13s/step - loss: 0.8743 - accuracy: 0.5543 - val_loss: 0.7746 - val_accuracy: 0.5674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "24/24 [==============================] - 300s 13s/step - loss: 0.5937 - accuracy: 0.6733 - val_loss: 0.3420 - val_accuracy: 0.8446\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 294s 12s/step - loss: 0.3684 - accuracy: 0.8341 - val_loss: 0.3559 - val_accuracy: 0.8071\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 288s 12s/step - loss: 0.3276 - accuracy: 0.8458 - val_loss: 0.2879 - val_accuracy: 0.8614\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 292s 12s/step - loss: 0.2897 - accuracy: 0.8605 - val_loss: 0.2784 - val_accuracy: 0.8764\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 296s 12s/step - loss: 0.2515 - accuracy: 0.8913 - val_loss: 0.2816 - val_accuracy: 0.8745\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 300s 12s/step - loss: 0.2233 - accuracy: 0.8996 - val_loss: 0.2635 - val_accuracy: 0.8820\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 291s 12s/step - loss: 0.2324 - accuracy: 0.9005 - val_loss: 0.3246 - val_accuracy: 0.8577\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 298s 12s/step - loss: 0.2378 - accuracy: 0.8943 - val_loss: 0.2708 - val_accuracy: 0.8970\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 290s 12s/step - loss: 0.2324 - accuracy: 0.8998 - val_loss: 0.2769 - val_accuracy: 0.8951\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 294s 12s/step - loss: 0.1926 - accuracy: 0.9231 - val_loss: 0.2967 - val_accuracy: 0.8801\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 292s 12s/step - loss: 0.1920 - accuracy: 0.9161 - val_loss: 0.3095 - val_accuracy: 0.8820\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 294s 12s/step - loss: 0.2201 - accuracy: 0.9111 - val_loss: 0.2701 - val_accuracy: 0.8839\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 300s 13s/step - loss: 0.2126 - accuracy: 0.9101 - val_loss: 0.2501 - val_accuracy: 0.9007\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 298s 13s/step - loss: 0.1785 - accuracy: 0.9307 - val_loss: 0.2940 - val_accuracy: 0.8858\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 299s 13s/step - loss: 0.1573 - accuracy: 0.9411 - val_loss: 0.3040 - val_accuracy: 0.8839\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 290s 12s/step - loss: 0.1803 - accuracy: 0.9220 - val_loss: 0.3183 - val_accuracy: 0.8801\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 295s 12s/step - loss: 0.1572 - accuracy: 0.9372 - val_loss: 0.2866 - val_accuracy: 0.8970\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 294s 12s/step - loss: 0.1617 - accuracy: 0.9410 - val_loss: 0.2902 - val_accuracy: 0.8764\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 277s 11s/step - loss: 0.1709 - accuracy: 0.9261 - val_loss: 0.3127 - val_accuracy: 0.8783\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 293s 12s/step - loss: 0.1495 - accuracy: 0.9442 - val_loss: 0.2642 - val_accuracy: 0.9007\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 288s 12s/step - loss: 0.1506 - accuracy: 0.9274 - val_loss: 0.2798 - val_accuracy: 0.9026\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 290s 12s/step - loss: 0.1322 - accuracy: 0.9534 - val_loss: 0.3408 - val_accuracy: 0.8989\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 296s 12s/step - loss: 0.1484 - accuracy: 0.9412 - val_loss: 0.4139 - val_accuracy: 0.8745\n",
      "Train loss : 0.13127534091472626\n",
      "Train accuracy : 0.945794403553009\n",
      "Test loss : 0.2500603199005127\n",
      "Test accuracy : 0.9007490873336792\n",
      "\n",
      " Train Log Loss Validation =  0.16965955045244407\n",
      " Test Log Loss Validation =  0.22802246442225077\n"
     ]
    }
   ],
   "source": [
    "preds = myAngleCV(X_train, X_angle, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "demographic-prisoner",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T00:01:39.471658Z",
     "start_time": "2021-02-11T00:01:39.407792Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = test['id']\n",
    "submission['is_iceberg'] = preds\n",
    "submission.to_csv('sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-protection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-decade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-tumor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-initial",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "572px",
    "left": "150px",
    "top": "295.8px",
    "width": "153.6px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
