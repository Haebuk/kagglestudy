{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "august-digit",
   "metadata": {},
   "source": [
    "# Kaggle study day 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-density",
   "metadata": {},
   "source": [
    "Transfer Learning with VGG-16 CNN+AUG LB 0.1712 : https://www.kaggle.com/devm2024/transfer-learning-with-vgg-16-cnn-aug-lb-0-1712"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-artist",
   "metadata": {},
   "source": [
    "### TL;DR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-andrew",
   "metadata": {},
   "source": [
    "GPU에서 실행한다. CPU와는 호환성 문제가 있다.\n",
    "\n",
    "1. 딥러닝의 하이퍼파라미터는 여러가지가 있으며, 이를 조정하려면 오래 걸린다(몇 주/달). 일반적으로 연구자들은 이 튜닝을 하고 다른 아키텍쳐보다 성능이 높은 아키텍쳐 세트를 발견하면 논문을 발표한다.\n",
    "2. 이 모델은 사전 학습을 했기 때문에 빠르게 수렴되고 사용자도 CPU를 사용해야한다. 일부 라이브러리 문제로 CPU에선 작동하지 않는다.\n",
    "3. 목적을 위해, 연구원들에 의해 이용할 수 있는 아키텍쳐를 사용할 수 있다.\n",
    "4. 이미 변수 추출 방법을 '알고'있는 레이어인 pertrained nets을 사용하면, 하이퍼파라미터를 튜닝하지 않아도 된다. 이미 일부 데이터셋을 학습했기 때문에(imagenet), 사전 학습된 가중치는 좋은 가중치 초기화를 제공하고 이로 인해 Convnet은 빠르게 수렴된다(그렇지 않으면 이 심층 아키텍쳐에 며칠이 걸릴 수 있다). 예시로, VGG16, InceptionNet, googlenet, Resnet 등이 있다.\n",
    "5. 이 커널에서는, 작은 크기의 이미지에서 매우 우수한 성능을 보이는 사전 학습된 VGG-16을 사용한다.\n",
    "\n",
    "VGG 아키텍처는 작은 크기의 이미지(CIFAR-10)에서 잘 작동한다. 이 데이터셋에서도 잘 작동할 것이다. 이 코드엔 데이터 augmentation 단계도 포함되어 있으므로 성능이 상당히 개선된다.\n",
    "(### augmentation : 원래 데이터를 부풀려서 성능 향상시킴)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rising-africa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T14:17:56.510008Z",
     "start_time": "2021-02-10T14:17:53.922417Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mandatory imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from os.path import join as opj\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pylab\n",
    "plt.rcParams['figure.figsize'] = 10,10\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "measured-mirror",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T14:18:07.399330Z",
     "start_time": "2021-02-10T14:17:56.515001Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('../input/train.json')\n",
    "target_train = train['is_iceberg']\n",
    "test = pd.read_json('../input/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-contrast",
   "metadata": {},
   "source": [
    "Keras는 사전학습된 VGG 구현을 제공한다. 라이브러리에 있으므로 직접 네트워크를 구축할 필요가 없다. 여기서 VGG의 마지막 레이어를 제거하고 이진예측을 위해 시그모이드 레이어를 넣을 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "south-stone",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T14:18:07.414883Z",
     "start_time": "2021-02-10T14:18:07.402915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       43.9239\n",
       "1       38.1562\n",
       "2       45.2859\n",
       "3       43.8306\n",
       "4       35.6256\n",
       "         ...   \n",
       "1599         na\n",
       "1600         na\n",
       "1601         na\n",
       "1602         na\n",
       "1603         na\n",
       "Name: inc_angle, Length: 1604, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['inc_angle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "focused-gallery",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T14:26:25.886879Z",
     "start_time": "2021-02-10T14:26:20.191115Z"
    }
   },
   "outputs": [],
   "source": [
    "target_train = train['is_iceberg']\n",
    "### inc_angle은 위에서 보이듯 object 타입이므로 numeric으로 변환\n",
    "test['inc_angle'] = pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "train['inc_angle'] = pd.to_numeric(train['inc_angle'], errors='coerce')#We have only 133 NAs.\n",
    "train['inc_angle'] = train['inc_angle'].fillna(method='pad')\n",
    "X_angle = train['inc_angle']\n",
    "test['inc_angle'] = pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "X_test_angle = test['inc_angle']\n",
    "\n",
    "# train 데이터 생성\n",
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "X_band_3=(X_band_1 + X_band_2) / 2\n",
    "#X_band_3=np.array([np.full((75, 75), angel).astype(np.float32) for angel in train[\"inc_angle\"]])\n",
    "X_train = np.concatenate([X_band_1[:,:,:,np.newaxis], \n",
    "                          X_band_2[:,:,:,np.newaxis], \n",
    "                          X_band_3[:,:,:,np.newaxis]], axis=-1)\n",
    "\n",
    "X_band_test_1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "X_band_test_2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "X_band_test_3 = (X_band_test_1 + X_band_test_2) / 2\n",
    "#X_band_test_3=np.array([np.full((75, 75), angel).astype(np.float32) for angel in test[\"inc_angle\"]])\n",
    "X_test = np.concatenate([X_band_test_1[:,:,:,np.newaxis]\n",
    "                          , X_band_test_2[:,:,:,np.newaxis]\n",
    "                         , X_band_test_3[:,:,:,np.newaxis]], axis=-1)\n",
    "\n",
    "# import Keras\n",
    "from matplotlib import pyplot\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# Data Aug for multi-input\n",
    "batch_size = 64\n",
    "# 이미지 변환 정의\n",
    "gen = ImageDataGenerator(horizontal_flip = True, vertical_flip = True, width_shift_range = 0., height_shift_range = 0.,\n",
    "                         channel_shift_range=0, zoom_range = 0.2, rotation_range = 10)\n",
    "\n",
    "# 두 생성자를 병합하는 함수\n",
    "# 동일한 랜덤 시드를 가진 동일한 생성자를 y와 angle 배열에 모두 사용\n",
    "def gen_flow_for_two_inputs(X1, X2, y):\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        X2i = genX2.next()\n",
    "        # 배열이 동일하다고 가정 - 마음의 평화를 위한 것이지만 학습속도를 늦춘다\n",
    "        # np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "        yield [X1i[0], X2i[1]], X1i[1]\n",
    "        \n",
    "    \n",
    "# 최종적으로 생성자 생성\n",
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping('val_loss', patience=10, mode='min')\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave]\n",
    "\n",
    "def getVggAngleModel():\n",
    "    input_2 = Input(shape=[1], name='angle')\n",
    "    angle_layer = Dense(1,)(input_2)\n",
    "    base_model = VGG16(weights='imagenet', include_top=False,\n",
    "                      input_shape=X_train.shape[1:], classes=1)\n",
    "    x = base_model.get_layer('block5_pool').output\n",
    "    \n",
    "    x = GlobalMaxPooling2D()(x)  ### GlobalMaxPooling : 차원을 급격히 줄임. 각 레이어에서 Max값 하나만 추출\n",
    "    merge_one = concatenate([x, angle_layer])\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    merge_one = Dense(512, activation='relu', name='fc2')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    \n",
    "    predictions = Dense(1, activation='sigmoid')(merge_one)\n",
    "    \n",
    "    model = Model([base_model.input, input_2], predictions)\n",
    "    \n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Data Augmentation과 함께 K-fold Cross Validation 사용\n",
    "def myAngleCV(X_train, X_angle, X_test):\n",
    "    K = 3\n",
    "    folds = list(StratifiedKFold(n_splits=K, shuffle=True, random_state=16).split(X_train, target_train))\n",
    "    y_test_pred_log = 0\n",
    "    y_train_pred_log = 0\n",
    "    y_valid_pred_log = 0.0 * target_train\n",
    "    \n",
    "    for j, (train_idx, test_idx) in enumerate(folds):\n",
    "        print('\\n==================FOLD=',j)\n",
    "        X_train_cv = X_train[train_idx]\n",
    "        y_train_cv = target_train[train_idx]\n",
    "        X_holdout = X_train[test_idx]\n",
    "        Y_holdout = target_train[test_idx]\n",
    "        \n",
    "        # Angle\n",
    "        X_angle_cv = X_angle[train_idx]\n",
    "        X_angle_hold = X_angle[test_idx]\n",
    "        \n",
    "        # 파일 경로 정의 및 callbacks \n",
    "        file_path = '%s_aug_model_weights.hdf5'%j\n",
    "        callbacks = get_callbacks(filepath=file_path, patience=5)\n",
    "        gen_flow = gen_flow_for_two_inputs(X_train_cv, X_angle_cv, y_train_cv)\n",
    "        galaxyModel = getVggAngleModel()\n",
    "        galaxyModel.fit_generator(gen_flow,\n",
    "                                 steps_per_epoch=24, epochs=100, shuffle=True, verbose=1,\n",
    "                                 validation_data=([X_holdout, X_angle_hold], Y_holdout), callbacks=callbacks)\n",
    "        \n",
    "        # 최적 모델 얻기\n",
    "        galaxyModel.load_weights(filepath=file_path)\n",
    "        # train score\n",
    "        score = galaxyModel.evaluate([X_train_cv, X_angle_cv], y_train_cv, verbose=0)\n",
    "        print('Train loss :', score[0])\n",
    "        print('Train accuracy :', score[1])\n",
    "        # test score\n",
    "        score = galaxyModel.evaluate([X_holdout, X_angle_hold], Y_holdout, verbose=0)\n",
    "        print('Test loss :', score[0])\n",
    "        print('Test accuracy :', score[1])\n",
    "        # Validation score\n",
    "        pred_valid = galaxyModel.predict([X_holdout, X_angle_hold])\n",
    "        y_valid_pred_log[test_idx] = pred_valid.reshape(pred_valid.shape[0])\n",
    "        \n",
    "        # test scores\n",
    "        temp_test = galaxyModel.predict([X_test, X_test_angle])\n",
    "        y_test_pred_log += temp_test.reshape(temp_test.shape[0])\n",
    "        # train scores\n",
    "        temp_train = galaxyModel.predict([X_train, X_angle])\n",
    "        y_train_pred_log += temp_train.shape(temp_train.shape[0])\n",
    "        \n",
    "    y_test_pred_log = y_test_pred_log / K\n",
    "    y_train_pred_log = y_train_pred_log / K\n",
    "    \n",
    "    print('\\n Train Log Loss Validation = ', log_loss(target_train, y_train_pred_log))\n",
    "    print(' Test Log Loss Validation = ', log_loss(target_train, y_valid_pred_log))\n",
    "    \n",
    "    return y_test_pred_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-danish",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-10T14:26:27.832Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================FOLD= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\study\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24/24 [==============================] - 281s 12s/step - loss: 0.9708 - accuracy: 0.5020 - val_loss: 0.6048 - val_accuracy: 0.6336\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 335s 14s/step - loss: 0.6532 - accuracy: 0.6187 - val_loss: 0.3962 - val_accuracy: 0.8243\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 344s 14s/step - loss: 0.4984 - accuracy: 0.7494 - val_loss: 0.3213 - val_accuracy: 0.8561\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 300s 13s/step - loss: 0.3687 - accuracy: 0.8160 - val_loss: 0.2837 - val_accuracy: 0.8729\n",
      "Epoch 5/100\n",
      "12/24 [==============>...............] - ETA: 2:10 - loss: 0.3278 - accuracy: 0.8382"
     ]
    }
   ],
   "source": [
    "preds = myAngleCV(X_train, X_angle, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-prisoner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-protection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-decade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-tumor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-initial",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "572px",
    "left": "150px",
    "top": "295.8px",
    "width": "153.6px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
