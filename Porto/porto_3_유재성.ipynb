{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1회차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T00:10:54.859468Z",
     "start_time": "2021-01-27T00:10:54.842453Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_ROUNDS = 400\n",
    "OPTIMIZE_ROUNDS = False\n",
    "LEARNING_RATE = 0.07\n",
    "EARLY_STOPPING_ROUNDS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "처음에는 MAX_ROUNDS를 상당히 높게 설정하고, OPTIMIZE_ROUNDS을 사용하여 적절한 수의 라운드(모든 폴드 중에서 best_ntree_limit의 최대값에 가까워야 하며, 모델이 적절히 정규화된 경우 더 높아질 수 있음. 또는 verbose=True을 설정하여 모든 폴드에 잘 적합한 여러 라운드를 찾을 수도 있습니다.) 그런 다움 OPTIMIZE_ROUNDS을 끄고 MAX_ROUNDS를 적절한 총 라운드 수로 설정합니다.\n",
    "\n",
    "각 폴드에 가장 적합한 라운드를 선택하여 \"조기 중지\"할 때의 문제는 검증 데이터에 지나치게 적합하다는 것입니다. 따라서 테스트 데이터를 예측하기 위한 최적의 모델을 만들지 못할 가능성이 높으며, 다른 모델과 함께 쌓거나 결합하기 위한 검증 데이터를 생성하는 데 사용될 경우 이 모델의 앙상블에 너무 많은 무게가 실리게 됩니다. 또 다른 가능성(XGBoost의 경우 기본값)은 최적 라운드가 아닌 조기 종료가 발생하는 라운드(개선 부족을 확인하는 지연 시간 포함)를 사용하는 것입니다. 이렇게 하면 과적합 문제가 해결되지만(지연이 충분히 길다면) 아직까지는 도움이 되지 않는 것 같습니다. (모든 폴드에 대해 일정한 라운드보다 폴드당 20라운드 조기 정지 점수가 더 나빴기 때문에 조기 정지가 실제로 적합하지 않는 것 같습니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T00:21:39.480209Z",
     "start_time": "2021-01-27T00:21:39.472202Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numba import jit\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T00:26:09.996221Z",
     "start_time": "2021-01-27T00:26:09.993219Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute gini\n",
    "\n",
    "@jit\n",
    "def eval_gini(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta = 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T00:49:48.166062Z",
     "start_time": "2021-01-27T00:49:48.150048Z"
    }
   },
   "outputs": [],
   "source": [
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = -eval_gini(labels, preds)\n",
    "    return [('gini', gini_score)]\n",
    "\n",
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "def target_encode(trn_series = None,\n",
    "                 val_series = None,\n",
    "                 tst_series = None,\n",
    "                 target = None,\n",
    "                 min_samples_leaf = 1,\n",
    "                 smoothing = 1,\n",
    "                 noise_level = 0):\n",
    "    \"\"\"trn_series : training categorical feature as a pd.Series\n",
    "       tst_series : test categorical feature as a pd.Series\n",
    "       target : target data as a pd.Series\n",
    "       min_sample_lef (int) : minimum samples to take category average into                                     account\n",
    "       smooting (int) : smoothing effect to balance categorical average vs prior\n",
    "    \"\"\"\n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean\n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg(['mean','count'])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1/(1+np.exp(-(averages['count'] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1-smoothing) + averages['mean'] * smoothing\n",
    "    averages.drop(['mean', 'count'], axis=1, inplace=True)\n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(trn_series.to_frame(trn_series.name), averages.reset_index().rename(columns={'index': target.name, target.name:'average'}), on=trn_series.name, how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    ft_val_series = pd.merge(val_series.to_frame(val_series.name), averages.reset_index().rename(columns={'index': target.name, target.name:'average'}), on = val_series.name, how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_val_series.index = val_series.index\n",
    "    ft_tst_series = pd.merge(tst_series.to_frame(tst_series.name), averages.reset_index().rename(columns={'index': target.name, target.name:'average'}), on = tst_series.name, how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_val_series, noise_level), add_noise(ft_tst_series, noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T00:50:16.714527Z",
     "start_time": "2021-01-27T00:50:13.610200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T00:52:26.036693Z",
     "start_time": "2021-01-27T00:52:26.029687Z"
    }
   },
   "outputs": [],
   "source": [
    "train_features = [\n",
    "    \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n",
    "\t\"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n",
    "\t\"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n",
    "\t\"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n",
    "\t\"ps_ind_15\",  #            :  922.18 / shadow  242.00\n",
    "\t\"ps_reg_02\",  #            :  920.65 / shadow  267.50\n",
    "\t\"ps_car_14\",  #            :  798.48 / shadow  549.58\n",
    "\t\"ps_car_12\",  #            :  731.93 / shadow  293.62\n",
    "\t\"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n",
    "\t\"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n",
    "\t\"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n",
    "\t\"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n",
    "\t\"ps_reg_01\",  #            :  598.60 / shadow  178.57\n",
    "\t\"ps_car_15\",  #            :  593.35 / shadow  226.43\n",
    "\t\"ps_ind_01\",  #            :  547.32 / shadow  154.58\n",
    "\t\"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n",
    "\t\"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n",
    "\t\"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n",
    "\t\"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n",
    "\t\"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n",
    "\t\"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n",
    "\t\"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n",
    "\t\"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n",
    "\t\"ps_car_11\",  #            :  173.28 / shadow   76.45\n",
    "\t\"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n",
    "\t\"ps_calc_09\",  #           :  169.13 / shadow  129.72\n",
    "\t\"ps_calc_05\",  #           :  148.83 / shadow  120.68\n",
    "\t\"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n",
    "\t\"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n",
    "\t\"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n",
    "\t\"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n",
    "\t\"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n",
    "\t\"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n",
    "\t\"ps_ind_14\",  #            :   37.37 / shadow   16.65\n",
    "]\n",
    "# add combinatioons\n",
    "combs = [\n",
    "    ('ps_reg_01', 'ps_car_02_cat'),\n",
    "    ('ps_reg_01', 'ps_car_04_cat')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T00:57:45.724470Z",
     "start_time": "2021-01-27T00:57:42.092159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current feature                                 ps_reg_01_plus_ps_car_04_cat    2 in   0.0"
     ]
    }
   ],
   "source": [
    "# Process data\n",
    "id_test = test_df['id'].values\n",
    "id_train = train_df['id'].values\n",
    "y = train_df['target']\n",
    "\n",
    "start = time.time()\n",
    "for n_c, (f1, f2) in enumerate(combs):\n",
    "    name1 = f1 + '_plus_' + f2\n",
    "    print('current feature %60s %4d in %5.1f'\n",
    "         % (name1, n_c+1, (time.time() - start)/60), end='')\n",
    "    print('\\r' * 75, end='')\n",
    "    train_df[name1] = train_df[f1].apply(lambda x: str(x)) + '_' + train_df[f2].apply(lambda x: str(x))\n",
    "    test_df[name1] = test_df[f1].apply(lambda x: str(x)) + '_' + test_df[f2].apply(lambda x: str(x))\n",
    "    # Label Encode\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(train_df[name1].values) + list(test_df[name1].values))\n",
    "    train_df[name1] = lbl.transform(list(train_df[name1].values))\n",
    "    test_df[name1] = lbl.transform(list(test_df[name1].values))\n",
    "    \n",
    "    train_features.append(name1)\n",
    "    \n",
    "X = train_df[train_features]\n",
    "test_df = test_df[train_features]\n",
    "\n",
    "f_cats = [f for f in X.columns if \"_cat\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T00:59:48.183332Z",
     "start_time": "2021-01-27T00:59:48.169320Z"
    }
   },
   "outputs": [],
   "source": [
    "y_valid_pred = 0*y\n",
    "y_test_pred = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T01:00:53.983675Z",
     "start_time": "2021-01-27T01:00:53.969662Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up folds\n",
    "K = 5\n",
    "kf = KFold(n_splits= K, random_state= 1, shuffle=True)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T01:03:46.291931Z",
     "start_time": "2021-01-27T01:03:46.281922Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up classifier\n",
    "model = XGBClassifier(n_estimators=MAX_ROUNDS,\n",
    "                     max_depth=4,\n",
    "                     objective='binary:logistic',\n",
    "                     learning_rate=LEARNING_RATE,\n",
    "                     subsample=.8,\n",
    "                     min_child_weight=6,\n",
    "                     colsample_bytree=.8,\n",
    "                     scale_pos_weight=1.6,\n",
    "                     gamma=10,\n",
    "                     reg_alpha=8,\n",
    "                     reg_lambda=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T01:29:14.820156Z",
     "start_time": "2021-01-27T01:25:38.147501Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Folds 0\n",
      "[10:25:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " Gini =  0.9999834978986151\n",
      "\n",
      "Folds 1\n",
      "[10:26:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " Gini =  0.9999833814529576\n",
      "\n",
      "Folds 2\n",
      "[10:27:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " Gini =  0.999983402578296\n",
      "\n",
      "Folds 3\n",
      "[10:27:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " Gini =  0.9999833954379415\n",
      "\n",
      "Folds 4\n",
      "[10:28:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " Gini =  0.999983372449609\n",
      "\n",
      "Gini for full training set: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-a7d7621db482>:3: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"eval_gini\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of argument at <ipython-input-3-a7d7621db482> (5)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-3-a7d7621db482>\", line 5:\u001b[0m\n",
      "\u001b[1mdef eval_gini(y_true, y_prob):\n",
      "\u001b[1m    y_true = np.asarray(y_true)\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "<ipython-input-3-a7d7621db482>:3: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"eval_gini\" failed type inference due to: \u001b[1m\u001b[1mcannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-3-a7d7621db482>\", line 11:\u001b[0m\n",
      "\u001b[1mdef eval_gini(y_true, y_prob):\n",
      "    <source elided>\n",
      "    n = len(y_true)\n",
      "\u001b[1m    for i in range(n-1, -1, -1):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numba\\core\\object_mode_passes.py:177: NumbaWarning: \u001b[1mFunction \"eval_gini\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"<ipython-input-3-a7d7621db482>\", line 5:\u001b[0m\n",
      "\u001b[1mdef eval_gini(y_true, y_prob):\n",
      "\u001b[1m    y_true = np.asarray(y_true)\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numba\\core\\object_mode_passes.py:187: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"<ipython-input-3-a7d7621db482>\", line 5:\u001b[0m\n",
      "\u001b[1mdef eval_gini(y_true, y_prob):\n",
      "\u001b[1m    y_true = np.asarray(y_true)\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999966865188047"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run CV\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n",
    "    \n",
    "    # Create data for this fold\n",
    "    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n",
    "    X_train, X_valid = X.iloc[train_index,:].copy(), X.iloc[test_index,:].copy()\n",
    "    X_test = test_df.copy()\n",
    "    print('\\nFolds', i)\n",
    "    \n",
    "    # Encode data\n",
    "    for f in f_cats:\n",
    "        X_train[f+'_avg'], X_valid[f+'_avg'], X_test[f+'_avg'] = target_encode(trn_series=X_train[f], val_series=X_valid[f], tst_series=X_test[f], target=y_train, min_samples_leaf=200, smoothing=10, noise_level=0)\n",
    "        \n",
    "    # Run model for this fold\n",
    "    if OPTIMIZE_ROUNDS:\n",
    "        eval_set = [(X_valid, y_valid)]\n",
    "        fit_model = model.fit(X_train, y_train, eval_set=eval_set, eval_metric=gini_xgb, early_stopping_rounds=EARLY_STOPPING_ROUNDS, verbose=False)\n",
    "        print(' Best N trees = ', model.best_ntree_limit)\n",
    "        print(' Best gini = ', model.best_score)\n",
    "    else:\n",
    "        fit_model = model.fit(X_train, y_train)\n",
    "        \n",
    "    # Generate validation predictions for this fold\n",
    "    pred = fit_model.predict_proba(X_valid)[:,1]\n",
    "    print(' Gini = ', eval_gini(y_valid, pred))\n",
    "    y_valid_pred.iloc[test_index] = pred\n",
    "    \n",
    "    # Accumulate test set prediction\n",
    "    y_test_pred += fit_model.predict_proba(X_test)[:,1]\n",
    "    del X_test, X_train, X_valid, y_train\n",
    "    \n",
    "y_test_pred /= K # Average test set predictions\n",
    "    \n",
    "print('\\nGini for full training set: ')\n",
    "eval_gini(y, y_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:22:29.581306Z",
     "start_time": "2021-01-27T03:22:28.410242Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save validation predictions for stacking/ensembling\n",
    "val = pd.DataFrame()\n",
    "val['id'] = id_train\n",
    "val['target'] = y_valid_pred.values\n",
    "val.to_csv('xgb_valid.csv', float_format='%.6f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:24:36.827528Z",
     "start_time": "2021-01-27T03:24:35.047910Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = id_test\n",
    "sub['target'] = y_test_pred\n",
    "sub.to_csv('xgb_submit.csv', float_format='%.6f',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2회차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:28:47.721750Z",
     "start_time": "2021-01-27T03:28:47.710740Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_ROUNDS = 400\n",
    "OPTIMIZE_ROUNDS = 0.07\n",
    "LEARNING_RATE = 0.07\n",
    "EARLY_STOPPING_ROUNDS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "처음에는 MAX_ROUNDS를 상당히 높게 설정하고, OPTIMIZE_ROUNDS을 사용하여 적절한 수의 라운드(모든 폴드 중에서 best_ntree_limit의 최대값에 가까워야 하며, 모델이 적절히 정규화된 경우 더 높아질 수 있음. 또는 verbose=True을 설정하여 모든 폴드에 잘 적합한 여러 라운드를 찾을 수도 있습니다.) 그런 다움 OPTIMIZE_ROUNDS을 끄고 MAX_ROUNDS를 적절한 총 라운드 수로 설정합니다.\n",
    "\n",
    "각 폴드에 가장 적합한 라운드를 선택하여 \"조기 중지\"할 때의 문제는 검증 데이터에 지나치게 적합하다는 것입니다. 따라서 테스트 데이터를 예측하기 위한 최적의 모델을 만들지 못할 가능성이 높으며, 다른 모델과 함께 쌓거나 결합하기 위한 검증 데이터를 생성하는 데 사용될 경우 이 모델의 앙상블에 너무 많은 무게가 실리게 됩니다. 또 다른 가능성(XGBoost의 경우 기본값)은 최적 라운드가 아닌 조기 종료가 발생하는 라운드(개선 부족을 확인하는 지연 시간 포함)를 사용하는 것입니다. 이렇게 하면 과적합 문제가 해결되지만(지연이 충분히 길다면) 아직까지는 도움이 되지 않는 것 같습니다. (모든 폴드에 대해 일정한 라운드보다 폴드당 20라운드 조기 정지 점수가 더 나빴기 때문에 조기 정지가 실제로 적합하지 않는 것 같습니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:29:58.553186Z",
     "start_time": "2021-01-27T03:29:58.538172Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numba import jit\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:33:12.677267Z",
     "start_time": "2021-01-27T03:33:12.671261Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute gini\n",
    "\n",
    "@jit\n",
    "def eval_gini(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T05:02:57.698386Z",
     "start_time": "2021-01-27T05:02:57.679368Z"
    }
   },
   "outputs": [],
   "source": [
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = -eval_gini(labels, preds)\n",
    "    return [('gini', gini_score)]\n",
    "\n",
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "def target_encode(trn_series=None,\n",
    "                 val_series=None, \n",
    "                 tst_series=None,\n",
    "                 target=None,\n",
    "                 min_samples_leaf=1,\n",
    "                 smoothing=1,\n",
    "                 noise_level=0):\n",
    "    \"\"\"\n",
    "    trn_series : training categorical feature as a pd.Series\n",
    "    tst_series : test categorical feature as a pd.Series\n",
    "    target : target data as a pd.Series\n",
    "    min_samples_leaf (int) : minimum samples to take category average into account\n",
    "    smoothing (int) : smoothing effect to balance categorical average vs prior\n",
    "    \"\"\"\n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean\n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg(['mean', 'count'])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1/(1+np.exp(-(averages['count']-min_samples_leaf)/smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1-smoothing) + averages['mean'] * smoothing\n",
    "    averages.drop(['mean', 'count'], axis=1, inplace=True)\n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(trn_series.to_frame(trn_series.name), averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}), on=trn_series.name, how='left')['average'].rename(trn_series.name +'_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    ft_val_series = pd.merge(val_series.to_frame(val_series.name), averages.reset_index().rename(columns={'index':target.name, target.name:'average'}), on=val_series.name, how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_val_series.index = val_series.index\n",
    "    ft_tst_series = pd.merge(tst_series.to_frame(tst_series.name), averages.reset_index().rename(columns={'index':target.name, target.name:'average'}), on=tst_series.name, how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_val_series, noise_level), add_noise(ft_tst_series, noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:45:20.163815Z",
     "start_time": "2021-01-27T03:45:16.967860Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:45:22.561995Z",
     "start_time": "2021-01-27T03:45:22.548984Z"
    }
   },
   "outputs": [],
   "source": [
    "train_features = [\n",
    "    \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n",
    "\t\"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n",
    "\t\"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n",
    "\t\"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n",
    "\t\"ps_ind_15\",  #            :  922.18 / shadow  242.00\n",
    "\t\"ps_reg_02\",  #            :  920.65 / shadow  267.50\n",
    "\t\"ps_car_14\",  #            :  798.48 / shadow  549.58\n",
    "\t\"ps_car_12\",  #            :  731.93 / shadow  293.62\n",
    "\t\"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n",
    "\t\"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n",
    "\t\"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n",
    "\t\"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n",
    "\t\"ps_reg_01\",  #            :  598.60 / shadow  178.57\n",
    "\t\"ps_car_15\",  #            :  593.35 / shadow  226.43\n",
    "\t\"ps_ind_01\",  #            :  547.32 / shadow  154.58\n",
    "\t\"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n",
    "\t\"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n",
    "\t\"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n",
    "\t\"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n",
    "\t\"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n",
    "\t\"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n",
    "\t\"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n",
    "\t\"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n",
    "\t\"ps_car_11\",  #            :  173.28 / shadow   76.45\n",
    "\t\"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n",
    "\t\"ps_calc_09\",  #           :  169.13 / shadow  129.72\n",
    "\t\"ps_calc_05\",  #           :  148.83 / shadow  120.68\n",
    "\t\"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n",
    "\t\"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n",
    "\t\"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n",
    "\t\"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n",
    "\t\"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n",
    "\t\"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n",
    "\t\"ps_ind_14\",  #            :   37.37 / shadow   16.65\n",
    "]\n",
    "# add combinations\n",
    "combs = [\n",
    "    ('ps_reg_01', 'ps_car_02_cat'),  \n",
    "    ('ps_reg_01', 'ps_car_04_cat'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:49:50.214030Z",
     "start_time": "2021-01-27T03:49:46.531866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current feature                                 ps_reg_01_plus_ps_car_04_cat    2 in   0.0"
     ]
    }
   ],
   "source": [
    "# Process Data\n",
    "id_test = test_df['id'].values\n",
    "id_train = train_df['id'].values\n",
    "y = train_df['target']\n",
    "\n",
    "start = time.time()\n",
    "for n_c, (f1, f2) in enumerate(combs):\n",
    "    name1 = f1 + \"_plus_\" + f2\n",
    "    print('current feature %60s %4d in %5.1f' % (name1, n_c+1, (time.time() - start)/60), end='')\n",
    "    print('\\r' * 75, end='')\n",
    "    train_df[name1] = train_df[f1].apply(lambda x: str(x)) + \"_\" + train_df[f2].apply(lambda x: str(x))\n",
    "    test_df[name1] = test_df[f1].apply(lambda x: str(x)) + \"_\" + test_df[f2].apply(lambda x: str(x))\n",
    "    #Label Encode\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(train_df[name1].values) + list(test_df[name1].values))\n",
    "    train_df[name1] = lbl.transform(list(train_df[name1].values))\n",
    "    test_df[name1] = lbl.transform(list(test_df[name1].values))\n",
    "    train_features.append(name1)\n",
    "    \n",
    "X = train_df[train_features]\n",
    "test_df = test_df[train_features]\n",
    "\n",
    "f_cats = [f for f in X.columns if '_cat' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:50:20.586649Z",
     "start_time": "2021-01-27T03:50:20.579643Z"
    }
   },
   "outputs": [],
   "source": [
    "y_valid_pred = 0*y\n",
    "y_test_pred = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:50:53.586176Z",
     "start_time": "2021-01-27T03:50:53.578169Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up folds\n",
    "K = 5\n",
    "kf = KFold(n_splits=K, random_state=1, shuffle=True)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T03:52:19.466785Z",
     "start_time": "2021-01-27T03:52:19.458778Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up classifier\n",
    "model = XGBClassifier(n_estimators=MAX_ROUNDS,\n",
    "                     max_depth=4,\n",
    "                     objective='binary:logistic',\n",
    "                     learning_rate=LEARNING_RATE,\n",
    "                     subsample=.8,\n",
    "                     min_child_weight=6,\n",
    "                     colsample_bytree=.8,\n",
    "                     scale_pos_weight=1.6,\n",
    "                     gamma=10,\n",
    "                     reg_alpha=8,\n",
    "                     reg_lambda=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T05:06:50.381605Z",
     "start_time": "2021-01-27T05:03:01.119495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:03:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "best N trees =  253\n",
      " best gini =  -0.28572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-e5b8afea9706>:3: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"eval_gini\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of argument at <ipython-input-23-e5b8afea9706> (5)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-23-e5b8afea9706>\", line 5:\u001b[0m\n",
      "\u001b[1mdef eval_gini(y_true, y_prob):\n",
      "\u001b[1m    y_true = np.asarray(y_true)\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "<ipython-input-23-e5b8afea9706>:3: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"eval_gini\" failed type inference due to: \u001b[1m\u001b[1mcannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-23-e5b8afea9706>\", line 11:\u001b[0m\n",
      "\u001b[1mdef eval_gini(y_true, y_prob):\n",
      "    <source elided>\n",
      "    n = len(y_true)\n",
      "\u001b[1m    for i in range(n-1, -1, -1):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numba\\core\\object_mode_passes.py:177: NumbaWarning: \u001b[1mFunction \"eval_gini\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"<ipython-input-23-e5b8afea9706>\", line 5:\u001b[0m\n",
      "\u001b[1mdef eval_gini(y_true, y_prob):\n",
      "\u001b[1m    y_true = np.asarray(y_true)\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numba\\core\\object_mode_passes.py:187: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"<ipython-input-23-e5b8afea9706>\", line 5:\u001b[0m\n",
      "\u001b[1mdef eval_gini(y_true, y_prob):\n",
      "\u001b[1m    y_true = np.asarray(y_true)\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini =  0.2857204327671663\n",
      "\n",
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:03:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "best N trees =  379\n",
      " best gini =  -0.282794\n",
      "Gini =  0.28279415220709414\n",
      "\n",
      "Fold 2\n",
      "[14:04:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "best N trees =  360\n",
      " best gini =  -0.273778\n",
      "Gini =  0.27377763392034316\n",
      "\n",
      "Fold 3\n",
      "[14:05:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "best N trees =  394\n",
      " best gini =  -0.298222\n",
      "Gini =  0.29822223272655657\n",
      "\n",
      "Fold 4\n",
      "[14:06:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "best N trees =  329\n",
      " best gini =  -0.286451\n",
      "Gini =  0.28645102636424713\n",
      "\n",
      "Gini for full training set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-e5b8afea9706>:3: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"eval_gini\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of argument at <ipython-input-23-e5b8afea9706> (5)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-23-e5b8afea9706>\", line 5:\u001b[0m\n",
      "\u001b[1mdef eval_gini(y_true, y_prob):\n",
      "\u001b[1m    y_true = np.asarray(y_true)\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "<ipython-input-23-e5b8afea9706>:3: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"eval_gini\" failed type inference due to: \u001b[1m\u001b[1mcannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-23-e5b8afea9706>\", line 11:\u001b[0m\n",
      "\u001b[1mdef eval_gini(y_true, y_prob):\n",
      "    <source elided>\n",
      "    n = len(y_true)\n",
      "\u001b[1m    for i in range(n-1, -1, -1):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numba\\core\\object_mode_passes.py:177: NumbaWarning: \u001b[1mFunction \"eval_gini\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"<ipython-input-23-e5b8afea9706>\", line 5:\u001b[0m\n",
      "\u001b[1mdef eval_gini(y_true, y_prob):\n",
      "\u001b[1m    y_true = np.asarray(y_true)\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numba\\core\\object_mode_passes.py:187: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"<ipython-input-23-e5b8afea9706>\", line 5:\u001b[0m\n",
      "\u001b[1mdef eval_gini(y_true, y_prob):\n",
      "\u001b[1m    y_true = np.asarray(y_true)\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.28520083708131594"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run CV\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n",
    "    \n",
    "    # Create data for this fold\n",
    "    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n",
    "    X_train, X_valid = X.iloc[train_index,:].copy(), X.iloc[test_index,:].copy()\n",
    "    X_test = test_df.copy()\n",
    "    print('\\nFold', i)\n",
    "    \n",
    "    # Encode data\n",
    "    for f in f_cats:\n",
    "        X_train[f+'_avg'], X_valid[f+'_avg'], X_test[f+'_avg'] = target_encode(trn_series=X_train[f], val_series=X_valid[f], tst_series=X_test[f], target=y_train, min_samples_leaf=200, smoothing=10, noise_level=0)\n",
    "        \n",
    "    # Run model for this fold\n",
    "    if OPTIMIZE_ROUNDS:\n",
    "        eval_set = [(X_valid, y_valid)]\n",
    "        fit_model = model.fit(X_train, y_train, eval_set=eval_set, eval_metric=gini_xgb, early_stopping_rounds=EARLY_STOPPING_ROUNDS, verbose=False)\n",
    "        print('best N trees = ', model.best_ntree_limit)\n",
    "        print(' best gini = ', model.best_score)\n",
    "    else:\n",
    "        fit_model = model.fit(X_train, y_train)\n",
    "        \n",
    "    # Generate validation predictions for this fold\n",
    "    pred = fit_model.predict_proba(X_valid)[:,1]\n",
    "    print('Gini = ', eval_gini(y_valid, pred))\n",
    "    y_valid_pred.iloc[test_index] = pred\n",
    "    \n",
    "    # Accumulate test set predictions\n",
    "    y_test_pred += fit_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    del X_test, X_train, X_valid, y_train\n",
    "\n",
    "y_test_pred /= K \n",
    "\n",
    "print('\\nGini for full training set:')\n",
    "eval_gini(y, y_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T05:11:56.038109Z",
     "start_time": "2021-01-27T05:11:54.868526Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save validation predictions for stacking/ensembling\n",
    "val = pd.DataFrame()\n",
    "val['id'] = id_train\n",
    "val['target'] = y_valid_pred.values\n",
    "val.to_csv('xgb_valid.csv', float_format='%.6f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T05:15:14.469088Z",
     "start_time": "2021-01-27T05:15:12.709488Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = id_test\n",
    "sub['target'] = y_test_pred\n",
    "sub.to_csv('xgb_submit.csv', float_format='%.6f', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "191.594px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
