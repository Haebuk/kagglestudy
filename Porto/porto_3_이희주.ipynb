{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- competition/dataset : [https://www.kaggle.com/c/porto-seguro-safe-driver-prediction](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction)\n",
    "- date : 2021/01/27\n",
    "- original : [https://www.kaggle.com/aharless/xgboost-cv-lb-284](https://www.kaggle.com/aharless/xgboost-cv-lb-284)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost CV (LB .284)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-19T23:23:23.804833Z",
     "iopub.status.busy": "2021-01-19T23:23:23.803834Z",
     "iopub.status.idle": "2021-01-19T23:23:23.811814Z",
     "shell.execute_reply": "2021-01-19T23:23:23.810817Z",
     "shell.execute_reply.started": "2021-01-19T23:23:23.804833Z"
    }
   },
   "source": [
    "**✏ 필사 1회** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[oliver의 스크립트](https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283)를 따랐습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T05:18:27.643876Z",
     "iopub.status.busy": "2021-01-27T05:18:27.643876Z",
     "iopub.status.idle": "2021-01-27T05:18:27.648863Z",
     "shell.execute_reply": "2021-01-27T05:18:27.647865Z",
     "shell.execute_reply.started": "2021-01-27T05:18:27.643876Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_ROUNDS = 400\n",
    "OPTIMIZE_ROUNDS = False\n",
    "LEARNING_RATE = 0.07\n",
    "EARLY_STOPPING_ROUNDS = 50\n",
    "# 결정하는데 많은 정보를 사용하기 위해 EARLY_STOPPING_ROUNDS를 높게 설정\n",
    "# early stopping을 원하면 EARLY_STOPPING_ROUNDS값을 줄여야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "처음에는 ```MAX_ROUNDS```는 꽤 높게 설정하고 적절한 라운드의 수를 얻기 위해 ```OPTIMIZE_ROUNDS```를 사용하는 것을 추천합니다. (제 판단으로는 모든 fold 중 ```best_ntree_limit```의 최댓값에 근접해야 하며, 모델이 정규화된 경우 더 값이 클 것입니다. 혹은 ```verbose=True```를 설정하여 세부내용을 살펴보면서 모든 fold에 대해 잘 작동하는 라운드의 수를 찾을 수 있습니다.)  그런 다음, ```OPTIMIZE_ROUNDS```를 제거하고 ```MAX_ROUNDS```를 적절한 총 라운드 수로 설정합니다.  \n",
    "\n",
    "각 fold에 가장 적합한 라운드를 선택하는 '조기 종료'는 검증 데이터에 과적합하는 문제가 있습니다. 따라서 테스트 데이터를 예측하기 위한 최적의 모델을 생성하지 못할 수 있고, 다른 모델들을 스태킹/앙상블하기 위해 검증 데이터를 생성할 경우 앙상블에 너무 많은 weight을 가지게 할 수 있습니다. 또 다른 가능성(XGBoost에서는 기본값)은 최적 라운드보다 조기 종료가 실제로 발생하는 라운드(개선 부족으로 인한 지연 포함)를 사용하는 것입니다. 이 방법은 과적합 문제(지연 시간이 너무 길어질 때의 문제점)를 해결해주지만, 현재까지 그다지 도움이 되지는 않았습니다. (모든 fold의 라운드 수를 사용했을 때보다 fold별로 20 라운드의 조기 종료를 사용했을 때 더 나쁜 검증 점수를 얻었습니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T05:18:27.650856Z",
     "iopub.status.busy": "2021-01-27T05:18:27.649859Z",
     "iopub.status.idle": "2021-01-27T05:18:38.929688Z",
     "shell.execute_reply": "2021-01-27T05:18:38.928782Z",
     "shell.execute_reply.started": "2021-01-27T05:18:27.650856Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numba import jit\n",
    "import time\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gini 지수 계산 과정은 [CPMP의 커널 참고](https://www.kaggle.com/cpmpml/extremely-fast-gini-computation)  \n",
    "$$gini = \\sum_{i=1}^{d}{(R_{i}(1-\\sum_{k=1}^{m}{p_{ik}^{2}}))}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T05:18:38.936670Z",
     "iopub.status.busy": "2021-01-27T05:18:38.934675Z",
     "iopub.status.idle": "2021-01-27T05:18:38.946645Z",
     "shell.execute_reply": "2021-01-27T05:18:38.944649Z",
     "shell.execute_reply.started": "2021-01-27T05:18:38.936670Z"
    }
   },
   "outputs": [],
   "source": [
    "# gini 계산\n",
    "@jit\n",
    "def eval_gini(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2*gini / (ntrue*(n - ntrue))\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[oliver의 커널 참고](https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T05:18:38.949636Z",
     "iopub.status.busy": "2021-01-27T05:18:38.949636Z",
     "iopub.status.idle": "2021-01-27T05:18:38.956618Z",
     "shell.execute_reply": "2021-01-27T05:18:38.955619Z",
     "shell.execute_reply.started": "2021-01-27T05:18:38.949636Z"
    }
   },
   "outputs": [],
   "source": [
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = -evar_gini(labels, preds)\n",
    "    return [('gini', gini_score)]\n",
    "\n",
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level*np.random.randn(len(series)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평활화는 [Daniele Micci-barreca](https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf)의 논문을 따랐습니다.  \n",
    "* trn_series: Series 형태의 트레이닝 변수 (범주형)  \n",
    "* tst_seires: Series 형태의 테스트 변수 (범주형)  \n",
    "* target: Series 형태의 target 데이터  \n",
    "* min_samples_leaf: 범주 평균을 고려한 최소 표본 수 (int)\n",
    "* smoothing: 범주 평균과 이전 값의 균형을 위한 평활화 효과 (int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T05:18:38.959609Z",
     "iopub.status.busy": "2021-01-27T05:18:38.959609Z",
     "iopub.status.idle": "2021-01-27T05:18:38.975566Z",
     "shell.execute_reply": "2021-01-27T05:18:38.974572Z",
     "shell.execute_reply.started": "2021-01-27T05:18:38.959609Z"
    }
   },
   "outputs": [],
   "source": [
    "def target_encode(trn_series=None,\n",
    "                  val_series=None,\n",
    "                  tst_series=None,\n",
    "                  target=None,\n",
    "                  min_samples_leaf=1,\n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    \n",
    "    # target의 평균값 계산\n",
    "    averages = temp.groupby(trn_series.name)[target.name].agg(['mean', 'count'])\n",
    "    \n",
    "    # 평활화 계산\n",
    "    smoothing = 1 / (1 + np.exp(-(averages['count']-min_samples_leaf)/smoothing))\n",
    "    \n",
    "    # 모든 target 데이터에 평균 함수 적용\n",
    "    prior = target.mean()\n",
    "    \n",
    "    # count가 증가할수록 전체 평균 적게 고려\n",
    "    averages[target.name] = prior*(1-smoothing) + averages['mean']*smoothing\n",
    "    averages.drop(['mean', 'count'], axis=1, inplace=True)\n",
    "    \n",
    "    # trn, tst Series에 averages 적용\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index':target.name, target.name:'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)    \n",
    "    # pd.merge는 인덱스를 유지하지 않으므로 목원\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    \n",
    "    ft_val_series = pd.merge(\n",
    "        val_series.to_frame(val_series.name),\n",
    "        averages.reset_index().rename(columns={'index':target.name, target.name:'average'}),\n",
    "        on=val_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    ft_val_series.index = val_series.index\n",
    "    \n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index':target.name, target.name:'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_val_series, noise_level), add_noise(ft_tst_series, noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T05:18:38.978557Z",
     "iopub.status.busy": "2021-01-27T05:18:38.977561Z",
     "iopub.status.idle": "2021-01-27T05:18:46.511419Z",
     "shell.execute_reply": "2021-01-27T05:18:46.510411Z",
     "shell.execute_reply.started": "2021-01-27T05:18:38.978557Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터 로딩\n",
    "train_df = pd.read_csv('../data/porto_train.csv', na_values='-1')\n",
    "test_df = pd.read_csv('../data/porto_test.csv', na_values='-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T05:18:46.512406Z",
     "iopub.status.busy": "2021-01-27T05:18:46.512406Z",
     "iopub.status.idle": "2021-01-27T05:18:46.519388Z",
     "shell.execute_reply": "2021-01-27T05:18:46.519388Z",
     "shell.execute_reply.started": "2021-01-27T05:18:46.512406Z"
    }
   },
   "outputs": [],
   "source": [
    "# from olivier\n",
    "train_features = [\n",
    "    \"ps_car_13\",      # : 1571.65 / shadow  609.23\n",
    "    \"ps_reg_03\",      # : 1408.42 / shadow  511.15\n",
    "    \"ps_ind_05_cat\",  # : 1387.87 / shadow   84.72\n",
    "    \"ps_ind_03\",      # : 1219.47 / shadow  230.55\n",
    "    \"ps_ind_15\",      # :  922.18 / shadow  242.00\n",
    "    \"ps_reg_02\",      # :  920.65 / shadow  267.50\n",
    "    \"ps_car_14\",      # :  798.48 / shadow  549.58\n",
    "    \"ps_car_12\",      # :  731.93 / shadow  293.62\n",
    "    \"ps_car_01_cat\",  # :  698.07 / shadow  178.72\n",
    "    \"ps_car_07_cat\",  # :  694.53 / shadow   36.35\n",
    "    \"ps_ind_17_bin\",  # :  620.77 / shadow   23.15\n",
    "    \"ps_car_03_cat\",  # :  611.73 / shadow   50.67\n",
    "    \"ps_reg_01\",      # :  598.60 / shadow  178.57\n",
    "    \"ps_car_15\",      # :  593.35 / shadow  226.43\n",
    "    \"ps_ind_01\",      # :  547.32 / shadow  154.58\n",
    "    \"ps_ind_16_bin\",  # :  475.37 / shadow   34.17\n",
    "    \"ps_ind_07_bin\",  # :  435.28 / shadow   28.92\n",
    "    \"ps_car_06_cat\",  # :  398.02 / shadow  212.43\n",
    "    \"ps_car_04_cat\",  # :  376.87 / shadow   76.98\n",
    "    \"ps_ind_06_bin\",  # :  370.97 / shadow   36.13\n",
    "    \"ps_car_09_cat\",  # :  214.12 / shadow   81.38\n",
    "    \"ps_car_02_cat\",  # :  203.03 / shadow   26.67\n",
    "    \"ps_ind_02_cat\",  # :  189.47 / shadow   65.68\n",
    "    \"ps_car_11\",      # :  173.28 / shadow   76.45\n",
    "    \"ps_car_05_cat\",  # :  172.75 / shadow   62.92\n",
    "    \"ps_calc_09\",     # :  169.13 / shadow  129.72\n",
    "    \"ps_calc_05\",     # :  148.83 / shadow  120.68\n",
    "    \"ps_ind_08_bin\",  # :  140.73 / shadow   27.63\n",
    "    \"ps_car_08_cat\",  # :  120.87 / shadow   28.82\n",
    "    \"ps_ind_09_bin\",  # :  113.92 / shadow   27.05\n",
    "    \"ps_ind_04_cat\",  # :  107.27 / shadow   37.43\n",
    "    \"ps_ind_18_bin\",  # :   77.42 / shadow   25.97\n",
    "    \"ps_ind_12_bin\",  # :   39.67 / shadow   15.52\n",
    "    \"ps_ind_14\",      # :   37.37 / shadow   16.65\n",
    "]\n",
    "# 조합 추가\n",
    "combs = [\n",
    "    ('ps_reg_01', 'ps_car_02_cat'),  \n",
    "    ('ps_reg_01', 'ps_car_04_cat'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T05:18:46.524375Z",
     "iopub.status.busy": "2021-01-27T05:18:46.522381Z",
     "iopub.status.idle": "2021-01-27T05:18:53.051913Z",
     "shell.execute_reply": "2021-01-27T05:18:53.050917Z",
     "shell.execute_reply.started": "2021-01-27T05:18:46.524375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current feature                                 ps_reg_01_plus_ps_car_02_cat    1 in   0.0current feature                                 ps_reg_01_plus_ps_car_04_cat    2 in   0.0"
     ]
    }
   ],
   "source": [
    "# 데이터 처리\n",
    "id_test = test_df['id'].values\n",
    "id_train = train_df['id'].values\n",
    "y = train_df['target']\n",
    "\n",
    "start = time.time()\n",
    "for n_c, (f1, f2) in enumerate(combs):\n",
    "    name1 = f1 + '_plus_' + f2\n",
    "    print('current feature %60s %4d in %5.1f'%(name1, n_c+1, (time.time()-start)/60), end='')\n",
    "    print('\\r'*75, end='')\n",
    "    \n",
    "    train_df[name1] = train_df[f1].apply(lambda x: str(x)) + '_' + train_df[f2].apply(lambda x:str(x))\n",
    "    test_df[name1] = test_df[f1].apply(lambda x: str(x)) + '_' + test_df[f2].apply(lambda x: str(x))\n",
    "    \n",
    "    # Label Encode\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(train_df[name1].values) + list(test_df[name1].values))\n",
    "    train_df[name1] = lbl.transform(list(train_df[name1].values))\n",
    "    test_df[name1] = lbl.transform(list(test_df[name1].values))\n",
    "    \n",
    "    train_features.append(name1)\n",
    "\n",
    "x = train_df[train_features]\n",
    "test_df = test_df[train_features]\n",
    "\n",
    "f_cats = [f for f in x.columns if '_cat' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T05:18:53.052912Z",
     "iopub.status.busy": "2021-01-27T05:18:53.052912Z",
     "iopub.status.idle": "2021-01-27T05:18:53.062885Z",
     "shell.execute_reply": "2021-01-27T05:18:53.061888Z",
     "shell.execute_reply.started": "2021-01-27T05:18:53.052912Z"
    }
   },
   "outputs": [],
   "source": [
    "y_valid_pred = 0 * y\n",
    "y_test_pred = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T05:18:53.063884Z",
     "iopub.status.busy": "2021-01-27T05:18:53.063884Z",
     "iopub.status.idle": "2021-01-27T05:18:53.072859Z",
     "shell.execute_reply": "2021-01-27T05:18:53.071862Z",
     "shell.execute_reply.started": "2021-01-27T05:18:53.063884Z"
    }
   },
   "outputs": [],
   "source": [
    "# folds 설정\n",
    "K = 5\n",
    "kf = KFold(n_splits=K, random_state=1, shuffle=True)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T05:18:53.073857Z",
     "iopub.status.busy": "2021-01-27T05:18:53.073857Z",
     "iopub.status.idle": "2021-01-27T05:18:53.081835Z",
     "shell.execute_reply": "2021-01-27T05:18:53.080838Z",
     "shell.execute_reply.started": "2021-01-27T05:18:53.073857Z"
    }
   },
   "outputs": [],
   "source": [
    "# 분류기 설정\n",
    "model = XGBClassifier(\n",
    "    n_estimators=MAX_ROUNDS,\n",
    "    max_depth=4,\n",
    "    objective='binary:logistic',\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    subsample=.8,\n",
    "    min_child_weight=6,\n",
    "    colsample_bytree=.8,\n",
    "    scale_pos_weight=1.6,\n",
    "    gamma=10,\n",
    "    reg_alpha=8,\n",
    "    reg_lambda=1.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T05:41:50.470026Z",
     "iopub.status.busy": "2021-01-27T05:41:50.469001Z",
     "iopub.status.idle": "2021-01-27T05:55:20.378977Z",
     "shell.execute_reply": "2021-01-27T05:55:20.378002Z",
     "shell.execute_reply.started": "2021-01-27T05:41:50.470026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  0\n",
      "[14:42:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  Gini =  0.2851059728784705\n",
      "\n",
      "Fold  1\n",
      "[14:44:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  Gini =  0.28185495483845957\n",
      "\n",
      "Fold  2\n",
      "[14:47:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  Gini =  0.27429910138514\n",
      "\n",
      "Fold  3\n",
      "[14:50:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  Gini =  0.2991202920581566\n",
      "\n",
      "Fold  4\n",
      "[14:52:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  Gini =  0.2857903122299573\n",
      "\n",
      "Gini for full training set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.28501477642381845"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n",
    "    \n",
    "    # fold에 데이터 생성\n",
    "    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n",
    "    x_train, x_valid = x.iloc[train_index,:].copy(), x.iloc[test_index,:].copy()\n",
    "    x_test = test_df.copy()\n",
    "    print( \"\\nFold \", i)\n",
    "    \n",
    "    # 데이터 encoding\n",
    "    for f in f_cats:\n",
    "        x_train[f + \"_avg\"], x_valid[f + \"_avg\"], x_test[f + \"_avg\"] = target_encode(\n",
    "            \n",
    "            trn_series=x_train[f],\n",
    "            val_series=x_valid[f],\n",
    "            tst_series=x_test[f],\n",
    "            target=y_train,\n",
    "            min_samples_leaf=200,\n",
    "            smoothing=10,\n",
    "            noise_level=0\n",
    "    )\n",
    "    # Run model for this fold\n",
    "    if OPTIMIZE_ROUNDS:\n",
    "        eval_set=[(x_valid,y_valid)]\n",
    "        fit_model = model.fit(\n",
    "            x_train, y_train,\n",
    "            eval_set=eval_set,\n",
    "            eval_metric=gini_xgb,\n",
    "            early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "            verbose=False\n",
    "    )\n",
    "        print(\"  Best N trees = \", model.best_ntree_limit)\n",
    "        print(\"  Best gini = \", model.best_score)\n",
    "    else:\n",
    "        fit_model = model.fit(x_train, y_train)\n",
    "        \n",
    "    # 검증 예측 생성\n",
    "    pred = fit_model.predict_proba(x_valid)[:, 1]\n",
    "    print(\"  Gini = \", eval_gini(y_valid, pred))\n",
    "    y_valid_pred.iloc[test_index] = pred\n",
    "    \n",
    "    # 테스트 셋 예측 축적\n",
    "    y_test_pred += fit_model.predict_proba(x_test)[:, 1]\n",
    "    \n",
    "    del x_test, x_train, x_valid, y_train\n",
    "    \n",
    "y_test_pred /= K  # Average test set predictions\n",
    "\n",
    "# 테스트 셋 예측값의 평균\n",
    "print( \"\\nGini for full training set:\" )\n",
    "eval_gini(y, y_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T07:05:18.795759Z",
     "iopub.status.busy": "2021-01-27T07:05:18.792745Z",
     "iopub.status.idle": "2021-01-27T07:05:20.636812Z",
     "shell.execute_reply": "2021-01-27T07:05:20.635815Z",
     "shell.execute_reply.started": "2021-01-27T07:05:18.795759Z"
    }
   },
   "outputs": [],
   "source": [
    "# 스태킹/앙상블을 검증 예측 결과 저장\n",
    "val = pd.DataFrame()\n",
    "val['id'] = id_train\n",
    "val['target'] = y_valid_pred.values\n",
    "val.to_csv('../data/porto_3_xgb_valid.csv', float_format='%.6f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T07:05:21.066664Z",
     "iopub.status.busy": "2021-01-27T07:05:21.066664Z",
     "iopub.status.idle": "2021-01-27T07:05:23.906070Z",
     "shell.execute_reply": "2021-01-27T07:05:23.906070Z",
     "shell.execute_reply.started": "2021-01-27T07:05:21.066664Z"
    }
   },
   "outputs": [],
   "source": [
    "# 제출 파일 생성\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = id_test\n",
    "sub['target'] = y_test_pred\n",
    "sub.to_csv('../data/porto_3_xgb_submit.csv', float_format='%.6f', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost CV (LB .284)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-19T23:23:23.804833Z",
     "iopub.status.busy": "2021-01-19T23:23:23.803834Z",
     "iopub.status.idle": "2021-01-19T23:23:23.811814Z",
     "shell.execute_reply": "2021-01-19T23:23:23.810817Z",
     "shell.execute_reply.started": "2021-01-19T23:23:23.804833Z"
    }
   },
   "source": [
    "**✏ 필사 2회** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[oliver의 스크립트](https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283)를 따랐습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T09:15:38.253655Z",
     "iopub.status.busy": "2021-01-27T09:15:38.253655Z",
     "iopub.status.idle": "2021-01-27T09:15:38.259638Z",
     "shell.execute_reply": "2021-01-27T09:15:38.258643Z",
     "shell.execute_reply.started": "2021-01-27T09:15:38.253655Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_ROUNDS = 400\n",
    "OPTIMIZE_ROUNDS = False\n",
    "LEARNING_RATE = 0.07\n",
    "EARLY_STOPPING_ROUNDS = 50\n",
    "# 결정하는데 많은 정보를 사용하기 위해 EARLY_STOPPING_ROUNDS를 높게 설정\n",
    "# early stopping을 원하면 EARLY_STOPPING_ROUNDS값을 줄여야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "처음에는 ```MAX_ROUNDS```는 꽤 높게 설정하고 적절한 라운드의 수를 얻기 위해 ```OPTIMIZE_ROUNDS```를 사용하는 것을 추천합니다. (제 판단으로는 모든 fold 중 ```best_ntree_limit```의 최댓값에 근접해야 하며, 모델이 정규화된 경우 더 값이 클 것입니다. 혹은 ```verbose=True```를 설정하여 세부내용을 살펴보면서 모든 fold에 대해 잘 작동하는 라운드의 수를 찾을 수 있습니다.)  그런 다음, ```OPTIMIZE_ROUNDS```를 제거하고 ```MAX_ROUNDS```를 적절한 총 라운드 수로 설정합니다.  \n",
    "\n",
    "각 fold에 가장 적합한 라운드를 선택하는 '조기 종료'는 검증 데이터에 과적합하는 문제가 있습니다. 따라서 테스트 데이터를 예측하기 위한 최적의 모델을 생성하지 못할 수 있고, 다른 모델들을 스태킹/앙상블하기 위해 검증 데이터를 생성할 경우 앙상블에 너무 많은 weight을 가지게 할 수 있습니다. 또 다른 가능성(XGBoost에서는 기본값)은 최적 라운드보다 조기 종료가 실제로 발생하는 라운드(개선 부족으로 인한 지연 포함)를 사용하는 것입니다. 이 방법은 과적합 문제(지연 시간이 너무 길어질 때의 문제점)를 해결해주지만, 현재까지 그다지 도움이 되지는 않았습니다. (모든 fold의 라운드 수를 사용했을 때보다 fold별로 20 라운드의 조기 종료를 사용했을 때 더 나쁜 검증 점수를 얻었습니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T09:15:38.260637Z",
     "iopub.status.busy": "2021-01-27T09:15:38.260637Z",
     "iopub.status.idle": "2021-01-27T09:15:49.917969Z",
     "shell.execute_reply": "2021-01-27T09:15:49.917969Z",
     "shell.execute_reply.started": "2021-01-27T09:15:38.260637Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numba import jit\n",
    "import time\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gini 지수 계산 과정은 [CPMP의 커널 참고](https://www.kaggle.com/cpmpml/extremely-fast-gini-computation)  \n",
    "$$gini = \\sum_{i=1}^{d}{(R_{i}(1-\\sum_{k=1}^{m}{p_{ik}^{2}}))}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T09:15:49.919961Z",
     "iopub.status.busy": "2021-01-27T09:15:49.919961Z",
     "iopub.status.idle": "2021-01-27T09:15:49.927940Z",
     "shell.execute_reply": "2021-01-27T09:15:49.926941Z",
     "shell.execute_reply.started": "2021-01-27T09:15:49.919961Z"
    }
   },
   "outputs": [],
   "source": [
    "# gini 계산\n",
    "@jit\n",
    "def eval_gini(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2*gini / (ntrue*(n - ntrue))\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[oliver의 커널 참고](https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T09:15:49.929934Z",
     "iopub.status.busy": "2021-01-27T09:15:49.929934Z",
     "iopub.status.idle": "2021-01-27T09:15:49.942900Z",
     "shell.execute_reply": "2021-01-27T09:15:49.939907Z",
     "shell.execute_reply.started": "2021-01-27T09:15:49.929934Z"
    }
   },
   "outputs": [],
   "source": [
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = -evar_gini(labels, preds)\n",
    "    return [('gini', gini_score)]\n",
    "\n",
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level*np.random.randn(len(series)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평활화는 [Daniele Micci-barreca](https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf)의 논문을 따랐습니다.  \n",
    "* trn_series: Series 형태의 트레이닝 변수 (범주형)  \n",
    "* tst_seires: Series 형태의 테스트 변수 (범주형)  \n",
    "* target: Series 형태의 target 데이터  \n",
    "* min_samples_leaf: 범주 평균을 고려한 최소 표본 수 (int)\n",
    "* smoothing: 범주 평균과 이전 값의 균형을 위한 평활화 효과 (int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T09:15:49.945893Z",
     "iopub.status.busy": "2021-01-27T09:15:49.944895Z",
     "iopub.status.idle": "2021-01-27T09:15:49.960852Z",
     "shell.execute_reply": "2021-01-27T09:15:49.959860Z",
     "shell.execute_reply.started": "2021-01-27T09:15:49.945893Z"
    }
   },
   "outputs": [],
   "source": [
    "def target_encode(trn_series=None,\n",
    "                  val_series=None,\n",
    "                  tst_series=None,\n",
    "                  target=None,\n",
    "                  min_samples_leaf=1,\n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    \n",
    "    # target의 평균값 계산\n",
    "    averages = temp.groupby(trn_series.name)[target.name].agg(['mean', 'count'])\n",
    "    \n",
    "    # 평활화 계산\n",
    "    smoothing = 1 / (1 + np.exp(-(averages['count']-min_samples_leaf)/smoothing))\n",
    "    \n",
    "    # 모든 target 데이터에 평균 함수 적용\n",
    "    prior = target.mean()\n",
    "    \n",
    "    # count가 증가할수록 전체 평균 적게 고려\n",
    "    averages[target.name] = prior*(1-smoothing) + averages['mean']*smoothing\n",
    "    averages.drop(['mean', 'count'], axis=1, inplace=True)\n",
    "    \n",
    "    # trn, tst Series에 averages 적용\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index':target.name, target.name:'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)    \n",
    "    # pd.merge는 인덱스를 유지하지 않으므로 목원\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    \n",
    "    ft_val_series = pd.merge(\n",
    "        val_series.to_frame(val_series.name),\n",
    "        averages.reset_index().rename(columns={'index':target.name, target.name:'average'}),\n",
    "        on=val_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    ft_val_series.index = val_series.index\n",
    "    \n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index':target.name, target.name:'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_val_series, noise_level), add_noise(ft_tst_series, noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T09:15:49.962846Z",
     "iopub.status.busy": "2021-01-27T09:15:49.962846Z",
     "iopub.status.idle": "2021-01-27T09:15:57.033931Z",
     "shell.execute_reply": "2021-01-27T09:15:57.032934Z",
     "shell.execute_reply.started": "2021-01-27T09:15:49.962846Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터 로딩\n",
    "train_df = pd.read_csv('../data/porto_train.csv', na_values='-1')\n",
    "test_df = pd.read_csv('../data/porto_test.csv', na_values='-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T09:15:57.034929Z",
     "iopub.status.busy": "2021-01-27T09:15:57.034929Z",
     "iopub.status.idle": "2021-01-27T09:15:57.042920Z",
     "shell.execute_reply": "2021-01-27T09:15:57.041914Z",
     "shell.execute_reply.started": "2021-01-27T09:15:57.034929Z"
    }
   },
   "outputs": [],
   "source": [
    "# from olivier\n",
    "train_features = [\n",
    "    \"ps_car_13\",      # : 1571.65 / shadow  609.23\n",
    "    \"ps_reg_03\",      # : 1408.42 / shadow  511.15\n",
    "    \"ps_ind_05_cat\",  # : 1387.87 / shadow   84.72\n",
    "    \"ps_ind_03\",      # : 1219.47 / shadow  230.55\n",
    "    \"ps_ind_15\",      # :  922.18 / shadow  242.00\n",
    "    \"ps_reg_02\",      # :  920.65 / shadow  267.50\n",
    "    \"ps_car_14\",      # :  798.48 / shadow  549.58\n",
    "    \"ps_car_12\",      # :  731.93 / shadow  293.62\n",
    "    \"ps_car_01_cat\",  # :  698.07 / shadow  178.72\n",
    "    \"ps_car_07_cat\",  # :  694.53 / shadow   36.35\n",
    "    \"ps_ind_17_bin\",  # :  620.77 / shadow   23.15\n",
    "    \"ps_car_03_cat\",  # :  611.73 / shadow   50.67\n",
    "    \"ps_reg_01\",      # :  598.60 / shadow  178.57\n",
    "    \"ps_car_15\",      # :  593.35 / shadow  226.43\n",
    "    \"ps_ind_01\",      # :  547.32 / shadow  154.58\n",
    "    \"ps_ind_16_bin\",  # :  475.37 / shadow   34.17\n",
    "    \"ps_ind_07_bin\",  # :  435.28 / shadow   28.92\n",
    "    \"ps_car_06_cat\",  # :  398.02 / shadow  212.43\n",
    "    \"ps_car_04_cat\",  # :  376.87 / shadow   76.98\n",
    "    \"ps_ind_06_bin\",  # :  370.97 / shadow   36.13\n",
    "    \"ps_car_09_cat\",  # :  214.12 / shadow   81.38\n",
    "    \"ps_car_02_cat\",  # :  203.03 / shadow   26.67\n",
    "    \"ps_ind_02_cat\",  # :  189.47 / shadow   65.68\n",
    "    \"ps_car_11\",      # :  173.28 / shadow   76.45\n",
    "    \"ps_car_05_cat\",  # :  172.75 / shadow   62.92\n",
    "    \"ps_calc_09\",     # :  169.13 / shadow  129.72\n",
    "    \"ps_calc_05\",     # :  148.83 / shadow  120.68\n",
    "    \"ps_ind_08_bin\",  # :  140.73 / shadow   27.63\n",
    "    \"ps_car_08_cat\",  # :  120.87 / shadow   28.82\n",
    "    \"ps_ind_09_bin\",  # :  113.92 / shadow   27.05\n",
    "    \"ps_ind_04_cat\",  # :  107.27 / shadow   37.43\n",
    "    \"ps_ind_18_bin\",  # :   77.42 / shadow   25.97\n",
    "    \"ps_ind_12_bin\",  # :   39.67 / shadow   15.52\n",
    "    \"ps_ind_14\",      # :   37.37 / shadow   16.65\n",
    "]\n",
    "# 조합 추가\n",
    "combs = [\n",
    "    ('ps_reg_01', 'ps_car_02_cat'),  \n",
    "    ('ps_reg_01', 'ps_car_04_cat'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T09:15:57.045899Z",
     "iopub.status.busy": "2021-01-27T09:15:57.044904Z",
     "iopub.status.idle": "2021-01-27T09:16:03.704090Z",
     "shell.execute_reply": "2021-01-27T09:16:03.704090Z",
     "shell.execute_reply.started": "2021-01-27T09:15:57.044904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current feature                                 ps_reg_01_plus_ps_car_02_cat    1 in   0.0current feature                                 ps_reg_01_plus_ps_car_04_cat    2 in   0.0"
     ]
    }
   ],
   "source": [
    "# 데이터 처리\n",
    "id_test = test_df['id'].values\n",
    "id_train = train_df['id'].values\n",
    "y = train_df['target']\n",
    "\n",
    "start = time.time()\n",
    "for n_c, (f1, f2) in enumerate(combs):\n",
    "    name1 = f1 + '_plus_' + f2\n",
    "    print('current feature %60s %4d in %5.1f'%(name1, n_c+1, (time.time()-start)/60), end='')\n",
    "    print('\\r'*75, end='')\n",
    "    \n",
    "    train_df[name1] = train_df[f1].apply(lambda x: str(x)) + '_' + train_df[f2].apply(lambda x:str(x))\n",
    "    test_df[name1] = test_df[f1].apply(lambda x: str(x)) + '_' + test_df[f2].apply(lambda x: str(x))\n",
    "    \n",
    "    # Label Encode\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(train_df[name1].values) + list(test_df[name1].values))\n",
    "    train_df[name1] = lbl.transform(list(train_df[name1].values))\n",
    "    test_df[name1] = lbl.transform(list(test_df[name1].values))\n",
    "    \n",
    "    train_features.append(name1)\n",
    "\n",
    "x = train_df[train_features]\n",
    "test_df = test_df[train_features]\n",
    "\n",
    "f_cats = [f for f in x.columns if '_cat' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T09:16:03.706085Z",
     "iopub.status.busy": "2021-01-27T09:16:03.706085Z",
     "iopub.status.idle": "2021-01-27T09:16:03.716058Z",
     "shell.execute_reply": "2021-01-27T09:16:03.716058Z",
     "shell.execute_reply.started": "2021-01-27T09:16:03.706085Z"
    }
   },
   "outputs": [],
   "source": [
    "y_valid_pred = 0 * y\n",
    "y_test_pred = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T09:16:03.718055Z",
     "iopub.status.busy": "2021-01-27T09:16:03.718055Z",
     "iopub.status.idle": "2021-01-27T09:16:03.756949Z",
     "shell.execute_reply": "2021-01-27T09:16:03.755952Z",
     "shell.execute_reply.started": "2021-01-27T09:16:03.718055Z"
    }
   },
   "outputs": [],
   "source": [
    "# folds 설정\n",
    "K = 5\n",
    "kf = KFold(n_splits=K, random_state=1, shuffle=True)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T09:16:03.758944Z",
     "iopub.status.busy": "2021-01-27T09:16:03.757947Z",
     "iopub.status.idle": "2021-01-27T09:16:03.776897Z",
     "shell.execute_reply": "2021-01-27T09:16:03.775899Z",
     "shell.execute_reply.started": "2021-01-27T09:16:03.758944Z"
    }
   },
   "outputs": [],
   "source": [
    "# 분류기 설정\n",
    "model = XGBClassifier(\n",
    "    n_estimators=MAX_ROUNDS,\n",
    "    max_depth=4,\n",
    "    objective='binary:logistic',\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    subsample=.8,\n",
    "    min_child_weight=6,\n",
    "    colsample_bytree=.8,\n",
    "    scale_pos_weight=1.6,\n",
    "    gamma=10,\n",
    "    reg_alpha=8,\n",
    "    reg_lambda=1.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T09:16:03.777893Z",
     "iopub.status.busy": "2021-01-27T09:16:03.777893Z",
     "iopub.status.idle": "2021-01-27T09:26:21.752970Z",
     "shell.execute_reply": "2021-01-27T09:26:21.751971Z",
     "shell.execute_reply.started": "2021-01-27T09:16:03.777893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  0\n",
      "[18:16:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  Gini =  0.2851059728784705\n",
      "\n",
      "Fold  1\n",
      "[18:18:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  Gini =  0.28185495483845957\n",
      "\n",
      "Fold  2\n",
      "[18:20:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  Gini =  0.27429910138514\n",
      "\n",
      "Fold  3\n",
      "[18:22:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  Gini =  0.2991202920581566\n",
      "\n",
      "Fold  4\n",
      "[18:24:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  Gini =  0.2857903122299573\n",
      "\n",
      "Gini for full training set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.28501477642381845"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n",
    "    \n",
    "    # fold에 데이터 생성\n",
    "    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n",
    "    x_train, x_valid = x.iloc[train_index,:].copy(), x.iloc[test_index,:].copy()\n",
    "    x_test = test_df.copy()\n",
    "    print( \"\\nFold \", i)\n",
    "    \n",
    "    # 데이터 encoding\n",
    "    for f in f_cats:\n",
    "        x_train[f + \"_avg\"], x_valid[f + \"_avg\"], x_test[f + \"_avg\"] = target_encode(\n",
    "            \n",
    "            trn_series=x_train[f],\n",
    "            val_series=x_valid[f],\n",
    "            tst_series=x_test[f],\n",
    "            target=y_train,\n",
    "            min_samples_leaf=200,\n",
    "            smoothing=10,\n",
    "            noise_level=0\n",
    "    )\n",
    "    # Run model for this fold\n",
    "    if OPTIMIZE_ROUNDS:\n",
    "        eval_set=[(x_valid,y_valid)]\n",
    "        fit_model = model.fit(\n",
    "            x_train, y_train,\n",
    "            eval_set=eval_set,\n",
    "            eval_metric=gini_xgb,\n",
    "            early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "            verbose=False\n",
    "    )\n",
    "        print(\"  Best N trees = \", model.best_ntree_limit)\n",
    "        print(\"  Best gini = \", model.best_score)\n",
    "    else:\n",
    "        fit_model = model.fit(x_train, y_train)\n",
    "        \n",
    "    # 검증 예측 생성\n",
    "    pred = fit_model.predict_proba(x_valid)[:, 1]\n",
    "    print(\"  Gini = \", eval_gini(y_valid, pred))\n",
    "    y_valid_pred.iloc[test_index] = pred\n",
    "    \n",
    "    # 테스트 셋 예측 축적\n",
    "    y_test_pred += fit_model.predict_proba(x_test)[:, 1]\n",
    "    \n",
    "    del x_test, x_train, x_valid, y_train\n",
    "    \n",
    "y_test_pred /= K  # Average test set predictions\n",
    "\n",
    "# 테스트 셋 예측값의 평균\n",
    "print( \"\\nGini for full training set:\" )\n",
    "eval_gini(y, y_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T09:26:21.753967Z",
     "iopub.status.busy": "2021-01-27T09:26:21.753967Z",
     "iopub.status.idle": "2021-01-27T09:26:23.443448Z",
     "shell.execute_reply": "2021-01-27T09:26:23.442538Z",
     "shell.execute_reply.started": "2021-01-27T09:26:21.753967Z"
    }
   },
   "outputs": [],
   "source": [
    "# 스태킹/앙상블을 검증 예측 결과 저장\n",
    "val = pd.DataFrame()\n",
    "val['id'] = id_train\n",
    "val['target'] = y_valid_pred.values\n",
    "val.to_csv('../data/porto_3_xgb_valid.csv', float_format='%.6f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T09:26:23.444445Z",
     "iopub.status.busy": "2021-01-27T09:26:23.443448Z",
     "iopub.status.idle": "2021-01-27T09:26:25.896884Z",
     "shell.execute_reply": "2021-01-27T09:26:25.895924Z",
     "shell.execute_reply.started": "2021-01-27T09:26:23.444445Z"
    }
   },
   "outputs": [],
   "source": [
    "# 제출 파일 생성\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = id_test\n",
    "sub['target'] = y_test_pred\n",
    "sub.to_csv('../data/porto_3_xgb_submit.csv', float_format='%.6f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
