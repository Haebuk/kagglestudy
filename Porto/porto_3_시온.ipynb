{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "married-meaning",
   "metadata": {},
   "source": [
    "# XGBoost CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-australian",
   "metadata": {},
   "source": [
    "참고 : https://www.kaggle.com/aharless/xgboost-cv-lb-284"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-scheduling",
   "metadata": {},
   "source": [
    "# 1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "reliable-lloyd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T09:03:45.693309Z",
     "start_time": "2021-01-27T09:03:45.675356Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_ROUNDS = 400\n",
    "OPTIMIZE_ROUNDS = False\n",
    "LEARNING_RATE = 0.07\n",
    "EARLY_STOPPING_ROUNDS = 50  # OPTIMIZE_ROUNDS가 설정된 경우 EARLY_STOPPING_ROuNDS를 높게 설정\n",
    "# 빨리 정지하고 싶다면 EARLY_STOPPING_ROUNDS를 줄임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-teens",
   "metadata": {},
   "source": [
    "처음에 MAX_ROUNDS를 아주 높게 설정하고 OPTIMIZE_ROUNDS를 사용해 적절한 라운드 수를 파악할 것을 권장한다. (round는 모든 fold 중 best_ntree_limit의 최대값과 가까워야하고, 아마 모델이 적절하게 정규화되면 조금 더 높을 수도 있다. 혹은 대체로, verbose=True로 설정하고 세부사항을 확인해 모든 fold에 잘 작동하는 round의 수를 찾을 수 있다.) 그런 다음, OPTIMAIZE_ROUNDS를 끄고 MAX_ROUNDS를 총 round의 적절한 수로 설정한다.<br><br>\n",
    "각 fold에 가장 적합한 round를 골라 \"early stopping\"하는 것의 문제는 검증용 데이터에 과적합한다는 것이다. 따라서 test 데이터를 예측하는 최적의 모델을 생성하지 않을 수 있고, 다른 모델과 stacking/ensembling할 검증 데이터를 생성하는 데 사용되면, 앙상블에 가중치가 너무 많이 실린다. 또 다른 가능성은 최적의 round보다 조기 멈춤이 실제로 일어나는 round를 사용하는 것이다. 이렇게 하면 과적합 문제는 해결되지만, 아직 도움이 되진 않는다. (모든 fold의 일정한 round 수보다 fold당 20 round의 조기 멈춤이 검증 점수를 더 악화하므로, 조기멈춤은 실제로 언더피팅되는 것 같다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "statistical-extension",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T09:55:16.822925Z",
     "start_time": "2021-01-27T09:55:16.804973Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from numba import jit\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sweet-finding",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T09:55:21.529189Z",
     "start_time": "2021-01-27T09:55:21.509244Z"
    }
   },
   "outputs": [],
   "source": [
    "# gini 계산\n",
    "\n",
    "#@jit\n",
    "def eval_gini(y_true,y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(ya_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    \n",
    "    for i in range(n-1,-1,-1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2*gini / (ntrue*(n-ntrue))\n",
    "    \n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "necessary-excuse",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T10:38:00.916614Z",
     "start_time": "2021-01-27T10:38:00.890683Z"
    }
   },
   "outputs": [],
   "source": [
    "def gini_xgb(pres,dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = -eval_gini(labels,preds)\n",
    "    return [('gini',gini_score)]\n",
    "\n",
    "def add_noise(series, noise_level):\n",
    "    return series * (1+noise_level*np.random.randn(len(series)))\n",
    "\n",
    "def target_encode(trn_series=None,val_series=None,tst_series=None,target=None,min_samples_leaf=1,smoothing=1,noise_level=0):\n",
    "    # trn_series : train의 범주형 변수\n",
    "    # tst_series : test의 범주형 변수\n",
    "    # min_samples_leaf(int) : 범주 평균을 취하는 최소 샘플 수\n",
    "    # smoothing(int) : 범주 평균과 이전 값의 균형을 맞추는 smoothing 효과\n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series,target],axis=1)\n",
    "    \n",
    "    # target 평균 계산\n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg(['mean','count'])\n",
    "    # smoothing 계산\n",
    "    smoothing = 1 / (1+np.exp(-(averages['count']-min_samples_leaf) / smoothing))\n",
    "    # 모든 target 데이터에 평균 함수 적용\n",
    "    prior = target.mean()\n",
    "    # count가 클수록 full_avg가 적게 고려됨\n",
    "    averages[target.name] = prior * (1-smoothing) + averages['mean'] * smoothing\n",
    "    averages.drop(['mean','count'],axis=1,inplace=True)\n",
    "    \n",
    "    # train series에 평균 적용\n",
    "    ft_trn_series = pd.merge(trn_series.to_frame(trn_series.name),\n",
    "                            averages.reset_index().rename(columns={'index':target.name,target.name:'average'}),\n",
    "                            on = trn_series.name, how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge는 인덱스를 유지하지 않으므로 복원\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    # validation series에 평균 적용\n",
    "    ft_val_series = pd.merge(val_series.to_frame(val_series.name),\n",
    "                            averages.reset_index().rename(columns={'index':target.name,target.name:'average'}),\n",
    "                            on = val_series.name, how='left')['average'].rename(val_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge는 인덱스를 유지하지 않으므로 복원\n",
    "    ft_val_series.index = val_series.index\n",
    "    # test series에 평균 적용\n",
    "    ft_tst_series = pd.merge(val_series.to_frame(val_series.name),\n",
    "                             averages.reset_index().rename(columns={'index':target.name,target.name:'average'}),\n",
    "                             on=val_series.name, how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge는 인덱스를 유지하지 않으므로 복원\n",
    "    ft_tst_series.index = val_series.index\n",
    "    \n",
    "    return add_noise(ft_trn_series, noise_level),add_noise(ft_val_series, noise_level),add_noise(ft_tst_series, noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "gentle-chorus",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T10:18:16.391328Z",
     "start_time": "2021-01-27T10:18:09.203824Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "train_df = pd.read_csv('../input/train.csv',na_values='-1')  # .iloc[0:200,:]\n",
    "test_df = pd.read_csv('../input/test.csv',na_values='-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "vietnamese-inflation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T10:10:40.448738Z",
     "start_time": "2021-01-27T10:10:40.439759Z"
    }
   },
   "outputs": [],
   "source": [
    "train_features = [\n",
    "    \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n",
    "    \"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n",
    "    \"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n",
    "    \"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n",
    "    \"ps_ind_15\",  #            :  922.18 / shadow  242.00\n",
    "    \"ps_reg_02\",  #            :  920.65 / shadow  267.50\n",
    "    \"ps_car_14\",  #            :  798.48 / shadow  549.58\n",
    "    \"ps_car_12\",  #            :  731.93 / shadow  293.62\n",
    "    \"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n",
    "    \"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n",
    "    \"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n",
    "    \"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n",
    "    \"ps_reg_01\",  #            :  598.60 / shadow  178.57\n",
    "    \"ps_car_15\",  #            :  593.35 / shadow  226.43\n",
    "    \"ps_ind_01\",  #            :  547.32 / shadow  154.58\n",
    "    \"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n",
    "    \"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n",
    "    \"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n",
    "    \"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n",
    "    \"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n",
    "    \"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n",
    "    \"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n",
    "    \"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n",
    "    \"ps_car_11\",  #            :  173.28 / shadow   76.45\n",
    "    \"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n",
    "    \"ps_calc_09\",  #           :  169.13 / shadow  129.72\n",
    "    \"ps_calc_05\",  #           :  148.83 / shadow  120.68\n",
    "    \"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n",
    "    \"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n",
    "    \"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n",
    "    \"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n",
    "    \"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n",
    "    \"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n",
    "    \"ps_ind_14\",  #            :   37.37 / shadow   16.65\n",
    "]\n",
    "\n",
    "# combinations 추가\n",
    "combs = [('ps_reg_01','ps_car_02_cat'), ('ps_reg_01','ps_car_04_cat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hearing-personality",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T10:18:40.487387Z",
     "start_time": "2021-01-27T10:18:34.554733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current featrues                                  ps_reg_01_plusps_car_04_cat    2 in   0.1"
     ]
    }
   ],
   "source": [
    "# 데이터 처리\n",
    "\n",
    "id_test = test_df['id'].values\n",
    "id_train = train_df['id'].values\n",
    "y = train_df['target']\n",
    "\n",
    "start = time.time()\n",
    "for n_c, (f1,f2) in enumerate(combs):\n",
    "    name1 = f1 + '_plus' + f2\n",
    "    print('current featrues %60s %4d in %5.1f' % (name1,n_c+1,(time.time()-start)/60),end='')\n",
    "    print('\\r'*75, end='')\n",
    "    \n",
    "    ### train,data의 name1 변수 추가 : combs의 두 변수값을 문자화해 합침\n",
    "    train_df[name1] = train_df[f1].apply(lambda x:str(x)) + '_' + train_df[f2].apply(lambda x:str(x))\n",
    "    test_df[name1] = test_df[f1].apply(lambda x:str(x)) + '_' + test_df[f2].apply(lambda x: str(x))\n",
    "    \n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(train_df[name1].values) + list(test_df[name1].values))\n",
    "    train_df[name1] = lbl.transform(list(train_df[name1].values))\n",
    "    test_df[name1] = lbl.transform(list(test_df[name1].values))\n",
    "    \n",
    "    train_features.append(name1)\n",
    "    \n",
    "    X = train_df[train_features]\n",
    "    test_df = test_df[train_features]\n",
    "    \n",
    "    f_cats = [f for f in X.columns if '_cat' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "engaged-rapid",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T10:19:04.509908Z",
     "start_time": "2021-01-27T10:19:04.500930Z"
    }
   },
   "outputs": [],
   "source": [
    "y_valid_pred = 0*y\n",
    "y_test_pred = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bound-jordan",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T10:19:30.279555Z",
     "start_time": "2021-01-27T10:19:30.264595Z"
    }
   },
   "outputs": [],
   "source": [
    "# fold 설정\n",
    "K = 5\n",
    "kf = KFold(n_splits=K, random_state=1, shuffle=True)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fatty-probability",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T10:21:09.123498Z",
     "start_time": "2021-01-27T10:21:09.106544Z"
    }
   },
   "outputs": [],
   "source": [
    "# 분류기 설정\n",
    "model = XGBClassifier(n_estimators=MAX_ROUNDS, max_depth=4, objective='binary:logistic',\n",
    "                     learning_rete=LEARNING_RATE, subsample=.8, min_child_weight=6,\n",
    "                     colsample_bytree=.8, scale_pos_weight=1.6, gamma=10, reg_alpha=8, reg_lambda=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-antarctica",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T11:15:20.384942Z",
     "start_time": "2021-01-27T11:02:22.391Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# CV 작동\n",
    "for i,(train_index,test_index) in enumerate(kf.split(train_df)):\n",
    "    # 이 fold로 데이터 생성\n",
    "    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n",
    "    X_train, X_valid = X.iloc[train_index,:].copy(), X.iloc[test_index,:].copy()\n",
    "    X_test = test_df.copy()\n",
    "    print('\\nFold ',i)\n",
    "    \n",
    "    # 데이터 encode\n",
    "    for f in f_cats:\n",
    "        X_train[f+'_avg'], X_valid[f+'_avg'], X_test[f+'_avg'] = target_encode(\n",
    "        trn_series=X_train[f], val_series=X_valid[f], tst_series=X_test[f],\n",
    "        target=y_train, min_samples_leaf=50, smoothing=5, noise_level=0)\n",
    "        \n",
    "    # 이 fold로 모델 작동\n",
    "    if OPTIMIZE_ROUNDS:\n",
    "        eval_set = [(X_valid,y_valid)]\n",
    "        fit_model = model.fit(X_train,y_train,eval_set=eval_set,eval_metric=gini_xgb,\n",
    "                             early_stopping_rounds=EARLY_STOPPING_ROUNDS,verbose=False)\n",
    "        print(' Best N trees = ', model.best_ntree_limit)\n",
    "        print(' Best gini = ', model.best_score)\n",
    "    else:\n",
    "        fit_model = model.fit(X_train,y_train)\n",
    "        \n",
    "    # 이 fold로 validation 데이터 예측 생성\n",
    "    pred = fit_model.predict_proba(X_valid)[:,1]\n",
    "    print(' Gini = ', eval_gini(y_valid,pred))\n",
    "    y_valid_pred.iloc[test_index] = pred\n",
    "    \n",
    "    # test set 예측값 축적\n",
    "    y_test_pred += fit_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    del X_test,X_train,X_valid,y_train\n",
    "    \n",
    "y_test_pred /= K  # test set 예측값 평균\n",
    "\n",
    "print('\\nGini for full training set:')\n",
    "eval_gini(y, y_valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-yield",
   "metadata": {},
   "source": [
    "위의 셀 너무 오래 걸려서 중지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "varied-battlefield",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T11:15:25.610684Z",
     "start_time": "2021-01-27T11:15:24.068466Z"
    }
   },
   "outputs": [],
   "source": [
    "# staking/ensembling을 위해 validation 예측 저장\n",
    "val = pd.DataFrame()\n",
    "val['id'] = id_train\n",
    "val['target'] = y_valid_pred.values\n",
    "val.to_csv('xgb_valid.csv',float_format='%.6f',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "confirmed-blocking",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T11:15:31.408006Z",
     "start_time": "2021-01-27T11:15:28.634119Z"
    }
   },
   "outputs": [],
   "source": [
    "# 제출 파일 생성\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = id_test\n",
    "sub['target'] = y_test_pred\n",
    "sub.to_csv('xgb_submit.csv', float_format='%.6f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-cookbook",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-accent",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "industrial-filing",
   "metadata": {},
   "source": [
    "# 2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "sustained-lounge",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T11:16:10.868535Z",
     "start_time": "2021-01-27T11:16:10.850584Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_ROUNDS = 400\n",
    "OPTIMIZE_ROUNDS = False\n",
    "LEARNING_RATE = 0.07\n",
    "EARLY_STOPPING_ROUNDS = 50  # OPTIMIZE_ROUNDS가 설정된 경우 EARLY_STOPPING_ROuNDS를 높게 설정\n",
    "# 빨리 정지하고 싶다면 EARLY_STOPPING_ROUNDS를 줄임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-vinyl",
   "metadata": {},
   "source": [
    "처음에 MAX_ROUNDS를 아주 높게 설정하고 OPTIMIZE_ROUNDS를 사용해 적절한 라운드 수를 파악할 것을 권장한다. (round는 모든 fold 중 best_ntree_limit의 최대값과 가까워야하고, 아마 모델이 적절하게 정규화되면 조금 더 높을 수도 있다. 혹은 대체로, verbose=True로 설정하고 세부사항을 확인해 모든 fold에 잘 작동하는 round의 수를 찾을 수 있다.) 그런 다음, OPTIMAIZE_ROUNDS를 끄고 MAX_ROUNDS를 총 round의 적절한 수로 설정한다.<br><br>\n",
    "각 fold에 가장 적합한 round를 골라 \"early stopping\"하는 것의 문제는 검증용 데이터에 과적합한다는 것이다. 따라서 test 데이터를 예측하는 최적의 모델을 생성하지 않을 수 있고, 다른 모델과 stacking/ensembling할 검증 데이터를 생성하는 데 사용되면, 앙상블에 가중치가 너무 많이 실린다. 또 다른 가능성은 최적의 round보다 조기 멈춤이 실제로 일어나는 round를 사용하는 것이다. 이렇게 하면 과적합 문제는 해결되지만, 아직 도움이 되진 않는다. (모든 fold의 일정한 round 수보다 fold당 20 round의 조기 멈춤이 검증 점수를 더 악화하므로, 조기멈춤은 실제로 언더피팅되는 것 같다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "exempt-bones",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T11:16:13.350340Z",
     "start_time": "2021-01-27T11:16:13.345352Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from numba import jit\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "secure-expression",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T11:16:14.799338Z",
     "start_time": "2021-01-27T11:16:14.786373Z"
    }
   },
   "outputs": [],
   "source": [
    "# gini 계산\n",
    "\n",
    "#@jit\n",
    "def eval_gini(y_true,y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(ya_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    \n",
    "    for i in range(n-1,-1,-1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2*gini / (ntrue*(n-ntrue))\n",
    "    \n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "burning-advance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T11:16:16.315654Z",
     "start_time": "2021-01-27T11:16:16.301690Z"
    }
   },
   "outputs": [],
   "source": [
    "def gini_xgb(pres,dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = -eval_gini(labels,preds)\n",
    "    return [('gini',gini_score)]\n",
    "\n",
    "def add_noise(series, noise_level):\n",
    "    return series * (1+noise_level*np.random.randn(len(series)))\n",
    "\n",
    "def target_encode(trn_series=None,val_series=None,tst_series=None,target=None,min_samples_leaf=1,smoothing=1,noise_level=0):\n",
    "    # trn_series : train의 범주형 변수\n",
    "    # tst_series : test의 범주형 변수\n",
    "    # min_samples_leaf(int) : 범주 평균을 취하는 최소 샘플 수\n",
    "    # smoothing(int) : 범주 평균과 이전 값의 균형을 맞추는 smoothing 효과\n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series,target],axis=1)\n",
    "    \n",
    "    # target 평균 계산\n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg(['mean','count'])\n",
    "    # smoothing 계산\n",
    "    smoothing = 1 / (1+np.exp(-(averages['count']-min_samples_leaf) / smoothing))\n",
    "    # 모든 target 데이터에 평균 함수 적용\n",
    "    prior = target.mean()\n",
    "    # count가 클수록 full_avg가 적게 고려됨\n",
    "    averages[target.name] = prior * (1-smoothing) + averages['mean'] * smoothing\n",
    "    averages.drop(['mean','count'],axis=1,inplace=True)\n",
    "    \n",
    "    # train series에 평균 적용\n",
    "    ft_trn_series = pd.merge(trn_series.to_frame(trn_series.name),\n",
    "                            averages.reset_index().rename(columns={'index':target.name,target.name:'average'}),\n",
    "                            on = trn_series.name, how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge는 인덱스를 유지하지 않으므로 복원\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    # validation series에 평균 적용\n",
    "    ft_val_series = pd.merge(val_series.to_frame(val_series.name),\n",
    "                            averages.reset_index().rename(columns={'index':target.name,target.name:'average'}),\n",
    "                            on = val_series.name, how='left')['average'].rename(val_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge는 인덱스를 유지하지 않으므로 복원\n",
    "    ft_val_series.index = val_series.index\n",
    "    # test series에 평균 적용\n",
    "    ft_tst_series = pd.merge(val_series.to_frame(val_series.name),\n",
    "                             averages.reset_index().rename(columns={'index':target.name,target.name:'average'}),\n",
    "                             on=val_series.name, how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge는 인덱스를 유지하지 않으므로 복원\n",
    "    ft_tst_series.index = val_series.index\n",
    "    \n",
    "    return add_noise(ft_trn_series, noise_level),add_noise(ft_val_series, noise_level),add_noise(ft_tst_series, noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dense-bleeding",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T11:16:25.221319Z",
     "start_time": "2021-01-27T11:16:18.064013Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "train_df = pd.read_csv('../input/train.csv',na_values='-1')  # .iloc[0:200,:]\n",
    "test_df = pd.read_csv('../input/test.csv',na_values='-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "accurate-father",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T11:16:26.935730Z",
     "start_time": "2021-01-27T11:16:26.922765Z"
    }
   },
   "outputs": [],
   "source": [
    "train_features = [\n",
    "    \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n",
    "    \"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n",
    "    \"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n",
    "    \"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n",
    "    \"ps_ind_15\",  #            :  922.18 / shadow  242.00\n",
    "    \"ps_reg_02\",  #            :  920.65 / shadow  267.50\n",
    "    \"ps_car_14\",  #            :  798.48 / shadow  549.58\n",
    "    \"ps_car_12\",  #            :  731.93 / shadow  293.62\n",
    "    \"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n",
    "    \"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n",
    "    \"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n",
    "    \"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n",
    "    \"ps_reg_01\",  #            :  598.60 / shadow  178.57\n",
    "    \"ps_car_15\",  #            :  593.35 / shadow  226.43\n",
    "    \"ps_ind_01\",  #            :  547.32 / shadow  154.58\n",
    "    \"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n",
    "    \"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n",
    "    \"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n",
    "    \"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n",
    "    \"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n",
    "    \"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n",
    "    \"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n",
    "    \"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n",
    "    \"ps_car_11\",  #            :  173.28 / shadow   76.45\n",
    "    \"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n",
    "    \"ps_calc_09\",  #           :  169.13 / shadow  129.72\n",
    "    \"ps_calc_05\",  #           :  148.83 / shadow  120.68\n",
    "    \"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n",
    "    \"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n",
    "    \"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n",
    "    \"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n",
    "    \"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n",
    "    \"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n",
    "    \"ps_ind_14\",  #            :   37.37 / shadow   16.65\n",
    "]\n",
    "\n",
    "# combinations 추가\n",
    "combs = [('ps_reg_01','ps_car_02_cat'), ('ps_reg_01','ps_car_04_cat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "certain-bundle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T11:16:35.477628Z",
     "start_time": "2021-01-27T11:16:28.447675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current featrues                                  ps_reg_01_plusps_car_04_cat    2 in   0.1"
     ]
    }
   ],
   "source": [
    "# 데이터 처리\n",
    "\n",
    "id_test = test_df['id'].values\n",
    "id_train = train_df['id'].values\n",
    "y = train_df['target']\n",
    "\n",
    "start = time.time()\n",
    "for n_c, (f1,f2) in enumerate(combs):\n",
    "    name1 = f1 + '_plus' + f2\n",
    "    print('current featrues %60s %4d in %5.1f' % (name1,n_c+1,(time.time()-start)/60),end='')\n",
    "    print('\\r'*75, end='')\n",
    "    \n",
    "    ### train,data의 name1 변수 추가 : combs의 두 변수값을 문자화해 합침\n",
    "    train_df[name1] = train_df[f1].apply(lambda x:str(x)) + '_' + train_df[f2].apply(lambda x:str(x))\n",
    "    test_df[name1] = test_df[f1].apply(lambda x:str(x)) + '_' + test_df[f2].apply(lambda x: str(x))\n",
    "    \n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(train_df[name1].values) + list(test_df[name1].values))\n",
    "    train_df[name1] = lbl.transform(list(train_df[name1].values))\n",
    "    test_df[name1] = lbl.transform(list(test_df[name1].values))\n",
    "    \n",
    "    train_features.append(name1)\n",
    "    \n",
    "    X = train_df[train_features]\n",
    "    test_df = test_df[train_features]\n",
    "    \n",
    "    f_cats = [f for f in X.columns if '_cat' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "endangered-radar",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T11:16:48.488596Z",
     "start_time": "2021-01-27T11:16:48.476629Z"
    }
   },
   "outputs": [],
   "source": [
    "y_valid_pred = 0*y\n",
    "y_test_pred = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "statistical-brown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T11:16:49.926735Z",
     "start_time": "2021-01-27T11:16:49.913766Z"
    }
   },
   "outputs": [],
   "source": [
    "# fold 설정\n",
    "K = 5\n",
    "kf = KFold(n_splits=K, random_state=1, shuffle=True)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "connected-detail",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T11:16:51.485853Z",
     "start_time": "2021-01-27T11:16:51.473887Z"
    }
   },
   "outputs": [],
   "source": [
    "# 분류기 설정\n",
    "model = XGBClassifier(n_estimators=MAX_ROUNDS, max_depth=4, objective='binary:logistic',\n",
    "                     learning_rete=LEARNING_RATE, subsample=.8, min_child_weight=6,\n",
    "                     colsample_bytree=.8, scale_pos_weight=1.6, gamma=10, reg_alpha=8, reg_lambda=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV 작동\n",
    "for i,(train_index,test_index) in enumerate(kf.split(train_df)):\n",
    "    # 이 fold로 데이터 생성\n",
    "    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n",
    "    X_train, X_valid = X.iloc[train_index,:].copy(), X.iloc[test_index,:].copy()\n",
    "    X_test = test_df.copy()\n",
    "    print('\\nFold ',i)\n",
    "    \n",
    "    # 데이터 encode\n",
    "    for f in f_cats:\n",
    "        X_train[f+'_avg'], X_valid[f+'_avg'], X_test[f+'_avg'] = target_encode(\n",
    "        trn_series=X_train[f], val_series=X_valid[f], tst_series=X_test[f],\n",
    "        target=y_train, min_samples_leaf=200, smoothing=10, noise_level=0)\n",
    "        \n",
    "    # 이 fold로 모델 작동\n",
    "    if OPTIMIZE_ROUNDS:\n",
    "        eval_set = [(X_valid,y_valid)]\n",
    "        fit_model = model.fit(X_train,y_train,eval_set=eval_set,eval_metric=gini_xgb,\n",
    "                             early_stopping_rounds=EARLY_STOPPING_ROUNDS,verbose=False)\n",
    "        print(' Best N trees = ', model.best_ntree_limit)\n",
    "        print(' Best gini = ', model.best_score)\n",
    "    else:\n",
    "        fit_model = model.fit(X_train,y_train)\n",
    "        \n",
    "    # 이 fold로 validation 데이터 예측 생성\n",
    "    pred = fit_model.predict_proba(X_valid)[:,1]\n",
    "    print(' Gini = ', eval_gini(y_valid,pred))\n",
    "    y_valid_pred.iloc[test_index] = pred\n",
    "    \n",
    "    # test set 예측값 축적\n",
    "    y_test_pred += fit_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    del X_test,X_train,X_valid,y_train\n",
    "    \n",
    "y_test_pred /= K  # test set 예측값 평균\n",
    "\n",
    "print('\\nGini for full training set:')\n",
    "eval_gini(y, y_valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-overhead",
   "metadata": {},
   "source": [
    "위 셀 너무 오래 걸려서 중지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "polish-notion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T11:17:14.390104Z",
     "start_time": "2021-01-27T11:17:13.672448Z"
    }
   },
   "outputs": [],
   "source": [
    "# staking/ensembling을 위해 validation 예측 저장\n",
    "val = pd.DataFrame()\n",
    "val['id'] = id_train\n",
    "val['target'] = y_valid_pred.values\n",
    "val.to_csv('xgb_valid.csv',float_format='%.6f',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "subsequent-approval",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T11:17:17.067797Z",
     "start_time": "2021-01-27T11:17:15.838090Z"
    }
   },
   "outputs": [],
   "source": [
    "# 제출 파일 생성\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = id_test\n",
    "sub['target'] = y_test_pred\n",
    "sub.to_csv('xgb_submit.csv', float_format='%.6f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-valentine",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
