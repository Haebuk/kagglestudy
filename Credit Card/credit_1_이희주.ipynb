{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- competition/dataset : [https://www.kaggle.com/mlg-ulb/creditcardfraud](https://www.kaggle.com/mlg-ulb/creditcardfraud)\n",
    "- date : 2021/03/31\n",
    "- original : [https://www.kaggle.com/joparga3/in-depth-skewed-data-classif-93-recall-acc-now](https://www.kaggle.com/joparga3/in-depth-skewed-data-classif-93-recall-acc-now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying multi-label comments (0.9741 lb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-19T23:23:23.804833Z",
     "iopub.status.busy": "2021-01-19T23:23:23.803834Z",
     "iopub.status.idle": "2021-01-19T23:23:23.811814Z",
     "shell.execute_reply": "2021-01-19T23:23:23.810817Z",
     "shell.execute_reply.started": "2021-01-19T23:23:23.804833Z"
    }
   },
   "source": [
    "**✏ 필사 1회** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 노트북은 편향된 데이터에 다양한 방법들을 테스트합니다. 우리의 예측 모델의 효율을 방해할 수 있는 압도적으로 다수인 클래스가 있을 때 전처리 기술이 더 잘 작동하는지를 비교하는 것이 한 가지 아이디어입니다.  \n",
    "\n",
    "또한 다양한 분류 모델에서 하이퍼파라미터 튜닝에 교차 검증을 적용하는 방법을 볼 수 있습니다. 제 의도는 다음의 모델들을 사용하여 모델을 만드는 것입니다:  \n",
    "1. Logistic Regression\n",
    "2. SVMs\n",
    "3. Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T13:23:45.766385Z",
     "iopub.status.busy": "2021-04-01T13:23:45.766385Z",
     "iopub.status.idle": "2021-04-01T13:23:50.097329Z",
     "shell.execute_reply": "2021-04-01T13:23:50.096354Z",
     "shell.execute_reply.started": "2021-04-01T13:23:45.766385Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T13:23:50.099315Z",
     "iopub.status.busy": "2021-04-01T13:23:50.099315Z",
     "iopub.status.idle": "2021-04-01T13:23:54.976738Z",
     "shell.execute_reply": "2021-04-01T13:23:54.975739Z",
     "shell.execute_reply.started": "2021-04-01T13:23:50.099315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/creditcard.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T13:23:54.978731Z",
     "iopub.status.busy": "2021-04-01T13:23:54.977734Z",
     "iopub.status.idle": "2021-04-01T13:23:55.232106Z",
     "shell.execute_reply": "2021-04-01T13:23:55.231110Z",
     "shell.execute_reply.started": "2021-04-01T13:23:54.977734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_classes = data.value_counts('Class', sort=True)\n",
    "count_classes.plot(kind='bar')\n",
    "plt.title('Fraud class histogram')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "확실히 데이터가 완전히 불균형합니다.  \n",
    "\n",
    "이것은 분류 알고리즘을 평가하기 위해 일반적인 정확도 점수를 사용하는 명확한 예시입니다. 예를 들어, 우리가 다수 클래스를 사용하여 모든 레코드에 값을 할당했다면 여전히 높은 정확도를 얻을 수는 있지만 우리는 모든 1을 잘못 분류하고 있을 것입니다.  \n",
    "\n",
    "이러한 불균형을 고려하여 분류 문제에 접근하기 위한 몇 가지 방법들이 있습니다:  \n",
    "- 더 많은 데이터 수집  \n",
    "    - 좋은 전략이지만 여기서는 적용 불가  \n",
    "- 평가 메트릭 변경  \n",
    "    - 정밀도와 재현율을 계산하기 위해 혼동 행렬 사용  \n",
    "    - F1 score\n",
    "    - Kappa 사용 - 데이터의 클래스 불균형에 의해 정규화된 분류 정확도\n",
    "    - ROC curve - 민감도(Sensitivity)/특이도(Specificity) 비율 계산  \n",
    "- 데이터 리샘플링  \n",
    "    - 데이터가 50:50 정도의 비율이 되도록 하는 방법  \n",
    "    - OVER-sampling - 수가 적은 클래스의 복사본을 추가 (데이터 수가 적을 때 추천)  \n",
    "    - UNDER-sampling - 수가 많은 클래스로부터 인스턴스를 제거 (데이터 수가 많을 때 추천)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach\n",
    "1. 우선은 feature engineering을 수행하지 않습니다.  \n",
    "2. resampling을 사용했을 때 발생하는 현상을 사용하지 않았을 때와 비교합니다. 간단한 로지스틱 회귀 분류기를 사용하여 이 접근 방법을 테스트합니다.  \n",
    "3. 위에서 언급한 평가 메트릭들을 사용하여 모델을 평가합니다.  \n",
    "4. 로지스틱 회귀 분류기의 파라미터를 조정하면서 최적의 resampling/not resampling 방법을 반복합니다.  \n",
    "5. 다른 분류 알고리즘을 사용하여 최종적으로 분류 모델을 수행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting our input and target variables + resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Normalising `Amount` column. The amount column is not in line with the anonimised features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T13:23:55.234115Z",
     "iopub.status.busy": "2021-04-01T13:23:55.234115Z",
     "iopub.status.idle": "2021-04-01T13:23:58.478920Z",
     "shell.execute_reply": "2021-04-01T13:23:58.477923Z",
     "shell.execute_reply.started": "2021-04-01T13:23:55.234115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "\n",
       "        V25       V26       V27       V28  Class  normAmount  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053      0    0.244964  \n",
       "1  0.167170  0.125895 -0.008983  0.014724      0   -0.342475  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752      0    1.160686  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "data.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T22:50:28.588661Z",
     "iopub.status.busy": "2021-03-30T22:50:28.588661Z",
     "iopub.status.idle": "2021-03-30T22:50:28.609606Z",
     "shell.execute_reply": "2021-03-30T22:50:28.608608Z",
     "shell.execute_reply.started": "2021-03-30T22:50:28.588661Z"
    }
   },
   "source": [
    "#### 2. Assigning X and Y. No resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T13:23:58.479920Z",
     "iopub.status.busy": "2021-04-01T13:23:58.479920Z",
     "iopub.status.idle": "2021-04-01T13:23:58.555789Z",
     "shell.execute_reply": "2021-04-01T13:23:58.554787Z",
     "shell.execute_reply.started": "2021-04-01T13:23:58.479920Z"
    }
   },
   "outputs": [],
   "source": [
    "x = data.drop('Class', axis=1)\n",
    "y = data.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Resampling\n",
    "undersampling과 oversampling 외에도 SMOTE(Synthetic Minority Over-Sampling Technique)라는 매우 인기 있는 방법이 있습니다. 이것은 oversampling과 undersampling을 조합한 것이긴 하지만, 오버샘플링 접근법은 소수 클래스를 복제하는 것이 아니라 알고리즘을 통해 새로운 소수 클래스 데이터 인스턴스를 구성하는 것입니다.  \n",
    "\n",
    "여기서는 전통적인 undersampling 방법을 사용합니다. 다수 클래스에서 무작위로 x만큼의 샘플을 선택합니다. (x는 소수 클래스의 수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T13:23:58.557782Z",
     "iopub.status.busy": "2021-04-01T13:23:58.557782Z",
     "iopub.status.idle": "2021-04-01T13:23:58.681496Z",
     "shell.execute_reply": "2021-04-01T13:23:58.680497Z",
     "shell.execute_reply.started": "2021-04-01T13:23:58.557782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of normal transactions: 0.5\n",
      "Percentage of fraud transactions: 0.5\n",
      "Total number of transactions in resampled data: 984\n"
     ]
    }
   ],
   "source": [
    "# Number of data points in the minority class\n",
    "# 소수 클래스 데이터 수\n",
    "number_records_fraud = len(data[data['Class'] == 1])\n",
    "fraud_indices = np.array(data[data['Class'] == 1].index)\n",
    "\n",
    "# Picking the indices of the normal classes\n",
    "# 일반 클래스 인덱스\n",
    "normal_indices = data[data['Class'] == 0].index\n",
    "\n",
    "# Out of the indices we picked, randomly select 'x' number (number_recods_fraud)\n",
    "# 선택한 인덱스 중 무작위로 x개 추출\n",
    "random_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace=False)\n",
    "random_normal_indices = np.array(random_normal_indices)\n",
    "\n",
    "# Appending the 2 indices\n",
    "# 두 인덱스 연결\n",
    "under_sample_indices = np.concatenate([fraud_indices, random_normal_indices])\n",
    "\n",
    "# Under sample dataset\n",
    "# 언더샘플링된 데이터셋 생성\n",
    "under_sample_data = data.iloc[under_sample_indices, :]\n",
    "\n",
    "x_undersample = under_sample_data.drop('Class', axis=1)\n",
    "y_undersample = under_sample_data.drop('Class', axis=1)\n",
    "\n",
    "# Showing ratio\n",
    "print('Percentage of normal transactions:',\n",
    "      len(under_sample_data[under_sample_data['Class'] == 0])/len(under_sample_data))\n",
    "print('Percentage of fraud transactions:',\n",
    "      len(under_sample_data[under_sample_data['Class'] == 1])/len(under_sample_data))\n",
    "print('Total number of transactions in resampled data:', len(under_sample_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into train and test set. Cross validation will be used when calculating accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T13:23:58.683491Z",
     "iopub.status.busy": "2021-04-01T13:23:58.683491Z",
     "iopub.status.idle": "2021-04-01T13:23:59.232053Z",
     "shell.execute_reply": "2021-04-01T13:23:59.231052Z",
     "shell.execute_reply.started": "2021-04-01T13:23:58.683491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number transactions train dataset: 199364\n",
      "Number transactions test dataset: 85443\n",
      "Total number of transactions: 284807\n",
      "\n",
      "Number transactions train dataset: 688\n",
      "Number transactions test dataset: 296\n",
      "Total number of transactions: 984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Whole dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print('Number transactions train dataset:', len(x_train))\n",
    "print('Number transactions test dataset:', len(x_test))\n",
    "print('Total number of transactions:', len(x_train) + len(x_test))\n",
    "\n",
    "# Undersampled dataset\n",
    "x_train_undersample, x_test_undersample, y_train_undersample, y_test_undersample =\\\n",
    "train_test_split(x_undersample, y_undersample, test_size=0.3, random_state=0)\n",
    "\n",
    "print()\n",
    "print('Number transactions train dataset:', len(x_train_undersample))\n",
    "print('Number transactions test dataset:', len(x_test_undersample))\n",
    "print('Total number of transactions:', len(x_train_undersample) + len(x_test_undersample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression classifier - Undersampled data\n",
    "재현율 점수는 가장 부정한 트랜잭션을 잡는데 도움이 되는 메트릭이기 때문에 우리는 재현율 점수에 관심이 있습니다. 정확도, 정밀도, 재현율이 혼동 행렬에서 어떻게 작동하는지에 대해 생각해본다면 재현율은 더욱 흥미로울 것입니다:  \n",
    "- 정확도(Accuracy) = (TP + TN) / total  \n",
    "- 정밀도(Precision) = TP / (TP + NP)  \n",
    "- 재현율(Recall) = TP / (TP + FN)  \n",
    "\n",
    "데이터의 불균형 때문에 많은 관측치가 일반 트랜잭션을 예측하는 False Negative로 예측될 수 있지만, 그것은 사실이 아닙니다. 재현율은 이것을 잡아냅니다.  \n",
    "- 재현율을 높이려고 하면 정밀도는 낮아지는 경향이 있습니다. 그러나 우리의 경우, 트랜잭션이 거짓인데 아니라고 판별한다면, 그 반대와 비교했을 때 큰 문제는 아닙니다.  \n",
    "- FN과 FP가 각 에러에 대해 서루 다른 가중치를 갖는 경우 cost function을 적용할 수도 있지만, 일단은 생략합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T13:23:59.236042Z",
     "iopub.status.busy": "2021-04-01T13:23:59.235045Z",
     "iopub.status.idle": "2021-04-01T13:23:59.450469Z",
     "shell.execute_reply": "2021-04-01T13:23:59.449471Z",
     "shell.execute_reply.started": "2021-04-01T13:23:59.236042Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n",
    "                             roc_auc_score, roc_curve, recall_score,\n",
    "                             classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Very ad-hoc functino to print K_fold_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T13:29:20.589837Z",
     "iopub.status.busy": "2021-04-01T13:29:20.589837Z",
     "iopub.status.idle": "2021-04-01T13:29:20.598813Z",
     "shell.execute_reply": "2021-04-01T13:29:20.598813Z",
     "shell.execute_reply.started": "2021-04-01T13:29:20.589837Z"
    }
   },
   "outputs": [],
   "source": [
    "def printing_Kfold_scores(x_train_data, y_train_data):\n",
    "    fold = KFold(len(y_train_data), shuffle=False)\n",
    "    \n",
    "    # Different C parameters\n",
    "    c_param_range = [0.01, 0.1, 1, 10, 100]\n",
    "    \n",
    "    results_table = pd.DataFrame(\n",
    "        index=range(len(c_param_range), 2),\n",
    "        columns=['C_parameter', 'Mean recall score']\n",
    "    )\n",
    "    results_table['C_parameter'] = c_param_range\n",
    "    # the k-fold will give 2 lists: train_indices=indices[0], test_indices=indices[1]\n",
    "    j = 0\n",
    "    for c_param in c_param_range:\n",
    "        print('-'*50)\n",
    "        print('C parameter:', c_param)\n",
    "        print('-'*50)\n",
    "        print()\n",
    "    \n",
    "        recall_accs = []\n",
    "        for iteration, indices in enumerate(fold.split(x_train_data), start=1):\n",
    "            # Call the logistic regression model with a certain C parameter\n",
    "            lr = LogisticRegression(C=c_param, penalty='l2')\n",
    "            \n",
    "            # Use the training data to fit the model\n",
    "            # In this case, we use the portion of the fold to train the model with indices[0]\n",
    "            # We then predict on the portion assigned as the 'test cross validation' with indices[1]\n",
    "            lr.fit(x_train_data.iloc[indices[0], :],\n",
    "                   y_train_data.iloc[indices[0], :].values.ravel())\n",
    "            \n",
    "            # Predict values using the test indices in the training data\n",
    "            y_pred_undersample = lr.predict(x_train_data.iloc[indices[1], :].values)\n",
    "            \n",
    "            # Calculate the recall score and append it to a list for recall scores\n",
    "            # representing the current c_parameter\n",
    "            recall_acc = recall_score(y_train_data.iloc[indices[1], :].values,\n",
    "                                      y_pred_undersample)\n",
    "            recall_accs.append(recall_acc)\n",
    "            print('Iteration', iteration, ': recall score =', recall_acc)\n",
    "            \n",
    "        # The mean value of those recall scores is the metric we want to save and get hold of.\n",
    "        results_table.iloc[j, 1] = np.mean(recall_accs)\n",
    "        j += 1\n",
    "        print()\n",
    "        print('Mean recall score', np.mean(recall_accs))\n",
    "        print()\n",
    "    \n",
    "    best_c = results_table.loc[results_table['Mean recall score'].idxmax()]['C_parameter']\n",
    "    \n",
    "    # Finally, we can check which C parameter is the best amongst the chosen.\n",
    "    print('*'*80)\n",
    "    print('Best model to choose from cross validation is with C parameter =', best_c)\n",
    "    print('*'*80)\n",
    "    \n",
    "    return best_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-01T13:29:20.946171Z",
     "iopub.status.busy": "2021-04-01T13:29:20.946171Z",
     "iopub.status.idle": "2021-04-01T13:29:20.986065Z",
     "shell.execute_reply": "2021-04-01T13:29:20.985067Z",
     "shell.execute_reply.started": "2021-04-01T13:29:20.946171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "C parameter: 0.01\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [687, 19923]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-02fa6bda7ac8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprinting_Kfold_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_undersample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_undersample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-44253b6d4c2c>\u001b[0m in \u001b[0;36mprinting_Kfold_scores\u001b[1;34m(x_train_data, y_train_data)\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;31m# We then predict on the portion assigned as the 'test cross validation' with indices[1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             lr.fit(x_train_data.iloc[indices[0], :],\n\u001b[1;32m---> 29\u001b[1;33m                    y_train_data.iloc[indices[0], :].values.ravel())\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;31m# Predict values using the test indices in the training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1344\u001b[0m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0;32m   1345\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1346\u001b[1;33m                                    accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[0;32m   1347\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1348\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    829\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 831\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 263\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [687, 19923]"
     ]
    }
   ],
   "source": [
    "best_c = printing_Kfold_scores(x_train_undersample, y_train_undersample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
