{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kaggle Study 45일차(CreditCard)\n",
    "코드출처 : https://www.kaggle.com/joparga3/in-depth-skewed-data-classif-93-recall-acc-now/data\n",
    "\n",
    "## Credit card fraud detection\n",
    "이 노트북은 치우친 데이터에 대해 여러 가지 방법을 테스트합니다. 이 아이디어는 예측 모델의 효율성을 저해할 수 있는 압도적 다수 클래스가 있을 때 사전 처리 기법이 더 잘 작동하는지 비교하는 것입니다.\n",
    "또한 다른 분류 모델에서 하이퍼 파라미터 튜닝에 교차 검증을 적용하는 방법도 확인할 수 있습니다. 저의 의도는 다음을 사용하여 모델을 만드는 것입니다.\n",
    "1. 로지스틱 회귀 분석\n",
    "2. SVM\n",
    "3. 의사 결정 트리  \n",
    "  \n",
    "저도 이상 징후 탐지 기술을 시도해 보고 싶지만, 그래도 좀 더 조사해 봐야 하니 조언해주시면 감사하겠습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T00:46:34.383240Z",
     "start_time": "2021-04-04T00:46:11.071048Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T00:46:38.973650Z",
     "start_time": "2021-04-04T00:46:34.396060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/Users/이동훈/Desktop/github/kaggle/kagglestudy/Data/CreditCard/creditcard.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T00:46:39.518897Z",
     "start_time": "2021-04-04T00:46:38.976254Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_classes = pd.value_counts(data['Class'], sort = True).sort_index()\n",
    "count_classes.plot(kind = 'bar')\n",
    "plt.title(\"Fraud class histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 완전히 불균형인 것은 분명합니다!!\n",
    "이것은 일반적인 정확도 점수를 사용하여 분류 알고리즘을 평가하는 명확한 예입니다. 예를 들어, 만일 우리가 단지 다수 클래스를 사용하여 모든 레코드에 값을 할당했다면, 우리는 여전히 높은 정확도를 가질 것입니다. 그러나 우리는 모든 \"1\"을 잘못 분류할 것입니다!!\n",
    "이러한 불균형을 고려하여 이 분류 문제에 접근하는 몇 가지 방법이 있습니다.\n",
    "- 더 많은 데이터를 수집? => 좋은 전략이지만 이 경우에는 해당되지 않습니다.\n",
    "- 성능 메트릭을 변경합니다.\n",
    "    - 혼동 행렬을 사용하여 정밀도, 리콜을 계산합니다.\n",
    "    - F1 점수(정밀 호출의 가중 평균)\n",
    "    - 카파 사용 : 데이터의 클래스 불균형에 의해 정규화된 분류 정확도\n",
    "    - ROC 곡선 - 민감도/특이성 비율을 계산합니다.\n",
    "- 데이터 집합을 다시 샘플링\n",
    "    - 기본적으로 이 방법은 데이터를 약 50-50 비율로 처리하는 방법\n",
    "    - 이를 위한 한 가지 방법은 표현되지 않는 클래스의 복사본을 추가하는 오버샘플링을 사용하는 것입니다(데이터가 거의 없을 때 더 좋습니다).\n",
    "    - 또 다른 것은 언더 샘플링으로, 과도하게 표현된 클래스에서 인스턴스를 삭제합니다(데이터가 많을 경우 더 좋음)\n",
    "\n",
    "## Approach\n",
    "1. 우리는 우선 기능 엔지니어링을 수행하지 않을 것입니다. 데이터 세트는 30개의 기능(28개의 익명 + 시간 + 양)을 포함하도록 다운그레이드되었습니다.\n",
    "2. 그런 다음 재샘플링을 사용할 때와 사용하지 않을 때의 상황을 비교합니다. 간단한 로지스틱 회귀 분석 분류기를 사용하여 이 방법을 테스트합니다.\n",
    "3. 위에서 언급한 몇 가지 성능 메트릭을 사용하여 모델을 평가합니다.\n",
    "4. 로지스틱 회귀 분석 분류기의 모수를 조정하여 최적의 재샘플링/비샘플링 방법을 반복합니다.\n",
    "5. 마지막으로 다른 분류 알고리즘을 사용하여 분류 모델을 수행하겠습니다.\n",
    "  \n",
    "## Setting our input and target variables + resampling.\n",
    "\n",
    "__1. 양 열을 정규화합니다. 양 열이 익명화된 형상과 일치하지 않습니다.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T00:47:57.767972Z",
     "start_time": "2021-04-04T00:46:39.520841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Class  normAmount  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053      0    0.244964  \n",
       "1  0.167170  0.125895 -0.008983  0.014724      0   -0.342475  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752      0    1.160686  \n",
       "3  0.647376 -0.221929  0.062723  0.061458      0    0.140534  \n",
       "4 -0.206010  0.502292  0.219422  0.215153      0   -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "data = data.drop(['Time','Amount'],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. X와 Y를 할당하고 다시 샘플링하지 않는 것\n",
    "3. 다시 샘플링.\n",
    "- 앞에서 언급했듯이, 치우친 데이터를 다시 샘플링하는 몇 가지 방법이 있습니다. 언더 샘플링과 오버 샘플링 외에도, SMOTE(Synthetic Minor Over-Sampling Technology)라는 매우 인기 있는 접근법이 있는데, 이는 오버샘플링과 언더샘플링을 결합한 것이지만 오버샘플링 접근법은 소수 클래스를 복제하는 것이 아니라 알고리즘을 통해 새로운 소수 클래스 데이터 인스턴스를 구성하는 것입니다.\n",
    "\n",
    "- 이 노트북에서는 기존의 언더 샘플링 방식을 사용합니다. 저는 아마 향후 버전의 코드에서 SMOTE를 구현하려고 노력할 것이지만, 현재로서는 기존의 언더샘플릭을 사용할 것입니다.\n",
    "\n",
    "- 데이터 세트를 표본으로 추출하는 방법은 50/50 비율을 만드는 것입니다. 이 작업은 다수 클래스에서 랜덤하게 \"x\"의 샘플 양을 선택하여 소수 클래스에서 총 레코드 수를 \"x\"로 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T00:47:57.776946Z",
     "start_time": "2021-04-04T00:47:57.769964Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
       "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Class', 'normAmount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T00:47:57.838781Z",
     "start_time": "2021-04-04T00:47:57.777944Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data.drop('Class',axis=1)\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T00:47:58.004888Z",
     "start_time": "2021-04-04T00:47:57.842311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of normal transactions:  0.5\n",
      "Percentage of fraud transactions:  0.5\n",
      "Total number of transactions in resampled data:  984\n"
     ]
    }
   ],
   "source": [
    "# 소수 계층 데이터 포인트 수\n",
    "number_records_fraud = len(data[data.Class == 1])\n",
    "fraud_indices = np.array(data[data.Class == 1].index)\n",
    "\n",
    "# 정상수업 지수를 고르기\n",
    "normal_indices = data[data.Class == 0].index\n",
    "\n",
    "# 저희가 고른 지수 중에서 무작위로 \"x\" 숫자를 선택(number_records_fraud)\n",
    "random_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace = False)\n",
    "random_normal_indices = np.array(random_normal_indices)\n",
    "\n",
    "# 지수 2개를 추가\n",
    "under_sample_indices = np.concatenate([fraud_indices,random_normal_indices])\n",
    "\n",
    "# 언더 샘플 데이터셋\n",
    "under_sample_data = data.iloc[under_sample_indices,:]\n",
    "\n",
    "X_undersample = under_sample_data.drop('Class',axis=1)\n",
    "y_undersample = under_sample_data['Class']\n",
    "\n",
    "# 비율을 표시\n",
    "print(\"Percentage of normal transactions: \", len(under_sample_data[under_sample_data.Class == 0])/len(under_sample_data))\n",
    "print(\"Percentage of fraud transactions: \", len(under_sample_data[under_sample_data.Class == 1])/len(under_sample_data))\n",
    "print(\"Total number of transactions in resampled data: \", len(under_sample_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into train and test set. Cross validation will be used when calculating accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T00:47:58.350886Z",
     "start_time": "2021-04-04T00:47:58.007880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number transactions train dataset:  199364\n",
      "Number transactions test dataset:  85443\n",
      "Total number of transactions:  284807\n",
      "\n",
      "Number transactions train dataset:  688\n",
      "Number transactions test dataset:  296\n",
      "Total number of transactions:  984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 전체 데이터셋\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)\n",
    "\n",
    "print(\"Number transactions train dataset: \", len(X_train))\n",
    "print(\"Number transactions test dataset: \", len(X_test))\n",
    "print(\"Total number of transactions: \", len(X_train)+len(X_test))\n",
    "\n",
    "# 언더샘플된 데이터셋\n",
    "X_train_undersample, X_test_undersample, y_train_undersample, y_test_undersample = train_test_split(X_undersample\n",
    "                                                                                                   ,y_undersample\n",
    "                                                                                                   ,test_size = 0.3\n",
    "                                                                                                   ,random_state = 0)\n",
    "print(\"\")\n",
    "print(\"Number transactions train dataset: \", len(X_train_undersample))\n",
    "print(\"Number transactions test dataset: \", len(X_test_undersample))\n",
    "print(\"Total number of transactions: \", len(X_train_undersample)+len(X_test_undersample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression classifier - Undersampled data\n",
    "리콜 점수가 가장 부정한 트랜잭션을 캡처하는 데 도움이 되는 메트릭이기 때문에, 리콜 점수에 매우 관심이 있습니다. 정밀도, 정밀도 및 리콜이 혼돈 행렬에 어떻게 작용하는지 알고 있는 경우 리콜이 가장 흥미로울 수 있습니다.\n",
    "\n",
    "- Accuracy = (TP+TN)/total\n",
    "- Precision = TP/(TP+FP)\n",
    "- Recall = TP/(TP+FN)  \n",
    "  \n",
    "__아시다시피, 데이터의 불균형으로 인해 많은 관측치가 거짓 부정으로 예측될 수 있습니다. 즉, 정상적인 트랜잭션을 예측하지만, 실제로는 부정 트랜잭션입니다. 리콜이 이를 캡처합니다.__  \n",
    "  \n",
    "- 분명히, 리콜을 늘리려고 하면 정밀도가 떨어지는 경향이 있습니다. 하지만, 우리의 경우, 만약 우리가 거래가 사기성이 있다고 예측하고 그렇지 않다고 밝혀진다면, 그 반대와 비교해 볼 때, 큰 문제는 아닙니다.\n",
    "- FN과 FP의 오류 유형별로 가중치가 다른 경우 비용 함수를 적용할 수도 있지만, 일단은 생략하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T00:47:58.513649Z",
     "start_time": "2021-04-04T00:47:58.353980Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K_fold_cores를 인쇄하기 위한 매우 특별한 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T00:54:45.944661Z",
     "start_time": "2021-04-04T00:54:45.930697Z"
    }
   },
   "outputs": [],
   "source": [
    "def printing_kfold_scores(x_train_data, y_train_data):\n",
    "    fold = KFold(5,shuffle=False)\n",
    "    \n",
    "    # Different C params\n",
    "    c_param_range = [0.01, 0.1, 1, 10, 100]\n",
    "    \n",
    "    result_table = pd.DataFrame(index=range(len(c_param_range),2), columns=['C_parameter', 'Mean recall score'])\n",
    "    result_table['C_parameter'] = c_param_range\n",
    "    \n",
    "    # k-fold는 2개의 리스트 제공: train_indices=indices[0], test_indices=indices[1]\n",
    "    j = 0\n",
    "    for c_param in c_param_range:\n",
    "        print('-'*30)\n",
    "        print('C parameter: ', c_param)\n",
    "        print('-'*30)\n",
    "        print('')\n",
    "        \n",
    "        recall_accs = []\n",
    "        for iteration, indices in enumerate(fold.split(x_train_data), start=1):\n",
    "            # 특정 C 파라미터를 가진 로지스틱 회귀 모형 호출\n",
    "            lr = LogisticRegression(C = c_param, penalty='l2')\n",
    "            \n",
    "            # 폴드된 훈련 데이터를 사용하여 모델 훈련\n",
    "            # 모델을 가지고 예측\n",
    "            lr.fit(x_train_data.iloc[indices[0],:], y_train_data.iloc[indices[0],:].values.ravel())\n",
    "            \n",
    "            # 훈련 데이터의 테스트 인덱스를 사용하여 값 예측\n",
    "            y_pred_undersample = lr.predict(x_train_data.iloc[indices[1],:].values)\n",
    "            # recall score 계산 후 현재 C값과 리스트에 추가\n",
    "            recall_acc = recall_score(y_train_data.iloc[indices[1],:].values,\n",
    "                                      y_pred_undersample)\n",
    "            recall_accs.append(recall_acc)\n",
    "            print('Iteration ', iteration, ': recall score = ', recall_acc)\n",
    "            \n",
    "        # recall score의 평균 저장\n",
    "        result_table.loc[j, 'Mean recall score'] = np.mean(recall_acc)\n",
    "        j += 1\n",
    "        print('')\n",
    "        print('Mean recall score', np.mean(recall_accs))\n",
    "        print('')\n",
    "        \n",
    "    best_c = result_table.iloc[result_table['Mean recall score'].astype(float).idxmax()]['C_parameter']\n",
    "    \n",
    "    # 최종적으로, 가장 최고의 C 파라미터 확인\n",
    "    print('*'*30)\n",
    "    print('Best model to choose from cross validation is with C parameter=', best_c)\n",
    "    return best_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T00:54:46.546784Z",
     "start_time": "2021-04-04T00:54:46.515183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "C parameter:  0.01\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "IndexingError",
     "evalue": "Too many indexers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-d5216ab932a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprinting_Kfold_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_undersample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_undersample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-1ce61c3279bb>\u001b[0m in \u001b[0;36mprinting_Kfold_scores\u001b[1;34m(x_train_data, y_train_data)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;31m# 폴드된 훈련 데이터를 사용하여 모델 훈련\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;31m# 모델을 가지고 예측\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;31m# 훈련 데이터의 테스트 인덱스를 사용하여 값 예측\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    887\u001b[0m                     \u001b[1;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1448\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1450\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1451\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1452\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    718\u001b[0m         \u001b[0mCheck\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0macross\u001b[0m \u001b[0mmy\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \"\"\"\n\u001b[1;32m--> 720\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    721\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_key_length\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Too many indexers\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    762\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple_same_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexingError\u001b[0m: Too many indexers"
     ]
    }
   ],
   "source": [
    "best_c = printing_Kfold_scores(X_train_undersample,y_train_undersample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 혼동 행렬을 표시하는 함수를 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T00:53:37.191068Z",
     "start_time": "2021-04-04T00:53:37.182090Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    이 함수는 혼동 행렬을 인쇄하고 표시합니다.\n",
    "    'normalize=True'를 설정하여 정규화를 적용할 수 있습니다.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        #print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "        thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__테스트 세트 예측 및 혼동 행렬 표시__  \n",
    "  \n",
    "__우리는 우리의 예측 모델이 얼마나 효과적인지에 대한 우리의 대리인으로서 리콜 메트릭을 사용하는 것에 대해 말해왔습니다. 리콜이 여전히 계산하고자 하는 리콜이지만, 표본이 부족한 데이터가 특정 클래스에 대한 왜곡이 없다는 점을 명심하십시오. 따라서 리콜 메트릭이 매우 중요하지는 않습니다.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T00:53:37.451837Z",
     "start_time": "2021-04-04T00:53:37.437393Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-0fa34c085ba0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 이 C_params를 사용하여 전체 교육 데이터 집합으로 최종 모델을 구축하고 테스트의 클래스를 예측합니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'l1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_undersample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_undersample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred_undersample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_undersample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_c' is not defined"
     ]
    }
   ],
   "source": [
    "# 이 C_params를 사용하여 전체 교육 데이터 집합으로 최종 모델을 구축하고 테스트의 클래스를 예측합니다.\n",
    "lr = LogisticRegression(C = best_c, penalty = 'l1')\n",
    "lr.fit(X_train_undersample,y_train_undersample.values.ravel())\n",
    "y_pred_undersample = lr.predict(X_test_undersample.values)\n",
    "\n",
    "# confuse matrix 계산\n",
    "cnf_matrix = confusion_matrix(y_test_undersample,y_pred_undersample)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(\"Recall metric in the testing dataset: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n",
    "\n",
    "# 비표준화된 confuse matrix 그리기\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix\n",
    "                      , classes=class_names\n",
    "                      , title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__따라서 이 모델은 일반화된 보이지 않는 데이터(테스트 세트)에 대해 93.2%의 회수 정확도를 제공합니다. 첫 번째 시도에는 나쁘지 않은 비율입니다. 그러나 이 값은 언더샘플링 테스트 세트에서 93.2%의 리콜 정확도 측도를 나타냅니다.__  \n",
    "  \n",
    "__이 결과에 만족하면서 적합 모형을 적용하여 전체 데이터에 대해 테스트해 보겠습니다.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T00:53:37.729762Z",
     "start_time": "2021-04-04T00:53:37.713653Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-38e2e6a156d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 이 C_params를 사용하여 전체 교육 데이터 집합으로 최종 모델을 구축하고 테스트의 클래스를 예측합니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'l1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_undersample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_undersample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_c' is not defined"
     ]
    }
   ],
   "source": [
    "# 이 C_params를 사용하여 전체 교육 데이터 집합으로 최종 모델을 구축하고 테스트의 클래스를 예측합니다.\n",
    "lr = LogisticRegression(C = best_c, penalty = 'l1')\n",
    "lr.fit(X_train_undersample,y_train_undersample.values.ravel())\n",
    "y_pred = lr.predict(X_test.values)\n",
    "\n",
    "# confuse matrix 계산\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(\"Recall metric in the testing dataset: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n",
    "\n",
    "# 비표준화된 confuse matrix 그리기\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix\n",
    "                      , classes=class_names\n",
    "                      , title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__훨씬 크고 치우쳐 있는 데이터 세트에 적용해도 회수 정확도는 매우 뛰어납니다!__\n",
    "__초기 접근 방식이 어떻게 작동하는지에 대해 만족하기 시작할 수 있습니다.__\n",
    "#### Plotting ROC curve and Precision-Recall curve\n",
    "- 저는 이 경우에 정밀 리콜 곡선이 훨씬 더 편리하다고 생각합니다. 왜냐하면 우리의 문제는 음수 등급보다 \"양수\" 등급에 의존하기 때문입니다. 하지만 우리가 회수 정밀도를 계산했기 때문에, 저는 아직 정밀 리콜 곡선을 그리지는 않을 것입니다.\n",
    "\n",
    "- AUC 및 ROC 곡선도 모형이 전체적으로 정확하게 예측하고 많은 오차를 만들지 여부를 확인하는 데 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T00:53:37.990200Z",
     "start_time": "2021-04-04T00:53:37.972244Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-936fdde1e2c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# ROC 곡선\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'l1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_pred_undersample_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_undersample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_undersample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_undersample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_undersample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred_undersample_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_c' is not defined"
     ]
    }
   ],
   "source": [
    "# ROC 곡선\n",
    "lr = LogisticRegression(C = best_c, penalty = 'l1')\n",
    "y_pred_undersample_score = lr.fit(X_train_undersample,y_train_undersample.values.ravel()).decision_function(X_test_undersample.values)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test_undersample.values.ravel(),y_pred_undersample_score)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "\n",
    "# ROC 그리기\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b',label='AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "흥미로운 추가 설명은 샘플이 부족한 여러 데이터 세트를 초기화하고 프로세스를 반복하는 것입니다. 언더샘플 데이터를 생성하기 위해 대부분의 클래스에서 랜덤하게 레코드를 얻었습니다. 이 매개 변수가 유효한 기술이지만 실제 모집단을 나타내지 않으므로 서로 다른 언더샘플 구성으로 프로세스를 반복하고 이전에 선택한 매개 변수가 여전히 가장 효과적인지 확인하는 것이 좋습니다. 결국, 아이디어는 전체 데이터 세트의 더 넓은 무작위 표현을 사용하고 평균적인 최상의 매개 변수에 의존하는 것입니다.\n",
    "## Logistic regression classifier - Skewed data\n",
    "__이전의 접근 방식을 테스트해 본 결과, 왜곡된 데이터에 대해 동일한 프로세스를 테스트하는 것이 매우 흥미롭습니다. 우리의 직관은 왜성이 포착하기 어려운 문제를 야기하여 덜 효과적인 알고리듬을 제공할 것이라는 것입니다.__\n",
    "- 공정하게 말하자면, 열차와 시험 데이터 세트가 미샘플링 데이터 세트보다 상당히 크다는 사실을 고려하면, K-폴드 교차 검증이 필요하다고 생각합니다. 교육 세트의 60%로 데이터를 분할하면 20%의 교차 검증과 20%의 테스트가 충분할 것으로 생각합니다. 하지만 이전과 동일한 방식을 취하도록 하겠습니다(이러한 문제 없이 K-폴드가 계산적으로 더 비쌉니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T00:53:38.330844Z",
     "start_time": "2021-04-04T00:53:38.244272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "C parameter:  0.01\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "IndexingError",
     "evalue": "Too many indexers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-2046cb22ef68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprinting_Kfold_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-1ce61c3279bb>\u001b[0m in \u001b[0;36mprinting_Kfold_scores\u001b[1;34m(x_train_data, y_train_data)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;31m# 폴드된 훈련 데이터를 사용하여 모델 훈련\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;31m# 모델을 가지고 예측\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;31m# 훈련 데이터의 테스트 인덱스를 사용하여 값 예측\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    887\u001b[0m                     \u001b[1;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1448\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1450\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1451\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1452\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    718\u001b[0m         \u001b[0mCheck\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0macross\u001b[0m \u001b[0mmy\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \"\"\"\n\u001b[1;32m--> 720\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    721\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_key_length\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Too many indexers\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    762\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple_same_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexingError\u001b[0m: Too many indexers"
     ]
    }
   ],
   "source": [
    "best_c = printing_Kfold_scores(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T00:53:38.448640Z",
     "start_time": "2021-04-04T00:53:38.430615Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-109e7143b5d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 이 C_params를 사용하여 전체 교육 데이터 집합으로 최종 모델을 구축하고 테스트의 클래스를 예측합니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'l1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred_undersample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_c' is not defined"
     ]
    }
   ],
   "source": [
    "# 이 C_params를 사용하여 전체 교육 데이터 집합으로 최종 모델을 구축하고 테스트의 클래스를 예측합니다.\n",
    "lr = LogisticRegression(C = best_c, penalty = 'l1')\n",
    "lr.fit(X_train,y_train.values.ravel())\n",
    "y_pred_undersample = lr.predict(X_test.values)\n",
    "\n",
    "# confuse matrix 계산\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred_undersample)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(\"Recall metric in the testing dataset: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n",
    "\n",
    "# 비표준화된 confuse matrix 그리기\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix\n",
    "                      , classes=class_names\n",
    "                      , title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__따라서 이 모델은 일반화된 보이지 않는 데이터(테스트 세트)에 대해 93.2%의 회수 정확도를 제공합니다. 첫 번째 시도에는 나쁘지 않은 비율입니다. 그러나 이 값은 언더샘플링 테스트 세트에서 93.2%의 리콜 정확도 측도를 나타냅니다.__  \n",
    "  \n",
    "\n",
    "__이 결과에 만족하면서 적합 모형을 적용하여 전체 데이터에 대해 테스트해 보겠습니다.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T00:47:59.699390Z",
     "start_time": "2021-04-04T00:46:11.088Z"
    }
   },
   "outputs": [],
   "source": [
    "# 이 C_params를 사용하여 전체 교육 데이터 집합으로 최종 모델을 구축하고 테스트의 클래스를 예측합니다.lr = LogisticRegression(C = best_c, penalty = 'l1')\n",
    "lr.fit(X_train_undersample,y_train_undersample.values.ravel())\n",
    "y_pred = lr.predict(X_test.values)\n",
    "\n",
    "# confuse matrix 계산\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(\"Recall metric in the testing dataset: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n",
    "\n",
    "# 비표준화된 confuse matrix 그리기\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix\n",
    "                      , classes=class_names\n",
    "                      , title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 계속하기 전에... 분류 임계값을 변경합니다.\n",
    "__우리는 데이터를 과소 샘플링함으로써 우리의 알고리즘이 사기를 탐지하는 데 훨씬 더 효과적이라는 것을 보아 왔습니다. 또한 임계값을 변경하여 최종 분류를 어떻게 조정할 수 있는지 보여드리고 싶었습니다.__\n",
    "- 처음에는 분류 모형을 만든 다음 이를 사용하여 보이지 않는 데이터를 예측합니다.\n",
    "- 이전에 \"예측()\" 방법을 사용하여 레코드가 \"1\"에 속해야 하는지 \"0\"에 속해야 하는지 여부를 결정했습니다.\n",
    "- 다른 방법 \"pedict_proba()\"가 있습니다.\n",
    "    - 이 메서드는 각 클래스에 대한 확률을 반환합니다. 클래스 1에 레코드를 할당하기 위해 임계값을 변경하면 정밀도와 호출을 제어할 수 있습니다.  \n",
    "      \n",
    "__언더샘플링된 데이터를 사용하여 확인하겠습니다(베스트 C_param = 0.01)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T00:47:59.701189Z",
     "start_time": "2021-04-04T00:46:11.091Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C = 0.01, penalty = 'l1')\n",
    "lr.fit(X_train_undersample,y_train_undersample.values.ravel())\n",
    "y_pred_undersample_proba = lr.predict_proba(X_test_undersample.values)\n",
    "\n",
    "thresholds = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "j = 1\n",
    "for i in thresholds:\n",
    "    y_test_predictions_high_recall = y_pred_undersample_proba[:,1] > i\n",
    "    \n",
    "    plt.subplot(3,3,j)\n",
    "    j += 1\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_test_undersample,y_test_predictions_high_recall)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    print(\"Recall metric in the testing dataset: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n",
    "\n",
    "    class_names = [0,1]\n",
    "    plot_confusion_matrix(cnf_matrix\n",
    "                          , classes=class_names\n",
    "                          , title='Threshold >= %s'%i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__이 패턴은 매우 명확합니다. 클래스 \"1\" 범주에 특정 값을 입력하는 데 필요한 확률을 낮출수록 해당 버킷에 더 많은 레코드가 들어갑니다.__  \n",
    "\n",
    "__이는 리콜 증가(모든 \"1\"을 원하지만 동시에 정밀도 감소)를 의미합니다(많은 다른 클래스를 잘못 분류함).__  \n",
    "\n",
    "__따라서 리콜이 목표 메트릭이지만(사기 트랜잭션을 놓치지 않음), 전체적으로 정확한 모델을 유지하고자 합니다.__\n",
    "- 이 문제를 해결하는 데는 꽤 흥미로운 방법이 있을 것 같습니다. 잘못된 분류에 비용을 할당할 수 있지만, \"1s\"를 올바르게 분류하는 데 관심이 있는 경우 \"1s\"를 잘못 분류하는 데 드는 비용은 \"0\"보다 커야 합니다. 그런 다음 알고리즘은 총 비용을 최소화하는 임계값을 선택합니다. 단점은 각 비용의 가중치를 수동으로 선택해야 한다는 것입니다. 그러므로, 나는 이것을 생각하여 남길 것입니다.\n",
    "- 임계값 변경으로 돌아가면 Precision-Recall 곡선이라는 옵션이 있습니다. 선택한 임계값에 따라 모델의 성능을 시각적으로 확인함으로써 높은 정밀도 값을 유지하면서 리콜이 충분히 높은 단점을 조사할 수 있습니다.  \n",
    "  \n",
    "__정밀도-호출 곡선과 이 곡선 아래의 영역을 조사합니다.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-04T00:47:59.702187Z",
     "start_time": "2021-04-04T00:46:11.093Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "lr = LogisticRegression(C = 0.01, penalty = 'l1')\n",
    "lr.fit(X_train_undersample,y_train_undersample.values.ravel())\n",
    "y_pred_undersample_proba = lr.predict_proba(X_test_undersample.values)\n",
    "\n",
    "thresholds = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "colors = cycle(['navy', 'turquoise', 'darkorange', 'cornflowerblue', 'teal', 'red', 'yellow', 'green', 'blue','black'])\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "j = 1\n",
    "for i,color in zip(thresholds,colors):\n",
    "    y_test_predictions_prob = y_pred_undersample_proba[:,1] > i\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(y_test_undersample,y_test_predictions_prob)\n",
    "    \n",
    "    # Plot Precision-Recall curve\n",
    "    plt.plot(recall, precision, color=color,\n",
    "                 label='Threshold: %s'%i)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall example')\n",
    "    plt.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upcoming updates:\n",
    "### testing SVMs\n",
    "### testing decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
