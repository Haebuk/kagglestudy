{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- competition/dataset : [https://www.kaggle.com/c/costa-rican-household-poverty-prediction](https://www.kaggle.com/c/costa-rican-household-poverty-prediction)\n",
    "- date : 2021/02/08\n",
    "- original : [https://www.kaggle.com/skooch/xgboost](https://www.kaggle.com/skooch/xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-19T23:23:23.804833Z",
     "iopub.status.busy": "2021-01-19T23:23:23.803834Z",
     "iopub.status.idle": "2021-01-19T23:23:23.811814Z",
     "shell.execute_reply": "2021-01-19T23:23:23.810817Z",
     "shell.execute_reply.started": "2021-01-19T23:23:23.804833Z"
    }
   },
   "source": [
    "**✏ 필사 1회** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. LGBM with random split for early stopping\n",
    "**Edits by Eric Antoine Scuccimarra:**  \n",
    "[Misha Losvyi의 노트북](https://www.kaggle.com/mlisovyi/feature-engineering-lighgbm-with-f1-macro)을 참고하였으며, 몇 가지 변경사항은 다음과 같습니다:  \n",
    "* LightGBM 모델 대신 XGBoost 사용  \n",
    "* 랜덤포레스트의 VotingClassifiers를 사용하여 fitting, XGB의 결과를 RF와 결합  \n",
    "* feature 추가  \n",
    "* code 수정  \n",
    "* 데이터를 한번에 나누어 LGBM의 조기종료를 위해 검증 데이터 사용하는 대신 트레이닝 셋 전체를 학습할 수 있도록 데이터를 분할 \\-\\> 여기서는 k-fold split보다 효과가 좋았음  \n",
    "\n",
    "추가적인 feature들은 [Kuriyaman의 노트북](https://www.kaggle.com/kuriyaman1002/reduce-features-140-84-keeping-f1-score)을 참고했습니다.  \n",
    "\n",
    "**Notes from Original Kernel (edited by EAS):**  \n",
    "Misha Losvyi의 노트북과 내용이 유사하나, 하이퍼파라미터를 최적화하는 대신 커널의 최적의 값을 사용하여 더욱 빠르게 실행됩니다.  \n",
    "\n",
    "중요한 점:  \n",
    "* (가족에 대한 종합 정보를 추출한 후) **이 커널은 가장에 대한 데이터만 학습합니다.** 이것은 가장에 대해서만 점수를 매긴다는 발표된 점수 산정 방식을 따랐습니다. 모든 가족 구성원이 테스트와 샘플 제출물에 포함되어 있지만 가장만 채점합니다. 그러나 [https://www.kaggle.com/c/costa-rican-household-poverty-prediction/discussion/61403#360115](https://www.kaggle.com/c/costa-rican-household-poverty-prediction/discussion/61403#360115)를 살펴보면, 현재로서는 가장이 아닌 구성원들에 대해서도 평가를 하는 것으로 보입니다. 실제로 점수가 ~0.4 PLB인 결과물에서 class 1의 가장이 아닌 구성원의 데이터를 전부 바꾸면 점수는 ~0.2 PLB까지 떨어집니다.  \n",
    "* **클래스별 빈도수의 균형이 매우 중요해 보입니다.** 학습 모델의 균형을 맞추지 않으면 ~0.39 PLB / ~0.43 local test의 점수인 반면, 균형을 이루면 ~0.42 PLB / ~0.47 local test의 점수를 보입니다. 이것은 수작업으로 가능하며, 언더샘플링을 통해 만들어 낼 수 있습니다. 그러나 가장 간단하고 언더샘플링보다 강력한 방법은 sklearn API의 LightGBM 모델을 생성할 때, ```class_weight='balanced'```를 설정하는 것입니다.  \n",
    "* **이 커널에서는 학습에서 조기종료 시 macro F1 score를 사용합니다.** 이것은 scoring 전략에 맞게 시행됩니다.  \n",
    "* 범주형들은 임의의 레이블 인코딩 대신 적절한 매핑을 통해 숫자형으로 변환됩니다. \n",
    "* **OHE는 트리 모델에 대해 더 쉽게 익힐 수 있으므로 레이블 인코딩으로 뒤바뀝니다.** 이 트릭은 트리 모델이 아닌 경우 더 위험할 수 있으므로 주의해야 합니다.  \n",
    "* **idhogar은 학습에 사용하지 않습니다.** 이것이 의미를 가질 수 있는 방법은 오로지 데이터 누수일 때입니다. 우리는 여기서 빈곤에 대해 싸우고 있으며, 누수를 이용하는 것은 어떤 방법으로든 빈곤을 감소시키지 못할 것입니다.  \n",
    "* **가구 내에서 집계가 이루어지며, 새로운 feature들은 수작업으로 생성합니다.** 이미 대부분이 가구 수준의 데이터이기 때문에 집계가 가능한 feature들은 많지 않다는 것을 주의해야 합니다.  \n",
    "* **Voting 분류기는 전체 LightGBM 모델들을 평균내는데 사용합니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:28:15.640215Z",
     "iopub.status.busy": "2021-02-08T05:28:15.640215Z",
     "iopub.status.idle": "2021-02-08T05:28:15.650189Z",
     "shell.execute_reply": "2021-02-08T05:28:15.649192Z",
     "shell.execute_reply.started": "2021-02-08T05:28:15.640215Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "from joblib import Parallel, delayed\n",
    "# from sklearn.externals.joblib import Parallel, delayed\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import VotingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:28:15.652183Z",
     "iopub.status.busy": "2021-02-08T05:28:15.651186Z",
     "iopub.status.idle": "2021-02-08T05:28:15.663157Z",
     "shell.execute_reply": "2021-02-08T05:28:15.662156Z",
     "shell.execute_reply.started": "2021-02-08T05:28:15.652183Z"
    }
   },
   "outputs": [],
   "source": [
    "# 범주형 변수 매핑\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 여기서는 idhogar 필드만 변환\n",
    "def encode_data(df):\n",
    "    df['idhogar'] = LabelEncoder().fit_transform(df['idhogar'])\n",
    "\n",
    "# sklearn 의사결정나무의 변수중요도\n",
    "def feature_importance(forest, x_train, display_results=True):\n",
    "    ranked_list = []\n",
    "    zero_features = []\n",
    "    \n",
    "    importances = forest.feature_importances_\n",
    "    \n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    if display_results:\n",
    "        print('Feature ranking:')\n",
    "    \n",
    "    for f in range(x_train.shape[1]):\n",
    "        if display_results:\n",
    "            print('%d. feature %d (%f) - %s'%(f+1, indices[f], importances[indices[f]], x_train.columns[indices[f]]))\n",
    "        ranked_list.append(x_train.columns[indices[f]])\n",
    "        \n",
    "        if importances[indices[f]] == 0.0:\n",
    "            zero_features.append(x_train.columns[indices[f]])\n",
    "    \n",
    "    return ranked_list, zero_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:28:15.665149Z",
     "iopub.status.busy": "2021-02-08T05:28:15.664151Z",
     "iopub.status.idle": "2021-02-08T05:28:15.677117Z",
     "shell.execute_reply": "2021-02-08T05:28:15.676119Z",
     "shell.execute_reply.started": "2021-02-08T05:28:15.665149Z"
    }
   },
   "outputs": [],
   "source": [
    "def do_features(df):\n",
    "    feats_div = [\n",
    "        ('children_fraction', 'r4t1', 'r4t3'), \n",
    "        ('working_man_fraction', 'r4h2', 'r4t3'),\n",
    "        ('all_man_fraction', 'r4h3', 'r4t3'),\n",
    "        ('human_density', 'tamviv', 'rooms'),\n",
    "        ('human_bed_density', 'tamviv', 'bedrooms'),\n",
    "        ('rent_per_person', 'v2a1', 'r4t3'),\n",
    "        ('rent_per_room', 'v2a1', 'rooms'),\n",
    "        ('mobile_density', 'qmobilephone', 'r4t3'),\n",
    "        ('tablet_density', 'v18q1', 'r4t3'),\n",
    "        ('mobile_adult_density', 'qmobilephone', 'r4t2'),\n",
    "        ('tablet_adult_density', 'v18q1', 'r4t2'),\n",
    "    ]\n",
    "    \n",
    "    feats_sub = [('people_not_living', 'tamhog', 'tamviv'),\n",
    "                 ('people_weird_stat', 'tamhog', 'r4t3')\n",
    "                ]\n",
    "    \n",
    "    for f_new, f1, f2 in feats_div:\n",
    "        df['fe_' + f_new] = (df[f1]/df[f2]).astype(np.float32)\n",
    "    for f_new, f1, f2 in feats_sub:\n",
    "        df['fe_' + f_new] = (df[f1]-df[f2]).astype(np.float32)\n",
    "    \n",
    "    # 가구에 대한 집계 규칙\n",
    "    aggs_num = {'age':['min', 'max', 'mean'],\n",
    "                'escolari': ['min', 'max', 'mean']\n",
    "               }\n",
    "    \n",
    "    aggs_cat = {'dis':['mean']}\n",
    "    for s_ in ['estadocivil', 'parentesco', 'instlevel']:\n",
    "        for f_ in [f_ for f_ in df.columns if f_.startswith(s_)]:\n",
    "            aggs_cat[f_] = ['mean', 'count']\n",
    "    \n",
    "    # 가구별 집계\n",
    "    for name_, df_ in [('18', df.query('age >= 18'))]:\n",
    "        df_agg = df_.groupby('idhogar').agg({**aggs_num, **aggs_cat}).astype(np.float32)\n",
    "        df_agg.columns = pd.Index(\n",
    "            ['agg' + name_ + '_' + e[0] + '_' + e[1].upper() for e in df_agg.columns.tolist()]\n",
    "        )\n",
    "        df = df.join(df_agg, how='left', on='idhogar')\n",
    "        del df_agg\n",
    "    \n",
    "    # id 제거\n",
    "    df.drop('Id', axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:28:15.679112Z",
     "iopub.status.busy": "2021-02-08T05:28:15.678114Z",
     "iopub.status.idle": "2021-02-08T05:28:15.690090Z",
     "shell.execute_reply": "2021-02-08T05:28:15.689099Z",
     "shell.execute_reply.started": "2021-02-08T05:28:15.679112Z"
    }
   },
   "outputs": [],
   "source": [
    "# 원핫인코딩 필드 -> 레이블인코딩\n",
    "def convert_OHE2LE(df):\n",
    "    tmp_df = df.copy(deep=True)\n",
    "    for s_ in ['pared', 'piso', 'techo', 'abastagua', 'sanitario', 'energcocinar', 'elimbasu', \n",
    "               'epared', 'etecho', 'eviv', 'estadocivil', 'parentesco', \n",
    "               'instlevel', 'lugar', 'tipovivi', 'manual_elec']:\n",
    "        if 'manual_' not in s_:\n",
    "            cols_s_ = [f_ for f_ in df.columns if f_.startswith(s_)]\n",
    "        elif 'elec' in s_:\n",
    "            cols_s_ = ['public', 'planpri', 'noelec', 'coopele']\n",
    "        sum_ohe = tmp_df[cols_s_].sum(axis=1).unique()\n",
    "        \n",
    "        # sum 결과가 0인 경우\n",
    "        if 0 in sum_ohe:\n",
    "            print('The OHE in {} is incomplete. A new column will be added before label encoding'.format(s_))\n",
    "            # 추가할 더미 컬럼명\n",
    "            col_dummy = s_ + '_dummy'\n",
    "            # 데이터프레임에 컬럼 추가\n",
    "            tmp_df[col_dummy] = (tmp_df[cols_s_].sum(axis=1) == 0).astype(np.int8)\n",
    "            # 레이블 인코딩을 위해 컬럼 리스트에 추가\n",
    "            cols_s_.append(col_dummy)\n",
    "            # 확인\n",
    "            sum_ohe = tmp_df[cols_s_].sum(axis=1).unique()\n",
    "            if 0 in sum_ohe:\n",
    "                print('The category completion did not work')\n",
    "        \n",
    "        tmp_cat = tmp_df[cols_s_].idxmax(axis=1)\n",
    "        tmp_df[s_ + '_LE'] = LabelEncoder().fit_transform(tmp_cat).astype(np.int16)\n",
    "        \n",
    "        if 'parentesco1' in cols_s_:\n",
    "            cols_s_.remove('parentesco1')\n",
    "        tmp_df.drop(cols_s_, axis=1, inplace=True)\n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Read in data and clean it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:28:15.692076Z",
     "iopub.status.busy": "2021-02-08T05:28:15.691080Z",
     "iopub.status.idle": "2021-02-08T05:28:16.045131Z",
     "shell.execute_reply": "2021-02-08T05:28:16.044134Z",
     "shell.execute_reply.started": "2021-02-08T05:28:15.691080Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "test_ids = test.Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:28:16.046130Z",
     "iopub.status.busy": "2021-02-08T05:28:16.046130Z",
     "iopub.status.idle": "2021-02-08T05:28:16.066082Z",
     "shell.execute_reply": "2021-02-08T05:28:16.065078Z",
     "shell.execute_reply.started": "2021-02-08T05:28:16.046130Z"
    }
   },
   "outputs": [],
   "source": [
    "description = [\n",
    "(\"v2a1\",\" Monthly rent payment\"),\n",
    "(\"hacdor\",\" =1 Overcrowding by bedrooms\"),\n",
    "(\"rooms\",\"  number of all rooms in the house\"),\n",
    "(\"hacapo\",\" =1 Overcrowding by rooms\"),\n",
    "(\"v14a\",\" =1 has toilet in the household\"),\n",
    "(\"refrig\",\" =1 if the household has refrigerator\"),\n",
    "(\"v18q\",\" owns a tablet\"),\n",
    "(\"v18q1\",\" number of tablets household owns\"),\n",
    "(\"r4h1\",\" Males younger than 12 years of age\"),\n",
    "(\"r4h2\",\" Males 12 years of age and older\"),\n",
    "(\"r4h3\",\" Total males in the household\"),\n",
    "(\"r4m1\",\" Females younger than 12 years of age\"),\n",
    "(\"r4m2\",\" Females 12 years of age and older\"),\n",
    "(\"r4m3\",\" Total females in the household\"),\n",
    "(\"r4t1\",\" persons younger than 12 years of age\"),\n",
    "(\"r4t2\",\" persons 12 years of age and older\"),\n",
    "(\"r4t3\",\" Total persons in the household\"),\n",
    "(\"tamhog\",\" size of the household\"),\n",
    "(\"tamviv\",\" number of persons living in the household\"),\n",
    "(\"escolari\",\" years of schooling\"),\n",
    "(\"rez_esc\",\" Years behind in school\"),\n",
    "(\"hhsize\",\" household size\"),\n",
    "(\"paredblolad\",\" =1 if predominant material on the outside wall is block or brick\"),\n",
    "(\"paredzocalo\",\" =1 if predominant material on the outside wall is socket (wood, zinc or absbesto\"),\n",
    "(\"paredpreb\",\" =1 if predominant material on the outside wall is prefabricated or cement\"),\n",
    "(\"pareddes\",\" =1 if predominant material on the outside wall is waste material\"),\n",
    "(\"paredmad\",\" =1 if predominant material on the outside wall is wood\"),\n",
    "(\"paredzinc\",\" =1 if predominant material on the outside wall is zink\"),\n",
    "(\"paredfibras\",\" =1 if predominant material on the outside wall is natural fibers\"),\n",
    "(\"paredother\",\" =1 if predominant material on the outside wall is other\"),\n",
    "(\"pisomoscer\",\" =1 if predominant material on the floor is mosaic ceramic   terrazo\"),\n",
    "(\"pisocemento\",\" =1 if predominant material on the floor is cement\"),\n",
    "(\"pisoother\",\" =1 if predominant material on the floor is other\"),\n",
    "(\"pisonatur\",\" =1 if predominant material on the floor is  natural material\"),\n",
    "(\"pisonotiene\",\" =1 if no floor at the household\"),\n",
    "(\"pisomadera\",\" =1 if predominant material on the floor is wood\"),\n",
    "(\"techozinc\",\" =1 if predominant material on the roof is metal foil or zink\"),\n",
    "(\"techoentrepiso\",\" =1 if predominant material on the roof is fiber cement,   mezzanine \"),\n",
    "(\"techocane\",\" =1 if predominant material on the roof is natural fibers\"),\n",
    "(\"techootro\",\" =1 if predominant material on the roof is other\"),\n",
    "(\"cielorazo\",\" =1 if the house has ceiling\"),\n",
    "(\"abastaguadentro\",\" =1 if water provision inside the dwelling\"),\n",
    "(\"abastaguafuera\",\" =1 if water provision outside the dwelling\"),\n",
    "(\"abastaguano\",\" =1 if no water provision\"),\n",
    "(\"public\",\" =1 electricity from CNFL,  ICE, ESPH/JASEC\"),\n",
    "(\"planpri\",\" =1 electricity from private plant\"),\n",
    "(\"noelec\",\" =1 no electricity in the dwelling\"),\n",
    "(\"coopele\",\" =1 electricity from cooperative\"),\n",
    "(\"sanitario1\",\" =1 no toilet in the dwelling\"),\n",
    "(\"sanitario2\",\" =1 toilet connected to sewer or cesspool\"),\n",
    "(\"sanitario3\",\" =1 toilet connected to  septic tank\"),\n",
    "(\"sanitario5\",\" =1 toilet connected to black hole or letrine\"),\n",
    "(\"sanitario6\",\" =1 toilet connected to other system\"),\n",
    "(\"energcocinar1\",\" =1 no main source of energy used for cooking (no kitchen)\"),\n",
    "(\"energcocinar2\",\" =1 main source of energy used for cooking electricity\"),\n",
    "(\"energcocinar3\",\" =1 main source of energy used for cooking gas\"),\n",
    "(\"energcocinar4\",\" =1 main source of energy used for cooking wood charcoal\"),\n",
    "(\"elimbasu1\",\" =1 if rubbish disposal mainly by tanker truck\"),\n",
    "(\"elimbasu2\",\" =1 if rubbish disposal mainly by botan hollow or buried\"),\n",
    "(\"elimbasu3\",\" =1 if rubbish disposal mainly by burning\"),\n",
    "(\"elimbasu4\",\" =1 if rubbish disposal mainly by throwing in an unoccupied space\"),\n",
    "(\"elimbasu5\",\" =1 if rubbish disposal mainly by throwing in river,   creek or sea\"),\n",
    "(\"elimbasu6\",\" =1 if rubbish disposal mainly other\"),\n",
    "(\"epared1\",\" =1 if walls are bad\"),\n",
    "(\"epared2\",\" =1 if walls are regular\"),\n",
    "(\"epared3\",\" =1 if walls are good\"),\n",
    "(\"etecho1\",\" =1 if roof are bad\"),\n",
    "(\"etecho2\",\" =1 if roof are regular\"),\n",
    "(\"etecho3\",\" =1 if roof are good\"),\n",
    "(\"eviv1\",\" =1 if floor are bad\"),\n",
    "(\"eviv2\",\" =1 if floor are regular\"),\n",
    "(\"eviv3\",\" =1 if floor are good\"),\n",
    "(\"dis\",\" =1 if disable person\"),\n",
    "(\"male\",\" =1 if male\"),\n",
    "(\"female\",\" =1 if female\"),\n",
    "(\"estadocivil1\",\" =1 if less than 10 years old\"),\n",
    "(\"estadocivil2\",\" =1 if free or coupled uunion\"),\n",
    "(\"estadocivil3\",\" =1 if married\"),\n",
    "(\"estadocivil4\",\" =1 if divorced\"),\n",
    "(\"estadocivil5\",\" =1 if separated\"),\n",
    "(\"estadocivil6\",\" =1 if widow/er\"),\n",
    "(\"estadocivil7\",\" =1 if single\"),\n",
    "(\"parentesco1\",\" =1 if household head\"),\n",
    "(\"parentesco2\",\" =1 if spouse/partner\"),\n",
    "(\"parentesco3\",\" =1 if son/doughter\"),\n",
    "(\"parentesco4\",\" =1 if stepson/doughter\"),\n",
    "(\"parentesco5\",\" =1 if son/doughter in law\"),\n",
    "(\"parentesco6\",\" =1 if grandson/doughter\"),\n",
    "(\"parentesco7\",\" =1 if mother/father\"),\n",
    "(\"parentesco8\",\" =1 if father/mother in law\"),\n",
    "(\"parentesco9\",\" =1 if brother/sister\"),\n",
    "(\"parentesco10\",\" =1 if brother/sister in law\"),\n",
    "(\"parentesco11\",\" =1 if other family member\"),\n",
    "(\"parentesco12\",\" =1 if other non family member\"),\n",
    "(\"idhogar\",\" Household level identifier\"),\n",
    "(\"hogar_nin\",\" Number of children 0 to 19 in household\"),\n",
    "(\"hogar_adul\",\" Number of adults in household\"),\n",
    "(\"hogar_mayor\",\" # of individuals 65+ in the household\"),\n",
    "(\"hogar_total\",\" # of total individuals in the household\"),\n",
    "(\"dependency\",\" Dependency rate\"),\n",
    "(\"edjefe\",\" years of education of male head of household\"),\n",
    "(\"edjefa\",\" years of education of female head of household\"),\n",
    "(\"meaneduc\",\"average years of education for adults (18+)\"),\n",
    "(\"instlevel1\",\" =1 no level of education\"),\n",
    "(\"instlevel2\",\" =1 incomplete primary\"),\n",
    "(\"instlevel3\",\" =1 complete primary\"),\n",
    "(\"instlevel4\",\" =1 incomplete academic secondary level\"),\n",
    "(\"instlevel5\",\" =1 complete academic secondary level\"),\n",
    "(\"instlevel6\",\" =1 incomplete technical secondary level\"),\n",
    "(\"instlevel7\",\" =1 complete technical secondary level\"),\n",
    "(\"instlevel8\",\" =1 undergraduate and higher education\"),\n",
    "(\"instlevel9\",\" =1 postgraduate higher education\"),\n",
    "(\"bedrooms\",\" number of bedrooms\"),\n",
    "(\"overcrowding\",\" # persons per room\"),\n",
    "(\"tipovivi1\",\" =1 own and fully paid house\"),\n",
    "(\"tipovivi2\",\" =1 own, paying in installments\"),\n",
    "(\"tipovivi3\",\" =1 rented\"),\n",
    "(\"tipovivi4\",\" =1 precarious\"),\n",
    "(\"tipovivi5\",\" =1 other(assigned\"),\n",
    "(\"computer\",\" =1 if the household has notebook or desktop computer,   borrowed)\"),\n",
    "(\"television\",\" =1 if the household has TV\"),\n",
    "(\"mobilephone\",\" =1 if mobile phone\"),\n",
    "(\"qmobilephone\",\" # of mobile phones\"),\n",
    "(\"lugar1\",\" =1 region Central\"),\n",
    "(\"lugar2\",\" =1 region Chorotega\"),\n",
    "(\"lugar3\",\" =1 region PacÃƒÂ­fico central\"),\n",
    "(\"lugar4\",\" =1 region Brunca\"),\n",
    "(\"lugar5\",\" =1 region Huetar AtlÃƒÂ¡ntica\"),\n",
    "(\"lugar6\",\" =1 region Huetar Norte\"),\n",
    "(\"area1\",\" =1 zona urbana\"),\n",
    "(\"area2\",\" =2 zona rural\"),\n",
    "(\"age\",\" Age in years\"),\n",
    "(\"SQBescolari\",\" escolari squared\"),\n",
    "(\"SQBage\",\" age squared\"),\n",
    "(\"SQBhogar_total\",\" hogar_total squared\"),\n",
    "(\"SQBedjefe\",\" edjefe squared\"),\n",
    "(\"SQBhogar_nin\",\" hogar_nin squared\"),\n",
    "(\"SQBovercrowding\",\" overcrowding squared\"),\n",
    "(\"SQBdependency\",\" dependency squared\"),\n",
    "(\"SQBmeaned\",\" meaned squared\"),\n",
    "(\"agesq\",\" Age squared\"),]\n",
    "\n",
    "description = pd.DataFrame(description, columns=['varname', 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:28:16.068071Z",
     "iopub.status.busy": "2021-02-08T05:28:16.067074Z",
     "iopub.status.idle": "2021-02-08T05:28:16.593387Z",
     "shell.execute_reply": "2021-02-08T05:28:16.592389Z",
     "shell.execute_reply.started": "2021-02-08T05:28:16.068071Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_df(df_):\n",
    "    # idhogar 인코딩\n",
    "    encode_data(df_)\n",
    "    \n",
    "    # 집계 feature 생성\n",
    "    return do_features(df_)\n",
    "\n",
    "train = process_df(train)\n",
    "test = process_df(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 제거, 문자형을 숫자형으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:28:16.596380Z",
     "iopub.status.busy": "2021-02-08T05:28:16.595383Z",
     "iopub.status.idle": "2021-02-08T05:28:16.681157Z",
     "shell.execute_reply": "2021-02-08T05:28:16.680156Z",
     "shell.execute_reply.started": "2021-02-08T05:28:16.596380Z"
    }
   },
   "outputs": [],
   "source": [
    "# dependency에 결측값이 있으므로 SQBdependency의 제곱근값을 사용\n",
    "train['dependency'] = np.sqrt(train['SQBdependency'])\n",
    "test['dependency'] = np.sqrt(test['SQBdependency'])\n",
    "\n",
    "# education의 'no'는 0으로 대체\n",
    "train.loc[train['edjefa'] == 'no', 'edjefa'] = 0\n",
    "train.loc[train['edjefe'] == 'no', 'edjefe'] = 0\n",
    "test.loc[test['edjefa'] == 'no', 'edjefa'] = 0\n",
    "test.loc[test['edjefe'] == 'no', 'edjefe'] = 0\n",
    "\n",
    "# education이 'yes'이고 가장인 경우 escolari 값으로 대체\n",
    "train.loc[(train['edjefa'] == 'yes')&(train['parentesco1'] == 1), 'edjefa'] = train.loc[(train['edjefa'] == 'yes')&(train['parentesco1'] == 1), 'escolari']\n",
    "train.loc[(train['edjefe'] == 'yes')&(train['parentesco1'] == 1), 'edjefe'] = train.loc[(train['edjefe'] == 'yes')&(train['parentesco1'] == 1), 'escolari']\n",
    "test.loc[(test['edjefa'] == 'yes')&(test['parentesco1'] == 1), 'edjefa'] = test.loc[(test['edjefa'] == 'yes')&(test['parentesco1'] == 1), 'escolari']\n",
    "test.loc[(test['edjefe'] == 'yes')&(test['parentesco1'] == 1), 'edjefe'] = test.loc[(test['edjefe'] == 'yes')&(test['parentesco1'] == 1), 'escolari']\n",
    "\n",
    "# edjefa, edjefe는 gender와 escolari의 상호작용에 대한 데이터, yes는 4로 대체\n",
    "train.loc[train['edjefa'] == 'yes', 'edjefa'] = 4\n",
    "train.loc[train['edjefe'] == 'yes', 'edjefe'] = 4\n",
    "test.loc[test['edjefa'] == 'yes', 'edjefa'] = 4\n",
    "test.loc[test['edjefe'] == 'yes', 'edjefe'] = 4\n",
    "\n",
    "# int 타입으로 변경\n",
    "train['edjefa'] = train['edjefa'].astype('int')\n",
    "train['edjefe'] = train['edjefe'].astype('int')\n",
    "test['edjefa'] = test['edjefa'].astype('int')\n",
    "test['edjefe'] = test['edjefe'].astype('int')\n",
    "\n",
    "# 가장의 최대 교육기간에 대한 feature 생성\n",
    "train['edjef'] = np.max(train[['edjefa', 'edjefe']], axis=1)\n",
    "test['edjef'] = np.max(test[['edjefa', 'edjefe']], axis=1)\n",
    "\n",
    "# nan에 0 입력\n",
    "train['v2a1'].fillna(0, inplace=True)\n",
    "test['v2a1'].fillna(0, inplace=True)\n",
    "\n",
    "train['v18q1'].fillna(0, inplace=True)\n",
    "test['v18q1'].fillna(0, inplace=True)\n",
    "\n",
    "train['rez_esc'].fillna(0, inplace=True)\n",
    "test['rez_esc'].fillna(0, inplace=True)\n",
    "\n",
    "train.loc[train['meaneduc'].isnull(), 'meaneduc'] = 0\n",
    "test.loc[test['meaneduc'].isnull(), 'meaneduc'] = 0\n",
    "\n",
    "train.loc[train['SQBmeaned'].isnull(), 'SQBmeaned'] = 0\n",
    "test.loc[test['SQBmeaned'].isnull(), 'SQBmeaned'] = 0\n",
    "\n",
    "# 일관성 없는 데이터 수정 - 수도 공급이 없는 경우 화장실도 없는 것으로 통일\n",
    "train.loc[(train['v14a'] == 1)&(train['sanitario1'] == 1)&(train['abastaguano'] == 0), 'v14a'] = 0\n",
    "train.loc[(train['v14a'] == 1)&(train['sanitario1'] == 1)&(train['abastaguano'] == 0), 'sanitario1'] = 1\n",
    "test.loc[(test['v14a'] == 1)&(test['sanitario1'] == 1)&(test['abastaguano'] == 0), 'v14a'] = 0\n",
    "test.loc[(test['v14a'] == 1)&(test['sanitario1'] == 1)&(test['abastaguano'] == 0), 'sanitario1'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:28:16.683150Z",
     "iopub.status.busy": "2021-02-08T05:28:16.683150Z",
     "iopub.status.idle": "2021-02-08T05:28:16.690128Z",
     "shell.execute_reply": "2021-02-08T05:28:16.689132Z",
     "shell.execute_reply.started": "2021-02-08T05:28:16.683150Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_apply_func(train_, test_, func_):\n",
    "    test_['Target'] = 0\n",
    "    xx = pd.concat([train_, test_])\n",
    "    \n",
    "    xx_func = func_(xx)\n",
    "    train_ = xx_func.iloc[:train_.shape[0], :]\n",
    "    test_ = xx_func.iloc[train_.shape[0]:, :].drop('Target', axis=1)\n",
    "    \n",
    "    del xx, xx_func\n",
    "    return train_, test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:28:16.691126Z",
     "iopub.status.busy": "2021-02-08T05:28:16.691126Z",
     "iopub.status.idle": "2021-02-08T05:28:18.365387Z",
     "shell.execute_reply": "2021-02-08T05:28:18.364393Z",
     "shell.execute_reply.started": "2021-02-08T05:28:16.691126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The OHE in techo is incomplete. A new column will be added before label encoding\n",
      "The OHE in instlevel is incomplete. A new column will be added before label encoding\n",
      "The OHE in manual_elec is incomplete. A new column will be added before label encoding\n"
     ]
    }
   ],
   "source": [
    "# 원핫인코딩된 필드를 레이블인코딩\n",
    "train, test = train_test_apply_func(train, test, convert_OHE2LE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Geo aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:28:18.367376Z",
     "iopub.status.busy": "2021-02-08T05:28:18.366378Z",
     "iopub.status.idle": "2021-02-08T05:28:18.672071Z",
     "shell.execute_reply": "2021-02-08T05:28:18.671073Z",
     "shell.execute_reply.started": "2021-02-08T05:28:18.367376Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_2_ohe = ['eviv_LE', 'etecho_LE', 'epared_LE', 'elimbasu_LE',\n",
    "              'energcocinar_LE', 'sanitario_LE', 'manual_elec_LE', 'pared_LE']\n",
    "cols_nums = ['age', 'meaneduc', 'dependency', 'hogar_nin', 'hogar_adul',\n",
    "             'hogar_mayor', 'hogar_total', 'bedrooms', 'overcrowding']\n",
    "\n",
    "def convert_geo2aggs(df_):\n",
    "    tmp_df = pd.concat([df_[(['lugar_LE', 'idhogar'] + cols_nums)],\n",
    "                        pd.get_dummies(df_[cols_2_ohe], columns=cols_2_ohe)], axis=1)\n",
    "    geo_agg = tmp_df.groupby(['lugar_LE', 'idhogar']).mean().groupby('lugar_LE').mean().astype(np.float32)\n",
    "    geo_agg.columns = pd.Index(['geo_' + e for e in geo_agg.columns.tolist()])\n",
    "    \n",
    "    del tmp_df\n",
    "    return df_.join(geo_agg, how='left', on='lugar_LE')\n",
    "\n",
    "# 지형별 집계 추가\n",
    "train, test = train_test_apply_func(train, test, convert_geo2aggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:28:18.673070Z",
     "iopub.status.busy": "2021-02-08T05:28:18.673070Z",
     "iopub.status.idle": "2021-02-08T05:28:19.073592Z",
     "shell.execute_reply": "2021-02-08T05:28:19.073592Z",
     "shell.execute_reply.started": "2021-02-08T05:28:18.673070Z"
    }
   },
   "outputs": [],
   "source": [
    "# 각 가정에서 18세 이상인 사람의 수\n",
    "train['num_over_18'] = 0\n",
    "train['num_over_18'] = train[train['age'] >= 18].groupby('idhogar').transform('count')\n",
    "train['num_over_18'] = train.groupby('idhogar')['num_over_18'].transform('max')\n",
    "train['num_over_18'].fillna(0, inplace=True)\n",
    "\n",
    "test['num_over_18'] = 0\n",
    "test['num_over_18'] = test[test['age'] >= 18].groupby('idhogar').transform('count')\n",
    "test['num_over_18'] = test.groupby('idhogar')['num_over_18'].transform('max')\n",
    "test['num_over_18'].fillna(0, inplace=True)\n",
    "\n",
    "# 그밖의 feature 추가 (다른 커널에서 가져옴)\n",
    "def extract_features(df):\n",
    "    df['bedroom_to_rooms'] = df['bedrooms'] / df['rooms']\n",
    "    df['rent_to_rooms'] = df['v2a1'] / df['rooms']\n",
    "    df['tamhog_to_rooms'] = df['tamhog'] / df['rooms']\n",
    "    df['r4t3_to_tamhog'] = df['r4t3'] / df['tamhog']\n",
    "    df['r4t3_to_rooms'] = df['r4t3'] / df['rooms']\n",
    "    df['v2a1_to_r4t3'] = df['v2a1'] / df['r4t3']\n",
    "    df['v2a1_to_under_12'] = df['v2a1'] / (df['r4t3'] - df['r4t1'])\n",
    "    df['hhsize_to_rooms'] = df['hhsize'] / df['rooms']\n",
    "    df['rent_to_hhsize'] = df['v2a1'] / df['hhsize']\n",
    "    df['rent_to_over_18'] = df['v2a1'] / df['num_over_18']\n",
    "    # 18세 이하가 없는 가정의 월세 총합\n",
    "    df.loc[df['num_over_18'] == 0, 'rent_to_over_18'] = df[df['num_over_18'] == 0].v2a1\n",
    "\n",
    "extract_features(train)\n",
    "extract_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:28:19.076585Z",
     "iopub.status.busy": "2021-02-08T05:28:19.075587Z",
     "iopub.status.idle": "2021-02-08T05:28:19.112487Z",
     "shell.execute_reply": "2021-02-08T05:28:19.112487Z",
     "shell.execute_reply.started": "2021-02-08T05:28:19.076585Z"
    }
   },
   "outputs": [],
   "source": [
    "# 중복된 컬럼 제거\n",
    "needless_cols = ['r4t3', 'tamhog', 'tamviv', 'hhsize', 'v18q', 'v14a', 'agesq',\n",
    "                 'mobilephone', 'female']\n",
    "\n",
    "instlevel_cols = [s for s in train.columns.tolist() if 'instlevel' in s]\n",
    "needless_cols.extend(instlevel_cols)\n",
    "\n",
    "train.drop(needless_cols, axis=1, inplace=True)\n",
    "test.drop(needless_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data\n",
    "같은 가구에 속하는 행들은 대부분 같은 데이터를 갖기 때문에 누수를 피하기 위해 데이터를 가구 단위로 분할합니다. 가장만 포함하도록 데이터를 필터링하기 대문에 기술적으로는 필요하지 않지만, 위와 같이 하기 위해서 전체 트레이닝 데이터를 쉽게 사용할 수 있습니다.  \n",
    "\n",
    "데이터를 분리한 후 트레이닝 데이터를 전체 데이터로 덮어 모든 데이터를 학습할 수 있다는 점을 기억해야 합니다. split_data 함수는 데이터를 덮어쓰는 것을 제외한 나머지 역할을 하고, K-fold split과 유사한 트레이닝 루프에 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:28:19.114482Z",
     "iopub.status.busy": "2021-02-08T05:28:19.114482Z",
     "iopub.status.idle": "2021-02-08T05:28:19.120467Z",
     "shell.execute_reply": "2021-02-08T05:28:19.120467Z",
     "shell.execute_reply.started": "2021-02-08T05:28:19.114482Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_data(train, y, sample_weight=None, households=None,\n",
    "               test_percentage=0.20, seed=None):\n",
    "    np.random.seed(seed=seed)\n",
    "    train2 = train.copy()\n",
    "    \n",
    "    # 무작위로 테스트에 사용할 가구 추출\n",
    "    cv_hhs = np.random.choice(households, size=int(len(households)*test_percentage), replace=False)\n",
    "    \n",
    "    # 랜덤으로 선택된 가구 적용\n",
    "    cv_idx = np.isin(households, cv_hhs)\n",
    "    x_test = train2[cv_idx]\n",
    "    y_test = y[cv_idx]\n",
    "    \n",
    "    x_train = train2[~cv_idx]\n",
    "    y_train = y[~cv_idx]\n",
    "    \n",
    "    if sample_weight is not None:\n",
    "        y_train_weights = sample_weight[~cv_idx]\n",
    "        return x_train, y_train, x_test, y_test, y_train_weights\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:28:19.122462Z",
     "iopub.status.busy": "2021-02-08T05:28:19.122462Z",
     "iopub.status.idle": "2021-02-08T05:28:19.162814Z",
     "shell.execute_reply": "2021-02-08T05:28:19.162814Z",
     "shell.execute_reply.started": "2021-02-08T05:28:19.122462Z"
    }
   },
   "outputs": [],
   "source": [
    "x = train.query('parentesco1 == 1')\n",
    "\n",
    "# target 변수 추출 및 제거\n",
    "y = x['Target'] - 1\n",
    "x.drop('Target', axis=1, inplace=True)\n",
    "\n",
    "np.random.seed(seed=None)\n",
    "x_train, y_train, x_test, y_test = split_data(x, y, households=x['idhogar'].unique(), test_percentage=0.15)\n",
    "\n",
    "# 전체 데이터셋 학습\n",
    "x_train = x\n",
    "y_train = y\n",
    "\n",
    "train_households = x_train['idhogar']\n",
    "\n",
    "# 불균형한 클래스가 있는 학습에 대한 클래스 가중치\n",
    "y_train_weights = class_weight.compute_sample_weight('balanced', y_train, indices=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:28:19.164809Z",
     "iopub.status.busy": "2021-02-08T05:28:19.163812Z",
     "iopub.status.idle": "2021-02-08T05:28:19.170793Z",
     "shell.execute_reply": "2021-02-08T05:28:19.169796Z",
     "shell.execute_reply.started": "2021-02-08T05:28:19.164809Z"
    }
   },
   "outputs": [],
   "source": [
    "# LGBM에 사용하지 않거나 변수중요도가 매우 낮은 feature 제거\n",
    "extra_drop_features = [\n",
    " 'agg18_estadocivil1_MEAN', 'agg18_estadocivil6_COUNT', 'agg18_estadocivil7_COUNT',\n",
    " 'agg18_parentesco10_COUNT', 'agg18_parentesco11_COUNT', 'agg18_parentesco12_COUNT',\n",
    " 'agg18_parentesco1_COUNT', 'agg18_parentesco2_COUNT', 'agg18_parentesco3_COUNT',\n",
    " 'agg18_parentesco4_COUNT', 'agg18_parentesco5_COUNT', 'agg18_parentesco6_COUNT',\n",
    " 'agg18_parentesco7_COUNT', 'agg18_parentesco8_COUNT', 'agg18_parentesco9_COUNT',\n",
    " 'geo_elimbasu_LE_4', 'geo_energcocinar_LE_1', 'geo_energcocinar_LE_2',\n",
    " 'geo_epared_LE_0', 'geo_hogar_mayor', 'geo_manual_elec_LE_2', 'geo_pared_LE_3',\n",
    " 'geo_pared_LE_4', 'geo_pared_LE_5', 'geo_pared_LE_6', 'num_over_18',\n",
    " 'parentesco_LE', 'rez_esc']\n",
    "\n",
    "xgb_drop_cols = extra_drop_features + ['idhogar', 'parentesco1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fit a voting classifier\n",
    "조기 종료를 위해 ```fit_params```를 통과할 수 있도록 파생된 VotingClassifier를 정의합니다. 투표는 LGBM 모델을 기반으로 하며, 이 모델은 macro F1과 쇠퇴하는 학습 속도를 기반으로 한 조기 종료를 사용합니다.  \n",
    "\n",
    "파라미터는 해당 커널에서 무작위 탐색을 통해 최적화됩니다: [https://www.kaggle.com/mlisovyi/lighgbm-hyperoptimisation-with-f1-macro](https://www.kaggle.com/mlisovyi/lighgbm-hyperoptimisation-with-f1-macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:28:19.171791Z",
     "iopub.status.busy": "2021-02-08T05:28:19.171791Z",
     "iopub.status.idle": "2021-02-08T05:28:19.180766Z",
     "shell.execute_reply": "2021-02-08T05:28:19.180766Z",
     "shell.execute_reply.started": "2021-02-08T05:28:19.171791Z"
    }
   },
   "outputs": [],
   "source": [
    "opt_parameters = {\n",
    "    'max_depth':35, 'eta':0.15, 'silent':1, 'objective':'multi:softmax',\n",
    "    'min_child_weight':2, 'num_class':4, 'gamma':2.5, 'colsample_bylevel':1,\n",
    "    'subsample':0.95, 'colsample_bytree':0.85, 'reg_lambda':0.35\n",
    "}\n",
    "\n",
    "def evaluate_macroF1_lgb(predictions, truth):\n",
    "    # https://github.com/Microsoft/LightGBM/issues/1483를 따름\n",
    "    pred_labels = predictions.argmax(axis=1)\n",
    "    truth = truth.get_label()\n",
    "    f1 = f1_score(truth, pred_labels, average='macro')\n",
    "    return ('macroF1', 1-f1)\n",
    "\n",
    "fit_params = {\n",
    "    'early_stopping_rounds':500, 'eval_metric':evaluate_macroF1_lgb, \n",
    "    'eval_set':[(x_train, y_train), (x_test, y_test)], 'verbose':False,\n",
    "}\n",
    "\n",
    "def learning_rate_power_0997(current_iter):\n",
    "    base_learning_rate = 0.1\n",
    "    min_learning_rate = 0.02\n",
    "    lr = base_learning_rate * np.power(.995, current_iter)\n",
    "    return max(lr, min_learning_rate)\n",
    "\n",
    "fit_params['verbose'] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:28:19.182762Z",
     "iopub.status.busy": "2021-02-08T05:28:19.181764Z",
     "iopub.status.idle": "2021-02-08T05:28:19.193732Z",
     "shell.execute_reply": "2021-02-08T05:28:19.193732Z",
     "shell.execute_reply.started": "2021-02-08T05:28:19.182762Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "\n",
    "def _parallel_fit_estimator(estimator1, x, y, sample_weight=None, threshold=True, **fit_params):\n",
    "    estimator = clone(estimator1)\n",
    "    \n",
    "    # 데이터 무작위 분할\n",
    "    if sample_weight is not None:\n",
    "        x_train, y_train, x_test, y_test, y_train_weight = split_data(x, y, sample_weight, households=train_households)\n",
    "    else:\n",
    "        x_train, y_train, x_test, y_test = split_data(x, y, households=train_households)\n",
    "        \n",
    "    # 새로운 분할에 대한 fit param 업데이트\n",
    "    fit_params['eval_set'] = [(x_test, y_test)]\n",
    "    \n",
    "    # fit the estimator\n",
    "    if sample_weight is not None:\n",
    "        if isinstance(estimator1, ExtraTreesClassifier) or isinstance(estimator1, RandomForestClassifier):\n",
    "            estimator.fit(x_train, y_train)\n",
    "        else:\n",
    "            _ = estimator.fit(x_train, y_train, sample_weight=y_train_weight, **fit_params)\n",
    "    else:\n",
    "        if isinstance(estimator1, ExtraTreesClassifier) or isinstance(estimator1, RandomForestClassifier):\n",
    "            estimator.fit(x_train, y_train)\n",
    "        else:\n",
    "            _ = estimator.fit(x_train, y_train, **fit_params)\n",
    "    \n",
    "    if not isinstance(estimator1, ExtraTreesClassifier) and not isinstance(estimator1, RandomForestClassifier) and not isinstance(estimator1, xgb.XGBClassifier):\n",
    "        best_cv_round = np.argmax(estimator.evals_result_['validation_0']['mlogloss'])\n",
    "        best_cv = np.max(estimator.evals_result_['validation_0']['mlogloss'])\n",
    "        best_train = estimator.evals_result_['train']['macroF1'][best_cv_round]\n",
    "    else:\n",
    "        best_train = f1_score(y_train, estimator.predict(x_train), average='macro')\n",
    "        best_cv = f1_score(y_test, estimator.predict(x_test), average='macro')\n",
    "        print('Train F1:', best_train)\n",
    "        print('Test F1:', best_cv)\n",
    "    \n",
    "    # reject some estimators based on their performance on train and test sets\n",
    "    if threshold:\n",
    "        # valid score가 매우 높으면 train score에서 보다 여유롭게 점수를 얻을 수 있습니다.\n",
    "        if ((best_cv > 0.37) and (best_train > 0.75)) or ((best_cv > 0.44) and (best_train > 0.65)):\n",
    "            return estimator\n",
    "        # 그렇지 않으면 더 좋은 점수가 나올 때까지 반복\n",
    "        else:\n",
    "            print('Unacceptable!!! Trying again...')\n",
    "            return _parallel_fit_estimator(estimator1, x, y, sample_weight=sample_weight, **fit_params)\n",
    "    else:\n",
    "        return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:28:19.195728Z",
     "iopub.status.busy": "2021-02-08T05:28:19.195728Z",
     "iopub.status.idle": "2021-02-08T05:28:19.210686Z",
     "shell.execute_reply": "2021-02-08T05:28:19.209689Z",
     "shell.execute_reply.started": "2021-02-08T05:28:19.195728Z"
    }
   },
   "outputs": [],
   "source": [
    "class VotingClassifierLGBM(VotingClassifier):\n",
    "    # fit_params를 전파하는 VotingClassifier의 fit 방법 구현\n",
    "    def fit(self, x, y, sample_weight=None, threshold=True, **fit_params):\n",
    "        if isinstance(y, np.ndarray) and len(y.shape) and y.shape[1] > 1:\n",
    "            raise NotImplementedError('Multilabel and multi-output classification is not supported.')\n",
    "        if self.voting not in ('soft', 'hard'):\n",
    "            raise ValueError(\"Voting must be 'soft' or 'hard'; got (voting=%r)\"%self.voting)\n",
    "        if self.estimators is None or len(self.estimators) == 0:\n",
    "            raise AttributeError('Invalie `estimators` attribute, `estimators` should be a list of (stirng, estimator) tuples')\n",
    "        if (self.weights is not None and len(self.wieghts) != len(slef.estimators)):\n",
    "            raise ValueError('Number of classifiers and weights must be equal; got %d weights, %d estimators'%(len(self.weights), len(self.estimators)))\n",
    "        \n",
    "        names, clfs = zip(*self.estimators)\n",
    "        self._validate_names(names)\n",
    "        \n",
    "        n_isnone = np.sum([clf is None for _, clf in self.estimators])\n",
    "        if n_isnone == len(self.estimators):\n",
    "            raise ValueError('All estimators are None. At least one is required to be a classifier!')\n",
    "        \n",
    "        self.le_ = LabelEncoder().fit(y)\n",
    "        self.classes_ = self.le_.classes_\n",
    "        self.estimators_ = []\n",
    "        \n",
    "        transformed_y = self.le_.transform(y)\n",
    "        \n",
    "        self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(_parallel_fit_estimator)(\n",
    "                clone(clf), x, transformed_y, sample_weight=sample_weight, threshold=threshold, **fit_params\n",
    "            ) for clf in clfs if clf is not None)\n",
    "    \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:28:19.212684Z",
     "iopub.status.busy": "2021-02-08T05:28:19.211684Z",
     "iopub.status.idle": "2021-02-08T05:32:53.955014Z",
     "shell.execute_reply": "2021-02-08T05:32:53.955014Z",
     "shell.execute_reply.started": "2021-02-08T05:28:19.212684Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:28:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:28:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30382\tvalidation_0-macroF1:0.66847\n",
      "[50]\tvalidation_0-mlogloss:0.91046\tvalidation_0-macroF1:0.63081\n",
      "[100]\tvalidation_0-mlogloss:0.90507\tvalidation_0-macroF1:0.62905\n",
      "[150]\tvalidation_0-mlogloss:0.90503\tvalidation_0-macroF1:0.63133\n",
      "[200]\tvalidation_0-mlogloss:0.90546\tvalidation_0-macroF1:0.63140\n",
      "[250]\tvalidation_0-mlogloss:0.90707\tvalidation_0-macroF1:0.63409\n",
      "[299]\tvalidation_0-mlogloss:0.90637\tvalidation_0-macroF1:0.63619\n",
      "Train F1: 0.8772064230716127\n",
      "Test F1: 0.3858798662205686\n",
      "[14:28:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:28:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30504\tvalidation_0-macroF1:0.64353\n",
      "[50]\tvalidation_0-mlogloss:0.92580\tvalidation_0-macroF1:0.58019\n",
      "[100]\tvalidation_0-mlogloss:0.92072\tvalidation_0-macroF1:0.57333\n",
      "[150]\tvalidation_0-mlogloss:0.92093\tvalidation_0-macroF1:0.58352\n",
      "[200]\tvalidation_0-mlogloss:0.92067\tvalidation_0-macroF1:0.58428\n",
      "[250]\tvalidation_0-mlogloss:0.92210\tvalidation_0-macroF1:0.58358\n",
      "[299]\tvalidation_0-mlogloss:0.92163\tvalidation_0-macroF1:0.58046\n",
      "Train F1: 0.8522398974792846\n",
      "Test F1: 0.432349293178682\n",
      "[14:28:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:28:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.31126\tvalidation_0-macroF1:0.64551\n",
      "[50]\tvalidation_0-mlogloss:0.98700\tvalidation_0-macroF1:0.61082\n",
      "[100]\tvalidation_0-mlogloss:0.99353\tvalidation_0-macroF1:0.61433\n",
      "[150]\tvalidation_0-mlogloss:0.99694\tvalidation_0-macroF1:0.61260\n",
      "[200]\tvalidation_0-mlogloss:0.99546\tvalidation_0-macroF1:0.61515\n",
      "[250]\tvalidation_0-mlogloss:0.99586\tvalidation_0-macroF1:0.61190\n",
      "[299]\tvalidation_0-mlogloss:0.99628\tvalidation_0-macroF1:0.61431\n",
      "Train F1: 0.8946511153118073\n",
      "Test F1: 0.394146102501546\n",
      "[14:29:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:29:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30641\tvalidation_0-macroF1:0.64312\n",
      "[50]\tvalidation_0-mlogloss:0.97384\tvalidation_0-macroF1:0.58902\n",
      "[100]\tvalidation_0-mlogloss:0.96744\tvalidation_0-macroF1:0.59398\n",
      "[150]\tvalidation_0-mlogloss:0.96464\tvalidation_0-macroF1:0.58105\n",
      "[200]\tvalidation_0-mlogloss:0.96213\tvalidation_0-macroF1:0.57935\n",
      "[250]\tvalidation_0-mlogloss:0.95976\tvalidation_0-macroF1:0.58378\n",
      "[299]\tvalidation_0-mlogloss:0.96161\tvalidation_0-macroF1:0.58404\n",
      "Train F1: 0.9262755994774918\n",
      "Test F1: 0.42351922939522074\n",
      "[14:29:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:29:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30898\tvalidation_0-macroF1:0.65848\n",
      "[50]\tvalidation_0-mlogloss:0.97469\tvalidation_0-macroF1:0.59326\n",
      "[100]\tvalidation_0-mlogloss:0.97204\tvalidation_0-macroF1:0.58528\n",
      "[150]\tvalidation_0-mlogloss:0.96797\tvalidation_0-macroF1:0.58772\n",
      "[200]\tvalidation_0-mlogloss:0.96493\tvalidation_0-macroF1:0.59609\n",
      "[250]\tvalidation_0-mlogloss:0.96232\tvalidation_0-macroF1:0.58932\n",
      "[299]\tvalidation_0-mlogloss:0.96097\tvalidation_0-macroF1:0.59152\n",
      "Train F1: 0.9116201335631835\n",
      "Test F1: 0.4189559696717682\n",
      "[14:29:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:29:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30320\tvalidation_0-macroF1:0.63419\n",
      "[50]\tvalidation_0-mlogloss:0.91713\tvalidation_0-macroF1:0.59692\n",
      "[100]\tvalidation_0-mlogloss:0.91459\tvalidation_0-macroF1:0.59459\n",
      "[150]\tvalidation_0-mlogloss:0.91374\tvalidation_0-macroF1:0.58823\n",
      "[200]\tvalidation_0-mlogloss:0.91424\tvalidation_0-macroF1:0.59864\n",
      "[250]\tvalidation_0-mlogloss:0.91456\tvalidation_0-macroF1:0.59022\n",
      "[299]\tvalidation_0-mlogloss:0.91353\tvalidation_0-macroF1:0.59272\n",
      "Train F1: 0.8950710159380263\n",
      "Test F1: 0.4324475386762979\n",
      "[14:30:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:30:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30563\tvalidation_0-macroF1:0.63578\n",
      "[50]\tvalidation_0-mlogloss:0.91940\tvalidation_0-macroF1:0.58837\n",
      "[100]\tvalidation_0-mlogloss:0.91395\tvalidation_0-macroF1:0.59046\n",
      "[150]\tvalidation_0-mlogloss:0.91024\tvalidation_0-macroF1:0.58340\n",
      "[200]\tvalidation_0-mlogloss:0.90848\tvalidation_0-macroF1:0.58351\n",
      "[250]\tvalidation_0-mlogloss:0.90744\tvalidation_0-macroF1:0.59412\n",
      "[299]\tvalidation_0-mlogloss:0.90629\tvalidation_0-macroF1:0.59827\n",
      "Train F1: 0.9149060121938941\n",
      "Test F1: 0.41910457304295146\n",
      "[14:30:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:30:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30423\tvalidation_0-macroF1:0.65586\n",
      "[50]\tvalidation_0-mlogloss:0.92722\tvalidation_0-macroF1:0.56944\n",
      "[100]\tvalidation_0-mlogloss:0.92069\tvalidation_0-macroF1:0.57200\n",
      "[150]\tvalidation_0-mlogloss:0.91680\tvalidation_0-macroF1:0.58137\n",
      "[200]\tvalidation_0-mlogloss:0.91364\tvalidation_0-macroF1:0.58228\n",
      "[250]\tvalidation_0-mlogloss:0.91248\tvalidation_0-macroF1:0.57930\n",
      "[299]\tvalidation_0-mlogloss:0.91224\tvalidation_0-macroF1:0.58392\n",
      "Train F1: 0.9048223283271533\n",
      "Test F1: 0.4357432944620368\n",
      "[14:30:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:30:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.29692\tvalidation_0-macroF1:0.67276\n",
      "[50]\tvalidation_0-mlogloss:0.89843\tvalidation_0-macroF1:0.57877\n",
      "[100]\tvalidation_0-mlogloss:0.89404\tvalidation_0-macroF1:0.56995\n",
      "[150]\tvalidation_0-mlogloss:0.89232\tvalidation_0-macroF1:0.57039\n",
      "[200]\tvalidation_0-mlogloss:0.89078\tvalidation_0-macroF1:0.56632\n",
      "[250]\tvalidation_0-mlogloss:0.88982\tvalidation_0-macroF1:0.56603\n",
      "[299]\tvalidation_0-mlogloss:0.89057\tvalidation_0-macroF1:0.56930\n",
      "Train F1: 0.9261991183854615\n",
      "Test F1: 0.43700733734219366\n",
      "[14:31:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:31:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30624\tvalidation_0-macroF1:0.63572\n",
      "[50]\tvalidation_0-mlogloss:0.97206\tvalidation_0-macroF1:0.58654\n",
      "[100]\tvalidation_0-mlogloss:0.96773\tvalidation_0-macroF1:0.57998\n",
      "[150]\tvalidation_0-mlogloss:0.97124\tvalidation_0-macroF1:0.58011\n",
      "[200]\tvalidation_0-mlogloss:0.97087\tvalidation_0-macroF1:0.58450\n",
      "[250]\tvalidation_0-mlogloss:0.97171\tvalidation_0-macroF1:0.58272\n",
      "[299]\tvalidation_0-mlogloss:0.97187\tvalidation_0-macroF1:0.57873\n",
      "Train F1: 0.8749981086102943\n",
      "Test F1: 0.4353773755376797\n",
      "[14:31:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:31:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.31570\tvalidation_0-macroF1:0.66482\n",
      "[50]\tvalidation_0-mlogloss:0.98149\tvalidation_0-macroF1:0.60552\n",
      "[100]\tvalidation_0-mlogloss:0.97754\tvalidation_0-macroF1:0.60880\n",
      "[150]\tvalidation_0-mlogloss:0.97388\tvalidation_0-macroF1:0.61502\n",
      "[200]\tvalidation_0-mlogloss:0.97194\tvalidation_0-macroF1:0.61225\n",
      "[250]\tvalidation_0-mlogloss:0.97187\tvalidation_0-macroF1:0.61810\n",
      "[299]\tvalidation_0-mlogloss:0.97307\tvalidation_0-macroF1:0.61514\n",
      "Train F1: 0.8846831954495141\n",
      "Test F1: 0.39917623522125634\n",
      "[14:31:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:31:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30616\tvalidation_0-macroF1:0.64463\n",
      "[50]\tvalidation_0-mlogloss:0.90810\tvalidation_0-macroF1:0.62875\n",
      "[100]\tvalidation_0-mlogloss:0.90170\tvalidation_0-macroF1:0.61907\n",
      "[150]\tvalidation_0-mlogloss:0.89746\tvalidation_0-macroF1:0.61186\n",
      "[200]\tvalidation_0-mlogloss:0.88841\tvalidation_0-macroF1:0.61548\n",
      "[250]\tvalidation_0-mlogloss:0.88685\tvalidation_0-macroF1:0.61670\n",
      "[299]\tvalidation_0-mlogloss:0.88573\tvalidation_0-macroF1:0.60867\n",
      "Train F1: 0.8572231805772951\n",
      "Test F1: 0.3963374085754642\n",
      "[14:31:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:31:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30280\tvalidation_0-macroF1:0.64224\n",
      "[50]\tvalidation_0-mlogloss:0.93558\tvalidation_0-macroF1:0.60174\n",
      "[100]\tvalidation_0-mlogloss:0.93323\tvalidation_0-macroF1:0.60774\n",
      "[150]\tvalidation_0-mlogloss:0.92930\tvalidation_0-macroF1:0.60053\n",
      "[200]\tvalidation_0-mlogloss:0.92962\tvalidation_0-macroF1:0.60702\n",
      "[250]\tvalidation_0-mlogloss:0.92744\tvalidation_0-macroF1:0.60663\n",
      "[299]\tvalidation_0-mlogloss:0.92659\tvalidation_0-macroF1:0.60329\n",
      "Train F1: 0.9251942137725502\n",
      "Test F1: 0.40193147923765526\n",
      "[14:32:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:32:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30940\tvalidation_0-macroF1:0.63505\n",
      "[50]\tvalidation_0-mlogloss:0.89655\tvalidation_0-macroF1:0.56483\n",
      "[100]\tvalidation_0-mlogloss:0.89349\tvalidation_0-macroF1:0.54988\n",
      "[150]\tvalidation_0-mlogloss:0.89409\tvalidation_0-macroF1:0.54502\n",
      "[200]\tvalidation_0-mlogloss:0.89288\tvalidation_0-macroF1:0.55717\n",
      "[250]\tvalidation_0-mlogloss:0.89285\tvalidation_0-macroF1:0.56218\n",
      "[299]\tvalidation_0-mlogloss:0.89308\tvalidation_0-macroF1:0.56460\n",
      "Train F1: 0.9122685031006187\n",
      "Test F1: 0.4587078893452209\n",
      "[14:32:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:32:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30756\tvalidation_0-macroF1:0.67758\n",
      "[50]\tvalidation_0-mlogloss:0.94936\tvalidation_0-macroF1:0.62648\n",
      "[100]\tvalidation_0-mlogloss:0.94922\tvalidation_0-macroF1:0.61995\n",
      "[150]\tvalidation_0-mlogloss:0.94720\tvalidation_0-macroF1:0.61992\n",
      "[200]\tvalidation_0-mlogloss:0.94523\tvalidation_0-macroF1:0.61255\n",
      "[250]\tvalidation_0-mlogloss:0.94501\tvalidation_0-macroF1:0.61585\n",
      "[299]\tvalidation_0-mlogloss:0.94504\tvalidation_0-macroF1:0.61040\n",
      "Train F1: 0.8997136166118413\n",
      "Test F1: 0.3981075989536087\n"
     ]
    }
   ],
   "source": [
    "clfs = []\n",
    "for i in range(15):\n",
    "    clf = xgb.XGBClassifier(random_state=217+i, n_estimators=300, learning_rate=0.15,\n",
    "                            n_jobs=4, **opt_parameters)\n",
    "    clfs.append(('xgb{}'.format(i), clf))\n",
    "\n",
    "vc = VotingClassifierLGBM(clfs, voting='soft')\n",
    "del clfs\n",
    "\n",
    "# learning rate 감소에 따라 최종 모델 학습\n",
    "_ = vc.fit(x_train.drop(xgb_drop_cols, axis=1), y_train,\n",
    "           sample_weight=y_train_weights, threshold=False, **fit_params)\n",
    "\n",
    "clf_final = vc.estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:32:53.957009Z",
     "iopub.status.busy": "2021-02-08T05:32:53.956011Z",
     "iopub.status.idle": "2021-02-08T05:32:54.238257Z",
     "shell.execute_reply": "2021-02-08T05:32:54.238257Z",
     "shell.execute_reply.started": "2021-02-08T05:32:53.957009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score of a single LGBM Classifier: 0.8215\n",
      "Validation score for a VotingClassifier on 3 LGBMs with soft voting strategy: 0.8970\n",
      "Validation score for a VotingClassifier on 3 LGBMs with hard voting strategy: 0.8940\n"
     ]
    }
   ],
   "source": [
    "# params 4 = 400 early stop - 15 estimators - l1 used features - weighted\n",
    "global_score = f1_score(y_test, clf_final.predict(x_test.drop(xgb_drop_cols, axis=1)), average='macro')\n",
    "\n",
    "vc.voting = 'soft'\n",
    "global_score_soft = f1_score(y_test, vc.predict(x_test.drop(xgb_drop_cols, axis=1)), average='macro')\n",
    "\n",
    "vc.voting = 'hard'\n",
    "global_score_hard = f1_score(y_test, vc.predict(x_test.drop(xgb_drop_cols, axis=1)), average='macro')\n",
    "\n",
    "print('Validation score of a single LGBM Classifier: {:.4f}'.format(global_score))\n",
    "print('Validation score for a VotingClassifier on 3 LGBMs with soft voting strategy: {:.4f}'.format(global_score_soft))\n",
    "print('Validation score for a VotingClassifier on 3 LGBMs with hard voting strategy: {:.4f}'.format(global_score_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:32:54.240252Z",
     "iopub.status.busy": "2021-02-08T05:32:54.239254Z",
     "iopub.status.idle": "2021-02-08T05:32:56.347190Z",
     "shell.execute_reply": "2021-02-08T05:32:56.346192Z",
     "shell.execute_reply.started": "2021-02-08T05:32:54.240252Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agg18_estadocivil5_COUNT',\n",
       " 'geo_energcocinar_LE_0',\n",
       " 'geo_epared_LE_2',\n",
       " 'geo_manual_elec_LE_3'}"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델들에 사용되지 않은 변수\n",
    "useless_features = []\n",
    "drop_features = set()\n",
    "counter = 0\n",
    "for est in vc.estimators_:\n",
    "    ranked_features, unused_features = feature_importance(est, x_train.drop(xgb_drop_cols, axis=1), display_results=False)\n",
    "    useless_features.append(unused_features)\n",
    "    if counter == 0:\n",
    "        drop_features = set(unused_features)\n",
    "    else:\n",
    "        drop_features = drop_features.intersection(set(unused_features))\n",
    "    counter += 1\n",
    "\n",
    "drop_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:32:56.350182Z",
     "iopub.status.busy": "2021-02-08T05:32:56.350182Z",
     "iopub.status.idle": "2021-02-08T05:32:56.531697Z",
     "shell.execute_reply": "2021-02-08T05:32:56.531697Z",
     "shell.execute_reply.started": "2021-02-08T05:32:56.350182Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 59 (0.023249) - agg18_escolari_MAX\n",
      "2. feature 42 (0.018774) - fe_children_fraction\n",
      "3. feature 37 (0.015907) - SQBedjefe\n",
      "4. feature 128 (0.014577) - geo_manual_elec_LE_0\n",
      "5. feature 60 (0.013138) - agg18_escolari_MEAN\n",
      "6. feature 36 (0.012107) - SQBhogar_total\n",
      "7. feature 125 (0.012032) - geo_sanitario_LE_2\n",
      "8. feature 22 (0.011352) - dependency\n",
      "9. feature 74 (0.011255) - agg18_parentesco2_MEAN\n",
      "10. feature 7 (0.010973) - r4h2\n",
      "11. feature 107 (0.010781) - geo_overcrowding\n",
      "12. feature 13 (0.010682) - r4t2\n",
      "13. feature 87 (0.010281) - piso_LE\n",
      "14. feature 15 (0.010171) - cielorazo\n",
      "15. feature 40 (0.010127) - SQBdependency\n",
      "16. feature 112 (0.010100) - geo_etecho_LE_1\n",
      "17. feature 102 (0.009908) - geo_dependency\n",
      "18. feature 105 (0.009904) - geo_hogar_total\n",
      "19. feature 65 (0.009884) - agg18_estadocivil3_MEAN\n",
      "20. feature 117 (0.009835) - geo_elimbasu_LE_1\n",
      "21. feature 124 (0.009646) - geo_sanitario_LE_1\n",
      "22. feature 23 (0.009519) - edjefe\n",
      "23. feature 96 (0.009518) - estadocivil_LE\n",
      "24. feature 39 (0.009434) - SQBovercrowding\n",
      "25. feature 137 (0.009392) - rent_to_rooms\n",
      "26. feature 49 (0.009320) - fe_mobile_density\n",
      "27. feature 55 (0.009250) - agg18_age_MIN\n",
      "28. feature 141 (0.009247) - v2a1_to_r4t3\n",
      "29. feature 69 (0.009147) - agg18_estadocivil5_MEAN\n",
      "30. feature 110 (0.008912) - geo_eviv_LE_2\n",
      "31. feature 122 (0.008817) - geo_energcocinar_LE_3\n",
      "32. feature 95 (0.008806) - eviv_LE\n",
      "33. feature 43 (0.008760) - fe_working_man_fraction\n",
      "34. feature 30 (0.008747) - qmobilephone\n",
      "35. feature 14 (0.008645) - escolari\n",
      "36. feature 109 (0.008608) - geo_eviv_LE_1\n",
      "37. feature 11 (0.008605) - r4m3\n",
      "38. feature 98 (0.008585) - tipovivi_LE\n",
      "39. feature 94 (0.008536) - etecho_LE\n",
      "40. feature 12 (0.008493) - r4t1\n",
      "41. feature 120 (0.008478) - geo_elimbasu_LE_5\n",
      "42. feature 113 (0.008416) - geo_etecho_LE_2\n",
      "43. feature 93 (0.008407) - epared_LE\n",
      "44. feature 34 (0.008370) - SQBescolari\n",
      "45. feature 21 (0.008284) - hogar_total\n",
      "46. feature 106 (0.008225) - geo_bedrooms\n",
      "47. feature 44 (0.008219) - fe_all_man_fraction\n",
      "48. feature 100 (0.008205) - geo_age\n",
      "49. feature 99 (0.008108) - manual_elec_LE\n",
      "50. feature 35 (0.008105) - SQBage\n",
      "51. feature 63 (0.008103) - agg18_estadocivil2_MEAN\n",
      "52. feature 29 (0.008095) - television\n",
      "53. feature 58 (0.008079) - agg18_escolari_MIN\n",
      "54. feature 26 (0.007987) - bedrooms\n",
      "55. feature 116 (0.007951) - geo_elimbasu_LE_0\n",
      "56. feature 25 (0.007917) - meaneduc\n",
      "57. feature 114 (0.007889) - geo_epared_LE_1\n",
      "58. feature 53 (0.007759) - fe_people_not_living\n",
      "59. feature 71 (0.007758) - agg18_estadocivil6_MEAN\n",
      "60. feature 143 (0.007715) - hhsize_to_rooms\n",
      "61. feature 75 (0.007686) - agg18_parentesco3_MEAN\n",
      "62. feature 0 (0.007667) - v2a1\n",
      "63. feature 136 (0.007650) - bedroom_to_rooms\n",
      "64. feature 104 (0.007611) - geo_hogar_adul\n",
      "65. feature 85 (0.007589) - edjef\n",
      "66. feature 86 (0.007588) - pared_LE\n",
      "67. feature 101 (0.007578) - geo_meaneduc\n",
      "68. feature 72 (0.007562) - agg18_estadocivil7_MEAN\n",
      "69. feature 10 (0.007559) - r4m2\n",
      "70. feature 97 (0.007550) - lugar_LE\n",
      "71. feature 33 (0.007540) - age\n",
      "72. feature 56 (0.007517) - agg18_age_MAX\n",
      "73. feature 52 (0.007511) - fe_tablet_adult_density\n",
      "74. feature 6 (0.007456) - r4h1\n",
      "75. feature 47 (0.007342) - fe_rent_per_person\n",
      "76. feature 27 (0.007286) - overcrowding\n",
      "77. feature 45 (0.007253) - fe_human_density\n",
      "78. feature 8 (0.007199) - r4h3\n",
      "79. feature 16 (0.007180) - dis\n",
      "80. feature 24 (0.007121) - edjefa\n",
      "81. feature 133 (0.007093) - geo_pared_LE_1\n",
      "82. feature 92 (0.007041) - elimbasu_LE\n",
      "83. feature 50 (0.006951) - fe_tablet_density\n",
      "84. feature 83 (0.006945) - agg18_parentesco11_MEAN\n",
      "85. feature 3 (0.006932) - hacapo\n",
      "86. feature 48 (0.006896) - fe_rent_per_room\n",
      "87. feature 140 (0.006878) - r4t3_to_rooms\n",
      "88. feature 17 (0.006862) - male\n",
      "89. feature 57 (0.006819) - agg18_age_MEAN\n",
      "90. feature 62 (0.006806) - agg18_estadocivil1_COUNT\n",
      "91. feature 90 (0.006712) - sanitario_LE\n",
      "92. feature 2 (0.006672) - rooms\n",
      "93. feature 41 (0.006621) - SQBmeaned\n",
      "94. feature 51 (0.006605) - fe_mobile_adult_density\n",
      "95. feature 31 (0.006562) - area1\n",
      "96. feature 91 (0.006457) - energcocinar_LE\n",
      "97. feature 19 (0.006429) - hogar_adul\n",
      "98. feature 138 (0.006409) - tamhog_to_rooms\n",
      "99. feature 9 (0.006380) - r4m1\n",
      "100. feature 67 (0.006357) - agg18_estadocivil4_MEAN\n",
      "101. feature 61 (0.006120) - agg18_dis_MEAN\n",
      "102. feature 20 (0.006097) - hogar_mayor\n",
      "103. feature 18 (0.006070) - hogar_nin\n",
      "104. feature 28 (0.005890) - computer\n",
      "105. feature 145 (0.005868) - rent_to_over_18\n",
      "106. feature 108 (0.005841) - geo_eviv_LE_0\n",
      "107. feature 32 (0.005720) - area2\n",
      "108. feature 46 (0.005691) - fe_human_bed_density\n",
      "109. feature 4 (0.005496) - refrig\n",
      "110. feature 38 (0.005358) - SQBhogar_nin\n",
      "111. feature 5 (0.005127) - v18q1\n",
      "112. feature 144 (0.004964) - rent_to_hhsize\n",
      "113. feature 89 (0.004934) - abastagua_LE\n",
      "114. feature 73 (0.004928) - agg18_parentesco1_MEAN\n",
      "115. feature 126 (0.004728) - geo_sanitario_LE_3\n",
      "116. feature 79 (0.004614) - agg18_parentesco7_MEAN\n",
      "117. feature 78 (0.004431) - agg18_parentesco6_MEAN\n",
      "118. feature 81 (0.004417) - agg18_parentesco9_MEAN\n",
      "119. feature 1 (0.004337) - hacdor\n",
      "120. feature 77 (0.004249) - agg18_parentesco5_MEAN\n",
      "121. feature 119 (0.004248) - geo_elimbasu_LE_3\n",
      "122. feature 142 (0.003765) - v2a1_to_under_12\n",
      "123. feature 88 (0.003471) - techo_LE\n",
      "124. feature 64 (0.003365) - agg18_estadocivil2_COUNT\n",
      "125. feature 129 (0.002963) - geo_manual_elec_LE_1\n",
      "126. feature 84 (0.002915) - agg18_parentesco12_MEAN\n",
      "127. feature 80 (0.001728) - agg18_parentesco8_MEAN\n",
      "128. feature 82 (0.001701) - agg18_parentesco10_MEAN\n",
      "129. feature 54 (0.000000) - fe_people_weird_stat\n",
      "130. feature 70 (0.000000) - agg18_estadocivil5_COUNT\n",
      "131. feature 118 (0.000000) - geo_elimbasu_LE_2\n",
      "132. feature 76 (0.000000) - agg18_parentesco4_MEAN\n",
      "133. feature 127 (0.000000) - geo_sanitario_LE_4\n",
      "134. feature 115 (0.000000) - geo_epared_LE_2\n",
      "135. feature 111 (0.000000) - geo_etecho_LE_0\n",
      "136. feature 130 (0.000000) - geo_manual_elec_LE_3\n",
      "137. feature 103 (0.000000) - geo_hogar_nin\n",
      "138. feature 132 (0.000000) - geo_pared_LE_0\n",
      "139. feature 68 (0.000000) - agg18_estadocivil4_COUNT\n",
      "140. feature 139 (0.000000) - r4t3_to_tamhog\n",
      "141. feature 66 (0.000000) - agg18_estadocivil3_COUNT\n",
      "142. feature 135 (0.000000) - geo_pared_LE_7\n",
      "143. feature 134 (0.000000) - geo_pared_LE_2\n",
      "144. feature 123 (0.000000) - geo_sanitario_LE_0\n",
      "145. feature 131 (0.000000) - geo_manual_elec_LE_4\n",
      "146. feature 121 (0.000000) - geo_energcocinar_LE_0\n"
     ]
    }
   ],
   "source": [
    "ranked_features = feature_importance(clf_final, x_train.drop(xgb_drop_cols, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:32:56.536683Z",
     "iopub.status.busy": "2021-02-08T05:32:56.535686Z",
     "iopub.status.idle": "2021-02-08T05:32:56.543665Z",
     "shell.execute_reply": "2021-02-08T05:32:56.543665Z",
     "shell.execute_reply.started": "2021-02-08T05:32:56.536683Z"
    }
   },
   "outputs": [],
   "source": [
    "et_drop_cols = [\n",
    "    'agg18_age_MAX', 'agg18_age_MEAN', 'agg18_age_MIN', 'agg18_dis_MEAN',\n",
    "    'agg18_escolari_MAX', 'agg18_escolari_MEAN', 'agg18_escolari_MIN',\n",
    "    'agg18_estadocivil1_COUNT', 'agg18_estadocivil1_MEAN',\n",
    "    'agg18_estadocivil2_COUNT', 'agg18_estadocivil2_MEAN',\n",
    "    'agg18_estadocivil3_COUNT', 'agg18_estadocivil3_MEAN',\n",
    "    'agg18_estadocivil4_COUNT', 'agg18_estadocivil4_MEAN',\n",
    "    'agg18_estadocivil5_COUNT', 'agg18_estadocivil5_MEAN',\n",
    "    'agg18_estadocivil6_COUNT', 'agg18_estadocivil6_MEAN',\n",
    "    'agg18_estadocivil7_COUNT', 'agg18_estadocivil7_MEAN',\n",
    "    'agg18_parentesco10_COUNT', 'agg18_parentesco10_MEAN',\n",
    "    'agg18_parentesco11_COUNT', 'agg18_parentesco11_MEAN',\n",
    "    'agg18_parentesco12_COUNT', 'agg18_parentesco12_MEAN',\n",
    "    'agg18_parentesco1_COUNT', 'agg18_parentesco1_MEAN',\n",
    "    'agg18_parentesco2_COUNT', 'agg18_parentesco2_MEAN',\n",
    "    'agg18_parentesco3_COUNT', 'agg18_parentesco3_MEAN',\n",
    "    'agg18_parentesco4_COUNT', 'agg18_parentesco4_MEAN',\n",
    "    'agg18_parentesco5_COUNT', 'agg18_parentesco5_MEAN',\n",
    "    'agg18_parentesco6_COUNT', 'agg18_parentesco6_MEAN',\n",
    "    'agg18_parentesco7_COUNT', 'agg18_parentesco7_MEAN',\n",
    "    'agg18_parentesco8_COUNT', 'agg18_parentesco8_MEAN',\n",
    "    'agg18_parentesco9_COUNT', 'agg18_parentesco9_MEAN'\n",
    "]\n",
    "    #+ ['parentesco_LE', 'rez_esc']\n",
    "\n",
    "et_drop_cols.extend([\n",
    "    'idhogar', 'parentesco1', 'fe_rent_per_person', 'fe_rent_per_room',\n",
    "    'fe_tablet_adult_density', 'fe_tablet_density'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:32:56.546657Z",
     "iopub.status.busy": "2021-02-08T05:32:56.545659Z",
     "iopub.status.idle": "2021-02-08T05:33:24.386421Z",
     "shell.execute_reply": "2021-02-08T05:33:24.385424Z",
     "shell.execute_reply.started": "2021-02-08T05:32:56.546657Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.8954372019112491\n",
      "Test F1: 0.4458623810259543\n",
      "Train F1: 0.8902466898736323\n",
      "Test F1: 0.434252672331085\n",
      "Train F1: 0.8975150989017542\n",
      "Test F1: 0.43286306265457275\n",
      "Train F1: 0.8936934335737534\n",
      "Test F1: 0.4182419864722403\n",
      "Train F1: 0.9005328671076449\n",
      "Test F1: 0.39998242036131787\n",
      "Train F1: 0.8961073649993477\n",
      "Test F1: 0.4779487868342571\n",
      "Train F1: 0.8948105591249009\n",
      "Test F1: 0.4127369072617175\n",
      "Train F1: 0.8939783041785534\n",
      "Test F1: 0.44027366000562207\n",
      "Train F1: 0.8848922924264201\n",
      "Test F1: 0.4586126835893988\n",
      "Train F1: 0.8978049456841827\n",
      "Test F1: 0.43410845734325465\n"
     ]
    }
   ],
   "source": [
    "# 반복\n",
    "ets = []\n",
    "for i in range(10):\n",
    "    rf = RandomForestClassifier(\n",
    "        max_depth=None, random_state=217+i, n_jobs=4, n_estimators=700,\n",
    "        min_impurity_decrease=1e-3, min_samples_leaf=2, verbose=0, class_weight='balanced'\n",
    "    )\n",
    "    ets.append(('rf{}'.format(i), rf))\n",
    "\n",
    "vc2 = VotingClassifierLGBM(ets, voting='soft')\n",
    "_ = vc2.fit(x_train.drop(et_drop_cols, axis=1), y_train, threshold=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:33:24.388416Z",
     "iopub.status.busy": "2021-02-08T05:33:24.387419Z",
     "iopub.status.idle": "2021-02-08T05:33:27.300428Z",
     "shell.execute_reply": "2021-02-08T05:33:27.299429Z",
     "shell.execute_reply.started": "2021-02-08T05:33:24.388416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: 0.8794\n",
      "Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: 0.8793\n"
     ]
    }
   ],
   "source": [
    "vc2.voting = 'soft'\n",
    "global_rf_score_soft = f1_score(y_test, vc2.predict(x_test.drop(et_drop_cols, axis=1)), average='macro')\n",
    "\n",
    "vc2.voting = 'hard'\n",
    "global_rf_score_hard = f1_score(y_test, vc2.predict(x_test.drop(et_drop_cols, axis=1)), average='macro')\n",
    "\n",
    "print('Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: {:.4f}'.format(global_rf_score_soft))\n",
    "print('Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: {:.4f}'.format(global_rf_score_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:33:27.302423Z",
     "iopub.status.busy": "2021-02-08T05:33:27.301425Z",
     "iopub.status.idle": "2021-02-08T05:33:28.380999Z",
     "shell.execute_reply": "2021-02-08T05:33:28.380002Z",
     "shell.execute_reply.started": "2021-02-08T05:33:27.302423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parentesco_LE', 'rez_esc'}"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델들에 사용되지 않은 변수\n",
    "useless_features = []\n",
    "drop_features = set()\n",
    "counter = 0\n",
    "for est in vc2.estimators_:\n",
    "    ranked_features, unused_features = feature_importance(est, x_train.drop(et_drop_cols, axis=1), display_results=False)\n",
    "    useless_features.append(unused_features)\n",
    "    if counter == 0:\n",
    "        drop_features = set(unused_features)\n",
    "    else:\n",
    "        drop_features = drop_features.intersection(set(unused_features))\n",
    "    counter += 1\n",
    "\n",
    "drop_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:33:28.381997Z",
     "iopub.status.busy": "2021-02-08T05:33:28.381997Z",
     "iopub.status.idle": "2021-02-08T05:33:28.389975Z",
     "shell.execute_reply": "2021-02-08T05:33:28.388978Z",
     "shell.execute_reply.started": "2021-02-08T05:33:28.381997Z"
    }
   },
   "outputs": [],
   "source": [
    "def combine_voters(data, weights=[0.5, 0.5]):\n",
    "    # 두 분류기를 모두 사용하여 soft voting 시행\n",
    "    vc.voting = 'soft'\n",
    "    vc1_probs = vc.predict_proba(data.drop(xgb_drop_cols, axis=1))\n",
    "    \n",
    "    vc2.voting = 'soft'\n",
    "    vc2_probs = vc2.predict_proba(data.drop(et_drop_cols, axis=1))\n",
    "    \n",
    "    final_vote = (vc1_probs * weights[0]) + (vc2_probs * weights[1])\n",
    "    predictions = np.argmax(final_vote, axis=1)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:33:28.390972Z",
     "iopub.status.busy": "2021-02-08T05:33:28.390972Z",
     "iopub.status.idle": "2021-02-08T05:33:29.930527Z",
     "shell.execute_reply": "2021-02-08T05:33:29.929532Z",
     "shell.execute_reply.started": "2021-02-08T05:33:28.390972Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9009788676236044"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_preds = combine_voters(x_test, weights=[0.5, 0.5])\n",
    "global_combo_score_soft = f1_score(y_test, combo_preds, average='macro')\n",
    "global_combo_score_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:33:29.932525Z",
     "iopub.status.busy": "2021-02-08T05:33:29.931526Z",
     "iopub.status.idle": "2021-02-08T05:33:31.397811Z",
     "shell.execute_reply": "2021-02-08T05:33:31.396813Z",
     "shell.execute_reply.started": "2021-02-08T05:33:29.932525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8963703061529148"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_preds = combine_voters(x_test, weights=[0.4, 0.6])\n",
    "global_combo_score_soft = f1_score(y_test, combo_preds, average='macro')\n",
    "global_combo_score_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:33:31.399806Z",
     "iopub.status.busy": "2021-02-08T05:33:31.398808Z",
     "iopub.status.idle": "2021-02-08T05:33:32.861503Z",
     "shell.execute_reply": "2021-02-08T05:33:32.860504Z",
     "shell.execute_reply.started": "2021-02-08T05:33:31.399806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9009788676236044"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_preds = combine_voters(x_test, weights=[0.6, 0.4])\n",
    "global_combo_score_soft = f1_score(y_test, combo_preds, average='macro')\n",
    "global_combo_score_soft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:33:32.864495Z",
     "iopub.status.busy": "2021-02-08T05:33:32.863497Z",
     "iopub.status.idle": "2021-02-08T05:33:32.874467Z",
     "shell.execute_reply": "2021-02-08T05:33:32.873470Z",
     "shell.execute_reply.started": "2021-02-08T05:33:32.863497Z"
    }
   },
   "outputs": [],
   "source": [
    "y_subm = pd.DataFrame()\n",
    "y_subm['Id'] = test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:33:32.875465Z",
     "iopub.status.busy": "2021-02-08T05:33:32.875465Z",
     "iopub.status.idle": "2021-02-08T05:33:52.543970Z",
     "shell.execute_reply": "2021-02-08T05:33:52.543970Z",
     "shell.execute_reply.started": "2021-02-08T05:33:32.875465Z"
    }
   },
   "outputs": [],
   "source": [
    "vc.voting = 'soft'\n",
    "y_subm_lgb = y_subm.copy(deep=True)\n",
    "y_subm_lgb['Target'] = vc.predict(test.drop(xgb_drop_cols, axis=1)) + 1\n",
    "\n",
    "vc2.voting = 'soft'\n",
    "y_subm_rf = y_subm.copy(deep=True)\n",
    "y_subm_rf['Target'] = vc2.predict(test.drop(et_drop_cols, axis=1)) + 1\n",
    "\n",
    "y_subm_ens = y_subm.copy(deep=True)\n",
    "y_subm_ens['Target'] = combine_voters(test) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T05:34:27.117730Z",
     "iopub.status.busy": "2021-02-08T05:34:27.117730Z",
     "iopub.status.idle": "2021-02-08T05:34:27.343099Z",
     "shell.execute_reply": "2021-02-08T05:34:27.343099Z",
     "shell.execute_reply.started": "2021-02-08T05:34:27.117730Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "\n",
    "sub_file_lgb = 'data/submission_3_soft_XGB_{:.4f}_{}.csv'.format(global_score_soft, str(now.strftime('%Y-%m-%d-%H-%M')))\n",
    "sub_file_rf = 'data/submission_3_soft_RF_{:.4f}_{}.csv'.format(global_rf_score_soft, str(now.strftime('%Y-%m-%d-%H-%M')))\n",
    "sub_file_ens = 'data/submission_3_soft_ens_{:.4f}_{}.csv'.format(global_combo_score_soft, str(now.strftime('%Y-%m-%d-%H-%M')))\n",
    "\n",
    "y_subm_lgb.to_csv(sub_file_lgb, index=False)\n",
    "y_subm_rf.to_csv(sub_file_rf, index=False)\n",
    "y_subm_ens.to_csv(sub_file_ens, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-19T23:23:23.804833Z",
     "iopub.status.busy": "2021-01-19T23:23:23.803834Z",
     "iopub.status.idle": "2021-01-19T23:23:23.811814Z",
     "shell.execute_reply": "2021-01-19T23:23:23.810817Z",
     "shell.execute_reply.started": "2021-01-19T23:23:23.804833Z"
    }
   },
   "source": [
    "**✏ 필사 2회** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. LGBM with random split for early stopping\n",
    "**Edits by Eric Antoine Scuccimarra:**  \n",
    "[Misha Losvyi의 노트북](https://www.kaggle.com/mlisovyi/feature-engineering-lighgbm-with-f1-macro)을 참고하였으며, 몇 가지 변경사항은 다음과 같습니다:  \n",
    "* LightGBM 모델 대신 XGBoost 사용  \n",
    "* 랜덤포레스트의 VotingClassifiers를 사용하여 fitting, XGB의 결과를 RF와 결합  \n",
    "* feature 추가  \n",
    "* code 수정  \n",
    "* 데이터를 한번에 나누어 LGBM의 조기종료를 위해 검증 데이터 사용하는 대신 트레이닝 셋 전체를 학습할 수 있도록 데이터를 분할 \\-\\> 여기서는 k-fold split보다 효과가 좋았음  \n",
    "\n",
    "추가적인 feature들은 [Kuriyaman의 노트북](https://www.kaggle.com/kuriyaman1002/reduce-features-140-84-keeping-f1-score)을 참고했습니다.  \n",
    "\n",
    "**Notes from Original Kernel (edited by EAS):**  \n",
    "Misha Losvyi의 노트북과 내용이 유사하나, 하이퍼파라미터를 최적화하는 대신 커널의 최적의 값을 사용하여 더욱 빠르게 실행됩니다.  \n",
    "\n",
    "중요한 점:  \n",
    "* (가족에 대한 종합 정보를 추출한 후) **이 커널은 가장에 대한 데이터만 학습합니다.** 이것은 가장에 대해서만 점수를 매긴다는 발표된 점수 산정 방식을 따랐습니다. 모든 가족 구성원이 테스트와 샘플 제출물에 포함되어 있지만 가장만 채점합니다. 그러나 [https://www.kaggle.com/c/costa-rican-household-poverty-prediction/discussion/61403#360115](https://www.kaggle.com/c/costa-rican-household-poverty-prediction/discussion/61403#360115)를 살펴보면, 현재로서는 가장이 아닌 구성원들에 대해서도 평가를 하는 것으로 보입니다. 실제로 점수가 ~0.4 PLB인 결과물에서 class 1의 가장이 아닌 구성원의 데이터를 전부 바꾸면 점수는 ~0.2 PLB까지 떨어집니다.  \n",
    "* **클래스별 빈도수의 균형이 매우 중요해 보입니다.** 학습 모델의 균형을 맞추지 않으면 ~0.39 PLB / ~0.43 local test의 점수인 반면, 균형을 이루면 ~0.42 PLB / ~0.47 local test의 점수를 보입니다. 이것은 수작업으로 가능하며, 언더샘플링을 통해 만들어 낼 수 있습니다. 그러나 가장 간단하고 언더샘플링보다 강력한 방법은 sklearn API의 LightGBM 모델을 생성할 때, ```class_weight='balanced'```를 설정하는 것입니다.  \n",
    "* **이 커널에서는 학습에서 조기종료 시 macro F1 score를 사용합니다.** 이것은 scoring 전략에 맞게 시행됩니다.  \n",
    "* 범주형들은 임의의 레이블 인코딩 대신 적절한 매핑을 통해 숫자형으로 변환됩니다. \n",
    "* **OHE는 트리 모델에 대해 더 쉽게 익힐 수 있으므로 레이블 인코딩으로 뒤바뀝니다.** 이 트릭은 트리 모델이 아닌 경우 더 위험할 수 있으므로 주의해야 합니다.  \n",
    "* **idhogar은 학습에 사용하지 않습니다.** 이것이 의미를 가질 수 있는 방법은 오로지 데이터 누수일 때입니다. 우리는 여기서 빈곤에 대해 싸우고 있으며, 누수를 이용하는 것은 어떤 방법으로든 빈곤을 감소시키지 못할 것입니다.  \n",
    "* **가구 내에서 집계가 이루어지며, 새로운 feature들은 수작업으로 생성합니다.** 이미 대부분이 가구 수준의 데이터이기 때문에 집계가 가능한 feature들은 많지 않다는 것을 주의해야 합니다.  \n",
    "* **Voting 분류기는 전체 LightGBM 모델들을 평균내는데 사용합니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T06:54:10.942236Z",
     "iopub.status.busy": "2021-02-08T06:54:10.942236Z",
     "iopub.status.idle": "2021-02-08T06:54:10.956178Z",
     "shell.execute_reply": "2021-02-08T06:54:10.955201Z",
     "shell.execute_reply.started": "2021-02-08T06:54:10.942236Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "from joblib import Parallel, delayed\n",
    "# from sklearn.externals.joblib import Parallel, delayed\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import VotingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T06:54:26.700221Z",
     "iopub.status.busy": "2021-02-08T06:54:26.700221Z",
     "iopub.status.idle": "2021-02-08T06:54:26.709197Z",
     "shell.execute_reply": "2021-02-08T06:54:26.708227Z",
     "shell.execute_reply.started": "2021-02-08T06:54:26.700221Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_data(df):\n",
    "    df['idhogar'] = LabelEncoder().fit_transform(df['idhogar'])\n",
    "\n",
    "def feature_importance(forest, x_train, display_results=True):\n",
    "    ranked_list = []\n",
    "    zero_features = []\n",
    "    importances = forest.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    if display_results:\n",
    "        print('Feature ranking:')\n",
    "    for f in range(x_train.shape[1]):\n",
    "        if display_results:\n",
    "            print('%d. feature %d (%f) - %s'%(f+1, indices[f], importances[indices[f]], x_train.columns[indices[f]]))\n",
    "        ranked_list.append(x_train.columns[indices[f]])\n",
    "        if importances[indices[f]] == 0.0:\n",
    "            zero_features.append(x_train.columns[indices[f]])\n",
    "    \n",
    "    return ranked_list, zero_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T06:54:40.232213Z",
     "iopub.status.busy": "2021-02-08T06:54:40.232213Z",
     "iopub.status.idle": "2021-02-08T06:54:40.243183Z",
     "shell.execute_reply": "2021-02-08T06:54:40.242207Z",
     "shell.execute_reply.started": "2021-02-08T06:54:40.232213Z"
    }
   },
   "outputs": [],
   "source": [
    "def do_features(df):\n",
    "    feats_div = [\n",
    "        ('children_fraction', 'r4t1', 'r4t3'), \n",
    "        ('working_man_fraction', 'r4h2', 'r4t3'),\n",
    "        ('all_man_fraction', 'r4h3', 'r4t3'),\n",
    "        ('human_density', 'tamviv', 'rooms'),\n",
    "        ('human_bed_density', 'tamviv', 'bedrooms'),\n",
    "        ('rent_per_person', 'v2a1', 'r4t3'),\n",
    "        ('rent_per_room', 'v2a1', 'rooms'),\n",
    "        ('mobile_density', 'qmobilephone', 'r4t3'),\n",
    "        ('tablet_density', 'v18q1', 'r4t3'),\n",
    "        ('mobile_adult_density', 'qmobilephone', 'r4t2'),\n",
    "        ('tablet_adult_density', 'v18q1', 'r4t2'),\n",
    "    ]\n",
    "    feats_sub = [('people_not_living', 'tamhog', 'tamviv'),\n",
    "                 ('people_weird_stat', 'tamhog', 'r4t3')\n",
    "                ]\n",
    "    for f_new, f1, f2 in feats_div:\n",
    "        df['fe_' + f_new] = (df[f1]/df[f2]).astype(np.float32)\n",
    "    for f_new, f1, f2 in feats_sub:\n",
    "        df['fe_' + f_new] = (df[f1]-df[f2]).astype(np.float32)\n",
    "    aggs_num = {'age':['min', 'max', 'mean'],\n",
    "                'escolari': ['min', 'max', 'mean']\n",
    "               }\n",
    "    aggs_cat = {'dis':['mean']}\n",
    "    for s_ in ['estadocivil', 'parentesco', 'instlevel']:\n",
    "        for f_ in [f_ for f_ in df.columns if f_.startswith(s_)]:\n",
    "            aggs_cat[f_] = ['mean', 'count']\n",
    "    for name_, df_ in [('18', df.query('age >= 18'))]:\n",
    "        df_agg = df_.groupby('idhogar').agg({**aggs_num, **aggs_cat}).astype(np.float32)\n",
    "        df_agg.columns = pd.Index(\n",
    "            ['agg' + name_ + '_' + e[0] + '_' + e[1].upper() for e in df_agg.columns.tolist()]\n",
    "        )\n",
    "        df = df.join(df_agg, how='left', on='idhogar')\n",
    "        del df_agg\n",
    "    df.drop('Id', axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T06:54:59.997412Z",
     "iopub.status.busy": "2021-02-08T06:54:59.997412Z",
     "iopub.status.idle": "2021-02-08T06:55:00.007385Z",
     "shell.execute_reply": "2021-02-08T06:55:00.006388Z",
     "shell.execute_reply.started": "2021-02-08T06:54:59.997412Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_OHE2LE(df):\n",
    "    tmp_df = df.copy(deep=True)\n",
    "    for s_ in ['pared', 'piso', 'techo', 'abastagua', 'sanitario', 'energcocinar', 'elimbasu', \n",
    "               'epared', 'etecho', 'eviv', 'estadocivil', 'parentesco', \n",
    "               'instlevel', 'lugar', 'tipovivi', 'manual_elec']:\n",
    "        if 'manual_' not in s_:\n",
    "            cols_s_ = [f_ for f_ in df.columns if f_.startswith(s_)]\n",
    "        elif 'elec' in s_:\n",
    "            cols_s_ = ['public', 'planpri', 'noelec', 'coopele']\n",
    "        sum_ohe = tmp_df[cols_s_].sum(axis=1).unique()\n",
    "        \n",
    "        if 0 in sum_ohe:\n",
    "            print('The OHE in {} is incomplete. A new column will be added before label encoding'.format(s_))\n",
    "            col_dummy = s_ + '_dummy'\n",
    "            tmp_df[col_dummy] = (tmp_df[cols_s_].sum(axis=1) == 0).astype(np.int8)\n",
    "            cols_s_.append(col_dummy)\n",
    "            sum_ohe = tmp_df[cols_s_].sum(axis=1).unique()\n",
    "            if 0 in sum_ohe:\n",
    "                print('The category completion did not work')\n",
    "        tmp_cat = tmp_df[cols_s_].idxmax(axis=1)\n",
    "        tmp_df[s_ + '_LE'] = LabelEncoder().fit_transform(tmp_cat).astype(np.int16)\n",
    "        \n",
    "        if 'parentesco1' in cols_s_:\n",
    "            cols_s_.remove('parentesco1')\n",
    "        tmp_df.drop(cols_s_, axis=1, inplace=True)\n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Read in data and clean it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T06:55:06.931430Z",
     "iopub.status.busy": "2021-02-08T06:55:06.930432Z",
     "iopub.status.idle": "2021-02-08T06:55:07.390202Z",
     "shell.execute_reply": "2021-02-08T06:55:07.389205Z",
     "shell.execute_reply.started": "2021-02-08T06:55:06.931430Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "test_ids = test.Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T06:55:16.750349Z",
     "iopub.status.busy": "2021-02-08T06:55:16.750349Z",
     "iopub.status.idle": "2021-02-08T06:55:17.236125Z",
     "shell.execute_reply": "2021-02-08T06:55:17.235128Z",
     "shell.execute_reply.started": "2021-02-08T06:55:16.750349Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_df(df_):\n",
    "    encode_data(df_)\n",
    "    return do_features(df_)\n",
    "\n",
    "train = process_df(train)\n",
    "test = process_df(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 제거, 문자형을 숫자형으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T06:55:34.950828Z",
     "iopub.status.busy": "2021-02-08T06:55:34.950828Z",
     "iopub.status.idle": "2021-02-08T06:55:35.041429Z",
     "shell.execute_reply": "2021-02-08T06:55:35.040421Z",
     "shell.execute_reply.started": "2021-02-08T06:55:34.950828Z"
    }
   },
   "outputs": [],
   "source": [
    "train['dependency'] = np.sqrt(train['SQBdependency'])\n",
    "test['dependency'] = np.sqrt(test['SQBdependency'])\n",
    "\n",
    "train.loc[train['edjefa'] == 'no', 'edjefa'] = 0\n",
    "train.loc[train['edjefe'] == 'no', 'edjefe'] = 0\n",
    "test.loc[test['edjefa'] == 'no', 'edjefa'] = 0\n",
    "test.loc[test['edjefe'] == 'no', 'edjefe'] = 0\n",
    "\n",
    "train.loc[(train['edjefa'] == 'yes')&(train['parentesco1'] == 1), 'edjefa'] = train.loc[(train['edjefa'] == 'yes')&(train['parentesco1'] == 1), 'escolari']\n",
    "train.loc[(train['edjefe'] == 'yes')&(train['parentesco1'] == 1), 'edjefe'] = train.loc[(train['edjefe'] == 'yes')&(train['parentesco1'] == 1), 'escolari']\n",
    "test.loc[(test['edjefa'] == 'yes')&(test['parentesco1'] == 1), 'edjefa'] = test.loc[(test['edjefa'] == 'yes')&(test['parentesco1'] == 1), 'escolari']\n",
    "test.loc[(test['edjefe'] == 'yes')&(test['parentesco1'] == 1), 'edjefe'] = test.loc[(test['edjefe'] == 'yes')&(test['parentesco1'] == 1), 'escolari']\n",
    "\n",
    "train.loc[train['edjefa'] == 'yes', 'edjefa'] = 4\n",
    "train.loc[train['edjefe'] == 'yes', 'edjefe'] = 4\n",
    "test.loc[test['edjefa'] == 'yes', 'edjefa'] = 4\n",
    "test.loc[test['edjefe'] == 'yes', 'edjefe'] = 4\n",
    "\n",
    "train['edjefa'] = train['edjefa'].astype('int')\n",
    "train['edjefe'] = train['edjefe'].astype('int')\n",
    "test['edjefa'] = test['edjefa'].astype('int')\n",
    "test['edjefe'] = test['edjefe'].astype('int')\n",
    "\n",
    "train['edjef'] = np.max(train[['edjefa', 'edjefe']], axis=1)\n",
    "test['edjef'] = np.max(test[['edjefa', 'edjefe']], axis=1)\n",
    "\n",
    "train['v2a1'].fillna(0, inplace=True)\n",
    "test['v2a1'].fillna(0, inplace=True)\n",
    "\n",
    "train['v18q1'].fillna(0, inplace=True)\n",
    "test['v18q1'].fillna(0, inplace=True)\n",
    "\n",
    "train['rez_esc'].fillna(0, inplace=True)\n",
    "test['rez_esc'].fillna(0, inplace=True)\n",
    "\n",
    "train.loc[train['meaneduc'].isnull(), 'meaneduc'] = 0\n",
    "test.loc[test['meaneduc'].isnull(), 'meaneduc'] = 0\n",
    "\n",
    "train.loc[train['SQBmeaned'].isnull(), 'SQBmeaned'] = 0\n",
    "test.loc[test['SQBmeaned'].isnull(), 'SQBmeaned'] = 0\n",
    "\n",
    "train.loc[(train['v14a'] == 1)&(train['sanitario1'] == 1)&(train['abastaguano'] == 0), 'v14a'] = 0\n",
    "train.loc[(train['v14a'] == 1)&(train['sanitario1'] == 1)&(train['abastaguano'] == 0), 'sanitario1'] = 1\n",
    "test.loc[(test['v14a'] == 1)&(test['sanitario1'] == 1)&(test['abastaguano'] == 0), 'v14a'] = 0\n",
    "test.loc[(test['v14a'] == 1)&(test['sanitario1'] == 1)&(test['abastaguano'] == 0), 'sanitario1'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T06:55:39.040701Z",
     "iopub.status.busy": "2021-02-08T06:55:39.040701Z",
     "iopub.status.idle": "2021-02-08T06:55:39.046655Z",
     "shell.execute_reply": "2021-02-08T06:55:39.045658Z",
     "shell.execute_reply.started": "2021-02-08T06:55:39.040701Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_apply_func(train_, test_, func_):\n",
    "    test_['Target'] = 0\n",
    "    xx = pd.concat([train_, test_])\n",
    "    xx_func = func_(xx)\n",
    "    train_ = xx_func.iloc[:train_.shape[0], :]\n",
    "    test_ = xx_func.iloc[train_.shape[0]:, :].drop('Target', axis=1)\n",
    "    \n",
    "    del xx, xx_func\n",
    "    return train_, test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T06:55:41.848233Z",
     "iopub.status.busy": "2021-02-08T06:55:41.847236Z",
     "iopub.status.idle": "2021-02-08T06:55:43.639528Z",
     "shell.execute_reply": "2021-02-08T06:55:43.638531Z",
     "shell.execute_reply.started": "2021-02-08T06:55:41.848233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The OHE in techo is incomplete. A new column will be added before label encoding\n",
      "The OHE in instlevel is incomplete. A new column will be added before label encoding\n",
      "The OHE in manual_elec is incomplete. A new column will be added before label encoding\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_apply_func(train, test, convert_OHE2LE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Geo aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T06:55:44.612990Z",
     "iopub.status.busy": "2021-02-08T06:55:44.611993Z",
     "iopub.status.idle": "2021-02-08T06:55:44.895234Z",
     "shell.execute_reply": "2021-02-08T06:55:44.895234Z",
     "shell.execute_reply.started": "2021-02-08T06:55:44.612990Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_2_ohe = ['eviv_LE', 'etecho_LE', 'epared_LE', 'elimbasu_LE',\n",
    "              'energcocinar_LE', 'sanitario_LE', 'manual_elec_LE', 'pared_LE']\n",
    "cols_nums = ['age', 'meaneduc', 'dependency', 'hogar_nin', 'hogar_adul',\n",
    "             'hogar_mayor', 'hogar_total', 'bedrooms', 'overcrowding']\n",
    "\n",
    "def convert_geo2aggs(df_):\n",
    "    tmp_df = pd.concat([df_[(['lugar_LE', 'idhogar'] + cols_nums)],\n",
    "                        pd.get_dummies(df_[cols_2_ohe], columns=cols_2_ohe)], axis=1)\n",
    "    geo_agg = tmp_df.groupby(['lugar_LE', 'idhogar']).mean().groupby('lugar_LE').mean().astype(np.float32)\n",
    "    geo_agg.columns = pd.Index(['geo_' + e for e in geo_agg.columns.tolist()])\n",
    "    \n",
    "    del tmp_df\n",
    "    return df_.join(geo_agg, how='left', on='lugar_LE')\n",
    "\n",
    "train, test = train_test_apply_func(train, test, convert_geo2aggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T06:56:18.136229Z",
     "iopub.status.busy": "2021-02-08T06:56:18.136229Z",
     "iopub.status.idle": "2021-02-08T06:56:18.538153Z",
     "shell.execute_reply": "2021-02-08T06:56:18.538153Z",
     "shell.execute_reply.started": "2021-02-08T06:56:18.136229Z"
    }
   },
   "outputs": [],
   "source": [
    "train['num_over_18'] = 0\n",
    "train['num_over_18'] = train[train['age'] >= 18].groupby('idhogar').transform('count')\n",
    "train['num_over_18'] = train.groupby('idhogar')['num_over_18'].transform('max')\n",
    "train['num_over_18'].fillna(0, inplace=True)\n",
    "\n",
    "test['num_over_18'] = 0\n",
    "test['num_over_18'] = test[test['age'] >= 18].groupby('idhogar').transform('count')\n",
    "test['num_over_18'] = test.groupby('idhogar')['num_over_18'].transform('max')\n",
    "test['num_over_18'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "def extract_features(df):\n",
    "    df['bedroom_to_rooms'] = df['bedrooms'] / df['rooms']\n",
    "    df['rent_to_rooms'] = df['v2a1'] / df['rooms']\n",
    "    df['tamhog_to_rooms'] = df['tamhog'] / df['rooms']\n",
    "    df['r4t3_to_tamhog'] = df['r4t3'] / df['tamhog']\n",
    "    df['r4t3_to_rooms'] = df['r4t3'] / df['rooms']\n",
    "    df['v2a1_to_r4t3'] = df['v2a1'] / df['r4t3']\n",
    "    df['v2a1_to_under_12'] = df['v2a1'] / (df['r4t3'] - df['r4t1'])\n",
    "    df['hhsize_to_rooms'] = df['hhsize'] / df['rooms']\n",
    "    df['rent_to_hhsize'] = df['v2a1'] / df['hhsize']\n",
    "    df['rent_to_over_18'] = df['v2a1'] / df['num_over_18']\n",
    "    df.loc[df['num_over_18'] == 0, 'rent_to_over_18'] = df[df['num_over_18'] == 0].v2a1\n",
    "\n",
    "extract_features(train)\n",
    "extract_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T06:56:20.290905Z",
     "iopub.status.busy": "2021-02-08T06:56:20.289908Z",
     "iopub.status.idle": "2021-02-08T06:56:20.331795Z",
     "shell.execute_reply": "2021-02-08T06:56:20.330807Z",
     "shell.execute_reply.started": "2021-02-08T06:56:20.290905Z"
    }
   },
   "outputs": [],
   "source": [
    "needless_cols = ['r4t3', 'tamhog', 'tamviv', 'hhsize', 'v18q', 'v14a', 'agesq',\n",
    "                 'mobilephone', 'female']\n",
    "\n",
    "instlevel_cols = [s for s in train.columns.tolist() if 'instlevel' in s]\n",
    "needless_cols.extend(instlevel_cols)\n",
    "\n",
    "train.drop(needless_cols, axis=1, inplace=True)\n",
    "test.drop(needless_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data\n",
    "같은 가구에 속하는 행들은 대부분 같은 데이터를 갖기 때문에 누수를 피하기 위해 데이터를 가구 단위로 분할합니다. 가장만 포함하도록 데이터를 필터링하기 대문에 기술적으로는 필요하지 않지만, 위와 같이 하기 위해서 전체 트레이닝 데이터를 쉽게 사용할 수 있습니다.  \n",
    "\n",
    "데이터를 분리한 후 트레이닝 데이터를 전체 데이터로 덮어 모든 데이터를 학습할 수 있다는 점을 기억해야 합니다. split_data 함수는 데이터를 덮어쓰는 것을 제외한 나머지 역할을 하고, K-fold split과 유사한 트레이닝 루프에 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T07:03:24.202506Z",
     "iopub.status.busy": "2021-02-08T07:03:24.202506Z",
     "iopub.status.idle": "2021-02-08T07:03:24.209465Z",
     "shell.execute_reply": "2021-02-08T07:03:24.208540Z",
     "shell.execute_reply.started": "2021-02-08T07:03:24.202506Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_data(train, y, sample_weight=None, households=None, test_percentage=0.20, seed=None):\n",
    "    np.random.seed(seed=seed)\n",
    "    train2 = train.copy()\n",
    "    cv_hhs = np.random.choice(households, size=int(len(households) * test_percentage), replace=False)\n",
    "    cv_idx = np.isin(households, cv_hhs)\n",
    "    x_test = train2[cv_idx]\n",
    "    y_test = y[cv_idx]\n",
    "    x_train = train2[~cv_idx]\n",
    "    y_train = y[~cv_idx]\n",
    "    \n",
    "    if sample_weight is not None:\n",
    "        y_train_weights = sample_weight[~cv_idx]\n",
    "        return x_train, y_train, x_test, y_test, y_train_weights\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T07:08:00.211848Z",
     "iopub.status.busy": "2021-02-08T07:08:00.210853Z",
     "iopub.status.idle": "2021-02-08T07:08:00.244760Z",
     "shell.execute_reply": "2021-02-08T07:08:00.243762Z",
     "shell.execute_reply.started": "2021-02-08T07:08:00.211848Z"
    }
   },
   "outputs": [],
   "source": [
    "x = train.query('parentesco1 == 1')\n",
    "\n",
    "y = x['Target'] - 1\n",
    "x = x.drop('Target', axis=1)\n",
    "\n",
    "np.random.seed(seed=None)\n",
    "train2 = x.copy()\n",
    "households = train2.idhogar.unique()\n",
    "cv_hhs = np.random.choice(households, size=int(len(households)*0.15), replace=False)\n",
    "cv_idx = np.isin(train2.idhogar, cv_hhs)\n",
    "x_test = train2[cv_idx]\n",
    "y_test = y[cv_idx]\n",
    "x_train = train2\n",
    "y_train = y\n",
    "train_households = x_train.idhogar\n",
    "y_train_weights = class_weight.compute_sample_weight('balanced', y_train, indices=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T07:08:06.319294Z",
     "iopub.status.busy": "2021-02-08T07:08:06.319294Z",
     "iopub.status.idle": "2021-02-08T07:08:06.326276Z",
     "shell.execute_reply": "2021-02-08T07:08:06.325279Z",
     "shell.execute_reply.started": "2021-02-08T07:08:06.319294Z"
    }
   },
   "outputs": [],
   "source": [
    "extra_drop_features = [\n",
    " 'agg18_estadocivil1_MEAN', 'agg18_estadocivil6_COUNT', 'agg18_estadocivil7_COUNT',\n",
    " 'agg18_parentesco10_COUNT', 'agg18_parentesco11_COUNT', 'agg18_parentesco12_COUNT',\n",
    " 'agg18_parentesco1_COUNT', 'agg18_parentesco2_COUNT', 'agg18_parentesco3_COUNT',\n",
    " 'agg18_parentesco4_COUNT', 'agg18_parentesco5_COUNT', 'agg18_parentesco6_COUNT',\n",
    " 'agg18_parentesco7_COUNT', 'agg18_parentesco8_COUNT', 'agg18_parentesco9_COUNT',\n",
    " 'geo_elimbasu_LE_4', 'geo_energcocinar_LE_1', 'geo_energcocinar_LE_2',\n",
    " 'geo_epared_LE_0', 'geo_hogar_mayor', 'geo_manual_elec_LE_2', 'geo_pared_LE_3',\n",
    " 'geo_pared_LE_4', 'geo_pared_LE_5', 'geo_pared_LE_6', 'num_over_18',\n",
    " 'parentesco_LE', 'rez_esc']\n",
    "\n",
    "xgb_drop_cols = extra_drop_features + ['idhogar', 'parentesco1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fit a voting classifier\n",
    "조기 종료를 위해 ```fit_params```를 통과할 수 있도록 파생된 VotingClassifier를 정의합니다. 투표는 LGBM 모델을 기반으로 하며, 이 모델은 macro F1과 쇠퇴하는 학습 속도를 기반으로 한 조기 종료를 사용합니다.  \n",
    "\n",
    "파라미터는 해당 커널에서 무작위 탐색을 통해 최적화됩니다: [https://www.kaggle.com/mlisovyi/lighgbm-hyperoptimisation-with-f1-macro](https://www.kaggle.com/mlisovyi/lighgbm-hyperoptimisation-with-f1-macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T07:10:16.322905Z",
     "iopub.status.busy": "2021-02-08T07:10:16.322905Z",
     "iopub.status.idle": "2021-02-08T07:10:16.334873Z",
     "shell.execute_reply": "2021-02-08T07:10:16.333876Z",
     "shell.execute_reply.started": "2021-02-08T07:10:16.322905Z"
    }
   },
   "outputs": [],
   "source": [
    "opt_parameters = {\n",
    "    'max_depth':35, 'eta':0.15, 'silent':1, 'objective':'multi:softmax',\n",
    "    'min_child_weight':2, 'num_class':4, 'gamma':2.5, 'colsample_bylevel':1,\n",
    "    'subsample':0.95, 'colsample_bytree':0.85, 'reg_lambda':0.35\n",
    "}\n",
    "\n",
    "def evaluate_macroF1_lgb(predictions, truth):\n",
    "    pred_labels = predictions.argmax(axis=1)\n",
    "    truth = truth.get_label()\n",
    "    f1 = f1_score(truth, pred_labels, average='macro')\n",
    "    return ('macroF1', 1-f1)\n",
    "\n",
    "fit_params={\"early_stopping_rounds\":500,\n",
    "            \"eval_metric\" : evaluate_macroF1_lgb, \n",
    "            \"eval_set\" : [(x_train, y_train), (x_test, y_test)],\n",
    "            'verbose': False}\n",
    "\n",
    "def learning_rate_power_0997(current_iter):\n",
    "    base_learning_rate = 0.1\n",
    "    min_learning_rate = 0.02\n",
    "    lr = base_learning_rate * np.power(.995, current_iter)\n",
    "    return max(lr, min_learning_rate)\n",
    "\n",
    "fit_params['verbose'] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T07:10:44.367826Z",
     "iopub.status.busy": "2021-02-08T07:10:44.367826Z",
     "iopub.status.idle": "2021-02-08T07:10:44.381788Z",
     "shell.execute_reply": "2021-02-08T07:10:44.380790Z",
     "shell.execute_reply.started": "2021-02-08T07:10:44.367826Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "\n",
    "def _parallel_fit_estimator(estimator1, x, y, sample_weight=None, threshold=True, **fit_params):\n",
    "    estimator = clone(estimator1)\n",
    "\n",
    "    if sample_weight is not None:\n",
    "        x_train, y_train, x_test, y_test, y_train_weight = split_data(x, y, sample_weight, households=train_households)\n",
    "    else:\n",
    "        x_train, y_train, x_test, y_test = split_data(x, y, households=train_households)\n",
    "    fit_params['eval_set'] = [(x_test, y_test)]\n",
    "\n",
    "    if sample_weight is not None:\n",
    "        if isinstance(estimator1, ExtraTreesClassifier) or isinstance(estimator1, RandomForestClassifier):\n",
    "            estimator.fit(x_train, y_train)\n",
    "        else:\n",
    "            _ = estimator.fit(x_train, y_train, sample_weight=y_train_weight, **fit_params)\n",
    "    else:\n",
    "        if isinstance(estimator1, ExtraTreesClassifier) or isinstance(estimator1, RandomForestClassifier):\n",
    "            estimator.fit(x_train, y_train)\n",
    "        else:\n",
    "            _ = estimator.fit(x_train, y_train, **fit_params)\n",
    "    \n",
    "    if not isinstance(estimator1, ExtraTreesClassifier) and not isinstance(estimator1, RandomForestClassifier) and not isinstance(estimator1, xgb.XGBClassifier):\n",
    "        best_cv_round = np.argmax(estimator.evals_result_['validation_0']['mlogloss'])\n",
    "        best_cv = np.max(estimator.evals_result_['validation_0']['mlogloss'])\n",
    "        best_train = estimator.evals_result_['train']['macroF1'][best_cv_round]\n",
    "    else:\n",
    "        best_train = f1_score(y_train, estimator.predict(x_train), average='macro')\n",
    "        best_cv = f1_score(y_test, estimator.predict(x_test), average='macro')\n",
    "        print('Train F1:', best_train)\n",
    "        print('Test F1:', best_cv)\n",
    "    \n",
    "    if threshold:\n",
    "        if ((best_cv > 0.37) and (best_train > 0.75)) or ((best_cv > 0.44) and (best_train > 0.65)):\n",
    "            return estimator\n",
    "        else:\n",
    "            print('Unacceptable!!! Trying again...')\n",
    "            return _parallel_fit_estimator(estimator1, x, y, sample_weight=sample_weight, **fit_params)\n",
    "    else:\n",
    "        return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T07:11:07.700818Z",
     "iopub.status.busy": "2021-02-08T07:11:07.700818Z",
     "iopub.status.idle": "2021-02-08T07:11:07.711788Z",
     "shell.execute_reply": "2021-02-08T07:11:07.710790Z",
     "shell.execute_reply.started": "2021-02-08T07:11:07.700818Z"
    }
   },
   "outputs": [],
   "source": [
    "class VotingClassifierLGBM(VotingClassifier):\n",
    "    def fit(self, x, y, sample_weight=None, threshold=True, **fit_params):\n",
    "        if isinstance(y, np.ndarray) and len(y.shape) and y.shape[1] > 1:\n",
    "            raise NotImplementedError('Multilabel and multi-output classification is not supported.')\n",
    "        if self.voting not in ('soft', 'hard'):\n",
    "            raise ValueError(\"Voting must be 'soft' or 'hard'; got (voting=%r)\"%self.voting)\n",
    "        if self.estimators is None or len(self.estimators) == 0:\n",
    "            raise AttributeError('Invalie `estimators` attribute, `estimators` should be a list of (stirng, estimator) tuples')\n",
    "        if (self.weights is not None and len(self.wieghts) != len(slef.estimators)):\n",
    "            raise ValueError('Number of classifiers and weights must be equal; got %d weights, %d estimators'%(len(self.weights), len(self.estimators)))\n",
    "       \n",
    "        names, clfs = zip(*self.estimators)\n",
    "        self._validate_names(names)\n",
    "        n_isnone = np.sum([clf is None for _, clf in self.estimators])\n",
    "        if n_isnone == len(self.estimators):\n",
    "            raise ValueError('All estimators are None. At least one is required to be a classifier!')\n",
    "        self.le_ = LabelEncoder().fit(y)\n",
    "        self.classes_ = self.le_.classes_\n",
    "        self.estimators_ = []\n",
    "        transformed_y = self.le_.transform(y)\n",
    "        self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(_parallel_fit_estimator)(\n",
    "                clone(clf), x, transformed_y, sample_weight=sample_weight, threshold=threshold, **fit_params\n",
    "            ) for clf in clfs if clf is not None)\n",
    "    \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T07:18:14.792808Z",
     "iopub.status.busy": "2021-02-08T07:18:14.792808Z",
     "iopub.status.idle": "2021-02-08T07:22:59.061364Z",
     "shell.execute_reply": "2021-02-08T07:22:59.059370Z",
     "shell.execute_reply.started": "2021-02-08T07:18:14.792808Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:18:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { h_jobs, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:18:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30198\tvalidation_0-macroF1:0.62322\n",
      "[50]\tvalidation_0-mlogloss:0.93623\tvalidation_0-macroF1:0.58164\n",
      "[100]\tvalidation_0-mlogloss:0.93519\tvalidation_0-macroF1:0.58533\n",
      "[150]\tvalidation_0-mlogloss:0.93394\tvalidation_0-macroF1:0.58252\n",
      "[200]\tvalidation_0-mlogloss:0.93058\tvalidation_0-macroF1:0.57567\n",
      "[250]\tvalidation_0-mlogloss:0.93034\tvalidation_0-macroF1:0.57423\n",
      "[299]\tvalidation_0-mlogloss:0.93250\tvalidation_0-macroF1:0.57463\n",
      "Train F1: 0.9257652559128702\n",
      "Test F1: 0.4283567965201257\n",
      "[16:18:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { h_jobs, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:18:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30664\tvalidation_0-macroF1:0.63996\n",
      "[50]\tvalidation_0-mlogloss:0.93684\tvalidation_0-macroF1:0.59370\n",
      "[100]\tvalidation_0-mlogloss:0.92536\tvalidation_0-macroF1:0.58814\n",
      "[150]\tvalidation_0-mlogloss:0.92254\tvalidation_0-macroF1:0.59037\n",
      "[200]\tvalidation_0-mlogloss:0.91953\tvalidation_0-macroF1:0.59177\n",
      "[250]\tvalidation_0-mlogloss:0.91857\tvalidation_0-macroF1:0.59898\n",
      "[299]\tvalidation_0-mlogloss:0.91797\tvalidation_0-macroF1:0.59307\n",
      "Train F1: 0.9184504097581396\n",
      "Test F1: 0.4185168375122931\n",
      "[16:18:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { h_jobs, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:18:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30211\tvalidation_0-macroF1:0.61097\n",
      "[50]\tvalidation_0-mlogloss:0.91303\tvalidation_0-macroF1:0.56453\n",
      "[100]\tvalidation_0-mlogloss:0.90208\tvalidation_0-macroF1:0.56266\n",
      "[150]\tvalidation_0-mlogloss:0.90080\tvalidation_0-macroF1:0.56750\n",
      "[200]\tvalidation_0-mlogloss:0.90022\tvalidation_0-macroF1:0.56711\n",
      "[250]\tvalidation_0-mlogloss:0.90274\tvalidation_0-macroF1:0.56861\n",
      "[299]\tvalidation_0-mlogloss:0.90271\tvalidation_0-macroF1:0.56695\n",
      "Train F1: 0.8953285045782837\n",
      "Test F1: 0.44234951808253153\n",
      "[16:19:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { h_jobs, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:19:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30671\tvalidation_0-macroF1:0.65279\n",
      "[50]\tvalidation_0-mlogloss:0.95004\tvalidation_0-macroF1:0.62466\n",
      "[100]\tvalidation_0-mlogloss:0.94572\tvalidation_0-macroF1:0.62031\n",
      "[150]\tvalidation_0-mlogloss:0.94890\tvalidation_0-macroF1:0.62176\n",
      "[200]\tvalidation_0-mlogloss:0.94818\tvalidation_0-macroF1:0.61783\n",
      "[250]\tvalidation_0-mlogloss:0.94790\tvalidation_0-macroF1:0.62439\n",
      "[299]\tvalidation_0-mlogloss:0.94776\tvalidation_0-macroF1:0.62042\n",
      "Train F1: 0.8774705608435603\n",
      "Test F1: 0.3938472600382544\n",
      "[16:19:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { h_jobs, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:19:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30277\tvalidation_0-macroF1:0.61071\n",
      "[50]\tvalidation_0-mlogloss:0.88260\tvalidation_0-macroF1:0.55355\n",
      "[100]\tvalidation_0-mlogloss:0.87221\tvalidation_0-macroF1:0.56229\n",
      "[150]\tvalidation_0-mlogloss:0.86601\tvalidation_0-macroF1:0.56293\n",
      "[200]\tvalidation_0-mlogloss:0.86430\tvalidation_0-macroF1:0.56107\n",
      "[250]\tvalidation_0-mlogloss:0.86157\tvalidation_0-macroF1:0.55872\n",
      "[299]\tvalidation_0-mlogloss:0.86088\tvalidation_0-macroF1:0.55719\n",
      "Train F1: 0.9080671023478344\n",
      "Test F1: 0.4508407811806771\n",
      "[16:19:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { h_jobs, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:19:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30334\tvalidation_0-macroF1:0.64727\n",
      "[50]\tvalidation_0-mlogloss:0.93874\tvalidation_0-macroF1:0.59291\n",
      "[100]\tvalidation_0-mlogloss:0.93620\tvalidation_0-macroF1:0.58901\n",
      "[150]\tvalidation_0-mlogloss:0.93610\tvalidation_0-macroF1:0.60616\n",
      "[200]\tvalidation_0-mlogloss:0.93498\tvalidation_0-macroF1:0.60229\n",
      "[250]\tvalidation_0-mlogloss:0.93818\tvalidation_0-macroF1:0.59682\n",
      "[299]\tvalidation_0-mlogloss:0.94001\tvalidation_0-macroF1:0.59259\n",
      "Train F1: 0.91179039505305\n",
      "Test F1: 0.4218657900773253\n",
      "[16:20:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { h_jobs, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:20:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.29533\tvalidation_0-macroF1:0.62774\n",
      "[50]\tvalidation_0-mlogloss:0.92848\tvalidation_0-macroF1:0.58479\n",
      "[100]\tvalidation_0-mlogloss:0.92807\tvalidation_0-macroF1:0.59140\n",
      "[150]\tvalidation_0-mlogloss:0.93024\tvalidation_0-macroF1:0.60047\n",
      "[200]\tvalidation_0-mlogloss:0.93140\tvalidation_0-macroF1:0.58882\n",
      "[250]\tvalidation_0-mlogloss:0.93142\tvalidation_0-macroF1:0.59169\n",
      "[299]\tvalidation_0-mlogloss:0.93204\tvalidation_0-macroF1:0.59156\n",
      "Train F1: 0.8873644836108686\n",
      "Test F1: 0.42914755730969656\n",
      "[16:20:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { h_jobs, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:20:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30027\tvalidation_0-macroF1:0.60537\n",
      "[50]\tvalidation_0-mlogloss:0.90037\tvalidation_0-macroF1:0.59087\n",
      "[100]\tvalidation_0-mlogloss:0.89818\tvalidation_0-macroF1:0.59518\n",
      "[150]\tvalidation_0-mlogloss:0.89679\tvalidation_0-macroF1:0.57853\n",
      "[200]\tvalidation_0-mlogloss:0.89694\tvalidation_0-macroF1:0.58566\n",
      "[250]\tvalidation_0-mlogloss:0.89444\tvalidation_0-macroF1:0.58269\n",
      "[299]\tvalidation_0-mlogloss:0.89378\tvalidation_0-macroF1:0.58184\n",
      "Train F1: 0.889358578045287\n",
      "Test F1: 0.44524082939499\n",
      "[16:20:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { h_jobs, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:20:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.29707\tvalidation_0-macroF1:0.62571\n",
      "[50]\tvalidation_0-mlogloss:0.90807\tvalidation_0-macroF1:0.58068\n",
      "[100]\tvalidation_0-mlogloss:0.90701\tvalidation_0-macroF1:0.57583\n",
      "[150]\tvalidation_0-mlogloss:0.90408\tvalidation_0-macroF1:0.58961\n",
      "[200]\tvalidation_0-mlogloss:0.90404\tvalidation_0-macroF1:0.57846\n",
      "[250]\tvalidation_0-mlogloss:0.90436\tvalidation_0-macroF1:0.58062\n",
      "[299]\tvalidation_0-mlogloss:0.90431\tvalidation_0-macroF1:0.57872\n",
      "Train F1: 0.9048464318018765\n",
      "Test F1: 0.42837902816283335\n",
      "[16:21:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { h_jobs, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:21:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30970\tvalidation_0-macroF1:0.67790\n",
      "[50]\tvalidation_0-mlogloss:0.95379\tvalidation_0-macroF1:0.59353\n",
      "[100]\tvalidation_0-mlogloss:0.95688\tvalidation_0-macroF1:0.60006\n",
      "[150]\tvalidation_0-mlogloss:0.95237\tvalidation_0-macroF1:0.59624\n",
      "[200]\tvalidation_0-mlogloss:0.95180\tvalidation_0-macroF1:0.59651\n",
      "[250]\tvalidation_0-mlogloss:0.95456\tvalidation_0-macroF1:0.59613\n",
      "[299]\tvalidation_0-mlogloss:0.95351\tvalidation_0-macroF1:0.60013\n",
      "Train F1: 0.8942184323536665\n",
      "Test F1: 0.4100214134521426\n",
      "[16:21:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { h_jobs, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:21:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.29443\tvalidation_0-macroF1:0.63447\n",
      "[50]\tvalidation_0-mlogloss:0.91346\tvalidation_0-macroF1:0.61649\n",
      "[100]\tvalidation_0-mlogloss:0.91749\tvalidation_0-macroF1:0.61779\n",
      "[150]\tvalidation_0-mlogloss:0.91575\tvalidation_0-macroF1:0.62296\n",
      "[200]\tvalidation_0-mlogloss:0.91371\tvalidation_0-macroF1:0.61114\n",
      "[250]\tvalidation_0-mlogloss:0.91279\tvalidation_0-macroF1:0.61814\n",
      "[299]\tvalidation_0-mlogloss:0.91517\tvalidation_0-macroF1:0.60784\n",
      "Train F1: 0.8916820797839367\n",
      "Test F1: 0.40912800414713735\n",
      "[16:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { h_jobs, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.29747\tvalidation_0-macroF1:0.61988\n",
      "[50]\tvalidation_0-mlogloss:0.89773\tvalidation_0-macroF1:0.56566\n",
      "[100]\tvalidation_0-mlogloss:0.89342\tvalidation_0-macroF1:0.56636\n",
      "[150]\tvalidation_0-mlogloss:0.89633\tvalidation_0-macroF1:0.56177\n",
      "[200]\tvalidation_0-mlogloss:0.89661\tvalidation_0-macroF1:0.56403\n",
      "[250]\tvalidation_0-mlogloss:0.89762\tvalidation_0-macroF1:0.56384\n",
      "[299]\tvalidation_0-mlogloss:0.89663\tvalidation_0-macroF1:0.56466\n",
      "Train F1: 0.8927319439282623\n",
      "Test F1: 0.450628219790175\n",
      "[16:22:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { h_jobs, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:22:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30587\tvalidation_0-macroF1:0.68170\n",
      "[50]\tvalidation_0-mlogloss:0.91794\tvalidation_0-macroF1:0.63243\n",
      "[100]\tvalidation_0-mlogloss:0.91446\tvalidation_0-macroF1:0.63686\n",
      "[150]\tvalidation_0-mlogloss:0.91467\tvalidation_0-macroF1:0.63291\n",
      "[200]\tvalidation_0-mlogloss:0.91122\tvalidation_0-macroF1:0.63630\n",
      "[250]\tvalidation_0-mlogloss:0.91205\tvalidation_0-macroF1:0.63323\n",
      "[299]\tvalidation_0-mlogloss:0.91308\tvalidation_0-macroF1:0.63062\n",
      "Train F1: 0.8756367208397602\n",
      "Test F1: 0.38719713468074146\n",
      "[16:22:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { h_jobs, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:22:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30683\tvalidation_0-macroF1:0.63731\n",
      "[50]\tvalidation_0-mlogloss:0.99753\tvalidation_0-macroF1:0.57921\n",
      "[100]\tvalidation_0-mlogloss:0.99279\tvalidation_0-macroF1:0.58753\n",
      "[150]\tvalidation_0-mlogloss:0.99492\tvalidation_0-macroF1:0.58293\n",
      "[200]\tvalidation_0-mlogloss:0.99541\tvalidation_0-macroF1:0.58281\n",
      "[250]\tvalidation_0-mlogloss:0.99555\tvalidation_0-macroF1:0.58384\n",
      "[299]\tvalidation_0-mlogloss:0.99827\tvalidation_0-macroF1:0.58541\n",
      "Train F1: 0.9022453752353303\n",
      "Test F1: 0.43658987070693656\n",
      "[16:22:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { h_jobs, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:22:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.31109\tvalidation_0-macroF1:0.69501\n",
      "[50]\tvalidation_0-mlogloss:0.94945\tvalidation_0-macroF1:0.63554\n",
      "[100]\tvalidation_0-mlogloss:0.94771\tvalidation_0-macroF1:0.62735\n",
      "[150]\tvalidation_0-mlogloss:0.95253\tvalidation_0-macroF1:0.62971\n",
      "[200]\tvalidation_0-mlogloss:0.95274\tvalidation_0-macroF1:0.62613\n",
      "[250]\tvalidation_0-mlogloss:0.95487\tvalidation_0-macroF1:0.62933\n",
      "[299]\tvalidation_0-mlogloss:0.95305\tvalidation_0-macroF1:0.62919\n",
      "Train F1: 0.8787797109332518\n",
      "Test F1: 0.3802862744151643\n"
     ]
    }
   ],
   "source": [
    "clfs = []\n",
    "for i in range(15):\n",
    "    clf = xgb.XGBClassifier(random_state=217+i, n_estimators=300, learning_rate=0.15, h_jobs=4, **opt_parameters)\n",
    "    clfs.append(('xgb{}'.format(i), clf))\n",
    "\n",
    "vc = VotingClassifierLGBM(clfs, voting='soft')\n",
    "del clfs\n",
    "\n",
    "_ = vc.fit(x_train.drop(xgb_drop_cols, axis=1), y_train, sample_weight=y_train_weights, threshold=False, **fit_params)\n",
    "clf_final = vc.estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T09:11:45.805409Z",
     "iopub.status.busy": "2021-02-08T09:11:45.804412Z",
     "iopub.status.idle": "2021-02-08T09:11:46.180937Z",
     "shell.execute_reply": "2021-02-08T09:11:46.179940Z",
     "shell.execute_reply.started": "2021-02-08T09:11:45.805409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score of a single LGBM Classifier: 0.8367\n",
      "Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: 0.9055\n",
      "Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: 0.9176\n"
     ]
    }
   ],
   "source": [
    "global_score = f1_score(y_test, clf_final.predict(x_test.drop(xgb_drop_cols, axis=1)), average='macro')\n",
    "print('Validation score of a single LGBM Classifier: {:.4f}'.format(global_score))\n",
    "\n",
    "vc.voting = 'soft'\n",
    "global_score_soft = f1_score(y_test, vc.predict(x_test.drop(xgb_drop_cols, axis=1)), average='macro')\n",
    "print('Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: {:.4f}'.format(global_score_soft))\n",
    "\n",
    "vc.voting = 'hard'\n",
    "global_score_soft = f1_score(y_test, vc.predict(x_test.drop(xgb_drop_cols, axis=1)), average='macro')\n",
    "print('Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: {:.4f}'.format(global_score_soft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T09:11:53.348048Z",
     "iopub.status.busy": "2021-02-08T09:11:53.348048Z",
     "iopub.status.idle": "2021-02-08T09:11:55.244504Z",
     "shell.execute_reply": "2021-02-08T09:11:55.243540Z",
     "shell.execute_reply.started": "2021-02-08T09:11:53.348048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agg18_estadocivil5_COUNT', 'geo_energcocinar_LE_0', 'geo_epared_LE_2'}"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useless_features = []\n",
    "drop_features = set()\n",
    "counter = 0\n",
    "for est in vc.estimators_:\n",
    "    ranked_features, unused_features = feature_importance(est, x_train.drop(xgb_drop_cols, axis=1), display_results=False)\n",
    "    useless_features.append(unused_features)\n",
    "    if counter == 0:\n",
    "        drop_features = set(unused_features)\n",
    "    else:\n",
    "        drop_features = drop_features.intersection(set(unused_features))\n",
    "    counter += 1\n",
    "\n",
    "drop_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T09:11:58.077058Z",
     "iopub.status.busy": "2021-02-08T09:11:58.077058Z",
     "iopub.status.idle": "2021-02-08T09:11:58.249595Z",
     "shell.execute_reply": "2021-02-08T09:11:58.248598Z",
     "shell.execute_reply.started": "2021-02-08T09:11:58.077058Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 59 (0.020225) - agg18_escolari_MAX\n",
      "2. feature 74 (0.017963) - agg18_parentesco2_MEAN\n",
      "3. feature 17 (0.017889) - male\n",
      "4. feature 42 (0.017873) - fe_children_fraction\n",
      "5. feature 60 (0.014787) - agg18_escolari_MEAN\n",
      "6. feature 111 (0.013076) - geo_etecho_LE_0\n",
      "7. feature 100 (0.012871) - geo_age\n",
      "8. feature 129 (0.012395) - geo_manual_elec_LE_1\n",
      "9. feature 110 (0.012376) - geo_eviv_LE_2\n",
      "10. feature 101 (0.011999) - geo_meaneduc\n",
      "11. feature 97 (0.011980) - lugar_LE\n",
      "12. feature 40 (0.011299) - SQBdependency\n",
      "13. feature 49 (0.011270) - fe_mobile_density\n",
      "14. feature 112 (0.010889) - geo_etecho_LE_1\n",
      "15. feature 69 (0.010647) - agg18_estadocivil5_MEAN\n",
      "16. feature 117 (0.010591) - geo_elimbasu_LE_1\n",
      "17. feature 12 (0.010582) - r4t1\n",
      "18. feature 41 (0.009625) - SQBmeaned\n",
      "19. feature 32 (0.009536) - area2\n",
      "20. feature 128 (0.009521) - geo_manual_elec_LE_0\n",
      "21. feature 52 (0.009370) - fe_tablet_adult_density\n",
      "22. feature 98 (0.009328) - tipovivi_LE\n",
      "23. feature 37 (0.009307) - SQBedjefe\n",
      "24. feature 125 (0.009280) - geo_sanitario_LE_2\n",
      "25. feature 51 (0.009229) - fe_mobile_adult_density\n",
      "26. feature 5 (0.009075) - v18q1\n",
      "27. feature 34 (0.009063) - SQBescolari\n",
      "28. feature 55 (0.009047) - agg18_age_MIN\n",
      "29. feature 22 (0.009017) - dependency\n",
      "30. feature 94 (0.009009) - etecho_LE\n",
      "31. feature 20 (0.008865) - hogar_mayor\n",
      "32. feature 6 (0.008752) - r4h1\n",
      "33. feature 102 (0.008748) - geo_dependency\n",
      "34. feature 62 (0.008740) - agg18_estadocivil1_COUNT\n",
      "35. feature 107 (0.008638) - geo_overcrowding\n",
      "36. feature 21 (0.008638) - hogar_total\n",
      "37. feature 85 (0.008631) - edjef\n",
      "38. feature 93 (0.008450) - epared_LE\n",
      "39. feature 39 (0.008430) - SQBovercrowding\n",
      "40. feature 95 (0.008416) - eviv_LE\n",
      "41. feature 116 (0.008411) - geo_elimbasu_LE_0\n",
      "42. feature 36 (0.008408) - SQBhogar_total\n",
      "43. feature 29 (0.008404) - television\n",
      "44. feature 87 (0.008370) - piso_LE\n",
      "45. feature 13 (0.008358) - r4t2\n",
      "46. feature 26 (0.008349) - bedrooms\n",
      "47. feature 137 (0.008301) - rent_to_rooms\n",
      "48. feature 7 (0.008271) - r4h2\n",
      "49. feature 25 (0.008238) - meaneduc\n",
      "50. feature 38 (0.008228) - SQBhogar_nin\n",
      "51. feature 86 (0.008059) - pared_LE\n",
      "52. feature 106 (0.008051) - geo_bedrooms\n",
      "53. feature 31 (0.007926) - area1\n",
      "54. feature 96 (0.007788) - estadocivil_LE\n",
      "55. feature 14 (0.007787) - escolari\n",
      "56. feature 3 (0.007758) - hacapo\n",
      "57. feature 4 (0.007748) - refrig\n",
      "58. feature 99 (0.007720) - manual_elec_LE\n",
      "59. feature 27 (0.007674) - overcrowding\n",
      "60. feature 33 (0.007635) - age\n",
      "61. feature 65 (0.007633) - agg18_estadocivil3_MEAN\n",
      "62. feature 23 (0.007508) - edjefe\n",
      "63. feature 11 (0.007502) - r4m3\n",
      "64. feature 57 (0.007496) - agg18_age_MEAN\n",
      "65. feature 58 (0.007431) - agg18_escolari_MIN\n",
      "66. feature 43 (0.007386) - fe_working_man_fraction\n",
      "67. feature 119 (0.007365) - geo_elimbasu_LE_3\n",
      "68. feature 105 (0.007291) - geo_hogar_total\n",
      "69. feature 123 (0.007244) - geo_sanitario_LE_0\n",
      "70. feature 30 (0.007239) - qmobilephone\n",
      "71. feature 47 (0.007234) - fe_rent_per_person\n",
      "72. feature 136 (0.007229) - bedroom_to_rooms\n",
      "73. feature 2 (0.007207) - rooms\n",
      "74. feature 91 (0.007189) - energcocinar_LE\n",
      "75. feature 15 (0.007172) - cielorazo\n",
      "76. feature 122 (0.007160) - geo_energcocinar_LE_3\n",
      "77. feature 90 (0.007119) - sanitario_LE\n",
      "78. feature 104 (0.007090) - geo_hogar_adul\n",
      "79. feature 1 (0.007050) - hacdor\n",
      "80. feature 63 (0.007046) - agg18_estadocivil2_MEAN\n",
      "81. feature 45 (0.007020) - fe_human_density\n",
      "82. feature 61 (0.007013) - agg18_dis_MEAN\n",
      "83. feature 24 (0.006987) - edjefa\n",
      "84. feature 35 (0.006970) - SQBage\n",
      "85. feature 124 (0.006935) - geo_sanitario_LE_1\n",
      "86. feature 120 (0.006905) - geo_elimbasu_LE_5\n",
      "87. feature 109 (0.006887) - geo_eviv_LE_1\n",
      "88. feature 126 (0.006877) - geo_sanitario_LE_3\n",
      "89. feature 10 (0.006867) - r4m2\n",
      "90. feature 19 (0.006866) - hogar_adul\n",
      "91. feature 143 (0.006857) - hhsize_to_rooms\n",
      "92. feature 9 (0.006660) - r4m1\n",
      "93. feature 72 (0.006544) - agg18_estadocivil7_MEAN\n",
      "94. feature 44 (0.006365) - fe_all_man_fraction\n",
      "95. feature 145 (0.006358) - rent_to_over_18\n",
      "96. feature 71 (0.006239) - agg18_estadocivil6_MEAN\n",
      "97. feature 140 (0.006238) - r4t3_to_rooms\n",
      "98. feature 56 (0.006154) - agg18_age_MAX\n",
      "99. feature 50 (0.006143) - fe_tablet_density\n",
      "100. feature 92 (0.006134) - elimbasu_LE\n",
      "101. feature 0 (0.006058) - v2a1\n",
      "102. feature 18 (0.005987) - hogar_nin\n",
      "103. feature 16 (0.005835) - dis\n",
      "104. feature 138 (0.005812) - tamhog_to_rooms\n",
      "105. feature 8 (0.005701) - r4h3\n",
      "106. feature 48 (0.005541) - fe_rent_per_room\n",
      "107. feature 77 (0.005375) - agg18_parentesco5_MEAN\n",
      "108. feature 78 (0.005279) - agg18_parentesco6_MEAN\n",
      "109. feature 28 (0.005259) - computer\n",
      "110. feature 133 (0.005128) - geo_pared_LE_1\n",
      "111. feature 75 (0.005118) - agg18_parentesco3_MEAN\n",
      "112. feature 131 (0.004984) - geo_manual_elec_LE_4\n",
      "113. feature 89 (0.004809) - abastagua_LE\n",
      "114. feature 114 (0.004807) - geo_epared_LE_1\n",
      "115. feature 46 (0.004806) - fe_human_bed_density\n",
      "116. feature 141 (0.004707) - v2a1_to_r4t3\n",
      "117. feature 142 (0.004445) - v2a1_to_under_12\n",
      "118. feature 67 (0.004393) - agg18_estadocivil4_MEAN\n",
      "119. feature 88 (0.004202) - techo_LE\n",
      "120. feature 81 (0.004176) - agg18_parentesco9_MEAN\n",
      "121. feature 113 (0.004168) - geo_etecho_LE_2\n",
      "122. feature 53 (0.003496) - fe_people_not_living\n",
      "123. feature 144 (0.002404) - rent_to_hhsize\n",
      "124. feature 84 (0.002354) - agg18_parentesco12_MEAN\n",
      "125. feature 64 (0.002276) - agg18_estadocivil2_COUNT\n",
      "126. feature 83 (0.002249) - agg18_parentesco11_MEAN\n",
      "127. feature 80 (0.001932) - agg18_parentesco8_MEAN\n",
      "128. feature 79 (0.001652) - agg18_parentesco7_MEAN\n",
      "129. feature 76 (0.001530) - agg18_parentesco4_MEAN\n",
      "130. feature 108 (0.000000) - geo_eviv_LE_0\n",
      "131. feature 68 (0.000000) - agg18_estadocivil4_COUNT\n",
      "132. feature 70 (0.000000) - agg18_estadocivil5_COUNT\n",
      "133. feature 73 (0.000000) - agg18_parentesco1_MEAN\n",
      "134. feature 139 (0.000000) - r4t3_to_tamhog\n",
      "135. feature 135 (0.000000) - geo_pared_LE_7\n",
      "136. feature 134 (0.000000) - geo_pared_LE_2\n",
      "137. feature 132 (0.000000) - geo_pared_LE_0\n",
      "138. feature 66 (0.000000) - agg18_estadocivil3_COUNT\n",
      "139. feature 82 (0.000000) - agg18_parentesco10_MEAN\n",
      "140. feature 130 (0.000000) - geo_manual_elec_LE_3\n",
      "141. feature 127 (0.000000) - geo_sanitario_LE_4\n",
      "142. feature 121 (0.000000) - geo_energcocinar_LE_0\n",
      "143. feature 118 (0.000000) - geo_elimbasu_LE_2\n",
      "144. feature 115 (0.000000) - geo_epared_LE_2\n",
      "145. feature 54 (0.000000) - fe_people_weird_stat\n",
      "146. feature 103 (0.000000) - geo_hogar_nin\n"
     ]
    }
   ],
   "source": [
    "ranked_features = feature_importance(clf_final, x_train.drop(xgb_drop_cols, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T09:12:03.327412Z",
     "iopub.status.busy": "2021-02-08T09:12:03.327412Z",
     "iopub.status.idle": "2021-02-08T09:12:03.335390Z",
     "shell.execute_reply": "2021-02-08T09:12:03.334403Z",
     "shell.execute_reply.started": "2021-02-08T09:12:03.327412Z"
    }
   },
   "outputs": [],
   "source": [
    "et_drop_cols = [\n",
    "    'agg18_age_MAX', 'agg18_age_MEAN', 'agg18_age_MIN', 'agg18_dis_MEAN',\n",
    "    'agg18_escolari_MAX', 'agg18_escolari_MEAN', 'agg18_escolari_MIN',\n",
    "    'agg18_estadocivil1_COUNT', 'agg18_estadocivil1_MEAN',\n",
    "    'agg18_estadocivil2_COUNT', 'agg18_estadocivil2_MEAN',\n",
    "    'agg18_estadocivil3_COUNT', 'agg18_estadocivil3_MEAN',\n",
    "    'agg18_estadocivil4_COUNT', 'agg18_estadocivil4_MEAN',\n",
    "    'agg18_estadocivil5_COUNT', 'agg18_estadocivil5_MEAN',\n",
    "    'agg18_estadocivil6_COUNT', 'agg18_estadocivil6_MEAN',\n",
    "    'agg18_estadocivil7_COUNT', 'agg18_estadocivil7_MEAN',\n",
    "    'agg18_parentesco10_COUNT', 'agg18_parentesco10_MEAN',\n",
    "    'agg18_parentesco11_COUNT', 'agg18_parentesco11_MEAN',\n",
    "    'agg18_parentesco12_COUNT', 'agg18_parentesco12_MEAN',\n",
    "    'agg18_parentesco1_COUNT', 'agg18_parentesco1_MEAN',\n",
    "    'agg18_parentesco2_COUNT', 'agg18_parentesco2_MEAN',\n",
    "    'agg18_parentesco3_COUNT', 'agg18_parentesco3_MEAN',\n",
    "    'agg18_parentesco4_COUNT', 'agg18_parentesco4_MEAN',\n",
    "    'agg18_parentesco5_COUNT', 'agg18_parentesco5_MEAN',\n",
    "    'agg18_parentesco6_COUNT', 'agg18_parentesco6_MEAN',\n",
    "    'agg18_parentesco7_COUNT', 'agg18_parentesco7_MEAN',\n",
    "    'agg18_parentesco8_COUNT', 'agg18_parentesco8_MEAN',\n",
    "    'agg18_parentesco9_COUNT', 'agg18_parentesco9_MEAN'\n",
    "]\n",
    "et_drop_cols.extend([\n",
    "    'idhogar', 'parentesco1', 'fe_rent_per_person', 'fe_rent_per_room',\n",
    "    'fe_tablet_adult_density', 'fe_tablet_density'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T09:12:21.290203Z",
     "iopub.status.busy": "2021-02-08T09:12:21.290203Z",
     "iopub.status.idle": "2021-02-08T09:12:45.792615Z",
     "shell.execute_reply": "2021-02-08T09:12:45.791618Z",
     "shell.execute_reply.started": "2021-02-08T09:12:21.290203Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.8967053028831977\n",
      "Test F1: 0.4415984453281717\n",
      "Train F1: 0.8895165722836282\n",
      "Test F1: 0.425542097614492\n",
      "Train F1: 0.8966419931929255\n",
      "Test F1: 0.4042115261132996\n",
      "Train F1: 0.8948606285884819\n",
      "Test F1: 0.44192363902082576\n",
      "Train F1: 0.8971289703135341\n",
      "Test F1: 0.3761610570281515\n",
      "Train F1: 0.8879124321976221\n",
      "Test F1: 0.4182277668373249\n",
      "Train F1: 0.8884395609577884\n",
      "Test F1: 0.39850654650738626\n",
      "Train F1: 0.8924923382778056\n",
      "Test F1: 0.4412403268965936\n",
      "Train F1: 0.890453876137964\n",
      "Test F1: 0.4314992204062239\n",
      "Train F1: 0.8966033200269068\n",
      "Test F1: 0.4287285338189526\n"
     ]
    }
   ],
   "source": [
    "# 반복\n",
    "ets = []\n",
    "for i in range(10):\n",
    "    rf = RandomForestClassifier(\n",
    "        max_depth=None, random_state=217+i, n_jobs=4, n_estimators=700,\n",
    "        min_impurity_decrease=1e-3, min_samples_leaf=2, verbose=0, class_weight='balanced'\n",
    "    )\n",
    "    ets.append(('rf{}'.format(i), rf))\n",
    "\n",
    "vc2 = VotingClassifierLGBM(ets, voting='soft')\n",
    "_ = vc2.fit(x_train.drop(et_drop_cols, axis=1), y_train, threshold=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T09:12:45.793613Z",
     "iopub.status.busy": "2021-02-08T09:12:45.793613Z",
     "iopub.status.idle": "2021-02-08T09:12:49.068287Z",
     "shell.execute_reply": "2021-02-08T09:12:49.067289Z",
     "shell.execute_reply.started": "2021-02-08T09:12:45.793613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: 0.8864\n",
      "Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: 0.8957\n"
     ]
    }
   ],
   "source": [
    "vc2.voting = 'soft'\n",
    "global_rf_score_soft = f1_score(y_test, vc2.predict(x_test.drop(et_drop_cols, axis=1)), average='macro')\n",
    "print('Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: {:.4f}'.format(global_rf_score_soft))\n",
    "\n",
    "vc2.voting = 'hard'\n",
    "global_rf_score_hard = f1_score(y_test, vc2.predict(x_test.drop(et_drop_cols, axis=1)), average='macro')\n",
    "print('Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: {:.4f}'.format(global_rf_score_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T09:13:10.375936Z",
     "iopub.status.busy": "2021-02-08T09:13:10.374939Z",
     "iopub.status.idle": "2021-02-08T09:13:11.376498Z",
     "shell.execute_reply": "2021-02-08T09:13:11.375511Z",
     "shell.execute_reply.started": "2021-02-08T09:13:10.375936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parentesco_LE', 'rez_esc'}"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useless_features = []\n",
    "drop_features = set()\n",
    "counter = 0\n",
    "for est in vc2.estimators_:\n",
    "    ranked_features, unused_features = feature_importance(est, x_train.drop(et_drop_cols, axis=1), display_results=False)\n",
    "    useless_features.append(unused_features)\n",
    "    if counter == 0:\n",
    "        drop_features = set(unused_features)\n",
    "    else:\n",
    "        drop_features = drop_features.intersection(set(unused_features))\n",
    "    counter += 1\n",
    "\n",
    "drop_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T09:13:15.901331Z",
     "iopub.status.busy": "2021-02-08T09:13:15.901331Z",
     "iopub.status.idle": "2021-02-08T09:13:15.908312Z",
     "shell.execute_reply": "2021-02-08T09:13:15.907315Z",
     "shell.execute_reply.started": "2021-02-08T09:13:15.901331Z"
    }
   },
   "outputs": [],
   "source": [
    "def combine_voters(data, weights=[0.5, 0.5]):\n",
    "    vc.voting = 'soft'\n",
    "    vc1_probs = vc.predict_proba(data.drop(xgb_drop_cols, axis=1))\n",
    "    \n",
    "    vc2.voting = 'soft'\n",
    "    vc2_probs = vc2.predict_proba(data.drop(et_drop_cols, axis=1))\n",
    "    \n",
    "    final_vote = (vc1_probs * weights[0]) + (vc2_probs * weights[1])\n",
    "    predictions = np.argmax(final_vote, axis=1)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T09:13:25.772331Z",
     "iopub.status.busy": "2021-02-08T09:13:25.772331Z",
     "iopub.status.idle": "2021-02-08T09:13:27.226688Z",
     "shell.execute_reply": "2021-02-08T09:13:27.225691Z",
     "shell.execute_reply.started": "2021-02-08T09:13:25.772331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9086853371310112"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_preds = combine_voters(x_test, weights=[0.5, 0.5])\n",
    "global_combo_score_soft = f1_score(y_test, combo_preds, average='macro')\n",
    "global_combo_score_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T09:13:45.029138Z",
     "iopub.status.busy": "2021-02-08T09:13:45.029138Z",
     "iopub.status.idle": "2021-02-08T09:13:46.667492Z",
     "shell.execute_reply": "2021-02-08T09:13:46.667492Z",
     "shell.execute_reply.started": "2021-02-08T09:13:45.029138Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9132077555154477"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_preds = combine_voters(x_test, weights=[0.4, 0.6])\n",
    "global_combo_score_soft = f1_score(y_test, combo_preds, average='macro')\n",
    "global_combo_score_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T09:13:40.797081Z",
     "iopub.status.busy": "2021-02-08T09:13:40.797081Z",
     "iopub.status.idle": "2021-02-08T09:13:42.497784Z",
     "shell.execute_reply": "2021-02-08T09:13:42.496787Z",
     "shell.execute_reply.started": "2021-02-08T09:13:40.797081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9031594390425502"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_preds = combine_voters(x_test, weights=[0.6, 0.4])\n",
    "global_combo_score_soft = f1_score(y_test, combo_preds, average='macro')\n",
    "global_combo_score_soft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T09:13:50.275181Z",
     "iopub.status.busy": "2021-02-08T09:13:50.274183Z",
     "iopub.status.idle": "2021-02-08T09:13:50.286152Z",
     "shell.execute_reply": "2021-02-08T09:13:50.285157Z",
     "shell.execute_reply.started": "2021-02-08T09:13:50.275181Z"
    }
   },
   "outputs": [],
   "source": [
    "y_subm = pd.DataFrame()\n",
    "y_subm['Id'] = test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T09:13:52.229462Z",
     "iopub.status.busy": "2021-02-08T09:13:52.229462Z",
     "iopub.status.idle": "2021-02-08T09:14:15.785829Z",
     "shell.execute_reply": "2021-02-08T09:14:15.785829Z",
     "shell.execute_reply.started": "2021-02-08T09:13:52.229462Z"
    }
   },
   "outputs": [],
   "source": [
    "vc.voting = 'soft'\n",
    "y_subm_lgb = y_subm.copy(deep=True)\n",
    "y_subm_lgb['Target'] = vc.predict(test.drop(xgb_drop_cols, axis=1)) + 1\n",
    "\n",
    "vc2.voting = 'soft'\n",
    "y_subm_rf = y_subm.copy(deep=True)\n",
    "y_subm_rf['Target'] = vc2.predict(test.drop(et_drop_cols, axis=1)) + 1\n",
    "\n",
    "y_subm_ens = y_subm.copy(deep=True)\n",
    "y_subm_ens['Target'] = combine_voters(test) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-08T09:14:15.787823Z",
     "iopub.status.busy": "2021-02-08T09:14:15.786825Z",
     "iopub.status.idle": "2021-02-08T09:14:16.025188Z",
     "shell.execute_reply": "2021-02-08T09:14:16.024192Z",
     "shell.execute_reply.started": "2021-02-08T09:14:15.787823Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "\n",
    "sub_file_lgb = 'data/submission_3_soft_XGB_{:.4f}_{}.csv'.format(global_score_soft, str(now.strftime('%Y-%m-%d-%H-%M')))\n",
    "sub_file_rf = 'data/submission_3_soft_RF_{:.4f}_{}.csv'.format(global_rf_score_soft, str(now.strftime('%Y-%m-%d-%H-%M')))\n",
    "sub_file_ens = 'data/submission_3_soft_ens_{:.4f}_{}.csv'.format(global_combo_score_soft, str(now.strftime('%Y-%m-%d-%H-%M')))\n",
    "\n",
    "y_subm_lgb.to_csv(sub_file_lgb, index=False)\n",
    "y_subm_rf.to_csv(sub_file_rf, index=False)\n",
    "y_subm_ens.to_csv(sub_file_ens, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
