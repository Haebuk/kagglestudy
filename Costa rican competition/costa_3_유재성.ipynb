{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1회차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LightGBM 모델은 XGBoost로 대체되었으며 그에 따라 코드가 업데이트됐습니다.\n",
    "- 또한 랜덤 포레스트의 투표 분류기를 장착하고 XGB의 결과를 RF와 결합합니다.\n",
    "- 데이터를 한 번 쪼개서 LGBM 조기 정지에 대한 검증 데이터를 사용하는 대신 전체 교육 세트를 훈련할 수 있도록 교육 중 데이터를 분할했습니다. 이것이 이 케이스에서 kfold 분할보다 더 효과가 있음을 발견했습니다.\n",
    "\n",
    "- 이 커널은 하이퍼 파라미터 최적화를 실행하는 대신 해당 커널의 최적값을 사용하여 더 빨리 실행됩니다.\n",
    "\n",
    "- __몇 가지 주요 요점은 다음과 같습니다.__:\n",
    "    - 이 커널은 가장에 대해서만 교육을 실행합니다. \n",
    "    - 클래스 크기의 균형을 맞추는 것이 매우 중요해보입니다. 이는 수작업으로 할 수 있고, 언더 샘플링으로 달성할 수 있습니다. 그러나 sklearn API의 LGBM 모델 생성자에 `class_weight='balance'`을 설정하는 것이 가장 간단합니다.\n",
    "    - 이 커널은 매크로 F1점수를 사용하여 교육을 조기 중단합니다. \n",
    "    - 범주는 블라인드 레이블 인코딩 대신 적절한 매핑을 가진 숫자로 바뀝니다.\n",
    "    - OHE를 라벨 인코딩으로 반전시키면, 트리 모델에 더 적합할 수 있으나 , 논트리 모델에는 안 좋을 수 있으니 유의해야합니다.\n",
    "    - `idhogar`는 훈련에서 사용되지 않습니다. 정보가 있을 수 있는 유일한 방법은 데이터 누출입니다. \n",
    "    - 가구 내에서 집계가 이루어지며 새로운 기능은 수작업으로 제작됩니다. 대부분의 기능이 이미 가정 수준에서 인용되었기 때문에 집계할 수 있는 기능이 많지 않습니다.\n",
    "    - 투표 분류기는 여러 LGBM 모델에서 평균을 내는데 사용됩니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T02:32:27.826147Z",
     "start_time": "2021-02-08T02:32:19.954252Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import VotingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.utils import class_weight\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T02:32:27.850082Z",
     "start_time": "2021-02-08T02:32:27.832131Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# this only transforms the idhogar field, the other things this function used to do are done elsewhere\n",
    "# 단지 idhogar만을 변환합니다. 이 함수가 사용하던 다른 것들은 다른 곳에서 행해집니다.\n",
    "\n",
    "def encode_data(df):\n",
    "    df['idhogar'] = LabelEncoder().fit_transform(df['idhogar'])\n",
    "    \n",
    "# Plot feature importance for sklearn decision trees\n",
    "def feature_importance(forest, X_train, display_results=True):\n",
    "    ranked_list = []\n",
    "    zero_features = []\n",
    "\n",
    "    importances = forest.feature_importances_\n",
    "    \n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    if display_results:\n",
    "        # Print the feature ranking\n",
    "        print('Feature ranking:')\n",
    "        \n",
    "    for f in range(X_train.shape[1]):\n",
    "        if display_results:\n",
    "            print('%d. feature %d (%f)' % (f+1, indices[f], importances[indices[f]]) + \n",
    "                 ' - ' + X_train.columns[indices[f]])\n",
    "            \n",
    "            ranked_list.append(X_train.columns[indices[f]])\n",
    "            \n",
    "            if importances[indices[f]] == 0.0:\n",
    "                zero_features.append(X_train.columns[indices[f]])\n",
    "                \n",
    "    return ranked_list, zero_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T02:32:27.883109Z",
     "start_time": "2021-02-08T02:32:27.856068Z"
    }
   },
   "outputs": [],
   "source": [
    "def do_features(df):\n",
    "    feats_div = [('children_fraction', 'r4t1', 'r4t3'),\n",
    "                ('working_man_fraction', 'r4h2', 'r4t3'),\n",
    "                ('all_man_fraction', 'r4h3', 'r4t3'),\n",
    "                ('human_density', 'tamviv', 'rooms'),\n",
    "                ('human_bed_density', 'tamviv', 'bedrooms'),\n",
    "                ('rent_per_person', 'v2a1', 'r4t3'),\n",
    "                ('rent_per_room', 'v2a1', 'rooms'),\n",
    "                ('mobile_density', 'qmobilephone', 'r4t3'),\n",
    "                ('tablet_density', 'v18q1', 'r4t3'),\n",
    "                ('mobile_adult_density', 'qmobilephone', 'r4t2'),\n",
    "                ('tablet_adult_density', 'v18q1', 'r4t2')]\n",
    "    \n",
    "    feats_sub = [('people_not_living', 'tamhog', 'tamviv'),\n",
    "                ('people_weird_stat', 'tamhog', 'r4t3')]\n",
    "    \n",
    "    for f_new, f1, f2 in feats_div:\n",
    "        df['fe_' + f_new] = (df[f1] / df[f2]).astype(np.float32)\n",
    "    for f_new, f1, f2 in feats_sub:\n",
    "        df['fe_' + f_new] = (df[f1] - df[f2]).astype(np.float32)\n",
    "        \n",
    "    # aggregation rules over household\n",
    "    aggs_num = {'age': ['min', 'max', 'mean'],\n",
    "               'escolari': ['min', 'max', 'mean']}\n",
    "    \n",
    "    aggs_cat = {'dis': ['mean']}\n",
    "    for s_ in ['estadocivil', 'parenteso', 'instlevel']:\n",
    "        for f_ in [f_ for f_ in df.columns if f_.startswith(s_)]:\n",
    "            aggs_cat[f_] = ['mean', 'count']\n",
    "            \n",
    "    # aggregation over household\n",
    "    for name_, df_ in [('18', df.query('age >= 18'))]:\n",
    "        df_agg = df_.groupby('idhogar').agg({**aggs_num, **aggs_cat}).astype(np.float32)\n",
    "        df_agg.columns = pd.Index(['agg' + name_ + '_' + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n",
    "        df = df.join(df_agg, how='left', on='idhogar')\n",
    "        del df_agg\n",
    "        \n",
    "    # Drop id's\n",
    "    df.drop(['Id'], axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data and clean it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T02:32:28.815503Z",
     "start_time": "2021-02-08T02:32:27.892969Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/test.csv')\n",
    "\n",
    "test_ids = test.Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T02:32:29.688167Z",
     "start_time": "2021-02-08T02:32:28.820489Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_df(df_):\n",
    "    # encode the idhogar\n",
    "    encode_data(df_)\n",
    "    \n",
    "    # create aggregate features\n",
    "    return do_features(df_)\n",
    "\n",
    "train = process_df(train)\n",
    "test = process_df(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측치를 정리하고 오브젝트를 숫자형으로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T02:38:18.422662Z",
     "start_time": "2021-02-08T02:38:17.899829Z"
    }
   },
   "outputs": [],
   "source": [
    "# Some dependencies are Na, fill those with the square root of the square\n",
    "train['dependency'] = np.sqrt(train['SQBdependency'])\n",
    "test['dependency'] = np.sqrt(test['SQBdependency'])\n",
    "\n",
    "# fill 'no's for education with 0s\n",
    "train.loc[train['edjefa'] == 'no', 'edjefa'] = 0\n",
    "train.loc[train['edjefe'] == 'no', 'edjefe'] = 0\n",
    "test.loc[test['edjefa'] == 'no', 'edjefa'] = 0\n",
    "test.loc[test['edjefe'] == 'no', 'edjefe'] = 0\n",
    "\n",
    "# if education is 'yes' and person is head of household, fill with escolari\n",
    "train.loc[(train['edjefa'] == 'yes') & (train['parentesco1'] == 1), 'edjefa'] = train.loc[(train['edjefa'] == 'yes') & (train['parentesco1'] == 1), 'escolari']\n",
    "train.loc[(train['edjefe'] == 'yes') & (train['parentesco1'] == 1), 'edjefe'] = train.loc[(train['edjefe'] == 'yes') & (train['parentesco1'] == 1), 'escolari']\n",
    "\n",
    "test.loc[(test['edjefa'] == 'yes') & (test['parentesco1'] == 1), 'edjefa'] = test.loc[(test['edjefa'] == 'yes') & (test['parentesco1'] == 1), 'escolari']\n",
    "test.loc[(test['edjefe'] == 'yes') & (test['parentesco1'] == 1), 'edjefe'] = test.loc[(test['edjefe'] == 'yes') & (test['parentesco1'] == 1), 'escolari']\n",
    "\n",
    "# this field is supposed to be interaction between gender and escolari, but it isn't clear what 'yes' means. let's fill it with 4\n",
    "train.loc[train['edjefa'] == 'yes', 'edjefa'] = 4\n",
    "train.loc[train['edjefe'] == 'yes', 'edjefe'] = 4\n",
    "\n",
    "test.loc[test['edjefa'] == 'yes', 'edjefa'] = 4\n",
    "test.loc[test['edjefe'] == 'yes', 'edjefe'] = 4\n",
    "\n",
    "# Convert to int for our models\n",
    "train['edjefe'] = train['edjefe'].astype('int')\n",
    "train['edjefa'] = train['edjefa'].astype('int')\n",
    "test['edjefe'] = test['edjefe'].astype('int')\n",
    "test['edjefa'] = test['edjefa'].astype('int')\n",
    "\n",
    "# create feature with max education of either head of household\n",
    "train['edjef'] = np.max(train[['edjefa', 'edjefe']], axis=1)\n",
    "test['edjef'] = np.max(test[['edjefa', 'edjefe']], axis=1)\n",
    "\n",
    "# fill some nas\n",
    "train['v2a1'] = train['v2a1'].fillna(0)\n",
    "test['v2a1'] = test['v2a1'].fillna(0)\n",
    "\n",
    "train['v18q1'] = train['v18q1'].fillna(0)\n",
    "test['v18q1'] = test['v18q1'].fillna(0)\n",
    "\n",
    "train['rez_esc'] = train['rez_esc'].fillna(0)\n",
    "test['rez_esc'] = test['rez_esc'].fillna(0)\n",
    "\n",
    "train.loc[train.meaneduc.isnull(), 'meaneduc'] = 0\n",
    "train.loc[train.SQBmeaned.isnull(), 'SQBmeaned'] = 0\n",
    "\n",
    "test.loc[test.meaneduc.isnull(), 'meaneduc'] = 0\n",
    "test.loc[test.SQBmeaned.isnull(), 'SQBmeaned'] = 0\n",
    "\n",
    "# fix some inconsistencies in the data - some rows indicate both that the household does and does not not have a toilet,\n",
    "# if there is no water we'll assume they do not\n",
    "train.loc[(train.v14a == 1) & (train.sanitario1 == 1) & (train.abastaguano == 0), 'v14a'] = 0\n",
    "train.loc[(train.v14a == 1) & (train.sanitario1 == 1) & (train.abastaguano == 0), 'sanitario'] = 0\n",
    "\n",
    "test.loc[(test.v14a == 1) & (test.sanitario1 == 1) & (test.abastaguano == 0), 'v14a'] = 0\n",
    "test.loc[(test.v14a == 1) & (test.sanitario1 == 1) & (test.abastaguano == 0), 'sanitario'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T02:39:45.683329Z",
     "start_time": "2021-02-08T02:39:45.676350Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_apply_func(train_, test_, func_):\n",
    "    test_['Target'] = 0\n",
    "    xx = pd.concat([train_, test_])\n",
    "    \n",
    "    xx_func = func_(xx)\n",
    "    train_ = xx_func.iloc[:train_.shape[0], :]\n",
    "    test_ = xx_func.iloc[train_.shape[0]:, :].drop('Target', axis=1)\n",
    "    \n",
    "    del xx, xx_func\n",
    "    return train_, test_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T02:40:21.621273Z",
     "start_time": "2021-02-08T02:40:20.685743Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convert_OHE2LE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-8d01f1d3c226>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# convert the one hot fields into label encoded\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_apply_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_OHE2LE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'convert_OHE2LE' is not defined"
     ]
    }
   ],
   "source": [
    "# convert the one hot fields into label encoded\n",
    "train, test = train_test_apply_func(train, test, convert_OHE2LE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
