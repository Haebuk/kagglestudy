{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kaggle study 26일차(tensorflow recognition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드출처 :https://www.kaggle.com/ivallesp/wavception-v1-a-1-d-inception-approach-lb-0-76"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WavCeption V1: just a 1-D Inception approach\n",
    "저는 제가 가지고 놀던 작은 장난감을 공유하고 싶었을 뿐이고, 놀라운 결과를 주었습니다. 저는 현재 시간이 없기 때문에, 사람들이 어떻게 그것을 가지고 노는지를 보기 위해 그것을 공유하고 싶습니다:-D. WaveCeption V1 네트워크는 일반 컨볼루션 신경망에 비해 인상적인 결과를 내는 것처럼 보이지만, 이번 대회에서는 전처리 및 알려지지 않은 트랙 관리에 대한 힘든 작업이 진행 중인 것으로 보입니다. 구글의 인셉션 네트워크에 기반을 두고 있습니다. 같은 생각이죠.\n",
    "\n",
    "저는 몇 주 전에 이 모듈들을 캐스케이드(아래 참조)로 연결하여 쉽게 1D 인셉션 네트워크를 구축할 수 있도록 이 모듈을 구현하는 모듈을 작성했습니다.\n",
    "\n",
    "불행히도 여러 가지 Kaggle 제약으로 인해 커널 시스템에서 실행되지 않으므로, 직접 다운로드하여 실행하는 것이 좋습니다.\n",
    "\n",
    "너무 무리하지 않고 12시간 동안 모델을 실행함으로써 리더보드에서 0.76을 달성했습니다(현지 테스트에서는 0.84). 같은 계열의 다른 실험에서는 0.89점을 주기도 했습니다. 그래서 미지의 클립을 다루는 방법이 크게 개선되었습니다:-D.\n",
    "\n",
    "### Load modules and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T07:17:57.403659Z",
     "start_time": "2021-02-22T07:17:57.362766Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import IPython\n",
    "from numpy.fft import rfft, irfft\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise generation functions\n",
    "이 섹션의 코드는 다음 링크에서 차용 및 개조되었습니다. : https://github.com/python-acoustics/python-acoustics/blob/master/acoustics/generator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T02:44:37.332052Z",
     "start_time": "2021-02-22T02:44:37.267221Z"
    }
   },
   "outputs": [],
   "source": [
    "def ms(x):\n",
    "    \"\"\"signal x의 제곱의 평균 값입니다.\n",
    "    :param_ x: 동적인 값\n",
    "    :return: \"x\"제곱의 평균 \n",
    "    \"\"\"\n",
    "    return (np.abs(x)**2.0).mean()\n",
    "\n",
    "def normalize(y, x=None):\n",
    "    \"\"\"는 (표준 정상) 흰색 노이즈 신호에 y의 전원을 공급합니다.\n",
    "    선택적으로 신호 'x'의 전원으로 정규화합니다.\n",
    "    수학에서 가우스 평균은 'mu=0,sigma=1 입니다.\n",
    "    \"\"\"\n",
    "    #return y * np.sqrt( (np.abs(x)**2.0).mean() / (np.abs(y)**2.0).mean() )\n",
    "    if x is not None:\n",
    "        x = ms(x)\n",
    "    else:\n",
    "        x = 1.0\n",
    "    return y * np.sqrt( x / ms(y) )\n",
    "    #return y * np.sqrt( 1.0 / (np.abs(y)**2.0).mean() )\n",
    "\n",
    "def white_noise(N, state=None):\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    return state.randn(N)\n",
    "\n",
    "def pink_noise(N, state=None):\n",
    "\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = np.sqrt(np.arange(len(X))+1.) # +1 to avoid divide by zero\n",
    "    y = (irfft(X/S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "def blue_noise(N, state=None):\n",
    "    \"\"\"\n",
    "   \n",
    "    \n",
    "    \"\"\"\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = np.sqrt(np.arange(len(X)))# Filter\n",
    "    y = (irfft(X*S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "def brown_noise(N, state=None):\n",
    "    \"\"\"\n",
    "    Violet noise.\n",
    "    \n",
    "    :param N: 샘플의 양입니다.\n",
    "    :param state: PRNG의 상태입니다.\n",
    "    :type state: :class:'np.random.RandomState\n",
    "\n",
    "    전력은 옥타브당 6dB씩 증가합니다.\n",
    "    전력 밀도는 옥타브당 3dB로 증가합니다.\n",
    "    \"\"\"\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = (np.arange(len(X))+1)# Filter\n",
    "    y = (irfft(X/S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "def violet_noise(N, state=None):\n",
    "    \"\"\"\n",
    "    Violet noise. Power increases with 6 dB per octave. \n",
    "    \n",
    "    :param N: 샘플의 양\n",
    "    :param state:  PRNG의 상태\n",
    "    :type state: :class:'np.random.RandomState\n",
    "    \n",
    "    전력은 옥타브당 9dB씩 증가합니다.\n",
    "    전력 밀도는 옥타브당 6dB로 증가합니다.\n",
    "    \n",
    "    \"\"\"\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = (np.arange(len(X)))# Filter\n",
    "    y = (irfft(X*S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow utilities\n",
    "텐서 흐름 공통 작업을 모듈화하는 유틸리티입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T02:57:10.151217Z",
     "start_time": "2021-02-22T02:57:10.136259Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tf Utils\n",
    "def get_tensorflow_configuration(device=\"0\", memory_fraction=1):\n",
    "    \"\"\"\n",
    "    사용할 GPU 및 프로세스에서 사용할 수 있는 메모리 양을 선택하는 기능입니다.\n",
    "    :param device: 사용할 디바이스(str)입니다.\n",
    "    :param memory_complet: 할당해야 하는 메모리 비율(comparent)입니다.\n",
    "    :return: 세션에 전달할 구성(tf 개체)입니다.\n",
    "    \"\"\"\n",
    "    device = str(device)\n",
    "    config = tf.ConfigProto()\n",
    "    config.allow_soft_placement = True\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = memory_fraction\n",
    "    config.gpu_options.visible_device_list = device\n",
    "    return(config)\n",
    "\n",
    "\n",
    "def start_tensorflow_session(device=\"0\", memory_fraction=1):\n",
    "    \"\"\"\n",
    "    사용할 GPU 장치를 관리하는 텐서 플로우 세션을 시작합니다.\n",
    "    즉, 사전 할당될 메모리의 비율입니다.\n",
    "    :device: 디바이스 번호(str)가 있는 문자열입니다.\n",
    "    :memory_backet: 지정된 메모리에서 사전 할당될 메모리의 일부입니다.\n",
    "    장치(예: [0, 1])입니다.\n",
    "    :return: tf.Session을 구성함 \n",
    "    \"\"\"\n",
    "    return(tf.Session(config=get_tensorflow_configuration(device=device, memory_fraction=memory_fraction)))\n",
    "\n",
    "\n",
    "def get_summary_writer(session, logs_path, project_id, version_id):\n",
    "    \"\"\"\n",
    "    텐서보드 보고용\n",
    "    :param session: 열린 텐서 흐름 세션(tf)입니다.(tf.Session)\n",
    "    :param logs_path: 텐서보드가 로그를 찾는 경로(str)입니다.\n",
    "    :param project_id: 보고용 프로젝트 이름입니다(str).\n",
    "    :param version_id: 보고용 버전 이름입니다(str).\n",
    "    :return summary_writer :summary_writer를 반환합니다.\n",
    "    \"\"\"\n",
    "    path = os.path.join(logs_path,\"{}_{}\".format(project_id, version_id)) \n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    summary_writer = tf.summary.FileWriter(path, graph_def=session.graph_def)\n",
    "    return(summary_writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths management module\n",
    "경로를 처리하는 모듈입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T03:01:17.309463Z",
     "start_time": "2021-02-22T03:01:17.294495Z"
    }
   },
   "outputs": [],
   "source": [
    "# Common paths\n",
    "def _norm_path(path):\n",
    "    \"\"\"\n",
    "    경로 검색 기능의 출력 유무를 확인하기 위한 Decorator 함수입니다. \n",
    "    슬래시/백슬래시 창 케이스를 고정하는 데 유용합니다.\n",
    "    \"\"\"\n",
    "    def normalize_path(*args, **kwargs):\n",
    "        return os.path.normpath(path(*args, **kwargs))\n",
    "    return normalize_path\n",
    "\n",
    "\n",
    "def _assure_path_exists(path):\n",
    "    \"\"\"\n",
    "    경로 검색 기능의 출력 유무를 확인하기 위한 Decorator 함수입니다. \n",
    "    슬래시/백슬래시 창 케이스를 고정하는 데 유용합니다.\n",
    "    \"\"\"\n",
    "    def assure_exists(*args, **kwargs):\n",
    "        p=path(*args, **kwargs)\n",
    "        assert os.path.exists(p), \"the following path does not exist: '{}'\".format(p)\n",
    "        return p\n",
    "    return assure_exists\n",
    "\n",
    "\n",
    "def _is_output_path(path):\n",
    "    \"\"\"\n",
    "    Decorator 함수는 출력 경로 검색 함수의 출력에 적용되는 함수를 그룹화하기 위한 것입니다.\n",
    "    \"\"\"\n",
    "    @_norm_path\n",
    "    @_assure_path_exists\n",
    "    def check_existence_or_create_it(*args, **kwargs):\n",
    "        if not os.path.exists(path(*args, **kwargs)):\n",
    "            \"Path does not exist... creating it: {}\".format(path(*args, **kwargs))\n",
    "            os.makedirs(path(*args, **kwargs))\n",
    "        return path(*args, **kwargs)\n",
    "    return check_existence_or_create_it\n",
    "\n",
    "\n",
    "def _is_input_path(path):\n",
    "    \"\"\"\n",
    "    Decorator function intended for grouping the functions which are applied over the output of an input path retrieval\n",
    "    function\n",
    "    \"\"\"\n",
    "    @_norm_path\n",
    "    @_assure_path_exists\n",
    "    def check_existence(*args, **kwargs):\n",
    "        return path(*args, **kwargs)\n",
    "    return check_existence\n",
    "\n",
    "@_is_input_path\n",
    "def get_train_path():\n",
    "    path = \"C:/Users/이동훈/Desktop/github/kaggle/kagglestudy/Data/tensorflow/train\"\n",
    "    return path\n",
    "\n",
    "@_is_input_path\n",
    "def get_test_path():\n",
    "    path = \"C:/Users/이동훈/Desktop/github/kaggle/kagglestudy/Data/tensorflow/test\"\n",
    "    return path\n",
    "\n",
    "@_is_input_path\n",
    "def get_train_audio_path():\n",
    "    path = os.path.join(get_train_path(), \"audio\")\n",
    "    return path\n",
    "\n",
    "@_is_input_path\n",
    "def get_scoring_audio_path():\n",
    "    path = os.path.join(get_test_path(), \"audio\")\n",
    "    return path\n",
    "\n",
    "@_is_output_path\n",
    "def get_submissions_path():\n",
    "    path = \"C:/Users/이동훈/Desktop/github/kaggle/kagglestudy/Data/tensorflow/working/output\"\n",
    "    return path\n",
    "\n",
    "@_is_output_path\n",
    "def get_silence_path():\n",
    "    path = \"C:/Users/이동훈/Desktop/github/kaggle/kagglestudy/Data/tensorflow/working/silence\"\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities\n",
    "범용 유틸리티입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T03:02:45.711095Z",
     "start_time": "2021-02-22T03:02:45.705138Z"
    }
   },
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "def batching(iterable,n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0,l,n):\n",
    "        yield iterable[ndx:min(ndx+n,l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Tools\n",
    "데이터 처리 도구입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T03:08:53.506692Z",
     "start_time": "2021-02-22T03:08:53.491731Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_wav(filepath, pad=True):\n",
    "    \"\"\"\n",
    "    웨이브 파일의 파일 경로를 지정하면 이 함수가 파일을 읽고 표준화하며 패드를 만듭니다.\n",
    "    16K 샘플을 가지고 있다는 것을 확실히 하기 위해서요.\n",
    "    :param filepath: wav 파일의 기존 파일 경로(str)\n",
    "    :param pad: 패딩이 필요합니까? (bool)\n",
    "    \n",
    "    :return: 샘플과 대상 변수(tuple of (np.array, str)\n",
    "    \"\"\"\n",
    "    sample_rate, x = wavfile.read(filepath)\n",
    "    target = os.path.split(os.path.split(filepath)[0])[1]\n",
    "    assert sample_rate==16000\n",
    "    if pad:\n",
    "        return np.pad(x, (0, 16000-len(x)), mode=\"constant\")/32768, target\n",
    "    else:\n",
    "        return x/32768, target\n",
    "\n",
    "def get_batcher(list_of_paths, batch_size, label_encoder=None, scoring=False):\n",
    "    \"\"\"\n",
    "    배치 목록이 지정된 배치 생성기를 빌드합니다.\n",
    "    :param list_of_class: 형식 요소(파일 경로, 대상)가 있는 튜플 목록입니다(list).\n",
    "    :param batch_size: 배치의 크기(int)\n",
    "    :param label_encoder: 적합된 LabelEncoder.LabelEncoder(sklearn.LabelEncoder|optional)\n",
    "    :param scoring: 목표를 고려해야 합니까? (bool)\n",
    "    \n",
    "    :return: 배치 생성기( batch generator)를 반환\n",
    "    \"\"\"\n",
    "    for filepaths in batching(list_of_paths, batch_size):\n",
    "        wavs, targets = zip(*list(map(read_wav, filepaths)))\n",
    "        if scoring:\n",
    "            yield np.expand_dims(np.row_stack(wavs), 2), filepaths\n",
    "        else:\n",
    "            if label_encoder is None:\n",
    "                yield np.expand_dims(np.row_stack(wavs), 2), np.row_stack(targets)\n",
    "            else:\n",
    "                yield np.expand_dims(np.row_stack(wavs), 2), np.expand_dims(label_encoder.transform(np.squeeze(targets)),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture building blocks\n",
    "Inception-1D(일명 웨이브 감지)는 이 문제를 위해 몇 주 전에 디자인한 모듈입니다. 일반 컨볼루션 신경망의 성능을 크게 향상시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T03:16:54.909181Z",
     "start_time": "2021-02-22T03:16:53.488978Z"
    }
   },
   "outputs": [],
   "source": [
    "class BatchNorm(object):\n",
    "    def __init__(self, epsilon=1e-5, momentum=0.999, name=\"batch_norm\"):\n",
    "        with tf.variable_scope(name):\n",
    "            self.epsilon = epsilon\n",
    "            self.momentum = momentum\n",
    "            self.name = name\n",
    "\n",
    "    def __call__(self, x, train=True):\n",
    "        return tf.contrib.layers.batch_norm(x,\n",
    "                                            decay=self.momentum,\n",
    "                                            updates_collections=None,\n",
    "                                            epsilon=self.epsilon,\n",
    "                                            scale=True,\n",
    "                                            is_training=train,\n",
    "                                            scope=self.name)\n",
    "    \n",
    "    \n",
    "\n",
    "def inception_1d(x, is_train, depth, norm_function, activ_function, name):\n",
    "    \"\"\"\n",
    "    Inception 1D 모듈 구현입니다.\n",
    "    :paramx: 현재 모듈에 대한 입력(4D 텐서(채널-마지막) 포함)입니다.\n",
    "    :param is_train: BatchNormalization 동작을 제어하기 위한 부울 자리 표시자(0D 텐서)를 의도합니다.\n",
    "    :param depth: 네트워크의 깊이를 선형적으로 제어합니다(int).\n",
    "    :param norm_function: 정규화 클래스(위의 BatchNorm 클래스와 동일한 형식)입니다.\n",
    "    :param active_function: 텐서 흐름 활성화 함수(예: tf.nn.relu)\n",
    "    :param name: 변수 범위(str)의 이름입니다.\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(name):\n",
    "        x_norm = norm_function(name=\"norm_input\")(x, train=is_train)\n",
    "\n",
    "        # Branch 1: 64 x conv 1x1 \n",
    "        branch_conv_1_1 = tf.layers.conv1d(inputs=x_norm, filters=16*depth, kernel_size=1,\n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_1_1\")\n",
    "        branch_conv_1_1 = norm_function(name=\"norm_conv_1_1\")(branch_conv_1_1, train=is_train)\n",
    "        branch_conv_1_1 = activ_function(branch_conv_1_1, \"activation_1_1\")\n",
    "\n",
    "        # Branch 2: 128 x conv 3x3 \n",
    "        branch_conv_3_3 = tf.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_3_3_1\")\n",
    "        branch_conv_3_3 = norm_function(name=\"norm_conv_3_3_1\")(branch_conv_3_3, train=is_train)\n",
    "        branch_conv_3_3 = activ_function(branch_conv_3_3, \"activation_3_3_1\")\n",
    "\n",
    "        branch_conv_3_3 = tf.layers.conv1d(inputs=branch_conv_3_3, filters=32*depth, kernel_size=3, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_3_3_2\")\n",
    "        branch_conv_3_3 = norm_function(name=\"norm_conv_3_3_2\")(branch_conv_3_3, train=is_train)\n",
    "        branch_conv_3_3 = activ_function(branch_conv_3_3, \"activation_3_3_2\")\n",
    "\n",
    "        # Branch 3: 128 x conv 5x5 \n",
    "        branch_conv_5_5 = tf.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_5_5_1\")\n",
    "        branch_conv_5_5 = norm_function(name=\"norm_conv_5_5_1\")(branch_conv_5_5, train=is_train)\n",
    "        branch_conv_5_5 = activ_function(branch_conv_5_5, \"activation_5_5_1\")\n",
    "\n",
    "        branch_conv_5_5 = tf.layers.conv1d(inputs=branch_conv_5_5, filters=32*depth, kernel_size=5, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_5_5_2\")\n",
    "        branch_conv_5_5 = norm_function(name=\"norm_conv_5_5_2\")(branch_conv_5_5, train=is_train)\n",
    "        branch_conv_5_5 = activ_function(branch_conv_5_5, \"activation_5_5_2\")\n",
    "\n",
    "        # Branch 4: 128 x conv 7x7\n",
    "        branch_conv_7_7 = tf.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_7_7_1\")\n",
    "        branch_conv_7_7 = norm_function(name=\"norm_conv_7_7_1\")(branch_conv_7_7, train=is_train)\n",
    "        branch_conv_7_7 = activ_function(branch_conv_7_7, \"activation_7_7_1\")\n",
    "\n",
    "        branch_conv_7_7 = tf.layers.conv1d(inputs=branch_conv_7_7, filters=32*depth, kernel_size=5, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_7_7_2\")\n",
    "        branch_conv_7_7 = norm_function(name=\"norm_conv_7_7_2\")(branch_conv_7_7, train=is_train)\n",
    "        branch_conv_7_7 = activ_function(branch_conv_7_7, \"activation_7_7_2\")\n",
    "\n",
    "        # Branch 5: 16 x (max_pool 3x3 + conv 1x1)\n",
    "        branch_maxpool_3_3 = tf.layers.max_pooling1d(inputs=x_norm, pool_size=3, strides=1, padding=\"same\", name=\"maxpool_3\")\n",
    "        branch_maxpool_3_3 = norm_function(name=\"norm_maxpool_3_3\")(branch_maxpool_3_3, train=is_train)\n",
    "        branch_maxpool_3_3 = tf.layers.conv1d(inputs=branch_maxpool_3_3, filters=16, kernel_size=1, \n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_maxpool_3\")\n",
    "\n",
    "        # Branch 6: 16 x (max_pool 5x5 + conv 1x1)\n",
    "        branch_maxpool_5_5 = tf.layers.max_pooling1d(inputs=x_norm, pool_size=5, strides=1, padding=\"same\", name=\"maxpool_5\")\n",
    "        branch_maxpool_5_5 = norm_function(name=\"norm_maxpool_5_5\")(branch_maxpool_5_5, train=is_train)\n",
    "        branch_maxpool_5_5 = tf.layers.conv1d(inputs=branch_maxpool_5_5, filters=16, kernel_size=1, \n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_maxpool_5\")\n",
    "\n",
    "        # Branch 7: 16 x (avg_pool 3x3 + conv 1x1)\n",
    "        branch_avgpool_3_3 = tf.layers.average_pooling1d(inputs=x_norm, pool_size=3, strides=1, padding=\"same\", name=\"avgpool_3\")\n",
    "        branch_avgpool_3_3 = norm_function(name=\"norm_avgpool_3_3\")(branch_avgpool_3_3, train=is_train)\n",
    "        branch_avgpool_3_3 = tf.layers.conv1d(inputs=branch_avgpool_3_3, filters=16, kernel_size=1,\n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_avgpool_3\")\n",
    "\n",
    "        # Branch 8: 16 x (avg_pool 5x5 + conv 1x1)\n",
    "        branch_avgpool_5_5 = tf.layers.average_pooling1d(inputs=x_norm, pool_size=5, strides=1, padding=\"same\", name=\"avgpool_5\")\n",
    "        branch_avgpool_5_5 = norm_function(name=\"norm_avgpool_5_5\")(branch_avgpool_5_5, train=is_train)\n",
    "        branch_avgpool_5_5 = tf.layers.conv1d(inputs=branch_avgpool_5_5, filters=16, kernel_size=1, \n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_avgpool_5\")\n",
    "\n",
    "        # Concatenate\n",
    "        output = tf.concat([branch_conv_1_1, branch_conv_3_3, branch_conv_5_5, branch_conv_7_7, branch_maxpool_3_3, \n",
    "                           branch_maxpool_5_5, branch_avgpool_3_3, branch_avgpool_5_5], axis=-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T03:22:03.035688Z",
     "start_time": "2021-02-22T03:22:02.025321Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\user\\lib\\site-packages\\ipykernel_launcher.py:10: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "filepaths_noise = glob.glob(os.path.join(get_train_audio_path(), \"_background_noise_\", \"*.wav\"))\n",
    "\n",
    "noise = np.concatenate(list(map(lambda x: read_wav(x, False)[0], filepaths_noise)))\n",
    "noise = np.concatenate([noise, noise[::-1]])\n",
    "synthetic_noise = np.concatenate([white_noise(N=16000*30, state=np.random.RandomState(655321)), \n",
    "                                  blue_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                  pink_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                  brown_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                  violet_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                  np.zeros(16000*60)])\n",
    "synthetic_noise /= np.max(np.abs(synthetic_noise))\n",
    "synthetic_noise = np.concatenate([synthetic_noise, (synthetic_noise+synthetic_noise[::-1])/2])\n",
    "all_noise = np.concatenate([noise, synthetic_noise])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T03:26:42.151152Z",
     "start_time": "2021-02-22T03:26:07.434351Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████▍                                      | 3991/8000 [00:19<00:16, 241.88it/s]C:\\user\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 8000/8000 [00:34<00:00, 231.09it/s]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(655321)\n",
    "random.seed(655321)\n",
    "\n",
    "path = get_silence_path()\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path) # It fails in kaggle kernel due to the read-only filesystem\n",
    "\n",
    "for noise_clip_no in tqdm(range(8000)):\n",
    "    if noise_clip_no<=4000:\n",
    "        idx = np.random.randint(0, len(noise)-16000)\n",
    "        clip = noise[idx:(idx+16000)]\n",
    "    else:\n",
    "        idx = np.random.randint(0, len(synthetic_noise)-16000)\n",
    "        clip = synthetic_noise[idx:(idx+16000)]\n",
    "    wavfile.write(os.path.join(path, \"{0:04d}.wav\".format(noise_clip_no)), 16000, \n",
    "                               ((32767*clip/np.max(np.abs(clip))).astype(np.int16)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T03:48:09.167197Z",
     "start_time": "2021-02-22T03:47:58.942766Z"
    }
   },
   "outputs": [],
   "source": [
    "filepaths = glob.glob(os.path.join(get_train_audio_path(), \"**/*.wav\"), recursive=True)\n",
    "filepaths += glob.glob(os.path.join(get_silence_path(), \"**/*.wav\"), recursive=True)\n",
    "filepaths = list(filter(lambda fp: \"_background_noise_\" not in fp, filepaths))\n",
    "validation_list = open(os.path.join(get_train_path(), \"validation_list.txt\")).readlines()\n",
    "test_list = open(os.path.join(get_train_path(), \"testing_list.txt\")).readlines()\n",
    "validation_list = list(map(lambda fn: os.path.join(get_train_audio_path(), fn.strip()), validation_list))\n",
    "testing_list = list(map(lambda fn: os.path.join(get_train_audio_path(), fn.strip()), test_list))\n",
    "training_list = np.setdiff1d(filepaths, validation_list+testing_list).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T03:48:09.417494Z",
     "start_time": "2021-02-22T03:48:09.175145Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(655321)\n",
    "random.shuffle(filepaths)\n",
    "random.shuffle(validation_list)\n",
    "random.shuffle(testing_list)\n",
    "random.shuffle(training_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T03:48:12.736012Z",
     "start_time": "2021-02-22T03:48:09.423480Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-a3570c77f7d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\".wav\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m64727\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m6\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m8000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m6798\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m6835\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m6798\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m6835\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert all(map(lambda fp: os.path.splitext(fp)[1]==\".wav\", filepaths))\n",
    "assert len(filepaths)==64727 - 6 + 8000\n",
    "assert len(training_list) == len(filepaths) - 6798 - 6835 \n",
    "assert len(validation_list) == 6798\n",
    "assert len(testing_list) == 6835\n",
    "\n",
    "# Test file existence\n",
    "assert all(map(lambda fn: os.path.exists(os.path.join(fn)), validation_list))\n",
    "assert all(map(lambda fn: os.path.exists(os.path.join(fn)), testing_list))\n",
    "assert all(map(lambda fn: os.path.exists(os.path.join(fn)), training_list))\n",
    "assert set(validation_list + testing_list + training_list) == set(filepaths)\n",
    "\n",
    "# Test non-overlap among sets\n",
    "assert len(np.intersect1d(validation_list, testing_list))==0\n",
    "assert len(np.intersect1d(training_list, testing_list))==0\n",
    "assert len(np.intersect1d(training_list, validation_list))==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T03:48:40.796648Z",
     "start_time": "2021-02-22T03:48:39.164636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'no': 2375,\n",
       "         'yes': 2377,\n",
       "         'stop': 2380,\n",
       "         'nine': 2364,\n",
       "         'left': 2353,\n",
       "         'dog': 1746,\n",
       "         'wow': 1745,\n",
       "         'up': 2375,\n",
       "         'one': 2370,\n",
       "         'six': 2369,\n",
       "         'zero': 2376,\n",
       "         'two': 2373,\n",
       "         'sheila': 1734,\n",
       "         'tree': 1733,\n",
       "         'silence': 8000,\n",
       "         'four': 2372,\n",
       "         'marvin': 1746,\n",
       "         'bed': 1713,\n",
       "         'right': 2367,\n",
       "         'seven': 2377,\n",
       "         'cat': 1733,\n",
       "         'eight': 2352,\n",
       "         'five': 2357,\n",
       "         'on': 2367,\n",
       "         'happy': 1742,\n",
       "         'off': 2357,\n",
       "         'three': 2356,\n",
       "         'go': 2372,\n",
       "         'down': 2359,\n",
       "         'bird': 1731,\n",
       "         'house': 1750})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardinal_classes = list(set(map(lambda fp:os.path.split(os.path.split(fp)[0])[1], filepaths)))\n",
    "le_classes = LabelEncoder().fit(cardinal_classes)\n",
    "Counter(map(\n",
    "    lambda fp:os.path.split(os.path.split(fp)[0])[1], filepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T04:01:33.388976Z",
     "start_time": "2021-02-22T04:01:23.340874Z"
    }
   },
   "outputs": [],
   "source": [
    "_gen_test = get_batcher(filepaths, 1000)\n",
    "batch_a_wav, batch_a_target = next(_gen_test)\n",
    "batch_b_wav, batch_b_target = next(_gen_test)\n",
    "_gen_test_le = get_batcher(filepaths, 1000, label_encoder=le_classes)\n",
    "batch_le_wav, batch_le_target = next(_gen_test_le)\n",
    "\n",
    "# 배치 행렬 형태 상관 관계를 검정합니다.\n",
    "assert batch_a_wav.shape == (1000, 16000, 1)\n",
    "assert batch_le_wav.shape == (1000, 16000, 1)\n",
    "assert batch_a_wav.shape == batch_b_wav.shape == batch_le_wav.shape\n",
    "\n",
    "# 배치 재현성을 테스트\n",
    "assert np.sum(np.abs(batch_a_wav-batch_b_wav)) != 0\n",
    "assert len(batch_a_target) == len(batch_b_target) == len(batch_le_target)\n",
    "assert any(batch_a_target != batch_b_target)\n",
    "\n",
    "# 클래스 레이블 인코더를 테스트\n",
    "assert all(batch_le_target == np.expand_dims(le_classes.transform(np.squeeze(batch_a_target)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T07:18:29.981110Z",
     "start_time": "2021-02-22T07:18:29.933237Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class NameSpacer:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "class Architecture:\n",
    "    def __init__(self, class_cardinality, seq_len=16000, name=\"architecture\"):\n",
    "        self.seq_len = seq_len\n",
    "        self.class_cardinality = class_cardinality\n",
    "        self.optimizer = tf.optimizers.Adam(learning_rate=0.0001)\n",
    "        self.name=name\n",
    "        self.define_computation_graph()\n",
    "        \n",
    "        #Aliases\n",
    "        self.ph = self.placeholders\n",
    "        self.op = self.optimizers\n",
    "        self.summ = self.summaries\n",
    "\n",
    "    def define_computation_graph(self):\n",
    "        # Reset graph\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        self.placeholders = NameSpacer(**self.define_placeholders())\n",
    "        self.core_model = NameSpacer(**self.define_core_model())\n",
    "        self.losses = NameSpacer(**self.define_losses())\n",
    "        self.optimizers = NameSpacer(**self.define_optimizers())\n",
    "        self.summaries = NameSpacer(**self.define_summaries())\n",
    "\n",
    "    def define_placeholders(self):\n",
    "        with tf.compat.v1.variable_scope(\"Placeholders\"):\n",
    "            wav_in = tf.compat.v1.placeholder(dtype=tf.float32, shape=(None, self.seq_len, 1), name=\"wav_in\")\n",
    "            is_train = tf.compat.v1.placeholder(dtype=tf.bool, shape=None, name=\"is_train\")\n",
    "            target = tf.compat.v1.placeholder(dtype=tf.int32, shape=(None, 1), name=\"target\")\n",
    "            acc_dev = tf.compat.v1.placeholder(dtype=tf.float32, shape=None, name=\"acc_dev\")\n",
    "            loss_dev = tf.compat.v1.placeholder(dtype=tf.float32, shape=None, name=\"loss_dev\")\n",
    "            return({\"wav_in\": wav_in, \"target\": target, \"is_train\": is_train, \"acc_dev\": \n",
    "                    acc_dev, \"loss_dev\": loss_dev})\n",
    "        \n",
    "    def define_core_model(self):\n",
    "        with tf.compat.v1.variable_scope(\"Core_Model\"):\n",
    "            x = inception_1d(x=self.placeholders.wav_in, is_train=self.placeholders.is_train, \n",
    "                             norm_function=BatchNorm, activ_function=tf.nn.relu, depth=1,\n",
    "                             name=\"Inception_1_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=1, name=\"Inception_1_2\")\n",
    "            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=1, name=\"Inception_2_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=1, name=\"Inception_2_3\")\n",
    "            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_2\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=2, name=\"Inception_3_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=2, name=\"Inception_3_2\")\n",
    "            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_3\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=2, name=\"Inception_4_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=2, name=\"Inception_4_2\")\n",
    "            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_4\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=3, name=\"Inception_5_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=3, name=\"Inception_5_2\")\n",
    "            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_5\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=3, name=\"Inception_6_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=3, name=\"Inception_6_2\")\n",
    "            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_6\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=4, name=\"Inception_7_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=4, name=\"Inception_7_2\")\n",
    "            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_7\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=4, name=\"Inception_8_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=4, name=\"Inception_8_2\")\n",
    "            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_8\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=4, name=\"Inception_9_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=4, name=\"Inception_9_2\")\n",
    "            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_9\")\n",
    "            x = tf.contrib.layers.flatten(x)\n",
    "            x = tf.layers.dense(BatchNorm(name=\"bn_dense_1\")(x,train=self.placeholders.is_train),\n",
    "                                128, activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                name=\"dense_1\")\n",
    "            output = tf.layers.dense(BatchNorm(name=\"bn_dense_2\")(x,train=self.placeholders.is_train),\n",
    "                                self.class_cardinality, activation=None, kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                name=\"output\")\n",
    "            return({\"output\": output})\n",
    "        \n",
    "    def define_losses(self):\n",
    "        with tf.compat.v1.variable_scope(\"Losses\"):\n",
    "            softmax_ce = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf.squeeze(self.placeholders.target), \n",
    "                                                                        logits=self.core_model.output,\n",
    "                                                                        name=\"softmax\")\n",
    "            return({\"softmax\": softmax_ce})\n",
    "\n",
    "    def define_optimizers(self):\n",
    "        with tf.compat.v1.variable_scope(\"Optimization\"):\n",
    "            op = self.optimizer.minimize(self.losses.softmax)\n",
    "            return({\"op\": op})\n",
    "\n",
    "    def define_summaries(self):\n",
    "        with tf.compat.v1.variable_scope(\"Summaries\"):\n",
    "            ind_max = tf.squeeze(tf.cast(tf.argmax(self.core_model.output, axis=1), tf.int32))\n",
    "            target = tf.squeeze(self.placeholders.target)\n",
    "            acc= tf.reduce_mean(tf.cast(tf.equal(ind_max, target), tf.float32))\n",
    "            loss = tf.reduce_mean(self.losses.softmax)\n",
    "            train_scalar_probes = {\"accuracy\": acc, \n",
    "                                   \"loss\": loss}\n",
    "            train_performance_scalar = [tf.summary.scalar(k, tf.reduce_mean(v), family=self.name) \n",
    "                                        for k, v in train_scalar_probes.items()]\n",
    "            train_performance_scalar = tf.summary.merge(train_performance_scalar)\n",
    "\n",
    "            dev_scalar_probes = {\"acc_dev\": self.placeholders.acc_dev, \n",
    "                                 \"loss_dev\": self.placeholders.loss_dev}\n",
    "            dev_performance_scalar = [tf.summary.scalar(k, v, family=self.name) for k, v in dev_scalar_probes.items()]\n",
    "            dev_performance_scalar = tf.summary.merge(dev_performance_scalar)\n",
    "            return({\"accuracy\": acc, \"loss\": loss, \"s_tr\": train_performance_scalar, \"s_de\": dev_performance_scalar})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model\n",
    "모델이 영원히 걸리지 않으려면 GPU를 사용하여 실행해야 합니다. 또한 예측하기 위해 네트워크를 중지할 시기를 결정해야 합니다. 타이탄 X 파스칼에서 12시간이나 걸렸어요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T07:18:30.898655Z",
     "start_time": "2021-02-22T07:18:30.821861Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "tf.placeholder() is not compatible with eager execution.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-00128af58348>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArchitecture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_cardinality\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcardinal_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"wavception\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-e42de8e810c2>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, class_cardinality, seq_len, name)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefine_computation_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m#Aliases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-e42de8e810c2>\u001b[0m in \u001b[0;36mdefine_computation_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# Reset graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNameSpacer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefine_placeholders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNameSpacer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefine_core_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNameSpacer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefine_losses\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-e42de8e810c2>\u001b[0m in \u001b[0;36mdefine_placeholders\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdefine_placeholders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Placeholders\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mwav_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"wav_in\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[0mis_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"is_train\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[1;34m(dtype, shape, name)\u001b[0m\n\u001b[0;32m   3174\u001b[0m   \"\"\"\n\u001b[0;32m   3175\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3176\u001b[1;33m     raise RuntimeError(\"tf.placeholder() is not compatible with \"\n\u001b[0m\u001b[0;32m   3177\u001b[0m                        \"eager execution.\")\n\u001b[0;32m   3178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: tf.placeholder() is not compatible with eager execution."
     ]
    }
   ],
   "source": [
    "net = Architecture(class_cardinality=len(cardinal_classes), name=\"wavception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T04:49:56.707545Z",
     "start_time": "2021-02-22T04:49:56.453193Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Session'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-2ef3b4a71a53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart_tensorflow_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_summary_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"~/.logs_tensorboard/\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wavception\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"V1\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Adjust your tensorboard logs path here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-22daa0eb957e>\u001b[0m in \u001b[0;36mstart_tensorflow_session\u001b[1;34m(device, memory_fraction)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession을\u001b[0m \u001b[0m구성함\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \"\"\"\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_tensorflow_configuration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_fraction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemory_fraction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
     ]
    }
   ],
   "source": [
    "sess = start_tensorflow_session(device=\"1\")\n",
    "sw = get_summary_writer(sess, \"~/.logs_tensorboard/\", \"wavception\", \"V1\") # Adjust your tensorboard logs path here\n",
    "c=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T04:49:57.725543Z",
     "start_time": "2021-02-22T04:49:57.695625Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-6af629785793>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T04:49:58.556320Z",
     "start_time": "2021-02-22T04:49:58.538364Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(655321)\n",
    "random.seed(655321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T04:50:01.725018Z",
     "start_time": "2021-02-22T04:50:01.393897Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-59f035617ed5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mbatcher\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_batcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mle_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatcher\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         _, loss, acc, s = sess.run([net.op.op, net.losses.softmax, net.summ.accuracy, net.summ.s_tr],\n\u001b[0m\u001b[0;32m      6\u001b[0m                                  feed_dict={net.ph.wav_in: batch_x, net.ph.target: batch_y, \n\u001b[0;32m      7\u001b[0m                                             net.ph.is_train: True})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(50000):\n",
    "    random.shuffle(training_list)\n",
    "    batcher = get_batcher(training_list, 16, le_classes)\n",
    "    for i, (batch_x, batch_y) in enumerate(batcher):\n",
    "        _, loss, acc, s = sess.run([net.op.op, net.losses.softmax, net.summ.accuracy, net.summ.s_tr],\n",
    "                                 feed_dict={net.ph.wav_in: batch_x, net.ph.target: batch_y, \n",
    "                                            net.ph.is_train: True})\n",
    "        print(\"[{0:04d}|{1:04d}] Accuracy train: {2:.2f}%\".format(epoch, i, acc*100))\n",
    "        sw.add_summary(s, c)\n",
    "        \n",
    "        if c%1000==0: # Validation\n",
    "            accuracies_dev=[]\n",
    "            losses_dev=[]\n",
    "            batcher = get_batcher(validation_list, 16, le_classes)\n",
    "            for i, (batch_x, batch_y) in enumerate(batcher):\n",
    "                acc, loss= sess.run([net.summ.accuracy, net.summ.loss], \n",
    "                               feed_dict={net.ph.wav_in: batch_x, net.ph.target: batch_y, \n",
    "                                          net.ph.is_train: False})\n",
    "                accuracies_dev.append(acc)\n",
    "                losses_dev.append(loss)\n",
    "            s = sess.run(net.summ.s_de, feed_dict={net.ph.acc_dev: np.mean(accuracies_dev),\n",
    "                                                        net.ph.loss_dev: np.mean(losses_dev)})\n",
    "            sw.add_summary(s, c)\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도를 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T03:48:12.762911Z",
     "start_time": "2021-02-22T03:48:02.027Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracies=[]\n",
    "batcher = get_batcher(testing_list, 64, le_classes)\n",
    "for i, (batch_x, batch_y) in tqdm(enumerate(batcher)):\n",
    "    acc= sess.run(net.summ.accuracy, feed_dict={net.ph.wav_in: batch_x, net.ph.target: batch_y, \n",
    "                                                     net.ph.is_train: False})\n",
    "    accuracies.append(acc)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and submission building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T03:48:12.764906Z",
     "start_time": "2021-02-22T03:48:02.454Z"
    }
   },
   "outputs": [],
   "source": [
    "scoring_list = glob.glob(os.path.join(get_scoring_audio_path(), \"*.wav\"), recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T03:48:12.765902Z",
     "start_time": "2021-02-22T03:48:02.625Z"
    }
   },
   "outputs": [],
   "source": [
    "batcher = get_batcher(scoring_list, 80, le_classes, scoring=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T03:48:12.767896Z",
     "start_time": "2021-02-22T03:48:02.804Z"
    }
   },
   "outputs": [],
   "source": [
    "fns = []\n",
    "prds = []\n",
    "for i, (batch_x, filepaths) in tqdm(enumerate(batcher)):\n",
    "    pred = sess.run(net.core_model.output, feed_dict={net.ph.wav_in: batch_x, net.ph.is_train: False})\n",
    "    fns.extend(map(lambda f:os.path.split(f)[1], filepaths))\n",
    "    prds.extend(map(lambda f:np.argmax(pred, axis=1).tolist(), pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고: 알 수 없는 클립 문제를 빠르고 더러운 방법으로 해결할 수 있는 방법을 여기에 구현했습니다. 성능은 여전히 우수하지만(약 76LB) 훨씬 더 현명한 방법이 있습니다;-)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T03:48:12.768896Z",
     "start_time": "2021-02-22T03:48:03.335Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame({\"fname\":fns, \"label\": prds})\n",
    "df.label = le_classes.inverse_transform(df.label)\n",
    "df.loc[~df.label.isin([\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\", \"silence\"]), \"label\"]=\"unknown\"\n",
    "df.to_csv(os.path.join(get_submissions_path(), \"submission.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
