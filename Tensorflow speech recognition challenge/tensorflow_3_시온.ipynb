{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "meaning-wings",
   "metadata": {},
   "source": [
    "# Kaggle Study Day 26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-holocaust",
   "metadata": {},
   "source": [
    "# WavCeption V1 : a 1-D Inception approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-lunch",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/ivallesp/wavception-v1-a-1-d-inception-approach-lb-0-76"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-motorcycle",
   "metadata": {},
   "source": [
    "WaveCeption V1 네트워크는 일반 컨볼루션 신경망에 비해 인상적인 결과를 내는 것처럼 보이지만, 이 대회에선 전처리와 알려지지 않은 트랙 관리에서 힘든 작업이 있는 것 같아보인다. 이는 같은 아이디어인 구글의 inception 네트워크를 기반으로 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-clerk",
   "metadata": {},
   "source": [
    "## Load modules and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fifteen-photograph",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T13:01:05.682106Z",
     "start_time": "2021-02-22T13:00:47.233679Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import IPython\n",
    "from numpy.fft import rfft, irfft\n",
    "import itertools\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-subject",
   "metadata": {},
   "source": [
    "## Noise generation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "juvenile-integration",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T14:01:17.435717Z",
     "start_time": "2021-02-22T14:01:17.401807Z"
    }
   },
   "outputs": [],
   "source": [
    "def ms(x):\n",
    "    # 신호 x 제곱의 평균값\n",
    "    # param x : 상수 (dynamic quantity)\n",
    "    # returns : x의 평균 제곱\n",
    "    return (np.abs(x)**2.0).mean()\n",
    "\n",
    "\n",
    "def normalize(y, x=None):\n",
    "    # y를 (standard normal인) 백색 소음 신호로 정규화\n",
    "    # 신호 x를 선택적으로 정규화\n",
    "    # \\\\mu=0과 \\\\signal=1인 가우시안의 평균은 1.\n",
    "    \n",
    "    # y * np.sqrt((np.abs(x)**2.0).mean() / (np.abs(y)**2.0).mean()) 반환\n",
    "    if x is not None:\n",
    "        x = ms(x)\n",
    "    else :\n",
    "        x = 1.0\n",
    "    return y* np.sqrt(x/ms(y))  # np.sqrt(1.0 / (np.abs(y)**2.0).mean()) 반환\n",
    "\n",
    "\n",
    "def white_noise(N, state=None):\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    return state.randn(N)\n",
    "\n",
    "\n",
    "def pink_noise(N, state=None):\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j*state.randn(N//2+1+uneven)\n",
    "    S = np.sqrt(np.arange(len(X))+1.)  # 0으로 나뉘는 것을 방지하기 위해 +1\n",
    "    y = (irfft(X/S)).real\n",
    "    if uneven :\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "\n",
    "def blue_noise(N, state=None):\n",
    "    # Blue noise\n",
    "    # param N : 샘플 수\n",
    "    # param state : PRNG의 state\n",
    "    # type state : class:'np.random.RandomState'\n",
    "    # 전력은 옥타브당 6dB씩 증가\n",
    "    # 전력 밀도는 옥타브당 3dB씩 증가\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j*state.randn(N//2+1+uneven)\n",
    "    S = np.sqrt(np.arange(len(X)))  # filter\n",
    "    y = (irfft(X*S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "\n",
    "def brown_noise(N, state=None):\n",
    "    # Violet noise\n",
    "    # param N : 샘플 수 \n",
    "    # param sate : PRNG의 state\n",
    "    # type state : class:'np.random.RandomState'\n",
    "    # 전력은 옥타브당 -3dB씩 감소\n",
    "    # 전력 밀도는 옥타브당 6dB씩 감소\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = (np.arange(len(X))+1)  # Filter\n",
    "    y = (irfft(X/S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "\n",
    "def violet_noise(N, state=None):\n",
    "    # Violet noise. 옥타브당 전력이 6dB씩 증가\n",
    "    # param N : 샘플 수 \n",
    "    # param sate : PRNG의 state\n",
    "    # type state : class:'np.random.RandomState'\n",
    "    # 전력은 옥타브당 +9dB씩 증가\n",
    "    # 전력 밀도는 옥타브당 +6dB씩 증가\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = (np.arange(len(X)))# Filter\n",
    "    y = (irfft(X*S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-stylus",
   "metadata": {},
   "source": [
    "## Tensorflow utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-marketplace",
   "metadata": {},
   "source": [
    "tensorflow의 공통 작업을 모듈화하는 유틸리티"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dutch-addiction",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T13:29:25.138354Z",
     "start_time": "2021-02-22T13:29:25.117412Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tf Utils\n",
    "def get_tensorflow_configuration(device='0', memory_fraction=1):\n",
    "    # 사용할 GPU 및 프로세스에서 사용할 수 있는 메모리 양을 선택하는 함수\n",
    "    # param device : 사용될 장치 (str)\n",
    "    # param memory_fraction : 할당해야하는 메모리 비율 (float)\n",
    "    # return : 세션에 전달할 config (tf 객체)\n",
    "    device = str(device)\n",
    "    config = tf.ConfigProto()\n",
    "    config.allow_soft_placement = True\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = memory_fraction\n",
    "    config.gpu_options.visible_device_list = device\n",
    "    return (config)\n",
    "\n",
    "\n",
    "def start_tensorflow_session(device='0', memory_fraction=1):\n",
    "    # 사용할 GPU 장치와 사전 할당될 메모리 부분을 관리하는 tensorflow 세션을 시작\n",
    "    # device : 장치 번호가 있는 문자열(str)\n",
    "    # memory_fraction : 지정된 메모리에서 사전 할당될 메모리 일부 (float[0.1])\n",
    "    # return : 구성(configure)된 tf.Session \n",
    "    return (tf.Session(config=get_tensorflow_configuration(device=device, memory_fraction=memory_fraction)))\n",
    "\n",
    "\n",
    "def get_summary_writer(session, logs_path, project_id, version_id):\n",
    "    # For tensorboarded reportin\n",
    "    # session : 열린 tensorflow 세션 (tf.Session)\n",
    "    # logs_path : tensorboard가 logs를 찾는 경로 (str)\n",
    "    # project_id : 목적을 보고하기 위한 프로젝트 이름\n",
    "    # version_id : 목적을 보고하기 위한 버전 이름\n",
    "    # return summary_writer : tesorboard writer\n",
    "    path = os.path.join(logs_path, '{}_{}'.format(project_id, version_id))\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    summary_writer = tf.suumary.FilterWriter(path, graph_def=session.graph_def)\n",
    "    return summary_writer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-teaching",
   "metadata": {},
   "source": [
    "## paths management module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "understanding-masters",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T13:43:07.740900Z",
     "start_time": "2021-02-22T13:43:07.729929Z"
    }
   },
   "outputs": [],
   "source": [
    "# common paths\n",
    "def _norm_path(path):\n",
    "    # 경로 검색 기능의 출력을 정규화하는 데 사용하기 위한 decorator 함수. 슬랙시/백슬래시 윈도우 케이스를 고정하는 데 유용\n",
    "    def normalize_path(*args, **kwargs):\n",
    "        return os.path.normpath(path(*args, **kwargs))\n",
    "    return normalize_path\n",
    "\n",
    "def _assure_path_exists(path):\n",
    "    # 경로 검색 기능의 출력 존재 여부를 확인하기 위한 decorator 함수. 슬래시/백슬래시 윈도우 케이스를 고정하는 데 유용\n",
    "    def assure_exists(*args, **kwargs):\n",
    "        p = path(*args, **kwargs)\n",
    "        assert os.path.exists(p), \"the following path does not exist: '{}'\".format(p)\n",
    "        return p\n",
    "    return assure_exists\n",
    "\n",
    "def _is_output_path(path):\n",
    "    # 출력 경로 검색 함수의 출력에 적용되는 함수를 그룹화하는 데 사용하는 decorator 함수\n",
    "    @_norm_path\n",
    "    @_assure_path_exists\n",
    "    def check_existence_or_create_it(*args, **kwargs):\n",
    "        if not os.path.exists(path(*args, **kwargs)):\n",
    "            \"Path does not exist... creating it: {}\".format(path(*args, **kwargs))\n",
    "            os.makedirs(path(*args, **kwargs))\n",
    "        return path(*args, **kwargs)\n",
    "    return check_existence_or_create_it\n",
    "\n",
    "def _is_input_path(path):\n",
    "    # 입력 경로 검색 함수의 출력에 적용되는 함수를 그룹화하는 데 사용되는 decorator 함수\n",
    "    @_norm_path\n",
    "    @_assure_path_exists\n",
    "    def check_existence(*args, **kwargs):\n",
    "        return path(*args, **kwargs)\n",
    "    return check_existence\n",
    "\n",
    "\n",
    "@_is_input_path\n",
    "def get_train_path():\n",
    "    path = \"../input/train\"\n",
    "    return path\n",
    "\n",
    "@_is_input_path\n",
    "def get_test_path():\n",
    "    path = \"../input/test\"\n",
    "    return path\n",
    "\n",
    "@_is_input_path\n",
    "def get_train_audio_path():\n",
    "    path = os.path.join(get_train_path(), \"audio\")\n",
    "    return path\n",
    "\n",
    "@_is_input_path\n",
    "def get_scoring_audio_path():\n",
    "    path = os.path.join(get_test_path(), \"audio\")\n",
    "    return path\n",
    "\n",
    "@_is_output_path\n",
    "def get_submissions_path():\n",
    "    path = \"../working/output\"\n",
    "    return path\n",
    "\n",
    "@_is_output_path\n",
    "def get_silence_path():\n",
    "    path = \"../working/silence\"\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-correction",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-ending",
   "metadata": {},
   "source": [
    "공통적인 일반 목적의 유틸리티"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pleased-encounter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T13:44:24.413068Z",
     "start_time": "2021-02-22T13:44:24.399105Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utilities\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "def batching(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0,1,n):\n",
    "        yield iterable[ndx:min(ndx+n, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-assembly",
   "metadata": {},
   "source": [
    "## Data tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-destination",
   "metadata": {},
   "source": [
    "데이터 처리 툴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "placed-screening",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T14:01:01.076876Z",
     "start_time": "2021-02-22T14:01:01.064870Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_wav(filepath, pad=True):\n",
    "    # wav file의 filepath를 지정하면 이 함수가 파일을 읽어 정규화하고 16k 샘플이 있는지 확인하기 위해 패딩한다.\n",
    "    # filpath : wav file 의 기존 파일 경로 (str)\n",
    "    # pad : 패딩이 필요한지 여부 (bool)\n",
    "    # returns : 샘플과 target 변수 ((np.array,str)의 튜플)\n",
    "    sample_rate, x = wavfile.read(filepath)\n",
    "    target = os.path.split(os.path.split(filepath)[0])[1]\n",
    "    assert sample_rate == 16000\n",
    "    if pad:\n",
    "        return np.pad(x, (0, 16000-len(x)), mode='constant')/32768, target\n",
    "    else:\n",
    "        return x/32769, target\n",
    "    \n",
    "def get_batcher(list_of_paths, batch_size, label_encoder=None, scoring=False):\n",
    "    # batches 리스트가 주어진 batch 생성기를 생성\n",
    "    # list_of_paths : 포맷 요소가 있는 튜플 리스트 (filepath, target) (list)\n",
    "    # batch_size : 배치 사이즈 (int)\n",
    "    # label_encoder : 적합된 LabelEncoder (sklearn.LabelEncoder|optional)\n",
    "    # scoring : target이 고려되어야하는지 여부 (bool)\n",
    "    # returns : 배치 생성기\n",
    "    for filepaths in batching(list_of_paths, batch_size):\n",
    "        wavs, targets = zip(*list(map(read_wav, filepaths)))\n",
    "        if scoring:\n",
    "            yield np.expand_dims(np.row_stack(wavs), 2), filepaths\n",
    "        else:\n",
    "            if label_encoder is None:\n",
    "                yield np.expand_dims(np.row_stack(wavs), 2), np.row_stack(targets)\n",
    "            else:\n",
    "                yield np.expand_dims(np.row_stack(wavs), 2), np.expand_dims(label_encoder.transform(np.squeeze(targets)),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-trust",
   "metadata": {},
   "source": [
    "## Architecture building blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-madagascar",
   "metadata": {},
   "source": [
    "Inception-1D(wavception)은 이 문제를 위해 설계한 모델이다. 일반 컨볼루션 신경망의 성능을 크게 향상시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "considered-simpson",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T13:57:25.321238Z",
     "start_time": "2021-02-22T13:57:25.292317Z"
    }
   },
   "outputs": [],
   "source": [
    "class BatchNorm(object):\n",
    "    def __init__(self, epsilon=1e-5, momentum=0.999, name='batch_norm'):\n",
    "        with tf.compat.v1.variabl_scope(name):\n",
    "            self.epsilon = epsilon\n",
    "            self.momentum = momentum\n",
    "            self.name = name\n",
    "            \n",
    "    def __call__(self, x, train=True):\n",
    "        return tf.contrib.layers.batch_norm(x, decay=self.momentum,\n",
    "                                           updates_collection=None, epsilon=self.epsilon,\n",
    "                                           scale=True, is_trainig=train, scope=self.name)\n",
    "    \n",
    "    def inception_1d(x, is_train, depth, norm_funtion, activ_function, name):\n",
    "        # Inception 1D 모듈 구현\n",
    "        # x : 현재 모듈에 대한 입력 (channels-last가 있는 4D tensor)\n",
    "        # is_train : BatchNormalization 동작을 제어하기 위한 boolean placeholder가 되도록 고안 (0D tensor)\n",
    "        # depth : 네트워크의 깊이를 선형적으로 제어 (int)\n",
    "        # norm_function : 정규화 클래스 (위의 BatchNorm 클래스와 동일한 포맷)\n",
    "        # activ_function : tensorclow 활성화함수 (예: tf.nn.relu)\n",
    "        # name : 변수 범위의 이름 (str)\n",
    "        with tf.variable_scope(name):\n",
    "            x_norm = norm_function(name=\"norm_input\")(x, train=is_train)\n",
    "\n",
    "        # Branch 1: 64 x conv 1x1 \n",
    "        branch_conv_1_1 = tf.layers.conv1d(inputs=x_norm, filters=16*depth, kernel_size=1,\n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_1_1\")\n",
    "        branch_conv_1_1 = norm_function(name=\"norm_conv_1_1\")(branch_conv_1_1, train=is_train)\n",
    "        branch_conv_1_1 = activ_function(branch_conv_1_1, \"activation_1_1\")\n",
    "\n",
    "        # Branch 2: 128 x conv 3x3 \n",
    "        branch_conv_3_3 = tf.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_3_3_1\")\n",
    "        branch_conv_3_3 = norm_function(name=\"norm_conv_3_3_1\")(branch_conv_3_3, train=is_train)\n",
    "        branch_conv_3_3 = activ_function(branch_conv_3_3, \"activation_3_3_1\")\n",
    "\n",
    "        branch_conv_3_3 = tf.layers.conv1d(inputs=branch_conv_3_3, filters=32*depth, kernel_size=3, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_3_3_2\")\n",
    "        branch_conv_3_3 = norm_function(name=\"norm_conv_3_3_2\")(branch_conv_3_3, train=is_train)\n",
    "        branch_conv_3_3 = activ_function(branch_conv_3_3, \"activation_3_3_2\")\n",
    "\n",
    "        # Branch 3: 128 x conv 5x5 \n",
    "        branch_conv_5_5 = tf.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_5_5_1\")\n",
    "        branch_conv_5_5 = norm_function(name=\"norm_conv_5_5_1\")(branch_conv_5_5, train=is_train)\n",
    "        branch_conv_5_5 = activ_function(branch_conv_5_5, \"activation_5_5_1\")\n",
    "\n",
    "        branch_conv_5_5 = tf.layers.conv1d(inputs=branch_conv_5_5, filters=32*depth, kernel_size=5, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_5_5_2\")\n",
    "        branch_conv_5_5 = norm_function(name=\"norm_conv_5_5_2\")(branch_conv_5_5, train=is_train)\n",
    "        branch_conv_5_5 = activ_function(branch_conv_5_5, \"activation_5_5_2\")\n",
    "\n",
    "        # Branch 4: 128 x conv 7x7\n",
    "        branch_conv_7_7 = tf.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_7_7_1\")\n",
    "        branch_conv_7_7 = norm_function(name=\"norm_conv_7_7_1\")(branch_conv_7_7, train=is_train)\n",
    "        branch_conv_7_7 = activ_function(branch_conv_7_7, \"activation_7_7_1\")\n",
    "\n",
    "        branch_conv_7_7 = tf.layers.conv1d(inputs=branch_conv_7_7, filters=32*depth, kernel_size=5, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_7_7_2\")\n",
    "        branch_conv_7_7 = norm_function(name=\"norm_conv_7_7_2\")(branch_conv_7_7, train=is_train)\n",
    "        branch_conv_7_7 = activ_function(branch_conv_7_7, \"activation_7_7_2\")\n",
    "\n",
    "        # Branch 5: 16 x (max_pool 3x3 + conv 1x1)\n",
    "        branch_maxpool_3_3 = tf.layers.max_pooling1d(inputs=x_norm, pool_size=3, strides=1, padding=\"same\", name=\"maxpool_3\")\n",
    "        branch_maxpool_3_3 = norm_function(name=\"norm_maxpool_3_3\")(branch_maxpool_3_3, train=is_train)\n",
    "        branch_maxpool_3_3 = tf.layers.conv1d(inputs=branch_maxpool_3_3, filters=16, kernel_size=1, \n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_maxpool_3\")\n",
    "\n",
    "        # Branch 6: 16 x (max_pool 5x5 + conv 1x1)\n",
    "        branch_maxpool_5_5 = tf.layers.max_pooling1d(inputs=x_norm, pool_size=5, strides=1, padding=\"same\", name=\"maxpool_5\")\n",
    "        branch_maxpool_5_5 = norm_function(name=\"norm_maxpool_5_5\")(branch_maxpool_5_5, train=is_train)\n",
    "        branch_maxpool_5_5 = tf.layers.conv1d(inputs=branch_maxpool_5_5, filters=16, kernel_size=1, \n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_maxpool_5\")\n",
    "\n",
    "        # Branch 7: 16 x (avg_pool 3x3 + conv 1x1)\n",
    "        branch_avgpool_3_3 = tf.layers.average_pooling1d(inputs=x_norm, pool_size=3, strides=1, padding=\"same\", name=\"avgpool_3\")\n",
    "        branch_avgpool_3_3 = norm_function(name=\"norm_avgpool_3_3\")(branch_avgpool_3_3, train=is_train)\n",
    "        branch_avgpool_3_3 = tf.layers.conv1d(inputs=branch_avgpool_3_3, filters=16, kernel_size=1,\n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_avgpool_3\")\n",
    "\n",
    "        # Branch 8: 16 x (avg_pool 5x5 + conv 1x1)\n",
    "        branch_avgpool_5_5 = tf.layers.average_pooling1d(inputs=x_norm, pool_size=5, strides=1, padding=\"same\", name=\"avgpool_5\")\n",
    "        branch_avgpool_5_5 = norm_function(name=\"norm_avgpool_5_5\")(branch_avgpool_5_5, train=is_train)\n",
    "        branch_avgpool_5_5 = tf.layers.conv1d(inputs=branch_avgpool_5_5, filters=16, kernel_size=1, \n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_avgpool_5\")\n",
    "\n",
    "        # Concatenate\n",
    "        output = tf.concat([branch_conv_1_1, branch_conv_3_3, branch_conv_5_5, branch_conv_7_7, branch_maxpool_3_3, \n",
    "                           branch_maxpool_5_5, branch_avgpool_3_3, branch_avgpool_5_5], axis=-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-washer",
   "metadata": {},
   "source": [
    "## Load and prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "checked-basic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T14:01:21.414422Z",
     "start_time": "2021-02-22T14:01:21.001828Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-c547605664d9>:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sample_rate, x = wavfile.read(filepath)\n"
     ]
    }
   ],
   "source": [
    "# 합성되고 제공된 노이즈 추가\n",
    "filepaths_noise = glob.glob(os.path.join(get_train_audio_path(), '_background_noise_', '*.wav'))\n",
    "\n",
    "noise = np.concatenate(list(map(lambda x: read_wav(x, False)[0], filepaths_noise)))\n",
    "noise = np.concatenate([noise, noise[::-1]])\n",
    "synthetic_noise = np.concatenate([white_noise(N=16000*30, state=np.random.RandomState(655321)), \n",
    "                                  blue_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                  pink_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                  brown_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                  violet_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                  np.zeros(16000*60)])\n",
    "synthetic_noise /= np.max(np.abs(synthetic_noise))\n",
    "synthetic_noise = np.concatenate([synthetic_noise, (synthetic_noise+synthetic_noise[::-1])/2])\n",
    "all_noise = np.concatenate([noise, synthetic_noise])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "mature-peter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T14:07:30.339570Z",
     "start_time": "2021-02-22T14:07:17.454540Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|█████████████████████████████████████▉                                       | 3945/8000 [00:06<00:05, 688.55it/s]<ipython-input-17-5fc15c3aeffc>:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ((32767*clip/np.max(np.abs(clip))).astype(np.int16)))\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 8000/8000 [00:12<00:00, 622.56it/s]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(655321)\n",
    "random.seed(655321)\n",
    "path = get_silence_path()\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "for noise_clip_no in tqdm(range(8000)):\n",
    "    if noise_clip_no <= 4000:\n",
    "        idx = np.random.randint(0, len(noise)-16000)\n",
    "        clip = noise[idx:(idx+16000)]\n",
    "    else:\n",
    "        idx = np.random.randint(0, len(synthetic_noise)-16000)\n",
    "        clip = synthetic_noise[idx:(idx+16000)]\n",
    "    wavfile.write(os.path.join(path, '{0:04d}.wav'.format(noise_clip_no)),16000,\n",
    "                 ((32767*clip/np.max(np.abs(clip))).astype(np.int16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "appropriate-correlation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T14:09:01.107574Z",
     "start_time": "2021-02-22T14:08:53.885761Z"
    }
   },
   "outputs": [],
   "source": [
    "filepaths = glob.glob(os.path.join(get_train_audio_path(), \"**/*.wav\"), recursive=True)\n",
    "filepaths += glob.glob(os.path.join(get_silence_path(), \"**/*.wav\"), recursive=True)\n",
    "filepaths = list(filter(lambda fp: \"_background_noise_\" not in fp, filepaths))\n",
    "validation_list = open(os.path.join(get_train_path(), \"validation_list.txt\")).readlines()\n",
    "test_list = open(os.path.join(get_train_path(), \"testing_list.txt\")).readlines()\n",
    "validation_list = list(map(lambda fn: os.path.join(get_train_audio_path(), fn.strip()), validation_list))\n",
    "testing_list = list(map(lambda fn: os.path.join(get_train_audio_path(), fn.strip()), test_list))\n",
    "training_list = np.setdiff1d(filepaths, validation_list+testing_list).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "completed-reading",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T14:17:39.938589Z",
     "start_time": "2021-02-22T14:17:39.730827Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(655321)\n",
    "random.shuffle(filepaths)\n",
    "random.shuffle(validation_list)\n",
    "random.shuffle(testing_list)\n",
    "random.shuffle(training_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "israeli-melbourne",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T14:17:40.377126Z",
     "start_time": "2021-02-22T14:17:40.183635Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-96c3b3f9a5d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'.wav'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m64727\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m8000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6798\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6835\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m6798\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m6835\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Quick Unit-Tests\n",
    "# 파일 수와 일관성 확인\n",
    "assert all(map(lambda fp: os.path.splitext(fp)[1]=='.wav', filepaths)) \n",
    "assert len(filepaths)==64727-6+8000\n",
    "assert len(training_list) == len(filepaths)-6798-6835\n",
    "assert len(validation_list) == 6798\n",
    "assert len(testing_list) == 6835\n",
    "\n",
    "# 파일 존재 확인\n",
    "assert all(map(lambda fn: os.path.exists(os.path.join(fn)), validation_list))\n",
    "assert all(map(lambda fn: os.path.exists(os.path.join(fn)), testing_list))\n",
    "assert all(map(lambda fn: os.path.exists(os.path.join(fn)), training_list))\n",
    "assert set(validation_list + testing_list + training_list) == set(filepaths)\n",
    "\n",
    "# 세트에 중복데이터 없는지 확인\n",
    "assert len(np.intersect1d(validation_list, testing_list)) == 0  ## intersect1d : 두 배열의 교집합 정렬해 반환\n",
    "assert len(np.intersect1d(training_list, testing_list)) == 0\n",
    "assert len(np.intersect1d(training_list, validation_list)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-operator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-africa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-compatibility",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-lyric",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "564px",
    "left": "67px",
    "top": "292.8px",
    "width": "153.6px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
