{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "going-olympus",
   "metadata": {},
   "source": [
    "# Kaggle Study Day 26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-sponsorship",
   "metadata": {},
   "source": [
    "# WavCeption V1 : a 1-D Inception approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-dover",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/ivallesp/wavception-v1-a-1-d-inception-approach-lb-0-76"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-hurricane",
   "metadata": {},
   "source": [
    "WaveCeption V1 네트워크는 일반 컨볼루션 신경망에 비해 인상적인 결과를 내는 것처럼 보이지만, 이 대회에선 전처리와 알려지지 않은 트랙 관리에서 힘든 작업이 있는 것 같아보인다. 이는 같은 아이디어인 구글의 inception 네트워크를 기반으로 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-outreach",
   "metadata": {},
   "source": [
    "## Load modules and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "following-bryan",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T13:01:05.682106Z",
     "start_time": "2021-02-22T13:00:47.233679Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import IPython\n",
    "from numpy.fft import rfft, irfft\n",
    "import itertools\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-sword",
   "metadata": {},
   "source": [
    "## Noise generation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acoustic-plaza",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T14:01:17.435717Z",
     "start_time": "2021-02-22T14:01:17.401807Z"
    }
   },
   "outputs": [],
   "source": [
    "def ms(x):\n",
    "    # 신호 x 제곱의 평균값\n",
    "    # param x : 상수 (dynamic quantity)\n",
    "    # returns : x의 평균 제곱\n",
    "    return (np.abs(x)**2.0).mean()\n",
    "\n",
    "\n",
    "def normalize(y, x=None):\n",
    "    # y를 (standard normal인) 백색 소음 신호로 정규화\n",
    "    # 신호 x를 선택적으로 정규화\n",
    "    # \\\\mu=0과 \\\\signal=1인 가우시안의 평균은 1.\n",
    "    \n",
    "    # y * np.sqrt((np.abs(x)**2.0).mean() / (np.abs(y)**2.0).mean()) 반환\n",
    "    if x is not None:\n",
    "        x = ms(x)\n",
    "    else :\n",
    "        x = 1.0\n",
    "    return y* np.sqrt(x/ms(y))  # np.sqrt(1.0 / (np.abs(y)**2.0).mean()) 반환\n",
    "\n",
    "\n",
    "def white_noise(N, state=None):\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    return state.randn(N)\n",
    "\n",
    "\n",
    "def pink_noise(N, state=None):\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j*state.randn(N//2+1+uneven)\n",
    "    S = np.sqrt(np.arange(len(X))+1.)  # 0으로 나뉘는 것을 방지하기 위해 +1\n",
    "    y = (irfft(X/S)).real\n",
    "    if uneven :\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "\n",
    "def blue_noise(N, state=None):\n",
    "    # Blue noise\n",
    "    # param N : 샘플 수\n",
    "    # param state : PRNG의 state\n",
    "    # type state : class:'np.random.RandomState'\n",
    "    # 전력은 옥타브당 6dB씩 증가\n",
    "    # 전력 밀도는 옥타브당 3dB씩 증가\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j*state.randn(N//2+1+uneven)\n",
    "    S = np.sqrt(np.arange(len(X)))  # filter\n",
    "    y = (irfft(X*S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "\n",
    "def brown_noise(N, state=None):\n",
    "    # Violet noise\n",
    "    # param N : 샘플 수 \n",
    "    # param sate : PRNG의 state\n",
    "    # type state : class:'np.random.RandomState'\n",
    "    # 전력은 옥타브당 -3dB씩 감소\n",
    "    # 전력 밀도는 옥타브당 6dB씩 감소\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = (np.arange(len(X))+1)  # Filter\n",
    "    y = (irfft(X/S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "\n",
    "def violet_noise(N, state=None):\n",
    "    # Violet noise. 옥타브당 전력이 6dB씩 증가\n",
    "    # param N : 샘플 수 \n",
    "    # param sate : PRNG의 state\n",
    "    # type state : class:'np.random.RandomState'\n",
    "    # 전력은 옥타브당 +9dB씩 증가\n",
    "    # 전력 밀도는 옥타브당 +6dB씩 증가\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = (np.arange(len(X)))# Filter\n",
    "    y = (irfft(X*S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-passage",
   "metadata": {},
   "source": [
    "## Tensorflow utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-dispatch",
   "metadata": {},
   "source": [
    "tensorflow의 공통 작업을 모듈화하는 유틸리티"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "african-italy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T13:29:25.138354Z",
     "start_time": "2021-02-22T13:29:25.117412Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tf Utils\n",
    "def get_tensorflow_configuration(device='0', memory_fraction=1):\n",
    "    # 사용할 GPU 및 프로세스에서 사용할 수 있는 메모리 양을 선택하는 함수\n",
    "    # param device : 사용될 장치 (str)\n",
    "    # param memory_fraction : 할당해야하는 메모리 비율 (float)\n",
    "    # return : 세션에 전달할 config (tf 객체)\n",
    "    device = str(device)\n",
    "    config = tf.ConfigProto()\n",
    "    config.allow_soft_placement = True\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = memory_fraction\n",
    "    config.gpu_options.visible_device_list = device\n",
    "    return (config)\n",
    "\n",
    "\n",
    "def start_tensorflow_session(device='0', memory_fraction=1):\n",
    "    # 사용할 GPU 장치와 사전 할당될 메모리 부분을 관리하는 tensorflow 세션을 시작\n",
    "    # device : 장치 번호가 있는 문자열(str)\n",
    "    # memory_fraction : 지정된 메모리에서 사전 할당될 메모리 일부 (float[0.1])\n",
    "    # return : 구성(configure)된 tf.Session \n",
    "    return (tf.Session(config=get_tensorflow_configuration(device=device, memory_fraction=memory_fraction)))\n",
    "\n",
    "\n",
    "def get_summary_writer(session, logs_path, project_id, version_id):\n",
    "    # For tensorboarded reportin\n",
    "    # session : 열린 tensorflow 세션 (tf.Session)\n",
    "    # logs_path : tensorboard가 logs를 찾는 경로 (str)\n",
    "    # project_id : 목적을 보고하기 위한 프로젝트 이름\n",
    "    # version_id : 목적을 보고하기 위한 버전 이름\n",
    "    # return summary_writer : tesorboard writer\n",
    "    path = os.path.join(logs_path, '{}_{}'.format(project_id, version_id))\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    summary_writer = tf.suumary.FilterWriter(path, graph_def=session.graph_def)\n",
    "    return summary_writer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-large",
   "metadata": {},
   "source": [
    "## paths management module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "naughty-veteran",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T13:43:07.740900Z",
     "start_time": "2021-02-22T13:43:07.729929Z"
    }
   },
   "outputs": [],
   "source": [
    "# common paths\n",
    "def _norm_path(path):\n",
    "    # 경로 검색 기능의 출력을 정규화하는 데 사용하기 위한 decorator 함수. 슬랙시/백슬래시 윈도우 케이스를 고정하는 데 유용\n",
    "    def normalize_path(*args, **kwargs):\n",
    "        return os.path.normpath(path(*args, **kwargs))\n",
    "    return normalize_path\n",
    "\n",
    "def _assure_path_exists(path):\n",
    "    # 경로 검색 기능의 출력 존재 여부를 확인하기 위한 decorator 함수. 슬래시/백슬래시 윈도우 케이스를 고정하는 데 유용\n",
    "    def assure_exists(*args, **kwargs):\n",
    "        p = path(*args, **kwargs)\n",
    "        assert os.path.exists(p), \"the following path does not exist: '{}'\".format(p)\n",
    "        return p\n",
    "    return assure_exists\n",
    "\n",
    "def _is_output_path(path):\n",
    "    # 출력 경로 검색 함수의 출력에 적용되는 함수를 그룹화하는 데 사용하는 decorator 함수\n",
    "    @_norm_path\n",
    "    @_assure_path_exists\n",
    "    def check_existence_or_create_it(*args, **kwargs):\n",
    "        if not os.path.exists(path(*args, **kwargs)):\n",
    "            \"Path does not exist... creating it: {}\".format(path(*args, **kwargs))\n",
    "            os.makedirs(path(*args, **kwargs))\n",
    "        return path(*args, **kwargs)\n",
    "    return check_existence_or_create_it\n",
    "\n",
    "def _is_input_path(path):\n",
    "    # 입력 경로 검색 함수의 출력에 적용되는 함수를 그룹화하는 데 사용되는 decorator 함수\n",
    "    @_norm_path\n",
    "    @_assure_path_exists\n",
    "    def check_existence(*args, **kwargs):\n",
    "        return path(*args, **kwargs)\n",
    "    return check_existence\n",
    "\n",
    "\n",
    "@_is_input_path\n",
    "def get_train_path():\n",
    "    path = \"../input/train\"\n",
    "    return path\n",
    "\n",
    "@_is_input_path\n",
    "def get_test_path():\n",
    "    path = \"../input/test\"\n",
    "    return path\n",
    "\n",
    "@_is_input_path\n",
    "def get_train_audio_path():\n",
    "    path = os.path.join(get_train_path(), \"audio\")\n",
    "    return path\n",
    "\n",
    "@_is_input_path\n",
    "def get_scoring_audio_path():\n",
    "    path = os.path.join(get_test_path(), \"audio\")\n",
    "    return path\n",
    "\n",
    "@_is_output_path\n",
    "def get_submissions_path():\n",
    "    path = \"../working/output\"\n",
    "    return path\n",
    "\n",
    "@_is_output_path\n",
    "def get_silence_path():\n",
    "    path = \"../working/silence\"\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-pittsburgh",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-secretary",
   "metadata": {},
   "source": [
    "공통적인 일반 목적의 유틸리티"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "motivated-collective",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T13:44:24.413068Z",
     "start_time": "2021-02-22T13:44:24.399105Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utilities\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "def batching(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0,1,n):\n",
    "        yield iterable[ndx:min(ndx+n, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-grammar",
   "metadata": {},
   "source": [
    "## Data tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-meter",
   "metadata": {},
   "source": [
    "데이터 처리 툴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "lucky-position",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T14:01:01.076876Z",
     "start_time": "2021-02-22T14:01:01.064870Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_wav(filepath, pad=True):\n",
    "    # wav file의 filepath를 지정하면 이 함수가 파일을 읽어 정규화하고 16k 샘플이 있는지 확인하기 위해 패딩한다.\n",
    "    # filpath : wav file 의 기존 파일 경로 (str)\n",
    "    # pad : 패딩이 필요한지 여부 (bool)\n",
    "    # returns : 샘플과 target 변수 ((np.array,str)의 튜플)\n",
    "    sample_rate, x = wavfile.read(filepath)\n",
    "    target = os.path.split(os.path.split(filepath)[0])[1]\n",
    "    assert sample_rate == 16000\n",
    "    if pad:\n",
    "        return np.pad(x, (0, 16000-len(x)), mode='constant')/32768, target\n",
    "    else:\n",
    "        return x/32769, target\n",
    "    \n",
    "def get_batcher(list_of_paths, batch_size, label_encoder=None, scoring=False):\n",
    "    # batches 리스트가 주어진 batch 생성기를 생성\n",
    "    # list_of_paths : 포맷 요소가 있는 튜플 리스트 (filepath, target) (list)\n",
    "    # batch_size : 배치 사이즈 (int)\n",
    "    # label_encoder : 적합된 LabelEncoder (sklearn.LabelEncoder|optional)\n",
    "    # scoring : target이 고려되어야하는지 여부 (bool)\n",
    "    # returns : 배치 생성기\n",
    "    for filepaths in batching(list_of_paths, batch_size):\n",
    "        wavs, targets = zip(*list(map(read_wav, filepaths)))\n",
    "        if scoring:\n",
    "            yield np.expand_dims(np.row_stack(wavs), 2), filepaths\n",
    "        else:\n",
    "            if label_encoder is None:\n",
    "                yield np.expand_dims(np.row_stack(wavs), 2), np.row_stack(targets)\n",
    "            else:\n",
    "                yield np.expand_dims(np.row_stack(wavs), 2), np.expand_dims(label_encoder.transform(np.squeeze(targets)),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-trinity",
   "metadata": {},
   "source": [
    "## Architecture building blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-flood",
   "metadata": {},
   "source": [
    "Inception-1D(wavception)은 이 문제를 위해 설계한 모델이다. 일반 컨볼루션 신경망의 성능을 크게 향상시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "invalid-infection",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T16:05:09.330210Z",
     "start_time": "2021-02-22T16:05:09.302285Z"
    }
   },
   "outputs": [],
   "source": [
    "class BatchNorm(object):\n",
    "    def __init__(self, epsilon=1e-5, momentum=0.999, name='batch_normalization'):\n",
    "        with tf.compat.v1.variable_scope(name):\n",
    "            self.epsilon = epsilon\n",
    "            self.momentum = momentum\n",
    "            self.name = name\n",
    "            \n",
    "    def __call__(self, x, train=True):\n",
    "        return tf.compat.v1.layers.batch_normalization(x, momentum=self.momentum,\n",
    "                                           epsilon=self.epsilon, scale=True, training=train, name=self.name)\n",
    "    \n",
    "def inception_1d(x, is_train, depth, norm_function, activ_function, name):\n",
    "    # Inception 1D 모듈 구현\n",
    "    # x : 현재 모듈에 대한 입력 (channels-last가 있는 4D tensor)\n",
    "    # is_train : BatchNormalization 동작을 제어하기 위한 boolean placeholder가 되도록 고안 (0D tensor)\n",
    "    # depth : 네트워크의 깊이를 선형적으로 제어 (int)\n",
    "    # norm_function : 정규화 클래스 (위의 BatchNorm 클래스와 동일한 포맷)\n",
    "    # activ_function : tensorclow 활성화함수 (예: tf.nn.relu)\n",
    "    # name : 변수 범위의 이름 (str)\n",
    "    with tf.compat.v1.variable_scope(name):\n",
    "        x_norm = norm_function(name=\"norm_input\")(x, train=is_train)\n",
    "\n",
    "        # Branch 1: 64 x conv 1x1 \n",
    "        branch_conv_1_1 = tf.compat.v1.layers.conv1d(inputs=x_norm, filters=16*depth, kernel_size=1,\n",
    "                                           kernel_initializer=tf.initializers.GlorotUniform(),\n",
    "                                           padding=\"same\", name=\"conv_1_1\")\n",
    "        branch_conv_1_1 = norm_function(name=\"norm_conv_1_1\")(branch_conv_1_1, train=is_train)\n",
    "        branch_conv_1_1 = activ_function(branch_conv_1_1, \"activation_1_1\")\n",
    "\n",
    "        # Branch 2: 128 x conv 3x3 \n",
    "        branch_conv_3_3 = tf.compat.v1.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n",
    "                                           kernel_initializer=tf.initializers.GlorotUniform(),\n",
    "                                           padding=\"same\", name=\"conv_3_3_1\")\n",
    "        branch_conv_3_3 = norm_function(name=\"norm_conv_3_3_1\")(branch_conv_3_3, train=is_train)\n",
    "        branch_conv_3_3 = activ_function(branch_conv_3_3, \"activation_3_3_1\")\n",
    "\n",
    "        branch_conv_3_3 = tf.compat.v1.layers.conv1d(inputs=branch_conv_3_3, filters=32*depth, kernel_size=3, \n",
    "                                           kernel_initializer=tf.initializers.GlorotUniform(),\n",
    "                                           padding=\"same\", name=\"conv_3_3_2\")\n",
    "        branch_conv_3_3 = norm_function(name=\"norm_conv_3_3_2\")(branch_conv_3_3, train=is_train)\n",
    "        branch_conv_3_3 = activ_function(branch_conv_3_3, \"activation_3_3_2\")\n",
    "\n",
    "        # Branch 3: 128 x conv 5x5 \n",
    "        branch_conv_5_5 = tf.compat.v1.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n",
    "                                           kernel_initializer=tf.initializers.GlorotUniform(),\n",
    "                                           padding=\"same\", name=\"conv_5_5_1\")\n",
    "        branch_conv_5_5 = norm_function(name=\"norm_conv_5_5_1\")(branch_conv_5_5, train=is_train)\n",
    "        branch_conv_5_5 = activ_function(branch_conv_5_5, \"activation_5_5_1\")\n",
    "\n",
    "        branch_conv_5_5 = tf.compat.v1.layers.conv1d(inputs=branch_conv_5_5, filters=32*depth, kernel_size=5, \n",
    "                                           kernel_initializer=tf.initializers.GlorotUniform(),\n",
    "                                           padding=\"same\", name=\"conv_5_5_2\")\n",
    "        branch_conv_5_5 = norm_function(name=\"norm_conv_5_5_2\")(branch_conv_5_5, train=is_train)\n",
    "        branch_conv_5_5 = activ_function(branch_conv_5_5, \"activation_5_5_2\")\n",
    "\n",
    "        # Branch 4: 128 x conv 7x7\n",
    "        branch_conv_7_7 = tf.compat.v1.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n",
    "                                           kernel_initializer=tf.initializers.GlorotUniform(),\n",
    "                                           padding=\"same\", name=\"conv_7_7_1\")\n",
    "        branch_conv_7_7 = norm_function(name=\"norm_conv_7_7_1\")(branch_conv_7_7, train=is_train)\n",
    "        branch_conv_7_7 = activ_function(branch_conv_7_7, \"activation_7_7_1\")\n",
    "\n",
    "        branch_conv_7_7 = tf.compat.v1.layers.conv1d(inputs=branch_conv_7_7, filters=32*depth, kernel_size=5, \n",
    "                                           kernel_initializer=tf.initializers.GlorotUniform(),\n",
    "                                           padding=\"same\", name=\"conv_7_7_2\")\n",
    "        branch_conv_7_7 = norm_function(name=\"norm_conv_7_7_2\")(branch_conv_7_7, train=is_train)\n",
    "        branch_conv_7_7 = activ_function(branch_conv_7_7, \"activation_7_7_2\")\n",
    "\n",
    "        # Branch 5: 16 x (max_pool 3x3 + conv 1x1)\n",
    "        branch_maxpool_3_3 = tf.compat.v1.layers.max_pooling1d(inputs=x_norm, pool_size=3, strides=1, padding=\"same\", name=\"maxpool_3\")\n",
    "        branch_maxpool_3_3 = norm_function(name=\"norm_maxpool_3_3\")(branch_maxpool_3_3, train=is_train)\n",
    "        branch_maxpool_3_3 = tf.compat.v1.layers.conv1d(inputs=branch_maxpool_3_3, filters=16, kernel_size=1, \n",
    "                                              kernel_initializer=tf.initializers.GlorotUniform(),\n",
    "                                              padding=\"same\", name=\"conv_maxpool_3\")\n",
    "\n",
    "        # Branch 6: 16 x (max_pool 5x5 + conv 1x1)\n",
    "        branch_maxpool_5_5 = tf.compat.v1.layers.max_pooling1d(inputs=x_norm, pool_size=5, strides=1, padding=\"same\", name=\"maxpool_5\")\n",
    "        branch_maxpool_5_5 = norm_function(name=\"norm_maxpool_5_5\")(branch_maxpool_5_5, train=is_train)\n",
    "        branch_maxpool_5_5 = tf.compat.v1.layers.conv1d(inputs=branch_maxpool_5_5, filters=16, kernel_size=1, \n",
    "                                              kernel_initializer=tf.initializers.GlorotUniform(),\n",
    "                                              padding=\"same\", name=\"conv_maxpool_5\")\n",
    "\n",
    "        # Branch 7: 16 x (avg_pool 3x3 + conv 1x1)\n",
    "        branch_avgpool_3_3 = tf.compat.v1.layers.average_pooling1d(inputs=x_norm, pool_size=3, strides=1, padding=\"same\", name=\"avgpool_3\")\n",
    "        branch_avgpool_3_3 = norm_function(name=\"norm_avgpool_3_3\")(branch_avgpool_3_3, train=is_train)\n",
    "        branch_avgpool_3_3 = tf.compat.v1.layers.conv1d(inputs=branch_avgpool_3_3, filters=16, kernel_size=1,\n",
    "                                              kernel_initializer=tf.initializers.GlorotUniform(),\n",
    "                                              padding=\"same\", name=\"conv_avgpool_3\")\n",
    "\n",
    "        # Branch 8: 16 x (avg_pool 5x5 + conv 1x1)\n",
    "        branch_avgpool_5_5 = tf.compat.v1.layers.average_pooling1d(inputs=x_norm, pool_size=5, strides=1, padding=\"same\", name=\"avgpool_5\")\n",
    "        branch_avgpool_5_5 = norm_function(name=\"norm_avgpool_5_5\")(branch_avgpool_5_5, train=is_train)\n",
    "        branch_avgpool_5_5 = tf.compat.v1.layers.conv1d(inputs=branch_avgpool_5_5, filters=16, kernel_size=1, \n",
    "                                              kernel_initializer=tf.initializers.GlorotUniform(),\n",
    "                                              padding=\"same\", name=\"conv_avgpool_5\")\n",
    "\n",
    "        # Concatenate\n",
    "        output = tf.concat([branch_conv_1_1, branch_conv_3_3, branch_conv_5_5, branch_conv_7_7, branch_maxpool_3_3, \n",
    "                           branch_maxpool_5_5, branch_avgpool_3_3, branch_avgpool_5_5], axis=-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-industry",
   "metadata": {},
   "source": [
    "## Load and prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aggressive-thumbnail",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T14:29:11.138945Z",
     "start_time": "2021-02-22T14:29:10.711089Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-c547605664d9>:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sample_rate, x = wavfile.read(filepath)\n"
     ]
    }
   ],
   "source": [
    "# 합성되고 제공된 노이즈 추가\n",
    "filepaths_noise = glob.glob(os.path.join(get_train_audio_path(), \"_background_noise_\", \"*.wav\"))\n",
    "\n",
    "noise = np.concatenate(list(map(lambda x: read_wav(x, False)[0], filepaths_noise)))\n",
    "noise = np.concatenate([noise, noise[::-1]])\n",
    "synthetic_noise = np.concatenate([white_noise(N=16000*30, state=np.random.RandomState(655321)), \n",
    "                                  blue_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                  pink_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                  brown_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                  violet_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                  np.zeros(16000*60)])\n",
    "synthetic_noise /= np.max(np.abs(synthetic_noise))\n",
    "synthetic_noise = np.concatenate([synthetic_noise, (synthetic_noise+synthetic_noise[::-1])/2])\n",
    "all_noise = np.concatenate([noise, synthetic_noise])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "continental-roommate",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T14:29:24.693160Z",
     "start_time": "2021-02-22T14:29:16.355439Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████▉                                      | 3988/8000 [00:03<00:03, 1086.56it/s]<ipython-input-26-9d89daa175ef>:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ((32767*clip/np.max(np.abs(clip))).astype(np.int16)))\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 8000/8000 [00:08<00:00, 961.56it/s]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(655321)\n",
    "random.seed(655321)\n",
    "path = get_silence_path()\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "for noise_clip_no in tqdm(range(8000)):\n",
    "    if noise_clip_no <= 4000:\n",
    "        idx = np.random.randint(0, len(noise)-16000)\n",
    "        clip = noise[idx:(idx+16000)]\n",
    "    else:\n",
    "        idx = np.random.randint(0, len(synthetic_noise)-16000)\n",
    "        clip = synthetic_noise[idx:(idx+16000)]\n",
    "    wavfile.write(os.path.join(path, \"{0:04d}.wav\".format(noise_clip_no)), 16000, \n",
    "                 ((32767*clip/np.max(np.abs(clip))).astype(np.int16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "valuable-austria",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T14:41:05.291791Z",
     "start_time": "2021-02-22T14:41:00.553530Z"
    }
   },
   "outputs": [],
   "source": [
    "filepaths = glob.glob(os.path.join(get_train_audio_path(), \"**/*.wav\"), recursive=True)\n",
    "filepaths += glob.glob(os.path.join(get_silence_path(), \"**/*.wav\"), recursive=True)\n",
    "filepaths = list(filter(lambda fp: \"_background_noise_\" not in fp, filepaths))\n",
    "validation_list = open(os.path.join(get_train_path(), \"validation_list.txt\")).readlines()\n",
    "test_list = open(os.path.join(get_train_path(), \"testing_list.txt\")).readlines()\n",
    "validation_list = list(map(lambda fn: os.path.join(get_train_audio_path(), fn.strip()), validation_list))\n",
    "testing_list = list(map(lambda fn: os.path.join(get_train_audio_path(), fn.strip()), test_list))\n",
    "#training_list = np.setdiff1d(filepaths, validation_list+testing_list).tolist()  ### setdif1d : 첫배열에서 두번째 배열 뺀 차집합 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "regulation-approval",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T14:29:34.949162Z",
     "start_time": "2021-02-22T14:29:34.757674Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(655321)\n",
    "random.shuffle(filepaths)\n",
    "random.shuffle(validation_list)\n",
    "random.shuffle(testing_list)\n",
    "random.shuffle(training_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "known-communication",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T14:29:38.147482Z",
     "start_time": "2021-02-22T14:29:37.837312Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-96c3b3f9a5d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'.wav'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m64727\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m8000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6798\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6835\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m6798\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m6835\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Quick Unit-Tests\n",
    "# 파일 수와 일관성 확인\n",
    "assert all(map(lambda fp: os.path.splitext(fp)[1]=='.wav', filepaths)) \n",
    "assert len(filepaths)==64727-6+8000\n",
    "assert len(training_list) == len(filepaths)-6798-6835\n",
    "assert len(validation_list) == 6798\n",
    "assert len(testing_list) == 6835\n",
    "\n",
    "# 파일 존재 확인\n",
    "assert all(map(lambda fn: os.path.exists(os.path.join(fn)), validation_list))\n",
    "assert all(map(lambda fn: os.path.exists(os.path.join(fn)), testing_list))\n",
    "assert all(map(lambda fn: os.path.exists(os.path.join(fn)), training_list))\n",
    "assert set(validation_list + testing_list + training_list) == set(filepaths)\n",
    "\n",
    "# 세트에 중복데이터 없는지 확인\n",
    "assert len(np.intersect1d(validation_list, testing_list)) == 0  ### intersect1d : 두 배열의 교집합 정렬해 반환\n",
    "assert len(np.intersect1d(training_list, testing_list)) == 0\n",
    "assert len(np.intersect1d(training_list, validation_list)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "seeing-pacific",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T15:12:43.180184Z",
     "start_time": "2021-02-22T15:12:41.728065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'bed': 1713,\n",
       "         'bird': 1731,\n",
       "         'cat': 1733,\n",
       "         'dog': 1746,\n",
       "         'down': 2359,\n",
       "         'eight': 2352,\n",
       "         'five': 2357,\n",
       "         'four': 2372,\n",
       "         'go': 2372,\n",
       "         'happy': 1742,\n",
       "         'house': 1750,\n",
       "         'left': 2353,\n",
       "         'marvin': 1746,\n",
       "         'nine': 2364,\n",
       "         'no': 2375,\n",
       "         'off': 2357,\n",
       "         'on': 2367,\n",
       "         'one': 2370,\n",
       "         'right': 2367,\n",
       "         'seven': 2377,\n",
       "         'sheila': 1734,\n",
       "         'six': 2369,\n",
       "         'stop': 2380,\n",
       "         'three': 2356,\n",
       "         'tree': 1733,\n",
       "         'two': 2373,\n",
       "         'up': 2375,\n",
       "         'wow': 1745,\n",
       "         'yes': 2377,\n",
       "         'zero': 2376,\n",
       "         'silence': 8000})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classes processing\n",
    "cardinal_classes = list(set(map(lambda fp:os.path.split(os.path.split(fp)[0])[1], filepaths)))\n",
    "le_classes = LabelEncoder().fit(cardinal_classes)\n",
    "Counter(map(lambda fp:os.path.split(os.path.split(fp)[0])[1], filepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "acknowledged-curve",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T15:13:52.464545Z",
     "start_time": "2021-02-22T15:13:52.426606Z"
    }
   },
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-b2c93965f18e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0m_gen_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_batcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbatch_a_wav\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_a_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_gen_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mbatch_b_wav\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_b_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_gen_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0m_gen_test_le\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_batcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mle_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mbatch_le_wav\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_le_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_gen_test_le\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Quick Unit-Tests\n",
    "# 데이터 사전준비 확인\n",
    "_gen_test = get_batcher(filepaths, 1000)\n",
    "batch_a_wav, batch_a_target = next(_gen_test)\n",
    "batch_b_wav, batch_b_target = next(_gen_test)\n",
    "_gen_test_le = get_batcher(filepaths, 1000, label_encoder=le_classes)\n",
    "batch_le_wav, batch_le_target = next(_gen_test_le)\n",
    "\n",
    "# batch matrix 형태 상관관계 확인\n",
    "assert batch_a_wav.shape == (1000, 16000, 1)\n",
    "assert batch_le_wav.shape == (1000, 16000, 1)\n",
    "assert batch_a_wav.shape == batch_b_wav.shape == batch_le_wav.shape\n",
    "\n",
    "# batch 재현성 확인\n",
    "assert np.sum(np.abs(batch_a_wav-batch_b_wav)) != 0\n",
    "assert len(batch_a_target) == len(batch_b_target) == len(batch_le_target)\n",
    "assert any(batch_a_target != batch_b_target)\n",
    "\n",
    "# 클래스 라벨 인코더 확인\n",
    "assert all(batch_le_target == np.expand_dims(le_classes.transform(np.squeeze(batch_a_target)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-shark",
   "metadata": {},
   "source": [
    "## Architecture design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-actress",
   "metadata": {},
   "source": [
    "이제 WavCeption을 디자인 해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "selected-decrease",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T16:09:54.633887Z",
     "start_time": "2021-02-22T16:09:54.600975Z"
    }
   },
   "outputs": [],
   "source": [
    "class NameSpacer:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "        \n",
    "class Architecture:\n",
    "    def __init__(self, class_cardinality, seq_len=16000, name='architecture'):\n",
    "        self.seq_len = seq_len\n",
    "        self.class_cardinality = class_cardinality\n",
    "        self.optimizer = tf.optimizers.Adam(learning_rate=0.0001)\n",
    "        self.name = name\n",
    "        self.define_computation_graph()\n",
    "        \n",
    "        # Aliases\n",
    "        self.ph = self.placeholders\n",
    "        self.op = self.optimizers\n",
    "        self.summ = self.summaries\n",
    "        \n",
    "    def define_computation_graph(self):\n",
    "        # reset graph\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        self.placeholders = NameSpacer(**self.define_placeholders())\n",
    "        self.core_model = NameSpacer(**self.define_core_model())\n",
    "        self.losses = NameSpacer(**self.define_losses())\n",
    "        self.optimizers = NameSpacer(**self.define_optimizers())\n",
    "        self.summaries = NameSpacer(**self.define_summaries())\n",
    "        \n",
    "    def define_placeholders(self):\n",
    "        import tensorflow.compat.v1 as tf\n",
    "        with tf.compat.v1.variable_scope('Placeholders'):\n",
    "            wav_in = tf.placeholder(dtype=tf.float32, shape=(None, self.seq_len, 1), name='wav_in')\n",
    "            is_train = tf.placeholder(dtype=tf.bool, shape=None, name='is_train')\n",
    "            target = tf.placeholder(dtype=tf.int32, shape=None, name='acc_dev')\n",
    "            acc_dev = tf.placeholder(dtype=tf.float32, shape=None, name=\"acc_dev\")\n",
    "            loss_dev = tf.placeholder(dtype=tf.float32, shape=None, name=\"loss_dev\")\n",
    "            return ({'wav_in':wav_in, 'target':target, 'is_train':is_train, 'acc_dev':acc_dev, 'loss_dev':loss_dev})\n",
    "        \n",
    "    def define_core_model(self):\n",
    "        with tf.compat.v1.variable_scope('Core_Model'):\n",
    "            x = inception_1d(x=self.placeholders.wav_in, is_train=self.placeholders.is_train, norm_function=BatchNorm,\n",
    "                            activ_function=tf.nn.relu, depth=1, name='Inception_1_1')\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm,\n",
    "                            activ_function=tf.nn.relu, depth=1, name='Inception_1_2')\n",
    "            x = tf.compat.v1.layers.max_pooling1d(x,2,2, name='maxpool_1')\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=1, name=\"Inception_2_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=1, name=\"Inception_2_3\")\n",
    "            x = tf.compat.v1.layers.max_pooling1d(x, 2, 2, name=\"maxpool_2\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=2, name=\"Inception_3_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=2, name=\"Inception_3_2\")\n",
    "            x = tf.compat.v1.layers.max_pooling1d(x, 2, 2, name=\"maxpool_3\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=2, name=\"Inception_4_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=2, name=\"Inception_4_2\")\n",
    "            x = tf.compat.v1.layers.max_pooling1d(x, 2, 2, name=\"maxpool_4\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=3, name=\"Inception_5_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=3, name=\"Inception_5_2\")\n",
    "            x = tf.compat.v1.layers.max_pooling1d(x, 2, 2, name=\"maxpool_5\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=3, name=\"Inception_6_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=3, name=\"Inception_6_2\")\n",
    "            x = tf.compat.v1.layers.max_pooling1d(x, 2, 2, name=\"maxpool_6\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=4, name=\"Inception_7_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=4, name=\"Inception_7_2\")\n",
    "            x = tf.compat.v1.layers.max_pooling1d(x, 2, 2, name=\"maxpool_7\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=4, name=\"Inception_8_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=4, name=\"Inception_8_2\")\n",
    "            x = tf.compat.v1.layers.max_pooling1d(x, 2, 2, name=\"maxpool_8\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=4, name=\"Inception_9_1\")\n",
    "            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n",
    "                             activ_function=tf.nn.relu, depth=4, name=\"Inception_9_2\")\n",
    "            x = tf.compat.v1.layers.max_pooling1d(x, 2, 2, name=\"maxpool_9\")\n",
    "            \n",
    "            x = tf.compat.v1.layers.flatten(x)\n",
    "            x = tf.compat.v1.layers.dense(BatchNorm(name='bn_dense_1')(x, train=self.placeholders.is_train),\n",
    "                               128, activation=tf.nn.relu, kernel_initializer=tf.initializers.GlorotUniform(), name='dense_1')\n",
    "            output = tf.compat.v1.layers.dense(BatchNorm(name='bn_dense_2')(x,train=self.placeholders.is_train),\n",
    "                                    self.class_cardinality, activation=None, kernel_initializer=tf.initializers.GlorotUniform(), name='output')\n",
    "            \n",
    "            return ({'output':output})\n",
    "        \n",
    "        \n",
    "    def define_losses(self):\n",
    "        with tf.compat.v1.variable_scope('Losses'):\n",
    "            softmax_ce = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf.squeeze(self.placeholders.target),\n",
    "                                                                        logits=self.core_model.output, name='softmax')\n",
    "        return ({'softmax':softmax_ce})\n",
    "            \n",
    "    def define_optimizers(self):\n",
    "        with tf.compat.v1.variable_scope('Optimization'):\n",
    "            op = self.optimizer.minimize(self.losses.softmax, var_list=None)\n",
    "            return ({'op':op})\n",
    "            \n",
    "    def define_summaries(self):\n",
    "        with tf.compat.v1.variable_scope('Summaries'):\n",
    "            ind_max = tf.squeeze(tf.cast(tf.argmax(self.core_model.output, axis=1), tf.int32))\n",
    "            target = tf.squeeze(self.placeholders.target)\n",
    "            acc= tf.reduce_mean(tf.cast(tf.equal(ind_max, target), tf.float32))\n",
    "        loss = tf.reduce_mean(self.losses.softmax)\n",
    "        train_scalar_probes = {\"accuracy\": acc, \n",
    "                                \"loss\": loss}\n",
    "        train_performance_scalar = [tf.summary.scalar(k, tf.reduce_mean(v), family=self.name) \n",
    "                                    for k, v in train_scalar_probes.items()]\n",
    "        train_performance_scalar = tf.summary.merge(train_performance_scalar)\n",
    "\n",
    "        dev_scalar_probes = {\"acc_dev\": self.placeholders.acc_dev, \n",
    "                                \"loss_dev\": self.placeholders.loss_dev}\n",
    "        dev_performance_scalar = [tf.summary.scalar(k, v, family=self.name) for k, v in dev_scalar_probes.items()]\n",
    "        dev_performance_scalar = tf.summary.merge(dev_performance_scalar)\n",
    "            \n",
    "        return({\"accuracy\": acc, \"loss\": loss, \"s_tr\": train_performance_scalar, \"s_de\": dev_performance_scalar})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-advance",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-moscow",
   "metadata": {},
   "source": [
    "모델 실행이 영원히 걸리지 않으려면 GPU를 사용해 실행해야한다. 또한 예측하기 위해 네트워크를 중지할 시기를 결정해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "meaningful-tuition",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T16:13:45.544679Z",
     "start_time": "2021-02-22T16:12:51.219018Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`tape` is required when a `Tensor` loss is passed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-8d6330a4016c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArchitecture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_cardinality\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcardinal_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Wavception'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"`tape` is required when a `Tensor` loss is passed.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-140-cdd56e1c32c2>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, class_cardinality, seq_len, name)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefine_computation_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# Aliases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-140-cdd56e1c32c2>\u001b[0m in \u001b[0;36mdefine_computation_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNameSpacer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefine_core_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNameSpacer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefine_losses\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNameSpacer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefine_optimizers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNameSpacer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefine_summaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-140-cdd56e1c32c2>\u001b[0m in \u001b[0;36mdefine_optimizers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdefine_optimizers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Optimization'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'op'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\study\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m     \"\"\"\n\u001b[1;32m--> 496\u001b[1;33m     grads_and_vars = self._compute_gradients(\n\u001b[0m\u001b[0;32m    497\u001b[0m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0;32m    498\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\study\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# TODO(josh11b): Test that we handle weight decay in a reasonable way.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"`tape` is required when a `Tensor` loss is passed.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m     \u001b[0mtape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `tape` is required when a `Tensor` loss is passed."
     ]
    }
   ],
   "source": [
    "net = Architecture(class_cardinality=len(cardinal_classes), name='Wavception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-guarantee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-arnold",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-reggae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-deadline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-acrylic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-artwork",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-stopping",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-hacker",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "564px",
    "left": "67px",
    "top": "292.8px",
    "width": "153.6px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
