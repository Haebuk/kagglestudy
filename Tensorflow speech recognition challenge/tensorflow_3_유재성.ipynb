{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WavCeption V1: a 1-D Inception approach\n",
    "https://www.kaggle.com/ivallesp/wavception-v1-a-1-d-inception-approach-lb-0-76"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T09:47:34.967078Z",
     "start_time": "2021-02-22T09:47:24.985024Z"
    }
   },
   "source": [
    "## Load modules and libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T09:47:34.985031Z",
     "start_time": "2021-02-22T09:47:34.970071Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import IPython\n",
    "from numpy.fft import rfft, irfft\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise generation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T09:52:05.584785Z",
     "start_time": "2021-02-22T09:52:05.560857Z"
    }
   },
   "outputs": [],
   "source": [
    "def ms(x):\n",
    "    \"\"\"시그널 x의 제곱의 평균 값.\n",
    "    x: Dynamic quantity.\n",
    "    returns: x의 제곱 평균\n",
    "    \"\"\"\n",
    "    return (np.abs(x)**2.0).mean()\n",
    "\n",
    "def normalize(y, x=None):\n",
    "    \"\"\"y를 (표준 정규) 백색 노이즈 신호로 정규화.\n",
    "    선택적으로 시그널 x의 파워로 정규화\n",
    "    \"\"\"\n",
    "    if x is not None:\n",
    "        x = ms(x)\n",
    "    else:\n",
    "        x = 1.0\n",
    "    return y * np.sqrt( x / ms(y) )\n",
    "\n",
    "def white_noise(N, state=None):\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    return state.randn(N)\n",
    "\n",
    "def pink_noise(N, state=None):\n",
    "\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = np.sqrt(np.arange(len(X))+1.) # +1 to avoid divide by zero\n",
    "    y = (irfft(X/S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "def blue_noise(N, state=None):\n",
    "    \"\"\"\n",
    "    청색 노이즈\n",
    "    N: 샘플 수\n",
    "    state: PRNG 상태\n",
    "    type state: :class:`np.random.RandomState`\n",
    "    \n",
    "    파워는 옥타브당 6dB 증가\n",
    "    파워 밀도는 옥타브당 3dB 증가\n",
    "\n",
    "    \"\"\"\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = np.sqrt(np.arange(len(X)))# Filter\n",
    "    y = (irfft(X*S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "def brown_noise(N, state=None):\n",
    "    \"\"\"\n",
    "    갈색 노이즈\n",
    "    N: 샘플 수\n",
    "    state: PRNG 상태\n",
    "    type state: :class:`np.random.RandomState`\n",
    "    \n",
    "    파워는 옥타브당 3dB 감소\n",
    "    파워 밀도는 옥타브당 6dB 증가\n",
    "\n",
    "    \"\"\"\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = (np.arange(len(X))+1)# Filter\n",
    "    y = (irfft(X/S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "def violet_noise(N, state=None):\n",
    "    \"\"\"\n",
    "    보라 노이즈\n",
    "    N: 샘플 수\n",
    "    state: PRNG 상태\n",
    "    type state: :class:`np.random.RandomState`\n",
    "    \n",
    "    파워는 옥타브당 3dB 감소\n",
    "    파워 밀도는 옥타브당 6dB 감소\n",
    "\n",
    "    \"\"\"\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = (np.arange(len(X)))# Filter\n",
    "    y = (irfft(X*S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow utilies\n",
    "텐서플로우의 공통 작업을 모듈화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T10:01:19.913909Z",
     "start_time": "2021-02-22T10:01:19.901938Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_tensorflow_configuration(device='0', memory_fraction=1):\n",
    "    \"\"\"\n",
    "    사용할 GPU 및 프로세스에서 사용할 수 있는 메모리 양을 선택하는 기능입니다.\n",
    "    device: 사용할 디바이스(str)\n",
    "    memory_complet: 할당해야하는 메모리 비율(comparent)\n",
    "    return: 세션에 전달할 config(tf 개체)\n",
    "    \"\"\"\n",
    "    device = str(device)\n",
    "    config = tf.ConfigPorto()\n",
    "    config.allow_soft_placement = True\n",
    "    config.gpu_options.per_process_gpu_memory_fractioon = memory_fraction\n",
    "    config.gpu_options.visible_device_list = device\n",
    "    return(config)\n",
    "\n",
    "def start_tensorflow_session(device='0', memory_fraction=1):\n",
    "    \"\"\"\n",
    "    사용할 GPU 장치를 관리하는 텐서 플로우 세션을 시작합니다. 즉, 사전 할당될 메모리의 비율입니다.\n",
    "    device: 사용할 디바이스(str): 디바이스 번호(str)가 있는 문자열입니다.\n",
    "    memory_fraction: 지정된 메모리(float[0,1)에서 사전 할당될 메모리의 일부입니다.\n",
    "    return: 세션에 전달할 config(tf 개체)\n",
    "    \"\"\"\n",
    "    return(tf.Session(config=get_tensorflow_configuration(device=device, memory_fraction=memory_fraction)))\n",
    "\n",
    "def get_summary_writer(session, logs_path, project_id, version_id):\n",
    "    \"\"\"\n",
    "    텐서보드 리포팅\n",
    "    session: 열린 텐서 플로우 세션\n",
    "    logs_path: 텐서보드가 로그를 찾는 경로(str)\n",
    "    project_id: 보고용 프로젝트 이름(str)\n",
    "    version_id: 보고용 버전 이름(str)\n",
    "    return summary_writer: 텐서보드 writer\n",
    "    \"\"\"\n",
    "    path = os.path.join(logs_path, \"{}_{}\".format(project_id, version_id))\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "        summary_writer = tf.summary.FileWriter(path, graph_def=session.graph_def)\n",
    "        return(summary_writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths management module\n",
    "경로를 다루는 모듈입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T10:22:17.865942Z",
     "start_time": "2021-02-22T10:22:17.847990Z"
    }
   },
   "outputs": [],
   "source": [
    "# Common paths\n",
    "def _norm_path(path):\n",
    "    \"\"\"\n",
    "    경로 검색 기능의 출력을 정규화하는데 사용합니다. \n",
    "    슬래시나 역슬래시 케이스를 고치는데 유용합니다.\n",
    "    \"\"\"\n",
    "    def normalize_path(*args, **kwargs):\n",
    "        return os.path.normpath(path(*args, **kwargs))\n",
    "    return normalize_path\n",
    "\n",
    "def _assure_path_exists(path):\n",
    "    \"\"\"\n",
    "    경로 검색 기능의 출력 유무를 확인하기 위한 함수입니다.\n",
    "    \"\"\"\n",
    "    def assure_exists(*args, **kwargs):\n",
    "        p = path(*args, **kwargs)\n",
    "        assert os.path.exists(p), \"다음 경로가 존재하지 않습니다: '{}'\".format(p)\n",
    "        return p\n",
    "    return assure_exists\n",
    "\n",
    "def _is_output_path(path):\n",
    "    \"\"\"\n",
    "    경로 검색 함수의 출력에 적용되는 함수를 그룹화하기 위한 함수입니다.\n",
    "    \"\"\"\n",
    "    @_norm_path\n",
    "    @_assure_path_exists\n",
    "    def check_existence_or_create_it(*args, **kwargs):\n",
    "        if not os.path.exists(path(*args, **kwargs)):\n",
    "            \"경로가 존재하지 않습니다.. 생성: {}\".format(path(*args, **kwargs))\n",
    "            os.makedirs(path(*args, **kwargs))\n",
    "        return path(*args, **kwargs)\n",
    "    return check_existence_or_create_it\n",
    "\n",
    "def _is_input_path(path):\n",
    "    \"\"\"\n",
    "    입력 경로 검색 함수의 출력에 적용되는 함수를 그룹화하기 위한 데코레이터 함수입니다.\n",
    "    \"\"\"\n",
    "    @_norm_path\n",
    "    @_assure_path_exists\n",
    "    def check_existence(*args, **kwargs):\n",
    "        return path(*args, **kwargs)\n",
    "    return check_existence\n",
    "\n",
    "@_is_input_path\n",
    "def get_train_path():\n",
    "    path = './input/train'\n",
    "    return path\n",
    "\n",
    "@_is_input_path\n",
    "def get_test_path():\n",
    "    path = './input/test'\n",
    "    return path\n",
    "\n",
    "@_is_input_path\n",
    "def get_train_audio_path():\n",
    "    path = os.path.join(get_train_path(), 'audio')\n",
    "    return path\n",
    "\n",
    "@_is_input_path\n",
    "def get_scoring_audio_path():\n",
    "    path = os.path.join(get_test_path(), 'audio')\n",
    "    return path\n",
    "\n",
    "@_is_output_path\n",
    "def get_submissions_path():\n",
    "    path = './working/output'\n",
    "    return path\n",
    "\n",
    "@_is_output_path\n",
    "def get_silence_path():\n",
    "    path = './working/silence'\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities\n",
    "범용 유틸리티 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T10:23:47.614714Z",
     "start_time": "2021-02-22T10:23:47.606767Z"
    }
   },
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "def batching(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, 1, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Tools\n",
    "데이터 핸들링 도구 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T10:31:55.295405Z",
     "start_time": "2021-02-22T10:31:55.282435Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_wav(filepath, pad=True):\n",
    "    \"\"\"\n",
    "    wav 파일의 경로를 지정하면 이 함수가 파일을 읽고 정규화하여 16k 샘플이 있는지     확인합니다.\n",
    "    filepath: wav 파일의 기존 파일 경로(str)입니다.\n",
    "    pad: 패딩 여부(bool)\n",
    "    returns: 샘플과 타겟 변수(tuple (np.array, str)를 반환합니다.\n",
    "    \"\"\"\n",
    "    sample_rate, x = wavfile.read(filepath)\n",
    "    target = os.path.split(os.path.split(filepath)[0])[1]\n",
    "    assert sample_rate==16000\n",
    "    if pad:\n",
    "        return np.pad(x, (0, 16000-len(x)), mode='constant')/32768, target\n",
    "    else:\n",
    "        return x/32768, target\n",
    "    \n",
    "def get_batcher(list_of_paths, batch_size, label_encoder=None, scoring=False):\n",
    "    \"\"\"\n",
    "    배치 목록이 지정된 배치 생성기를 빌드합니다.\n",
    "    list_of_class: (파일 경로, 대상)이 있는 튜플 리스트입니다.(list)\n",
    "    batch_size: 배치의 크기(int)입니다.\n",
    "    label_encoder: 라벨 인코더입니다.\n",
    "    scoring: 타겟 고려 여부(bool)\n",
    "    returns: 배치 생성기\n",
    "    \"\"\"\n",
    "    for filepaths in batching(list_of_paths, batch_size):\n",
    "        wavs, targets = zip(*list(map(read_wav, filepaths)))\n",
    "        if scoring:\n",
    "            yield np.expand_dims(np.row_stack(wavs), 2), filepaths\n",
    "        else:\n",
    "            if label_encoder is None:\n",
    "                yield np.expand_dims(np.row_stack(wavs), 2), np.row_stack(targets)\n",
    "            else:\n",
    "                yield np.expand_dims(np.row_stack(wavs), 2), np.expand_dims(label_encoder.transform(np.squeeze(targets)), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture building blocks\n",
    "Inception-1D(일명 wavception)는 일반 컨볼루션 신경망의 성능을 크게 향상시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T10:53:49.410845Z",
     "start_time": "2021-02-22T10:53:49.366965Z"
    }
   },
   "outputs": [],
   "source": [
    "class BatchNorm(object):\n",
    "    def __init__(self, epsilon=1e-5, momentum=0.999, name='batch_norm'):\n",
    "        with tf.variable_scope(name):\n",
    "            self.epsilon = epsilon\n",
    "            self.momentum = momentum\n",
    "            self.name = name\n",
    "            \n",
    "    def __call__(self, x, train=True):\n",
    "        return tf.contrib.layers.batch_norm(x,\n",
    "                                           decay=self.momentum,\n",
    "                                           updates_collections=None,\n",
    "                                           epsilon=self.epsilon,\n",
    "                                           scale=True,\n",
    "                                           is_training=train,\n",
    "                                           scope=self.name)\n",
    "    \n",
    "def inception_1d(x, is_train, depth, norm_function, activ_function, name):\n",
    "    \"\"\"\n",
    "    Inception 1d 모듈 구현입니다.\n",
    "    x: 현재 모듈에 대한 입력(채널-마지막을 포함한 4D 텐서)\n",
    "    is_train: 배치정규화 동작을 제어\n",
    "    depth: 네트워크의 깊이를 선형적으로 제어(int)\n",
    "    norm_function: 정규화 클래스(위의 BatchNorm 클래스와 동일한 형식)\n",
    "    activ_function: 활성화 함수\n",
    "    name: 변수 범위(str)의 이름\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(name):\n",
    "        x_norm = norm_function(name='norm_input')(x, train=is_train)\n",
    "        \n",
    "        # Branch 1: 64 x conv 1x1\n",
    "        branch_conv_1_1 = tf.layers.conv1d(inputs=x_norm, filters=16*depth, kernel_size=1, kernel_initializer=tf.contrib.layers.xavier_initializer(), padding='same', name='conv_1_1')\n",
    "        branch_conv_1_1 = norm_function(name='norm_conv_1_1')(branch_conv_1_1, train=is_train)\n",
    "        branch_conv_1_1 = activ_function(branch_conv_1_1, 'activation_1_1')\n",
    "        \n",
    "        # Branch 2: 128 x conv 3x3\n",
    "        branch_conv_3_3 = tf.layers.conv1d(inputs=x_norm, filters=16*depth, kernel_size=1, kernel_initializer=tf.contrib.layers.xavier_initializer(), padding='same', name='conv_3_3_1')\n",
    "        branch_conv_3_3 = norm_function(name='norm_conv_3_3_1')(branch_conv_3_3, train=is_train)\n",
    "        branch_conv_3_3 = activ_function(branch_conv_3_3, 'activation_3_3_1')\n",
    "        \n",
    "        branch_conv_3_3 = tf.layers.conv1d(inputs=branch_conv_3_3, filters=32*depth, kernel_size=3, kernel_initializer=tf.contrib.layers.xavier_initializer(), padding='same', name='conv_3_3_2')\n",
    "        branch_conv_3_3 = norm_function(name='norm_conv_3_3_2')(branch_conv_3_3, train=is_train)\n",
    "        branch_conv_3_3 = activ_function(branch_conv_3_3, 'activation_3_3_2')\n",
    "        \n",
    "        # Branch 3: 128 x conv 5x5\n",
    "        branch_conv_5_5 = tf.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, kernel_initializer=tf.contrib.layers.xavier_initializer(), padding='same', name='conv_5_5_1')\n",
    "        branch_conv_5_5 = norm_function(name='norm_conv_5_5_1')(branch_conv_5_5, train=is_train)\n",
    "        branch_conv_5_5 = activ_function(branch_conv_5_5, 'activation_5_5_1')\n",
    "        \n",
    "        branch_conv_5_5 = tf.layers.conv1d(inputs=branch_conv_5_5, filters=32*depth, kernel_size=5, kernel_initializer=tf.contrib.layers.xavier_initializer(), padding='same', name='conv_5_5_2')\n",
    "        branch_conv_5_5 = norm_function(name='norm_conv_5_5_2')(branch_conv_5_5, train=is_train)\n",
    "        branch_conv_5_5 = activ_function(branch_conv_5_5, 'activation_5_5_2')\n",
    "        \n",
    "        # Branch 4: 128 x conv 7x7\n",
    "        branch_conv_7_7 = tf.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_7_7_1\")\n",
    "        branch_conv_7_7 = norm_function(name=\"norm_conv_7_7_1\")(branch_conv_7_7, train=is_train)\n",
    "        branch_conv_7_7 = activ_function(branch_conv_7_7, \"activation_7_7_1\")\n",
    "\n",
    "        branch_conv_7_7 = tf.layers.conv1d(inputs=branch_conv_7_7, filters=32*depth, kernel_size=5, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_7_7_2\")\n",
    "        branch_conv_7_7 = norm_function(name=\"norm_conv_7_7_2\")(branch_conv_7_7, train=is_train)\n",
    "        branch_conv_7_7 = activ_function(branch_conv_7_7, \"activation_7_7_2\")        \n",
    "        # Branch 5: 16 x (max_pool 3x3 + conv 1x1)\n",
    "        branch_maxpool_3_3 = tf.layers.max_pooling1d(inputs=x_norm, pool_size=3, strides=1, padding=\"same\", name=\"maxpool_3\")\n",
    "        branch_maxpool_3_3 = norm_function(name=\"norm_maxpool_3_3\")(branch_maxpool_3_3, train=is_train)\n",
    "        branch_maxpool_3_3 = tf.layers.conv1d(inputs=branch_maxpool_3_3, filters=16, kernel_size=1, \n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_maxpool_3\")\n",
    "        \n",
    "        # Branch 6: 16 x(max_pool 5x5 + conv 1x1)\n",
    "        branch_maxpool_5_5 = tf.layers.max_pooling1d(inputs=x_norm, pool_size=5, strides=1, padding='same', name='maxpool_5')\n",
    "        branch_maxpool_5_5 = norm_function(name='norm_maxpool_5_5')(branch_maxpool_5_5, train=is_train)\n",
    "        branch_maxpool_5_5 = tf.layers.conv1d(inputs=branch_maxpool_5_5, filters=16, kernel_size=1, kernel_initializer=tf.contrib.layers.xavier_initializer(), padding='same', name='conv_maxpool_5')\n",
    "        \n",
    "        # Branch 7: 16 x (avg_pool 3x3 + conv 1x1)\n",
    "        branch_avgpool_3_3 = tf.layers.average_pooling1d(inputs=x_norm, pool_size=3, strides=1, padding='same', name='avgpool_3')\n",
    "        branch_avgpool_3_3 = norm_function(name='norm_avgpool_3_3')(branch_avgpool_3_3, train=is_train)\n",
    "        branch_avgpool_3_3 = tf.layers.conv1d(inputs=branch_avgpool_3_3, filters=16, kernel_size=1,\n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_avgpool_3\")\n",
    "\n",
    "        # Branch 8: 16 x (avg_pool 5x5 + conv 1x1)\n",
    "        branch_avgpool_5_5 = tf.layers.average_pooling1d(inputs=x_norm, pool_size=5, strides=1, padding=\"same\", name=\"avgpool_5\")\n",
    "        branch_avgpool_5_5 = norm_function(name=\"norm_avgpool_5_5\")(branch_avgpool_5_5, train=is_train)\n",
    "        branch_avgpool_5_5 = tf.layers.conv1d(inputs=branch_avgpool_5_5, filters=16, kernel_size=1, \n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_avgpool_5\")\n",
    "        \n",
    "        # Concatnate\n",
    "        output = tf.concat([branch_conv_1_1, branch_conv_3_3, branch_conv_5_5, branch_conv_7_7, branch_maxpool_3_3, branch_maxpool_5_5, branch_avgpool_3_3, branch_avgpool_5_5], axis=-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare data\n",
    "합성 및 제공된 노이즈 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T11:05:25.026319Z",
     "start_time": "2021-02-22T11:05:24.161633Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-dde1cb910946>:8: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sample_rate, x = wavfile.read(filepath)\n"
     ]
    }
   ],
   "source": [
    "filepath_noise = glob.glob(os.path.join(get_train_audio_path(), '_background_noise_', '*.wav'))\n",
    "\n",
    "noise = np.concatenate(list(map(lambda x: read_wav(x, False)[0], filepath_noise)))\n",
    "noise = np.concatenate([noise, noise[::-1]])\n",
    "synthetic_noise = np.concatenate([white_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                 blue_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                 pink_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                 brown_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                 violet_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                 np.zeros(16000*60)])\n",
    "synthetic_noise /= np.max(np.abs(synthetic_noise))\n",
    "synthetic_noise = np.concatenate([synthetic_noise, (synthetic_noise+synthetic_noise[::-1])/2])\n",
    "all_noise = np.concatenate([noise, synthetic_noise])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T11:15:45.762835Z",
     "start_time": "2021-02-22T11:15:37.740399Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████▍                                      | 3997/8000 [00:07<00:07, 533.03it/s]<ipython-input-17-949d621b51aa>:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  wavfile.write(os.path.join(path, '{0:04d}.wav'.format(noise_clip_no)), 16000, ((32767*clip/np.max(np.abs(clip))).astype(np.int16)))\n",
      " 50%|██████████████████████████████████████▌                                      | 4004/8000 [00:07<00:07, 502.79it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-949d621b51aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m16000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msynthetic_noise\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m16000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mwavfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'{0:04d}.wav'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise_clip_no\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32767\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2703\u001b[0m     \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2704\u001b[0m     \"\"\"\n\u001b[1;32m-> 2705\u001b[1;33m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0m\u001b[0;32m   2706\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0;32m   2707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "np.random.seed(655321)\n",
    "random.seed(655321)\n",
    "\n",
    "path = get_silence_path()\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "for noise_clip_no in tqdm(range(8000)):\n",
    "    if noise_clip_no <= 4000:\n",
    "        idx = np.random.randint(0, len(noise)-16000)\n",
    "        clip = noise[idx:(idx+16000)]\n",
    "    else:\n",
    "        idx = np.random.randint(0, len(noise)-16000)\n",
    "        clip = synthetic_noise[idx:(idx+16000)]\n",
    "    wavfile.write(os.path.join(path, '{0:04d}.wav'.format(noise_clip_no)), 16000, ((32767*clip/np.max(np.abs(clip))).astype(np.int16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
